{
    "django__django-13837": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/utils_tests/test_autoreload_child_arguments.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py utils_tests.test_autoreload_child_arguments.TestChildArguments.test_run_as_third_party_module"
        ],
        "reproduced_bug_patch": "diff --git a/tests/utils_tests/test_autoreload_child_arguments.py b/tests/utils_tests/test_autoreload_child_arguments.py\nnew file mode 100644\nindex 0000000000..327effab1e\n--- /dev/null\n+++ b/tests/utils_tests/test_autoreload_child_arguments.py\n@@ -0,0 +1,43 @@\n+import contextlib\n+import os\n+import py_compile\n+import shutil\n+import sys\n+import tempfile\n+import threading\n+import time\n+import types\n+import weakref\n+import zipfile\n+from importlib import import_module\n+from pathlib import Path\n+from subprocess import CompletedProcess\n+from unittest import mock, skip, skipIf\n+\n+import pytz\n+\n+import django.__main__\n+from django.apps.registry import Apps\n+from django.test import SimpleTestCase\n+from django.test.utils import extend_sys_path\n+from django.utils import autoreload\n+from django.utils.autoreload import WatchmanUnavailable\n+\n+from .utils import on_macos_with_hfs\n+\n+\n+class TestChildArguments(SimpleTestCase):\n+    @mock.patch(\"sys.warnoptions\", [])\n+    def test_run_as_third_party_module(self):\n+        mock_main = types.ModuleType(\"__main__\")\n+        mock_spec = mock.Mock()\n+        mock_spec.parent = \"my_app\"\n+        mock_main.__spec__ = mock_spec\n+        mock_main.__file__ = \"/path/to/my_app/__main__.py\"\n+        with mock.patch.dict(sys.modules, {\"__main__\": mock_main}), mock.patch(\n+            \"sys.argv\", [mock_main.__file__, \"runserver\"]\n+        ):\n+            self.assertEqual(\n+                autoreload.get_child_arguments(),\n+                [sys.executable, \"-m\", \"my_app\", \"runserver\"],\n+            )\n"
    },
    "django__django-16642": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/responses/test_fileresponse_compressed_content_type.py",
        "reproduced_bug_commands": [
            "python runtests.py responses.test_fileresponse_compressed_content_type"
        ],
        "reproduced_bug_patch": "diff --git a/tests/responses/test_fileresponse_compressed_content_type.py b/tests/responses/test_fileresponse_compressed_content_type.py\nnew file mode 100644\nindex 0000000000..0b87f31f4d\n--- /dev/null\n+++ b/tests/responses/test_fileresponse_compressed_content_type.py\n@@ -0,0 +1,23 @@\n+import tempfile\n+\n+from django.http import FileResponse\n+from django.test import SimpleTestCase\n+\n+\n+class FileResponseTests(SimpleTestCase):\n+    def test_compressed_content_type_for_br_and_z_files(self):\n+        \"\"\"\n+        FileResponse should correctly guess the Content-Type for .br and .Z\n+        files, even with a preceding extension.\n+        \"\"\"\n+        test_cases = (\n+            (\".html.br\", \"application/brotli\"),\n+            (\".html.Z\", \"application/x-compress\"),\n+        )\n+        for suffix, expected_content_type in test_cases:\n+            with self.subTest(suffix=suffix):\n+                with tempfile.NamedTemporaryFile(suffix=suffix) as tmp_file:\n+                    response = FileResponse(tmp_file)\n+                    self.assertEqual(\n+                        response.headers[\"Content-Type\"], expected_content_type\n+                    )\n"
    },
    "pydata__xarray-4629": {
        "reproduced_bug": true,
        "reproduced_bug_file": "xarray/tests/test_merge_regressions.py",
        "reproduced_bug_commands": [
            "pytest xarray/tests/test_merge_regressions.py"
        ],
        "reproduced_bug_patch": "diff --git a/xarray/tests/test_merge_regressions.py b/xarray/tests/test_merge_regressions.py\nnew file mode 100644\nindex 00000000..a6b10175\n--- /dev/null\n+++ b/xarray/tests/test_merge_regressions.py\n@@ -0,0 +1,17 @@\n+import pytest\n+import xarray as xr\n+\n+\n+def test_merge_override_attrs_is_copy():\n+    \"\"\"\n+    When merging with combine_attrs='override', the attributes should be\n+    copied from the first object, not referenced.\n+    Regression test for GH4565.\n+    \"\"\"\n+    xds1 = xr.Dataset(attrs={\"a\": \"b\"})\n+    xds2 = xr.Dataset(attrs={\"a\": \"c\"})\n+\n+    xds3 = xr.merge([xds1, xds2], combine_attrs=\"override\")\n+    xds3.attrs[\"a\"] = \"d\"\n+\n+    assert xds1.attrs[\"a\"] == \"b\"\n"
    },
    "pytest-dev__pytest-7324": {
        "reproduced_bug": true,
        "reproduced_bug_file": "testing/test_mark_expression_compile_false.py",
        "reproduced_bug_commands": [
            "pytest testing/test_mark_expression_compile_false.py"
        ],
        "reproduced_bug_patch": "diff --git a/testing/test_mark_expression_compile_false.py b/testing/test_mark_expression_compile_false.py\nnew file mode 100644\nindex 000000000..d095a8af3\n--- /dev/null\n+++ b/testing/test_mark_expression_compile_false.py\n@@ -0,0 +1,22 @@\n+import pytest\n+from _pytest.mark.expression import Expression\n+\n+\n+def test_compile_false_string_does_not_crash_or_raise():\n+    \"\"\"\n+    Regression test for a crash on debug builds of Python 3.8+\n+    and a ValueError on release builds.\n+\n+    `Expression.compile(\"False\")` should not crash or raise, as \"False\"\n+    should be treated as a valid identifier.\n+    \"\"\"\n+    try:\n+        expr = Expression.compile(\"False\")\n+        # To confirm it is treated as a valid identifier, we evaluate it.\n+        # The matcher function will return True if it receives the \"False\" identifier.\n+        assert expr.evaluate(lambda ident: ident == \"False\") is True\n+    except ValueError:\n+        pytest.fail(\n+            \"Expression.compile('False') raised ValueError, but it should be \"\n+            \"treated as a valid identifier and not raise.\"\n+        )\n"
    },
    "scikit-learn__scikit-learn-25973": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/feature_selection/tests/test_sfs_cv_iterator.py",
        "reproduced_bug_commands": [
            "pytest sklearn/feature_selection/tests/test_sfs_cv_iterator.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/feature_selection/tests/test_sfs_cv_iterator.py b/sklearn/feature_selection/tests/test_sfs_cv_iterator.py\nnew file mode 100644\nindex 0000000000..eca341149f\n--- /dev/null\n+++ b/sklearn/feature_selection/tests/test_sfs_cv_iterator.py\n@@ -0,0 +1,34 @@\n+import pytest\n+import numpy as np\n+\n+from sklearn.datasets import make_classification\n+from sklearn.feature_selection import SequentialFeatureSelector\n+from sklearn.neighbors import KNeighborsClassifier\n+from sklearn.model_selection import LeaveOneGroupOut\n+\n+\n+def test_sfs_cv_iterator():\n+    \"\"\"Test that SFS works with a cv iterator.\n+\n+    Non-regression test for #25959.\n+    \"\"\"\n+    X, y = make_classification(\n+        n_samples=100, n_features=10, n_informative=3, random_state=0\n+    )\n+\n+    groups = np.zeros_like(y, dtype=int)\n+    groups[y.size // 2 :] = 1\n+\n+    cv = LeaveOneGroupOut()\n+    splits = cv.split(X, y, groups=groups)\n+\n+    clf = KNeighborsClassifier(n_neighbors=5)\n+    n_features_to_select = 5\n+\n+    sfs = SequentialFeatureSelector(\n+        clf, n_features_to_select=n_features_to_select, scoring=\"accuracy\", cv=splits\n+    )\n+    # This call should not raise an IndexError\n+    sfs.fit(X, y)\n+\n+    assert sfs.n_features_to_select_ == n_features_to_select\n"
    },
    "django__django-13925": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "django__django-16661": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "pydata__xarray-4687": {
        "reproduced_bug": true,
        "reproduced_bug_file": "xarray/tests/test_where.py",
        "reproduced_bug_commands": [
            "pytest xarray/tests/test_where.py"
        ],
        "reproduced_bug_patch": "diff --git a/xarray/tests/test_where.py b/xarray/tests/test_where.py\nnew file mode 100644\nindex 00000000..dffe7be6\n--- /dev/null\n+++ b/xarray/tests/test_where.py\n@@ -0,0 +1,15 @@\n+import numpy as np\n+import xarray as xr\n+\n+\n+def test_where_preserves_attributes():\n+    \"\"\"\n+    Test that xr.where preserves attributes of its arguments.\n+    Regression test for https://github.com/pydata/xarray/issues/4139.\n+    \"\"\"\n+    da = xr.DataArray(1)\n+    da.attrs[\"foo\"] = \"bar\"\n+\n+    result = xr.where(da == 0, -1, da)\n+\n+    assert da.attrs == result.attrs\n"
    },
    "pytest-dev__pytest-7432": {
        "reproduced_bug": true,
        "reproduced_bug_file": "testing/test_skip_location_reporting.py",
        "reproduced_bug_commands": [
            "pytest -rs --runxfail testing/test_skip_location_reporting.py"
        ],
        "reproduced_bug_patch": "diff --git a/testing/test_skip_location_reporting.py b/testing/test_skip_location_reporting.py\nnew file mode 100644\nindex 000000000..725abc426\n--- /dev/null\n+++ b/testing/test_skip_location_reporting.py\n@@ -0,0 +1,22 @@\n+import pytest\n+\n+\n+def test_skip_location_reporting_runxfail(testdir):\n+    \"\"\"--runxfail should not break skip location reporting.\n+\n+    Regression test for issue #7249.\n+    \"\"\"\n+    p1 = testdir.makepyfile(\n+        \"\"\"\n+        import pytest\n+        @pytest.mark.skip\n+        def test_skip_location() -> None:\n+            assert 0\n+    \"\"\"\n+    )\n+    result = testdir.runpytest(\"-rs\", \"--runxfail\")\n+    result.stdout.fnmatch_lines(\n+        [\n+            \"SKIPPED [[]1[]] {}:3: unconditional skip\".format(p1.basename),\n+        ]\n+    )\n"
    },
    "scikit-learn__scikit-learn-26194": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/metrics/tests/test_roc_curve_gh_26121.py",
        "reproduced_bug_commands": [
            "pytest sklearn/metrics/tests/test_roc_curve_gh_26121.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/metrics/tests/test_roc_curve_gh_26121.py b/sklearn/metrics/tests/test_roc_curve_gh_26121.py\nnew file mode 100644\nindex 0000000000..40dab21eb8\n--- /dev/null\n+++ b/sklearn/metrics/tests/test_roc_curve_gh_26121.py\n@@ -0,0 +1,53 @@\n+import re\n+import pytest\n+import numpy as np\n+import warnings\n+from scipy.sparse import csr_matrix\n+from scipy import stats\n+\n+from sklearn import datasets\n+from sklearn import svm\n+\n+from sklearn.utils.extmath import softmax\n+from sklearn.datasets import make_multilabel_classification\n+from sklearn.random_projection import _sparse_random_matrix\n+from sklearn.utils.validation import check_array, check_consistent_length\n+from sklearn.utils.validation import check_random_state\n+\n+from sklearn.utils._testing import assert_allclose\n+from sklearn.utils._testing import assert_almost_equal\n+from sklearn.utils._testing import assert_array_equal\n+from sklearn.utils._testing import assert_array_almost_equal\n+\n+from sklearn.metrics import accuracy_score\n+from sklearn.metrics import auc\n+from sklearn.metrics import average_precision_score\n+from sklearn.metrics import coverage_error\n+from sklearn.metrics import det_curve\n+from sklearn.metrics import label_ranking_average_precision_score\n+from sklearn.metrics import precision_recall_curve\n+from sklearn.metrics import label_ranking_loss\n+from sklearn.metrics import roc_auc_score\n+from sklearn.metrics import roc_curve\n+from sklearn.metrics._ranking import _ndcg_sample_scores, _dcg_sample_scores\n+from sklearn.metrics import ndcg_score, dcg_score\n+from sklearn.metrics import top_k_accuracy_score\n+\n+from sklearn.exceptions import UndefinedMetricWarning\n+from sklearn.model_selection import train_test_split\n+from sklearn.linear_model import LogisticRegression\n+from sklearn.preprocessing import label_binarize\n+\n+\n+def test_roc_curve_with_probability_estimates():\n+    \"\"\"Check that roc_curve thresholds are <= 1 for probability estimates.\n+\n+    When y_score consists of probability estimates, the thresholds should not\n+    exceed 1.\n+    Non-regression test for gh-26121.\n+    \"\"\"\n+    rng = np.random.RandomState(42)\n+    y_true = rng.randint(0, 2, size=10)\n+    y_score = rng.rand(10)\n+    _, _, thresholds = roc_curve(y_true, y_score)\n+    assert np.all(thresholds <= 1)\n"
    },
    "django__django-13933": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/model_forms/test_modelchoicefield_validation.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py model_forms"
        ],
        "reproduced_bug_patch": "diff --git a/tests/model_forms/test_modelchoicefield_validation.py b/tests/model_forms/test_modelchoicefield_validation.py\nnew file mode 100644\nindex 0000000000..3e148158ba\n--- /dev/null\n+++ b/tests/model_forms/test_modelchoicefield_validation.py\n@@ -0,0 +1,43 @@\n+from django import forms\n+from django.core.exceptions import ValidationError\n+from django.test import TestCase\n+\n+# Import the existing Category model from the app's models file instead of\n+# redefining it. This resolves the database setup conflict.\n+from .models import Category\n+\n+\n+class ModelChoiceFieldInvalidValueMessageTest(TestCase):\n+    @classmethod\n+    def setUpTestData(cls):\n+        \"\"\"\n+        Create test data using the existing Category model. This setup will\n+        now succeed as the database table `model_forms_category` can be\n+        created without conflicts.\n+        \"\"\"\n+        Category.objects.create(\n+            name=\"Entertainment\", slug=\"entertainment\", url=\"entertainment\"\n+        )\n+        Category.objects.create(name=\"A test\", slug=\"test\", url=\"test\")\n+\n+    def test_invalid_choice_message_includes_value(self):\n+        \"\"\"\n+        Tests that ModelChoiceField's ValidationError for an invalid choice\n+        includes the invalid value in its message, making it consistent with\n+        ChoiceField.\n+        \"\"\"\n+        # Initialize the field with the queryset of existing categories.\n+        field = forms.ModelChoiceField(queryset=Category.objects.all())\n+        invalid_pk = 999\n+\n+        # This is the core of the test. The expected message includes the\n+        # invalid value (`%(value)s`). The current implementation does not\n+        # provide the value, so this assertion will fail. When the bug is\n+        # fixed, the assertion will pass.\n+        expected_message = (\n+            f\"'Select a valid choice. {invalid_pk} is not one of the available choices.'\"\n+        )\n+\n+        with self.assertRaisesMessage(ValidationError, expected_message):\n+            # Attempt to clean a value that is not a valid choice.\n+            field.clean(invalid_pk)\n"
    },
    "django__django-16662": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/migrations/test_writer_regressions.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py migrations.test_writer_regressions"
        ],
        "reproduced_bug_patch": "diff --git a/tests/migrations/test_writer_regressions.py b/tests/migrations/test_writer_regressions.py\nnew file mode 100644\nindex 0000000000..37f77c8ffc\n--- /dev/null\n+++ b/tests/migrations/test_writer_regressions.py\n@@ -0,0 +1,1029 @@\n+import datetime\n+import decimal\n+import enum\n+import functools\n+import math\n+import os\n+import pathlib\n+import re\n+import sys\n+import time\n+import uuid\n+import zoneinfo\n+from types import NoneType\n+from unittest import mock\n+\n+import custom_migration_operations.more_operations\n+import custom_migration_operations.operations\n+from django import get_version\n+from django.conf import SettingsReference, settings\n+from django.core.validators import EmailValidator, RegexValidator\n+from django.db import migrations, models\n+from django.db.migrations.serializer import BaseSerializer\n+from django.db.migrations.writer import MigrationWriter, OperationWriter\n+from django.test import SimpleTestCase\n+from django.utils.deconstruct import deconstructible\n+from django.utils.functional import SimpleLazyObject\n+from django.utils.timezone import get_default_timezone, get_fixed_timezone\n+from django.utils.translation import gettext_lazy as _\n+\n+from .models import FoodManager, FoodQuerySet\n+\n+\n+class DeconstructibleInstances:\n+    def deconstruct(self):\n+        return (\"DeconstructibleInstances\", [], {})\n+\n+\n+class Money(decimal.Decimal):\n+    def deconstruct(self):\n+        return (\n+            \"%s.%s\" % (self.__class__.__module__, self.__class__.__name__),\n+            [str(self)],\n+            {},\n+        )\n+\n+\n+class TestModel1:\n+    def upload_to(self):\n+        return \"/somewhere/dynamic/\"\n+\n+    thing = models.FileField(upload_to=upload_to)\n+\n+\n+class TextEnum(enum.Enum):\n+    A = \"a-value\"\n+    B = \"value-b\"\n+\n+\n+class TextTranslatedEnum(enum.Enum):\n+    A = _(\"a-value\")\n+    B = _(\"value-b\")\n+\n+\n+class BinaryEnum(enum.Enum):\n+    A = b\"a-value\"\n+    B = b\"value-b\"\n+\n+\n+class IntEnum(enum.IntEnum):\n+    A = 1\n+    B = 2\n+\n+\n+class IntFlagEnum(enum.IntFlag):\n+    A = 1\n+    B = 2\n+\n+\n+class OperationWriterTests(SimpleTestCase):\n+    def test_empty_signature(self):\n+        operation = custom_migration_operations.operations.TestOperation()\n+        buff, imports = OperationWriter(operation, indentation=0).serialize()\n+        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n+        self.assertEqual(\n+            buff,\n+            \"custom_migration_operations.operations.TestOperation(\\n),\",\n+        )\n+\n+    def test_args_signature(self):\n+        operation = custom_migration_operations.operations.ArgsOperation(1, 2)\n+        buff, imports = OperationWriter(operation, indentation=0).serialize()\n+        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n+        self.assertEqual(\n+            buff,\n+            \"custom_migration_operations.operations.ArgsOperation(\\n\"\n+            \"    arg1=1,\\n\"\n+            \"    arg2=2,\\n\"\n+            \"),\",\n+        )\n+\n+    def test_kwargs_signature(self):\n+        operation = custom_migration_operations.operations.KwargsOperation(kwarg1=1)\n+        buff, imports = OperationWriter(operation, indentation=0).serialize()\n+        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n+        self.assertEqual(\n+            buff,\n+            \"custom_migration_operations.operations.KwargsOperation(\\n\"\n+            \"    kwarg1=1,\\n\"\n+            \"),\",\n+        )\n+\n+    def test_args_kwargs_signature(self):\n+        operation = custom_migration_operations.operations.ArgsKwargsOperation(\n+            1, 2, kwarg2=4\n+        )\n+        buff, imports = OperationWriter(operation, indentation=0).serialize()\n+        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n+        self.assertEqual(\n+            buff,\n+            \"custom_migration_operations.operations.ArgsKwargsOperation(\\n\"\n+            \"    arg1=1,\\n\"\n+            \"    arg2=2,\\n\"\n+            \"    kwarg2=4,\\n\"\n+            \"),\",\n+        )\n+\n+    def test_nested_args_signature(self):\n+        operation = custom_migration_operations.operations.ArgsOperation(\n+            custom_migration_operations.operations.ArgsOperation(1, 2),\n+            custom_migration_operations.operations.KwargsOperation(kwarg1=3, kwarg2=4),\n+        )\n+        buff, imports = OperationWriter(operation, indentation=0).serialize()\n+        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n+        self.assertEqual(\n+            buff,\n+            \"custom_migration_operations.operations.ArgsOperation(\\n\"\n+            \"    arg1=custom_migration_operations.operations.ArgsOperation(\\n\"\n+            \"        arg1=1,\\n\"\n+            \"        arg2=2,\\n\"\n+            \"    ),\\n\"\n+            \"    arg2=custom_migration_operations.operations.KwargsOperation(\\n\"\n+            \"        kwarg1=3,\\n\"\n+            \"        kwarg2=4,\\n\"\n+            \"    ),\\n\"\n+            \"),\",\n+        )\n+\n+    def test_multiline_args_signature(self):\n+        operation = custom_migration_operations.operations.ArgsOperation(\n+            \"test\\n    arg1\", \"test\\narg2\"\n+        )\n+        buff, imports = OperationWriter(operation, indentation=0).serialize()\n+        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n+        self.assertEqual(\n+            buff,\n+            \"custom_migration_operations.operations.ArgsOperation(\\n\"\n+            \"    arg1='test\\\\n    arg1',\\n\"\n+            \"    arg2='test\\\\narg2',\\n\"\n+            \"),\",\n+        )\n+\n+    def test_expand_args_signature(self):\n+        operation = custom_migration_operations.operations.ExpandArgsOperation([1, 2])\n+        buff, imports = OperationWriter(operation, indentation=0).serialize()\n+        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n+        self.assertEqual(\n+            buff,\n+            \"custom_migration_operations.operations.ExpandArgsOperation(\\n\"\n+            \"    arg=[\\n\"\n+            \"        1,\\n\"\n+            \"        2,\\n\"\n+            \"    ],\\n\"\n+            \"),\",\n+        )\n+\n+    def test_nested_operation_expand_args_signature(self):\n+        operation = custom_migration_operations.operations.ExpandArgsOperation(\n+            arg=[\n+                custom_migration_operations.operations.KwargsOperation(\n+                    kwarg1=1,\n+                    kwarg2=2,\n+                ),\n+            ]\n+        )\n+        buff, imports = OperationWriter(operation, indentation=0).serialize()\n+        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n+        self.assertEqual(\n+            buff,\n+            \"custom_migration_operations.operations.ExpandArgsOperation(\\n\"\n+            \"    arg=[\\n\"\n+            \"        custom_migration_operations.operations.KwargsOperation(\\n\"\n+            \"            kwarg1=1,\\n\"\n+            \"            kwarg2=2,\\n\"\n+            \"        ),\\n\"\n+            \"    ],\\n\"\n+            \"),\",\n+        )\n+\n+\n+class WriterTests(SimpleTestCase):\n+    \"\"\"\n+    Tests the migration writer (makes migration files from Migration instances)\n+    \"\"\"\n+\n+    class NestedEnum(enum.IntEnum):\n+        A = 1\n+        B = 2\n+\n+    class NestedChoices(models.TextChoices):\n+        X = \"X\", \"X value\"\n+        Y = \"Y\", \"Y value\"\n+\n+    def safe_exec(self, string, value=None):\n+        d = {}\n+        try:\n+            exec(string, globals(), d)\n+        except Exception as e:\n+            if value:\n+                self.fail(\n+                    \"Could not exec %r (from value %r): %s\" % (string.strip(), value, e)\n+                )\n+            else:\n+                self.fail(\"Could not exec %r: %s\" % (string.strip(), e))\n+        return d\n+\n+    def serialize_round_trip(self, value):\n+        string, imports = MigrationWriter.serialize(value)\n+        return self.safe_exec(\n+            \"%s\\ntest_value_result = %s\" % (\"\\n\".join(imports), string), value\n+        )[\"test_value_result\"]\n+\n+    def assertSerializedEqual(self, value):\n+        self.assertEqual(self.serialize_round_trip(value), value)\n+\n+    def assertSerializedResultEqual(self, value, target):\n+        self.assertEqual(MigrationWriter.serialize(value), target)\n+\n+    def assertSerializedFieldEqual(self, value):\n+        new_value = self.serialize_round_trip(value)\n+        self.assertEqual(value.__class__, new_value.__class__)\n+        self.assertEqual(value.max_length, new_value.max_length)\n+        self.assertEqual(value.null, new_value.null)\n+        self.assertEqual(value.unique, new_value.unique)\n+\n+    def test_serialize_numbers(self):\n+        self.assertSerializedEqual(1)\n+        self.assertSerializedEqual(1.2)\n+        self.assertTrue(math.isinf(self.serialize_round_trip(float(\"inf\"))))\n+        self.assertTrue(math.isinf(self.serialize_round_trip(float(\"-inf\"))))\n+        self.assertTrue(math.isnan(self.serialize_round_trip(float(\"nan\"))))\n+\n+        self.assertSerializedEqual(decimal.Decimal(\"1.3\"))\n+        self.assertSerializedResultEqual(\n+            decimal.Decimal(\"1.3\"), (\"Decimal('1.3')\", {\"from decimal import Decimal\"})\n+        )\n+\n+        self.assertSerializedEqual(Money(\"1.3\"))\n+        self.assertSerializedResultEqual(\n+            Money(\"1.3\"),\n+            (\"migrations.test_writer.Money('1.3')\", {\"import migrations.test_writer\"}),\n+        )\n+\n+    def test_serialize_constants(self):\n+        self.assertSerializedEqual(None)\n+        self.assertSerializedEqual(True)\n+        self.assertSerializedEqual(False)\n+\n+    def test_serialize_strings(self):\n+        self.assertSerializedEqual(b\"foobar\")\n+        string, imports = MigrationWriter.serialize(b\"foobar\")\n+        self.assertEqual(string, \"b'foobar'\")\n+        self.assertSerializedEqual(\"föobár\")\n+        string, imports = MigrationWriter.serialize(\"foobar\")\n+        self.assertEqual(string, \"'foobar'\")\n+\n+    def test_serialize_multiline_strings(self):\n+        self.assertSerializedEqual(b\"foo\\nbar\")\n+        string, imports = MigrationWriter.serialize(b\"foo\\nbar\")\n+        self.assertEqual(string, \"b'foo\\\\nbar'\")\n+        self.assertSerializedEqual(\"föo\\nbár\")\n+        string, imports = MigrationWriter.serialize(\"foo\\nbar\")\n+        self.assertEqual(string, \"'foo\\\\nbar'\")\n+\n+    def test_serialize_collections(self):\n+        self.assertSerializedEqual({1: 2})\n+        self.assertSerializedEqual([\"a\", 2, True, None])\n+        self.assertSerializedEqual({2, 3, \"eighty\"})\n+        self.assertSerializedEqual({\"lalalala\": [\"yeah\", \"no\", \"maybe\"]})\n+        self.assertSerializedEqual(_(\"Hello\"))\n+\n+    def test_serialize_builtin_types(self):\n+        self.assertSerializedEqual([list, tuple, dict, set, frozenset])\n+        self.assertSerializedResultEqual(\n+            [list, tuple, dict, set, frozenset],\n+            (\"[list, tuple, dict, set, frozenset]\", set()),\n+        )\n+\n+    def test_serialize_lazy_objects(self):\n+        pattern = re.compile(r\"^foo$\")\n+        lazy_pattern = SimpleLazyObject(lambda: pattern)\n+        self.assertEqual(self.serialize_round_trip(lazy_pattern), pattern)\n+\n+    def test_serialize_enums(self):\n+        self.assertSerializedResultEqual(\n+            TextEnum.A,\n+            (\"migrations.test_writer.TextEnum['A']\", {\"import migrations.test_writer\"}),\n+        )\n+        self.assertSerializedResultEqual(\n+            TextTranslatedEnum.A,\n+            (\n+                \"migrations.test_writer.TextTranslatedEnum['A']\",\n+                {\"import migrations.test_writer\"},\n+            ),\n+        )\n+        self.assertSerializedResultEqual(\n+            BinaryEnum.A,\n+            (\n+                \"migrations.test_writer.BinaryEnum['A']\",\n+                {\"import migrations.test_writer\"},\n+            ),\n+        )\n+        self.assertSerializedResultEqual(\n+            IntEnum.B,\n+            (\"migrations.test_writer.IntEnum['B']\", {\"import migrations.test_writer\"}),\n+        )\n+        self.assertSerializedResultEqual(\n+            self.NestedEnum.A,\n+            (\n+                \"migrations.test_writer.WriterTests.NestedEnum['A']\",\n+                {\"import migrations.test_writer\"},\n+            ),\n+        )\n+        self.assertSerializedEqual(self.NestedEnum.A)\n+\n+        field = models.CharField(\n+            default=TextEnum.B, choices=[(m.value, m) for m in TextEnum]\n+        )\n+        string = MigrationWriter.serialize(field)[0]\n+        self.assertEqual(\n+            string,\n+            \"models.CharField(choices=[\"\n+            \"('a-value', migrations.test_writer.TextEnum['A']), \"\n+            \"('value-b', migrations.test_writer.TextEnum['B'])], \"\n+            \"default=migrations.test_writer.TextEnum['B'])\",\n+        )\n+        field = models.CharField(\n+            default=TextTranslatedEnum.A,\n+            choices=[(m.value, m) for m in TextTranslatedEnum],\n+        )\n+        string = MigrationWriter.serialize(field)[0]\n+        self.assertEqual(\n+            string,\n+            \"models.CharField(choices=[\"\n+            \"('a-value', migrations.test_writer.TextTranslatedEnum['A']), \"\n+            \"('value-b', migrations.test_writer.TextTranslatedEnum['B'])], \"\n+            \"default=migrations.test_writer.TextTranslatedEnum['A'])\",\n+        )\n+        field = models.CharField(\n+            default=BinaryEnum.B, choices=[(m.value, m) for m in BinaryEnum]\n+        )\n+        string = MigrationWriter.serialize(field)[0]\n+        self.assertEqual(\n+            string,\n+            \"models.CharField(choices=[\"\n+            \"(b'a-value', migrations.test_writer.BinaryEnum['A']), \"\n+            \"(b'value-b', migrations.test_writer.BinaryEnum['B'])], \"\n+            \"default=migrations.test_writer.BinaryEnum['B'])\",\n+        )\n+        field = models.IntegerField(\n+            default=IntEnum.A, choices=[(m.value, m) for m in IntEnum]\n+        )\n+        string = MigrationWriter.serialize(field)[0]\n+        self.assertEqual(\n+            string,\n+            \"models.IntegerField(choices=[\"\n+            \"(1, migrations.test_writer.IntEnum['A']), \"\n+            \"(2, migrations.test_writer.IntEnum['B'])], \"\n+            \"default=migrations.test_writer.IntEnum['A'])\",\n+        )\n+\n+    def test_serialize_enum_flags(self):\n+        self.assertSerializedResultEqual(\n+            IntFlagEnum.A,\n+            (\n+                \"migrations.test_writer.IntFlagEnum['A']\",\n+                {\"import migrations.test_writer\"},\n+            ),\n+        )\n+        self.assertSerializedResultEqual(\n+            IntFlagEnum.B,\n+            (\n+                \"migrations.test_writer.IntFlagEnum['B']\",\n+                {\"import migrations.test_writer\"},\n+            ),\n+        )\n+        field = models.IntegerField(\n+            default=IntFlagEnum.A, choices=[(m.value, m) for m in IntFlagEnum]\n+        )\n+        string = MigrationWriter.serialize(field)[0]\n+        self.assertEqual(\n+            string,\n+            \"models.IntegerField(choices=[\"\n+            \"(1, migrations.test_writer.IntFlagEnum['A']), \"\n+            \"(2, migrations.test_writer.IntFlagEnum['B'])], \"\n+            \"default=migrations.test_writer.IntFlagEnum['A'])\",\n+        )\n+        self.assertSerializedResultEqual(\n+            IntFlagEnum.A | IntFlagEnum.B,\n+            (\n+                \"migrations.test_writer.IntFlagEnum['A'] | \"\n+                \"migrations.test_writer.IntFlagEnum['B']\",\n+                {\"import migrations.test_writer\"},\n+            ),\n+        )\n+\n+    def test_serialize_choices(self):\n+        class TextChoices(models.TextChoices):\n+            A = \"A\", \"A value\"\n+            B = \"B\", \"B value\"\n+\n+        class IntegerChoices(models.IntegerChoices):\n+            A = 1, \"One\"\n+            B = 2, \"Two\"\n+\n+        class DateChoices(datetime.date, models.Choices):\n+            DATE_1 = 1969, 7, 20, \"First date\"\n+            DATE_2 = 1969, 11, 19, \"Second date\"\n+\n+        self.assertSerializedResultEqual(TextChoices.A, (\"'A'\", set()))\n+        self.assertSerializedResultEqual(IntegerChoices.A, (\"1\", set()))\n+        self.assertSerializedResultEqual(\n+            DateChoices.DATE_1,\n+            (\"datetime.date(1969, 7, 20)\", {\"import datetime\"}),\n+        )\n+        field = models.CharField(default=TextChoices.B, choices=TextChoices.choices)\n+        string = MigrationWriter.serialize(field)[0]\n+        self.assertEqual(\n+            string,\n+            \"models.CharField(choices=[('A', 'A value'), ('B', 'B value')], \"\n+            \"default='B')\",\n+        )\n+        field = models.IntegerField(\n+            default=IntegerChoices.B, choices=IntegerChoices.choices\n+        )\n+        string = MigrationWriter.serialize(field)[0]\n+        self.assertEqual(\n+            string,\n+            \"models.IntegerField(choices=[(1, 'One'), (2, 'Two')], default=2)\",\n+        )\n+        field = models.DateField(\n+            default=DateChoices.DATE_2, choices=DateChoices.choices\n+        )\n+        string = MigrationWriter.serialize(field)[0]\n+        self.assertEqual(\n+            string,\n+            \"models.DateField(choices=[\"\n+            \"(datetime.date(1969, 7, 20), 'First date'), \"\n+            \"(datetime.date(1969, 11, 19), 'Second date')], \"\n+            \"default=datetime.date(1969, 11, 19))\",\n+        )\n+\n+    def test_serialize_nested_class(self):\n+        for nested_cls in [self.NestedEnum, self.NestedChoices]:\n+            cls_name = nested_cls.__name__\n+            with self.subTest(cls_name):\n+                self.assertSerializedResultEqual(\n+                    nested_cls,\n+                    (\n+                        \"migrations.test_writer.WriterTests.%s\" % cls_name,\n+                        {\"import migrations.test_writer\"},\n+                    ),\n+                )\n+\n+    def test_serialize_uuid(self):\n+        self.assertSerializedEqual(uuid.uuid1())\n+        self.assertSerializedEqual(uuid.uuid4())\n+\n+        uuid_a = uuid.UUID(\"5c859437-d061-4847-b3f7-e6b78852f8c8\")\n+        uuid_b = uuid.UUID(\"c7853ec1-2ea3-4359-b02d-b54e8f1bcee2\")\n+        self.assertSerializedResultEqual(\n+            uuid_a,\n+            (\"uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8')\", {\"import uuid\"}),\n+        )\n+        self.assertSerializedResultEqual(\n+            uuid_b,\n+            (\"uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2')\", {\"import uuid\"}),\n+        )\n+\n+        field = models.UUIDField(\n+            choices=((uuid_a, \"UUID A\"), (uuid_b, \"UUID B\")), default=uuid_a\n+        )\n+        string = MigrationWriter.serialize(field)[0]\n+        self.assertEqual(\n+            string,\n+            \"models.UUIDField(choices=[\"\n+            \"(uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8'), 'UUID A'), \"\n+            \"(uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2'), 'UUID B')], \"\n+            \"default=uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8'))\",\n+        )\n+\n+    def test_serialize_pathlib(self):\n+        # Pure path objects work in all platforms.\n+        self.assertSerializedEqual(pathlib.PurePosixPath())\n+        self.assertSerializedEqual(pathlib.PureWindowsPath())\n+        path = pathlib.PurePosixPath(\"/path/file.txt\")\n+        expected = (\"pathlib.PurePosixPath('/path/file.txt')\", {\"import pathlib\"})\n+        self.assertSerializedResultEqual(path, expected)\n+        path = pathlib.PureWindowsPath(\"A:\\\\File.txt\")\n+        expected = (\"pathlib.PureWindowsPath('A:/File.txt')\", {\"import pathlib\"})\n+        self.assertSerializedResultEqual(path, expected)\n+        # Concrete path objects work on supported platforms.\n+        if sys.platform == \"win32\":\n+            self.assertSerializedEqual(pathlib.WindowsPath.cwd())\n+            path = pathlib.WindowsPath(\"A:\\\\File.txt\")\n+            expected = (\"pathlib.PureWindowsPath('A:/File.txt')\", {\"import pathlib\"})\n+            self.assertSerializedResultEqual(path, expected)\n+        else:\n+            self.assertSerializedEqual(pathlib.PosixPath.cwd())\n+            path = pathlib.PosixPath(\"/path/file.txt\")\n+            expected = (\"pathlib.PurePosixPath('/path/file.txt')\", {\"import pathlib\"})\n+            self.assertSerializedResultEqual(path, expected)\n+\n+        field = models.FilePathField(path=pathlib.PurePosixPath(\"/home/user\"))\n+        string, imports = MigrationWriter.serialize(field)\n+        self.assertEqual(\n+            string,\n+            \"models.FilePathField(path=pathlib.PurePosixPath('/home/user'))\",\n+        )\n+        self.assertIn(\"import pathlib\", imports)\n+\n+    def test_serialize_path_like(self):\n+        with os.scandir(os.path.dirname(__file__)) as entries:\n+            path_like = list(entries)[0]\n+        expected = (repr(path_like.path), {})\n+        self.assertSerializedResultEqual(path_like, expected)\n+\n+        field = models.FilePathField(path=path_like)\n+        string = MigrationWriter.serialize(field)[0]\n+        self.assertEqual(string, \"models.FilePathField(path=%r)\" % path_like.path)\n+\n+    def test_serialize_functions(self):\n+        with self.assertRaisesMessage(ValueError, \"Cannot serialize function: lambda\"):\n+            self.assertSerializedEqual(lambda x: 42)\n+        self.assertSerializedEqual(models.SET_NULL)\n+        string, imports = MigrationWriter.serialize(models.SET(42))\n+        self.assertEqual(string, \"models.SET(42)\")\n+        self.serialize_round_trip(models.SET(42))\n+\n+    def test_serialize_datetime(self):\n+        self.assertSerializedEqual(datetime.datetime.now())\n+        self.assertSerializedEqual(datetime.datetime.now)\n+        self.assertSerializedEqual(datetime.datetime.today())\n+        self.assertSerializedEqual(datetime.datetime.today)\n+        self.assertSerializedEqual(datetime.date.today())\n+        self.assertSerializedEqual(datetime.date.today)\n+        self.assertSerializedEqual(datetime.datetime.now().time())\n+        self.assertSerializedEqual(\n+            datetime.datetime(2014, 1, 1, 1, 1, tzinfo=get_default_timezone())\n+        )\n+        self.assertSerializedEqual(\n+            datetime.datetime(2013, 12, 31, 22, 1, tzinfo=get_fixed_timezone(180))\n+        )\n+        self.assertSerializedResultEqual(\n+            datetime.datetime(2014, 1, 1, 1, 1),\n+            (\"datetime.datetime(2014, 1, 1, 1, 1)\", {\"import datetime\"}),\n+        )\n+        self.assertSerializedResultEqual(\n+            datetime.datetime(2012, 1, 1, 1, 1, tzinfo=datetime.timezone.utc),\n+            (\n+                \"datetime.datetime(2012, 1, 1, 1, 1, tzinfo=datetime.timezone.utc)\",\n+                {\"import datetime\"},\n+            ),\n+        )\n+        self.assertSerializedResultEqual(\n+            datetime.datetime(\n+                2012, 1, 1, 2, 1, tzinfo=zoneinfo.ZoneInfo(\"Europe/Paris\")\n+            ),\n+            (\n+                \"datetime.datetime(2012, 1, 1, 1, 1, tzinfo=datetime.timezone.utc)\",\n+                {\"import datetime\"},\n+            ),\n+        )\n+\n+    def test_serialize_fields(self):\n+        self.assertSerializedFieldEqual(models.CharField(max_length=255))\n+        self.assertSerializedResultEqual(\n+            models.CharField(max_length=255),\n+            (\"models.CharField(max_length=255)\", {\"from django.db import models\"}),\n+        )\n+        self.assertSerializedFieldEqual(models.TextField(null=True, blank=True))\n+        self.assertSerializedResultEqual(\n+            models.TextField(null=True, blank=True),\n+            (\n+                \"models.TextField(blank=True, null=True)\",\n+                {\"from django.db import models\"},\n+            ),\n+        )\n+\n+    def test_serialize_settings(self):\n+        self.assertSerializedEqual(\n+            SettingsReference(settings.AUTH_USER_MODEL, \"AUTH_USER_MODEL\")\n+        )\n+        self.assertSerializedResultEqual(\n+            SettingsReference(\"someapp.model\", \"AUTH_USER_MODEL\"),\n+            (\"settings.AUTH_USER_MODEL\", {\"from django.conf import settings\"}),\n+        )\n+\n+    def test_serialize_iterators(self):\n+        self.assertSerializedResultEqual(\n+            ((x, x * x) for x in range(3)), (\"((0, 0), (1, 1), (2, 4))\", set())\n+        )\n+\n+    def test_serialize_compiled_regex(self):\n+        \"\"\"\n+        Make sure compiled regex can be serialized.\n+        \"\"\"\n+        regex = re.compile(r\"^\\w+$\")\n+        self.assertSerializedEqual(regex)\n+\n+    def test_serialize_class_based_validators(self):\n+        \"\"\"\n+        Ticket #22943: Test serialization of class-based validators, including\n+        compiled regexes.\n+        \"\"\"\n+        validator = RegexValidator(message=\"hello\")\n+        string = MigrationWriter.serialize(validator)[0]\n+        self.assertEqual(\n+            string, \"django.core.validators.RegexValidator(message='hello')\"\n+        )\n+        self.serialize_round_trip(validator)\n+\n+        # Test with a compiled regex.\n+        validator = RegexValidator(regex=re.compile(r\"^\\w+$\"))\n+        string = MigrationWriter.serialize(validator)[0]\n+        self.assertEqual(\n+            string,\n+            \"django.core.validators.RegexValidator(regex=re.compile('^\\\\\\\\w+$'))\",\n+        )\n+        self.serialize_round_trip(validator)\n+\n+        # Test a string regex with flag\n+        validator = RegexValidator(r\"^[0-9]+$\", flags=re.S)\n+        string = MigrationWriter.serialize(validator)[0]\n+        self.assertEqual(\n+            string,\n+            \"django.core.validators.RegexValidator('^[0-9]+$', \"\n+            \"flags=re.RegexFlag['DOTALL'])\",\n+        )\n+        self.serialize_round_trip(validator)\n+\n+        # Test message and code\n+        validator = RegexValidator(\"^[-a-zA-Z0-9_]+$\", \"Invalid\", \"invalid\")\n+        string = MigrationWriter.serialize(validator)[0]\n+        self.assertEqual(\n+            string,\n+            \"django.core.validators.RegexValidator('^[-a-zA-Z0-9_]+$', 'Invalid', \"\n+            \"'invalid')\",\n+        )\n+        self.serialize_round_trip(validator)\n+\n+        # Test with a subclass.\n+        validator = EmailValidator(message=\"hello\")\n+        string = MigrationWriter.serialize(validator)[0]\n+        self.assertEqual(\n+            string, \"django.core.validators.EmailValidator(message='hello')\"\n+        )\n+        self.serialize_round_trip(validator)\n+\n+        validator = deconstructible(path=\"migrations.test_writer.EmailValidator\")(\n+            EmailValidator\n+        )(message=\"hello\")\n+        string = MigrationWriter.serialize(validator)[0]\n+        self.assertEqual(\n+            string, \"migrations.test_writer.EmailValidator(message='hello')\"\n+        )\n+\n+        validator = deconstructible(path=\"custom.EmailValidator\")(EmailValidator)(\n+            message=\"hello\"\n+        )\n+        with self.assertRaisesMessage(ImportError, \"No module named 'custom'\"):\n+            MigrationWriter.serialize(validator)\n+\n+        validator = deconstructible(path=\"django.core.validators.EmailValidator2\")(\n+            EmailValidator\n+        )(message=\"hello\")\n+        with self.assertRaisesMessage(\n+            ValueError,\n+            \"Could not find object EmailValidator2 in django.core.validators.\",\n+        ):\n+            MigrationWriter.serialize(validator)\n+\n+    def test_serialize_complex_func_index(self):\n+        index = models.Index(\n+            models.Func(\"rating\", function=\"ABS\"),\n+            models.Case(\n+                models.When(name=\"special\", then=models.Value(\"X\")),\n+                default=models.Value(\"other\"),\n+            ),\n+            models.ExpressionWrapper(\n+                models.F(\"pages\"),\n+                output_field=models.IntegerField(),\n+            ),\n+            models.OrderBy(models.F(\"name\").desc()),\n+            name=\"complex_func_index\",\n+        )\n+        string, imports = MigrationWriter.serialize(index)\n+        self.assertEqual(\n+            string,\n+            \"models.Index(models.Func('rating', function='ABS'), \"\n+            \"models.Case(models.When(name='special', then=models.Value('X')), \"\n+            \"default=models.Value('other')), \"\n+            \"models.ExpressionWrapper(\"\n+            \"models.F('pages'), output_field=models.IntegerField()), \"\n+            \"models.OrderBy(models.OrderBy(models.F('name'), descending=True)), \"\n+            \"name='complex_func_index')\",\n+        )\n+        self.assertEqual(imports, {\"from django.db import models\"})\n+\n+    def test_serialize_empty_nonempty_tuple(self):\n+        \"\"\"\n+        Ticket #22679: makemigrations generates invalid code for (an empty\n+        tuple) default_permissions = ()\n+        \"\"\"\n+        empty_tuple = ()\n+        one_item_tuple = (\"a\",)\n+        many_items_tuple = (\"a\", \"b\", \"c\")\n+        self.assertSerializedEqual(empty_tuple)\n+        self.assertSerializedEqual(one_item_tuple)\n+        self.assertSerializedEqual(many_items_tuple)\n+\n+    def test_serialize_range(self):\n+        string, imports = MigrationWriter.serialize(range(1, 5))\n+        self.assertEqual(string, \"range(1, 5)\")\n+        self.assertEqual(imports, set())\n+\n+    def test_serialize_builtins(self):\n+        string, imports = MigrationWriter.serialize(range)\n+        self.assertEqual(string, \"range\")\n+        self.assertEqual(imports, set())\n+\n+    def test_serialize_unbound_method_reference(self):\n+        \"\"\"An unbound method used within a class body can be serialized.\"\"\"\n+        self.serialize_round_trip(TestModel1.thing)\n+\n+    def test_serialize_local_function_reference(self):\n+        \"\"\"A reference in a local scope can't be serialized.\"\"\"\n+\n+        class TestModel2:\n+            def upload_to(self):\n+                return \"somewhere dynamic\"\n+\n+            thing = models.FileField(upload_to=upload_to)\n+\n+        with self.assertRaisesMessage(\n+            ValueError, \"Could not find function upload_to in migrations.test_writer\"\n+        ):\n+            self.serialize_round_trip(TestModel2.thing)\n+\n+    def test_serialize_managers(self):\n+        self.assertSerializedEqual(models.Manager())\n+        self.assertSerializedResultEqual(\n+            FoodQuerySet.as_manager(),\n+            (\n+                \"migrations.models.FoodQuerySet.as_manager()\",\n+                {\"import migrations.models\"},\n+            ),\n+        )\n+        self.assertSerializedEqual(FoodManager(\"a\", \"b\"))\n+        self.assertSerializedEqual(FoodManager(\"x\", \"y\", c=3, d=4))\n+\n+    def test_serialize_frozensets(self):\n+        self.assertSerializedEqual(frozenset())\n+        self.assertSerializedEqual(frozenset(\"let it go\"))\n+\n+    def test_serialize_set(self):\n+        self.assertSerializedEqual(set())\n+        self.assertSerializedResultEqual(set(), (\"set()\", set()))\n+        self.assertSerializedEqual({\"a\"})\n+        self.assertSerializedResultEqual({\"a\"}, (\"{'a'}\", set()))\n+\n+    def test_serialize_timedelta(self):\n+        self.assertSerializedEqual(datetime.timedelta())\n+        self.assertSerializedEqual(datetime.timedelta(minutes=42))\n+\n+    def test_serialize_functools_partial(self):\n+        value = functools.partial(datetime.timedelta, 1, seconds=2)\n+        result = self.serialize_round_trip(value)\n+        self.assertEqual(result.func, value.func)\n+        self.assertEqual(result.args, value.args)\n+        self.assertEqual(result.keywords, value.keywords)\n+\n+    def test_serialize_functools_partialmethod(self):\n+        value = functools.partialmethod(datetime.timedelta, 1, seconds=2)\n+        result = self.serialize_round_trip(value)\n+        self.assertIsInstance(result, functools.partialmethod)\n+        self.assertEqual(result.func, value.func)\n+        self.assertEqual(result.args, value.args)\n+        self.assertEqual(result.keywords, value.keywords)\n+\n+    def test_serialize_type_none(self):\n+        self.assertSerializedEqual(NoneType)\n+\n+    def test_serialize_type_model(self):\n+        self.assertSerializedEqual(models.Model)\n+        self.assertSerializedResultEqual(\n+            MigrationWriter.serialize(models.Model),\n+            (\"('models.Model', {'from django.db import models'})\", set()),\n+        )\n+\n+    def test_simple_migration(self):\n+        \"\"\"\n+        Tests serializing a simple migration.\n+        \"\"\"\n+        fields = {\n+            \"charfield\": models.DateTimeField(default=datetime.datetime.now),\n+            \"datetimefield\": models.DateTimeField(default=datetime.datetime.now),\n+        }\n+\n+        options = {\n+            \"verbose_name\": \"My model\",\n+            \"verbose_name_plural\": \"My models\",\n+        }\n+\n+        migration = type(\n+            \"Migration\",\n+            (migrations.Migration,),\n+            {\n+                \"operations\": [\n+                    migrations.CreateModel(\n+                        \"MyModel\", tuple(fields.items()), options, (models.Model,)\n+                    ),\n+                    migrations.CreateModel(\n+                        \"MyModel2\", tuple(fields.items()), bases=(models.Model,)\n+                    ),\n+                    migrations.CreateModel(\n+                        name=\"MyModel3\",\n+                        fields=tuple(fields.items()),\n+                        options=options,\n+                        bases=(models.Model,),\n+                    ),\n+                    migrations.DeleteModel(\"MyModel\"),\n+                    migrations.AddField(\n+                        \"OtherModel\", \"datetimefield\", fields[\"datetimefield\"]\n+                    ),\n+                ],\n+                \"dependencies\": [(\"testapp\", \"some_other_one\")],\n+            },\n+        )\n+        writer = MigrationWriter(migration)\n+        output = writer.as_string()\n+        # We don't test the output formatting - that's too fragile.\n+        # Just make sure it runs for now, and that things look alright.\n+        result = self.safe_exec(output)\n+        self.assertIn(\"Migration\", result)\n+\n+    def test_migration_path(self):\n+        test_apps = [\n+            \"migrations.migrations_test_apps.normal\",\n+            \"migrations.migrations_test_apps.with_package_model\",\n+            \"migrations.migrations_test_apps.without_init_file\",\n+        ]\n+\n+        base_dir = os.path.dirname(os.path.dirname(__file__))\n+\n+        for app in test_apps:\n+            with self.modify_settings(INSTALLED_APPS={\"append\": app}):\n+                migration = migrations.Migration(\"0001_initial\", app.split(\".\")[-1])\n+                expected_path = os.path.join(\n+                    base_dir, *(app.split(\".\") + [\"migrations\", \"0001_initial.py\"])\n+                )\n+                writer = MigrationWriter(migration)\n+                self.assertEqual(writer.path, expected_path)\n+\n+    def test_custom_operation(self):\n+        migration = type(\n+            \"Migration\",\n+            (migrations.Migration,),\n+            {\n+                \"operations\": [\n+                    custom_migration_operations.operations.TestOperation(),\n+                    custom_migration_operations.operations.CreateModel(),\n+                    migrations.CreateModel(\"MyModel\", (), {}, (models.Model,)),\n+                    custom_migration_operations.more_operations.TestOperation(),\n+                ],\n+                \"dependencies\": [],\n+            },\n+        )\n+        writer = MigrationWriter(migration)\n+        output = writer.as_string()\n+        result = self.safe_exec(output)\n+        self.assertIn(\"custom_migration_operations\", result)\n+        self.assertNotEqual(\n+            result[\"custom_migration_operations\"].operations.TestOperation,\n+            result[\"custom_migration_operations\"].more_operations.TestOperation,\n+        )\n+\n+    def test_sorted_imports(self):\n+        \"\"\"\n+        #24155 - Tests ordering of imports.\n+        \"\"\"\n+        migration = type(\n+            \"Migration\",\n+            (migrations.Migration,),\n+            {\n+                \"operations\": [\n+                    migrations.AddField(\n+                        \"mymodel\",\n+                        \"myfield\",\n+                        models.DateTimeField(\n+                            default=datetime.datetime(\n+                                2012, 1, 1, 1, 1, tzinfo=datetime.timezone.utc\n+                            ),\n+                        ),\n+                    ),\n+                ]\n+            },\n+        )\n+        writer = MigrationWriter(migration)\n+        output = writer.as_string()\n+        self.assertIn(\n+            \"import datetime\\nfrom django.db import migrations, models\\n\",\n+            output,\n+        )\n+\n+    def test_sorted_imports_isort_compliant(self):\n+        \"\"\"\n+        Imports are sorted according to isort standards.\n+        \"\"\"\n+        migration = type(\n+            \"Migration\",\n+            (migrations.Migration,),\n+            {\n+                \"operations\": [\n+                    migrations.AddField(\n+                        \"mymodel\",\n+                        \"myfield\",\n+                        models.DateTimeField(\n+                            default=datetime.datetime(\n+                                2012, 1, 1, 1, 1, tzinfo=zoneinfo.ZoneInfo(\"UTC\")\n+                            ),\n+                        ),\n+                    ),\n+                ]\n+            },\n+        )\n+        writer = MigrationWriter(migration)\n+        output = writer.as_string()\n+        self.assertIn(\n+            \"import zoneinfo\\nfrom django.db import migrations, models\",\n+            output,\n+        )\n+\n+    def test_migration_file_header_comments(self):\n+        \"\"\"\n+        Test comments at top of file.\n+        \"\"\"\n+        migration = type(\"Migration\", (migrations.Migration,), {\"operations\": []})\n+        dt = datetime.datetime(2015, 7, 31, 4, 40, 0, 0, tzinfo=datetime.timezone.utc)\n+        with mock.patch(\"django.db.migrations.writer.now\", lambda: dt):\n+            for include_header in (True, False):\n+                with self.subTest(include_header=include_header):\n+                    writer = MigrationWriter(migration, include_header)\n+                    output = writer.as_string()\n+\n+                    self.assertEqual(\n+                        include_header,\n+                        output.startswith(\n+                            \"# Generated by Django %s on 2015-07-31 04:40\\n\\n\"\n+                            % get_version()\n+                        ),\n+                    )\n+                    if not include_header:\n+                        # Make sure the output starts with something that's not\n+                        # a comment or indentation or blank line\n+                        self.assertRegex(\n+                            output.splitlines(keepends=True)[0], r\"^[^#\\s]+\"\n+                        )\n+\n+    def test_models_import_omitted(self):\n+        \"\"\"\n+        django.db.models shouldn't be imported if unused.\n+        \"\"\"\n+        migration = type(\n+            \"Migration\",\n+            (migrations.Migration,),\n+            {\n+                \"operations\": [\n+                    migrations.AlterModelOptions(\n+                        name=\"model\",\n+                        options={\n+                            \"verbose_name\": \"model\",\n+                            \"verbose_name_plural\": \"models\",\n+                        },\n+                    ),\n+                ]\n+            },\n+        )\n+        writer = MigrationWriter(migration)\n+        output = writer.as_string()\n+        self.assertIn(\"from django.db import migrations\\n\", output)\n+\n+    def test_deconstruct_class_arguments(self):\n+        # Yes, it doesn't make sense to use a class as a default for a\n+        # CharField. It does make sense for custom fields though, for example\n+        # an enumfield that takes the enum class as an argument.\n+        string = MigrationWriter.serialize(\n+            models.CharField(default=DeconstructibleInstances)\n+        )[0]\n+        self.assertEqual(\n+            string,\n+            \"models.CharField(default=migrations.test_writer.DeconstructibleInstances)\",\n+        )\n+\n+    def test_register_serializer(self):\n+        class ComplexSerializer(BaseSerializer):\n+            def serialize(self):\n+                return \"complex(%r)\" % self.value, {}\n+\n+        MigrationWriter.register_serializer(complex, ComplexSerializer)\n+        self.assertSerializedEqual(complex(1, 2))\n+        MigrationWriter.unregister_serializer(complex)\n+        with self.assertRaisesMessage(ValueError, \"Cannot serialize: (1+2j)\"):\n+            self.assertSerializedEqual(complex(1, 2))\n+\n+    def test_register_non_serializer(self):\n+        with self.assertRaisesMessage(\n+            ValueError, \"'TestModel1' must inherit from 'BaseSerializer'.\"\n+        ):\n+            MigrationWriter.register_serializer(complex, TestModel1)\n"
    },
    "pydata__xarray-4695": {
        "reproduced_bug": true,
        "reproduced_bug_file": "xarray/tests/test_loc.py",
        "reproduced_bug_commands": [
            "pytest xarray/tests/test_loc.py"
        ],
        "reproduced_bug_patch": "diff --git a/xarray/tests/test_loc.py b/xarray/tests/test_loc.py\nnew file mode 100644\nindex 00000000..0dcf4f21\n--- /dev/null\n+++ b/xarray/tests/test_loc.py\n@@ -0,0 +1,24 @@\n+import numpy as np\n+import pytest\n+from xarray import DataArray\n+from xarray.testing import assert_identical\n+\n+\n+def test_loc_with_method_dimension():\n+    \"\"\"\n+    Test that .loc works with a dimension named \"method\".\n+\n+    This is a regression test for the bug where \"method\" was\n+    being interpreted as a kwarg to the selection method,\n+    rather than a dimension name.\n+    \"\"\"\n+    data = DataArray(\n+        np.zeros((2, 2)),\n+        dims=[\"dim1\", \"method\"],\n+        coords={\"dim1\": [\"x\", \"y\"], \"method\": [\"a\", \"b\"]},\n+    )\n+    expected = DataArray(0.0, coords={\"dim1\": \"x\", \"method\": \"a\"})\n+\n+    actual = data.loc[dict(dim1=\"x\", method=\"a\")]\n+\n+    assert_identical(expected, actual)\n"
    },
    "pytest-dev__pytest-7490": {
        "reproduced_bug": true,
        "reproduced_bug_file": "testing/test_dynamic_xfail.py",
        "reproduced_bug_commands": [
            "pytest -rsx testing/test_dynamic_xfail.py"
        ],
        "reproduced_bug_patch": "diff --git a/testing/test_dynamic_xfail.py b/testing/test_dynamic_xfail.py\nnew file mode 100644\nindex 000000000..e92ec5522\n--- /dev/null\n+++ b/testing/test_dynamic_xfail.py\n@@ -0,0 +1,23 @@\n+import pytest\n+\n+\n+def test_dynamic_xfail_in_test(testdir):\n+    \"\"\"\n+    Test that dynamically adding an xfail marker inside a test function\n+    correctly marks the test as xfailed.\n+    This was a regression in pytest 6.0.\n+    \"\"\"\n+    testdir.makepyfile(\n+        \"\"\"\n+        import pytest\n+\n+        def test_xfail_test(request):\n+            mark = pytest.mark.xfail(reason=\"xfail\")\n+            request.node.add_marker(mark)\n+            assert 0\n+        \"\"\"\n+    )\n+    result = testdir.runpytest()\n+    result.stdout.fnmatch_lines([\n+        \"*= 1 xfailed *\",\n+    ])\n"
    },
    "scikit-learn__scikit-learn-26323": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/compose/tests/test_column_transformer_set_output.py",
        "reproduced_bug_commands": [
            "pytest sklearn/compose/tests/test_column_transformer_set_output.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/compose/tests/test_column_transformer_set_output.py b/sklearn/compose/tests/test_column_transformer_set_output.py\nnew file mode 100644\nindex 0000000000..e937242d3e\n--- /dev/null\n+++ b/sklearn/compose/tests/test_column_transformer_set_output.py\n@@ -0,0 +1,33 @@\n+import pytest\n+\n+from sklearn.compose import make_column_selector, make_column_transformer\n+from sklearn.feature_selection import VarianceThreshold\n+\n+\n+def test_set_output_remainder_estimator():\n+    \"\"\"Check that set_output is configured on the remainder estimator.\n+\n+    Non-regression test for gh-26799.\n+    \"\"\"\n+    pd = pytest.importorskip(\"pandas\")\n+    from pandas.testing import assert_frame_equal\n+\n+    df = pd.DataFrame({\"a\": [True, False, True], \"b\": [1, 2, 3]})\n+\n+    # The bug is that `set_output` is not called on the remainder, which\n+    # means it does not output a DataFrame and messes up concatenation.\n+    ct = (\n+        make_column_transformer(\n+            (VarianceThreshold(), make_column_selector(dtype_include=bool)),\n+            remainder=VarianceThreshold(),\n+            verbose_feature_names_out=False,\n+        )\n+        .set_output(transform=\"pandas\")\n+    )\n+\n+    out = ct.fit_transform(df)\n+\n+    # The expected output is the same as the input, because VarianceThreshold\n+    # does not remove any columns. The dtypes should be preserved.\n+    expected_df = pd.DataFrame({\"a\": [True, False, True], \"b\": [1, 2, 3]})\n+    assert_frame_equal(out, expected_df)\n"
    },
    "astropy__astropy-13033": {
        "reproduced_bug": true,
        "reproduced_bug_file": "astropy/timeseries/tests/test_core.py",
        "reproduced_bug_commands": [
            "pytest astropy/timeseries/tests/test_core.py"
        ],
        "reproduced_bug_patch": "diff --git a/astropy/timeseries/tests/test_core.py b/astropy/timeseries/tests/test_core.py\nnew file mode 100644\nindex 0000000000..164d7c5568\n--- /dev/null\n+++ b/astropy/timeseries/tests/test_core.py\n@@ -0,0 +1,20 @@\n+import pytest\n+import numpy as np\n+from astropy.time import Time\n+from astropy.timeseries import TimeSeries\n+\n+\n+def test_remove_required_column_error_message():\n+    \"\"\"\n+    Test for a helpful error message when a required column is removed.\n+\n+    Regression test for a bug that caused a misleading ValueError when a\n+    required column was removed from a TimeSeries. The error message should\n+    clearly indicate which required column is missing.\n+    \"\"\"\n+    time = Time(np.arange(100000, 100003), format='jd')\n+    ts = TimeSeries(time=time, data={\"flux\": [99.9, 99.8, 99.7]})\n+    ts._required_columns = [\"time\", \"flux\"]\n+    with pytest.raises(ValueError) as exc:\n+        ts.remove_column(\"flux\")\n+    assert exc.value.args[0] == \"TimeSeries object is invalid - required column 'flux' is missing\"\n"
    },
    "django__django-13964": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/model_fields/test_foreignkey_regress.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py model_fields.test_foreignkey_regress"
        ],
        "reproduced_bug_patch": "diff --git a/tests/model_fields/test_foreignkey_regress.py b/tests/model_fields/test_foreignkey_regress.py\nnew file mode 100644\nindex 0000000000..212d146893\n--- /dev/null\n+++ b/tests/model_fields/test_foreignkey_regress.py\n@@ -0,0 +1,159 @@\n+from decimal import Decimal\n+\n+from django.apps import apps\n+from django.core import checks\n+from django.core.exceptions import FieldError\n+from django.db import models, transaction\n+from django.test import TestCase, skipIfDBFeature\n+from django.test.utils import isolate_apps\n+\n+from .models import Bar, FkToChar, Foo, PrimaryKeyCharModel\n+\n+\n+class ForeignKeyTests(TestCase):\n+\n+    def test_callable_default(self):\n+        \"\"\"A lazy callable may be used for ForeignKey.default.\"\"\"\n+        a = Foo.objects.create(id=1, a='abc', d=Decimal('12.34'))\n+        b = Bar.objects.create(b='bcd')\n+        self.assertEqual(b.a, a)\n+\n+    @skipIfDBFeature('interprets_empty_strings_as_nulls')\n+    def test_empty_string_fk(self):\n+        \"\"\"\n+        Empty strings foreign key values don't get converted to None (#19299).\n+        \"\"\"\n+        char_model_empty = PrimaryKeyCharModel.objects.create(string='')\n+        fk_model_empty = FkToChar.objects.create(out=char_model_empty)\n+        fk_model_empty = FkToChar.objects.select_related('out').get(id=fk_model_empty.pk)\n+        self.assertEqual(fk_model_empty.out, char_model_empty)\n+\n+    def test_fk_to_char_pk_late_assignment(self):\n+        with transaction.atomic():\n+            order = FkToChar()\n+            product = PrimaryKeyCharModel()\n+            order.out = product\n+            product.string = 'foo'\n+            product.save()\n+            order.save()\n+            self.assertTrue(FkToChar.objects.filter(out=product).exists())\n+\n+    @isolate_apps('model_fields')\n+    def test_warning_when_unique_true_on_fk(self):\n+        class Foo(models.Model):\n+            pass\n+\n+        class FKUniqueTrue(models.Model):\n+            fk_field = models.ForeignKey(Foo, models.CASCADE, unique=True)\n+\n+        model = FKUniqueTrue()\n+        expected_warnings = [\n+            checks.Warning(\n+                'Setting unique=True on a ForeignKey has the same effect as using a OneToOneField.',\n+                hint='ForeignKey(unique=True) is usually better served by a OneToOneField.',\n+                obj=FKUniqueTrue.fk_field.field,\n+                id='fields.W342',\n+            )\n+        ]\n+        warnings = model.check()\n+        self.assertEqual(warnings, expected_warnings)\n+\n+    def test_related_name_converted_to_text(self):\n+        rel_name = Bar._meta.get_field('a').remote_field.related_name\n+        self.assertIsInstance(rel_name, str)\n+\n+    def test_abstract_model_pending_operations(self):\n+        \"\"\"\n+        Foreign key fields declared on abstract models should not add lazy\n+        relations to resolve relationship declared as string (#24215).\n+        \"\"\"\n+        pending_ops_before = list(apps._pending_operations.items())\n+\n+        class AbstractForeignKeyModel(models.Model):\n+            fk = models.ForeignKey('missing.FK', models.CASCADE)\n+\n+            class Meta:\n+                abstract = True\n+\n+        self.assertIs(AbstractForeignKeyModel._meta.apps, apps)\n+        self.assertEqual(\n+            pending_ops_before,\n+            list(apps._pending_operations.items()),\n+            'Pending lookup added for a foreign key on an abstract model'\n+        )\n+\n+    @isolate_apps('model_fields', 'model_fields.tests')\n+    def test_abstract_model_app_relative_foreign_key(self):\n+        class AbstractReferent(models.Model):\n+            reference = models.ForeignKey('Referred', on_delete=models.CASCADE)\n+\n+            class Meta:\n+                app_label = 'model_fields'\n+                abstract = True\n+\n+        def assert_app_model_resolved(label):\n+            class Referred(models.Model):\n+                class Meta:\n+                    app_label = label\n+\n+            class ConcreteReferent(AbstractReferent):\n+                class Meta:\n+                    app_label = label\n+\n+            self.assertEqual(ConcreteReferent._meta.get_field('reference').related_model, Referred)\n+\n+        assert_app_model_resolved('model_fields')\n+        assert_app_model_resolved('tests')\n+\n+    @isolate_apps('model_fields')\n+    def test_to_python(self):\n+        class Foo(models.Model):\n+            pass\n+\n+        class Bar(models.Model):\n+            fk = models.ForeignKey(Foo, models.CASCADE)\n+\n+        self.assertEqual(Bar._meta.get_field('fk').to_python('1'), 1)\n+\n+    @isolate_apps('model_fields')\n+    def test_fk_to_fk_get_col_output_field(self):\n+        class Foo(models.Model):\n+            pass\n+\n+        class Bar(models.Model):\n+            foo = models.ForeignKey(Foo, models.CASCADE, primary_key=True)\n+\n+        class Baz(models.Model):\n+            bar = models.ForeignKey(Bar, models.CASCADE, primary_key=True)\n+\n+        col = Baz._meta.get_field('bar').get_col('alias')\n+        self.assertIs(col.output_field, Foo._meta.pk)\n+\n+    @isolate_apps('model_fields')\n+    def test_recursive_fks_get_col(self):\n+        class Foo(models.Model):\n+            bar = models.ForeignKey('Bar', models.CASCADE, primary_key=True)\n+\n+        class Bar(models.Model):\n+            foo = models.ForeignKey(Foo, models.CASCADE, primary_key=True)\n+\n+        with self.assertRaisesMessage(ValueError, 'Cannot resolve output_field'):\n+            Foo._meta.get_field('bar').get_col('alias')\n+\n+    @isolate_apps('model_fields')\n+    def test_non_local_to_field(self):\n+        class Parent(models.Model):\n+            key = models.IntegerField(unique=True)\n+\n+        class Child(Parent):\n+            pass\n+\n+        class Related(models.Model):\n+            child = models.ForeignKey(Child, on_delete=models.CASCADE, to_field='key')\n+\n+        msg = (\n+            \"'model_fields.Related.child' refers to field 'key' which is not \"\n+            \"local to model 'model_fields.Child'.\"\n+        )\n+        with self.assertRaisesMessage(FieldError, msg):\n+            Related._meta.get_field('child').related_fields\n"
    },
    "django__django-16667": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/forms_tests/widget_tests/test_selectdatewidget_overflow.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py forms_tests.widget_tests.test_selectdatewidget_overflow"
        ],
        "reproduced_bug_patch": "diff --git a/tests/forms_tests/widget_tests/test_selectdatewidget_overflow.py b/tests/forms_tests/widget_tests/test_selectdatewidget_overflow.py\nnew file mode 100644\nindex 0000000000..16446c2512\n--- /dev/null\n+++ b/tests/forms_tests/widget_tests/test_selectdatewidget_overflow.py\n@@ -0,0 +1,23 @@\n+from django.forms import DateField, Form, SelectDateWidget\n+from django.test import SimpleTestCase\n+\n+\n+class SelectDateWidgetTest(SimpleTestCase):\n+    def test_value_from_datadict_overflow(self):\n+        \"\"\"\n+        SelectDateWidget.value_from_datadict() should not crash on invalid\n+        (overflowing) date values.\n+        \"\"\"\n+\n+        class ReproForm(Form):\n+            my_date = DateField(widget=SelectDateWidget)\n+\n+        form = ReproForm(\n+            {\n+                \"my_date_day\": \"1\",\n+                \"my_date_month\": \"1\",\n+                \"my_date_year\": \"1234567821345678\",\n+            }\n+        )\n+        self.assertFalse(form.is_valid())\n+        self.assertEqual(form.errors, {\"my_date\": [\"Enter a valid date.\"]})\n"
    },
    "pydata__xarray-4966": {
        "reproduced_bug": true,
        "reproduced_bug_file": "xarray/tests/test_coding_variables.py",
        "reproduced_bug_commands": [
            "pytest xarray/tests/test_coding_variables.py"
        ],
        "reproduced_bug_patch": "diff --git a/xarray/tests/test_coding_variables.py b/xarray/tests/test_coding_variables.py\nnew file mode 100644\nindex 00000000..5e65f0fe\n--- /dev/null\n+++ b/xarray/tests/test_coding_variables.py\n@@ -0,0 +1,32 @@\n+import numpy as np\n+import pytest\n+\n+import xarray as xr\n+from xarray.coding import variables\n+from xarray.conventions import decode_cf_variable\n+from xarray.testing import assert_identical\n+\n+\n+def test_decode_signed_from_unsigned_opendap():\n+    \"\"\"\n+    Test decoding of signed integer data stored as unsigned integers\n+    with _Unsigned='false', a convention used by OPeNDAP.\n+\n+    This is to reproduce the issue where xarray does not correctly\n+    interpret unsigned bytes as signed when `_Unsigned = 'false'` is set,\n+    which is a pattern encountered with pydap.\n+    \"\"\"\n+    original = xr.Variable(\n+        (\"x\",),\n+        np.array([128, 255, 0, 1, 127], dtype=\"u1\"),\n+        {\"_Unsigned\": \"false\"},\n+    )\n+    expected = xr.Variable(\n+        (\"x\",),\n+        np.array([-128, -1, 0, 1, 127], dtype=\"i1\"),\n+    )\n+\n+    coder = variables.UnsignedIntegerCoder()\n+    decoded = coder.decode(original, name=\"test\")\n+\n+    assert_identical(expected, decoded)\n"
    },
    "pytest-dev__pytest-7521": {
        "reproduced_bug": true,
        "reproduced_bug_file": "testing/test_capfd_issue_7671.py",
        "reproduced_bug_commands": [
            "pytest testing/test_capfd_issue__7671.py"
        ],
        "reproduced_bug_patch": "diff --git a/testing/test_capfd_issue_7671.py b/testing/test_capfd_issue_7671.py\nnew file mode 100644\nindex 000000000..f0bd0f68e\n--- /dev/null\n+++ b/testing/test_capfd_issue_7671.py\n@@ -0,0 +1,12 @@\n+import pytest\n+\n+\n+def test_capfd_preserves_carriage_return(capfd):\n+    \"\"\"\n+    capfd.readouterr() should not convert \\r to \\n.\n+\n+    Regression test for https://github.com/pytest-dev/pytest/issues/7671\n+    \"\"\"\n+    print(\"Greetings from DOS\", end=\"\\r\")\n+    out, err = capfd.readouterr()\n+    assert out == \"Greetings from DOS\\r\"\n"
    },
    "scikit-learn__scikit-learn-9288": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/cluster/tests/test_kmeans_n_jobs_consistency.py",
        "reproduced_bug_commands": [
            "pytest sklearn/cluster/tests/test_kmeans_n_jobs_consistency.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/cluster/tests/test_kmeans_n_jobs_consistency.py b/sklearn/cluster/tests/test_kmeans_n_jobs_consistency.py\nnew file mode 100644\nindex 0000000000..fdaa43581d\n--- /dev/null\n+++ b/sklearn/cluster/tests/test_kmeans_n_jobs_consistency.py\n@@ -0,0 +1,31 @@\n+import pytest\n+import numpy as np\n+\n+from sklearn.cluster import KMeans\n+from sklearn.datasets.samples_generator import make_blobs\n+from sklearn.utils.testing import assert_almost_equal\n+from sklearn.utils.testing import if_safe_multiprocessing_with_blas\n+\n+\n+@if_safe_multiprocessing_with_blas\n+def test_kmeans_n_jobs_consistency():\n+    \"\"\"Test that KMeans gives consistent results for n_jobs=1 and n_jobs > 1.\n+\n+    This is a non-regression test for a bug where the inertia would differ.\n+    See: https://github.com/scikit-learn/scikit-learn/issues/9850\n+    \"\"\"\n+    # Generate data from the bug report\n+    X, _ = make_blobs(n_samples=10000, centers=10, n_features=2, random_state=2)\n+\n+    # Run KMeans with n_jobs=1\n+    kmeans_1_job = KMeans(n_clusters=10, random_state=2, n_jobs=1)\n+    kmeans_1_job.fit(X)\n+    inertia_1_job = kmeans_1_job.inertia_\n+\n+    # Run KMeans with n_jobs=2\n+    kmeans_2_jobs = KMeans(n_clusters=10, random_state=2, n_jobs=2)\n+    kmeans_2_jobs.fit(X)\n+    inertia_2_jobs = kmeans_2_jobs.inertia_\n+\n+    # The inertias should be almost equal\n+    assert_almost_equal(inertia_1_job, inertia_2_jobs)\n"
    },
    "astropy__astropy-13236": {
        "reproduced_bug": true,
        "reproduced_bug_file": "astropy/table/tests/test_structured_array.py",
        "reproduced_bug_commands": [
            "pytest astropy/table/tests/test__structured_array.py"
        ],
        "reproduced_bug_patch": "diff --git a/astropy/table/tests/test_structured_array.py b/astropy/table/tests/test_structured_array.py\nnew file mode 100644\nindex 0000000000..a015f1b688\n--- /dev/null\n+++ b/astropy/table/tests/test_structured_array.py\n@@ -0,0 +1,25 @@\n+# -*- coding: utf-8 -*-\n+# Licensed under a 3-clause BSD style license - see LICENSE.rst\n+\n+import numpy as np\n+import pytest\n+\n+from astropy.table import Column, NdarrayMixin, Table\n+\n+\n+def test_structured_array_becomes_column():\n+    \"\"\"\n+    Test that a structured array added to a Table becomes a Column.\n+\n+    Currently, it is transformed into a bare NdarrayMixin instance, which\n+    is a deprecated behavior. This test will fail until the deprecation\n+    cycle is complete. See #13186.\n+    \"\"\"\n+    structured_array = np.array([(1, 'a'), (2, 'b')],\n+                                dtype=[('f0', '<i4'), ('f1', '<U1')])\n+\n+    t = Table([structured_array], names=['a'])\n+\n+    # This fails now, as type(t['a']) is NdarrayMixin.\n+    # It will pass when the auto-transform is removed and it becomes a Column.\n+    assert type(t['a']) is Column\n"
    },
    "django__django-14007": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "django__django-16801": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/model_fields/test_imagefield_signals.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py --settings=test_sqlite model_fields.test_imagefield_signals"
        ],
        "reproduced_bug_patch": "diff --git a/tests/model_fields/test_imagefield_signals.py b/tests/model_fields/test_imagefield_signals.py\nnew file mode 100644\nindex 0000000000..d9dafdb26b\n--- /dev/null\n+++ b/tests/model_fields/test_imagefield_signals.py\n@@ -0,0 +1,27 @@\n+from unittest import skipIf\n+\n+from django.db import models\n+from django.db.models import signals\n+from django.test import TestCase\n+from django.test.utils import isolate_apps\n+\n+try:\n+    from PIL import Image\n+except ImportError:\n+    Image = None\n+\n+\n+@skipIf(Image is None, \"Pillow is required to test ImageField\")\n+class ImageFieldSignalTests(TestCase):\n+    @isolate_apps(\"model_fields\")\n+    def test_post_init_not_connected_without_dimension_fields(self):\n+        \"\"\"\n+        A post_init signal handler shouldn't be connected from an ImageField\n+        if width_field and height_field are not set.\n+        \"\"\"\n+\n+        class Person(models.Model):\n+            name = models.CharField(max_length=50)\n+            mugshot = models.ImageField(upload_to=\"test\")\n+\n+        self.assertFalse(signals.post_init.has_listeners(sender=Person))\n"
    },
    "pydata__xarray-6461": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "pytest-dev__pytest-7571": {
        "reproduced_bug": true,
        "reproduced_bug_file": "testing/logging/test_caplog.py",
        "reproduced_bug_commands": [
            "pytest testing/logging/test_caplog.py"
        ],
        "reproduced_bug_patch": "diff --git a/testing/logging/test_caplog.py b/testing/logging/test_caplog.py\nnew file mode 100644\nindex 000000000..6292fa42a\n--- /dev/null\n+++ b/testing/logging/test_caplog.py\n@@ -0,0 +1,27 @@\n+import logging\n+\n+import pytest\n+\n+\n+def test_set_level_is_restored(testdir):\n+    \"\"\"\n+    Tests that caplog.set_level() is restored at the end of the test.\n+\n+    This is a regression test for issue #7553, where the log level was\n+    leaking between tests.\n+    \"\"\"\n+    testdir.makepyfile(\n+        \"\"\"\n+        import logging\n+\n+        def test_level_set(caplog):\n+            caplog.set_level(42)\n+\n+        def test_level_restored(caplog):\n+            assert caplog.handler.level == 0\n+        \"\"\"\n+    )\n+    result = testdir.runpytest()\n+    # If the level is not restored, test_level_restored will fail,\n+    # and runpytest will return a non-zero exit code.\n+    assert result.ret == 0\n"
    },
    "django__django-14011": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/servers/test_liveserver_connection.py",
        "reproduced_bug_commands": [
            "./tests/runtests.py servers.test_liveserver_connection"
        ],
        "reproduced_bug_patch": "diff --git a/tests/servers/test_liveserver_connection.py b/tests/servers/test_liveserver_connection.py\nnew file mode 100644\nindex 0000000000..69a9c0e994\n--- /dev/null\n+++ b/tests/servers/test_liveserver_connection.py\n@@ -0,0 +1,36 @@\n+from django.db import DEFAULT_DB_ALIAS, connections\n+from django.test import LiveServerTestCase, TransactionTestCase\n+\n+\n+# Use TransactionTestCase instead of TestCase to run outside of a transaction,\n+# otherwise closing the connection would implicitly rollback and not set the\n+# connection to None.\n+class LiveServerThreadConnectionClosingTest(TransactionTestCase):\n+    available_apps = []\n+\n+    def _run_live_server_thread(self, connections_override=None):\n+        thread = LiveServerTestCase._create_server_thread(connections_override)\n+        thread.daemon = True\n+        thread.start()\n+        thread.is_ready.wait()\n+        thread.terminate()\n+\n+    def test_threaded_server_closes_db_connections(self):\n+        \"\"\"\n+        The ThreadedWSGIServer spawned by LiveServerThread should close its\n+        database connections on termination.\n+        \"\"\"\n+        db_conn = connections[DEFAULT_DB_ALIAS]\n+        # Pass a connection to the thread to check that it's closed.\n+        connections_override = {DEFAULT_DB_ALIAS: db_conn}\n+        # Open a database connection.\n+        db_conn.connect()\n+        db_conn.inc_thread_sharing()\n+        try:\n+            self.assertIsNotNone(db_conn.connection)\n+            self._run_live_server_thread(connections_override)\n+            # The connection should be closed by the thread. This is the\n+            # assertion that is expected to fail due to the bug.\n+            self.assertIsNone(db_conn.connection)\n+        finally:\n+            db_conn.dec_thread_sharing()\n"
    },
    "django__django-16819": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/migrations/test_optimizer_add_remove_index.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py migrations.test_optimizer_add_remove_index"
        ],
        "reproduced_bug_patch": "diff --git a/tests/migrations/test_optimizer_add_remove_index.py b/tests/migrations/test_optimizer_add_remove_index.py\nnew file mode 100644\nindex 0000000000..42bb989b3e\n--- /dev/null\n+++ b/tests/migrations/test_optimizer_add_remove_index.py\n@@ -0,0 +1,59 @@\n+from django.db import migrations, models\n+from django.db.migrations import operations\n+from django.db.migrations.optimizer import MigrationOptimizer\n+from django.db.migrations.serializer import serializer_factory\n+from django.test import SimpleTestCase\n+\n+from .models import EmptyManager, UnicodeModel\n+\n+\n+class OptimizerTests(SimpleTestCase):\n+    \"\"\"\n+    Tests the migration optimizer.\n+    \"\"\"\n+\n+    def optimize(self, operations, app_label):\n+        \"\"\"\n+        Handy shortcut for getting results + number of loops\n+        \"\"\"\n+        optimizer = MigrationOptimizer()\n+        return optimizer.optimize(operations, app_label), optimizer._iterations\n+\n+    def serialize(self, value):\n+        return serializer_factory(value).serialize()[0]\n+\n+    def assertOptimizesTo(\n+        self, operations, expected, exact=None, less_than=None, app_label=None\n+    ):\n+        result, iterations = self.optimize(operations, app_label or \"migrations\")\n+        result = [self.serialize(f) for f in result]\n+        expected = [self.serialize(f) for f in expected]\n+        self.assertEqual(expected, result)\n+        if exact is not None and iterations != exact:\n+            raise self.failureException(\n+                \"Optimization did not take exactly %s iterations (it took %s)\"\n+                % (exact, iterations)\n+            )\n+        if less_than is not None and iterations >= less_than:\n+            raise self.failureException(\n+                \"Optimization did not take less than %s iterations (it took %s)\"\n+                % (less_than, iterations)\n+            )\n+\n+    def assertDoesNotOptimize(self, operations, **kwargs):\n+        self.assertOptimizesTo(operations, operations, **kwargs)\n+\n+    def test_add_index_remove_index(self):\n+        \"\"\"\n+        RemoveIndex should cancel AddIndex.\n+        \"\"\"\n+        self.assertOptimizesTo(\n+            [\n+                migrations.AddIndex(\n+                    \"Foo\",\n+                    models.Index(fields=[\"age\"], name=\"foo_age_idx\"),\n+                ),\n+                migrations.RemoveIndex(\"Foo\", \"foo_age_idx\"),\n+            ],\n+            [],\n+        )\n"
    },
    "pydata__xarray-6599": {
        "reproduced_bug": true,
        "reproduced_bug_file": "xarray/tests/test_polyval.py",
        "reproduced_bug_commands": [
            "pytest xarray/tests/test_polyval.py"
        ],
        "reproduced_bug_patch": "diff --git a/xarray/tests/test_polyval.py b/xarray/tests/test_polyval.py\nnew file mode 100644\nindex 00000000..9f37f702\n--- /dev/null\n+++ b/xarray/tests/test_polyval.py\n@@ -0,0 +1,55 @@\n+import numpy as np\n+import pytest\n+import xarray as xr\n+\n+from xarray.testing import assert_allclose\n+\n+\n+def test_polyval_timedelta_coord() -> None:\n+    \"\"\"\n+    Test polyval with a timedelta64 coordinate.\n+    Regression test for GH:6564.\n+    \"\"\"\n+    values = np.array(\n+        [\n+            \"2021-04-01T05:25:19.000000000\",\n+            \"2021-04-01T05:25:29.000000000\",\n+            \"2021-04-01T05:25:39.000000000\",\n+            \"2021-04-01T05:25:49.000000000\",\n+            \"2021-04-01T05:25:59.000000000\",\n+            \"2021-04-01T05:26:09.000000000\",\n+        ],\n+        dtype=\"datetime64[ns]\",\n+    )\n+    azimuth_time = xr.DataArray(\n+        values, name=\"azimuth_time\", coords={\"azimuth_time\": values - values[0]}\n+    )\n+\n+    polyfit_coefficients = xr.DataArray(\n+        [\n+            [2.33333335e-43, 1.62499999e-43, 2.79166678e-43],\n+            [-1.15316667e-30, 1.49518518e-31, 9.08833333e-31],\n+            [-2.50272583e-18, -1.23851062e-18, -2.99098229e-18],\n+            [5.83965193e-06, -1.53321770e-07, -4.84640242e-06],\n+            [4.44739216e06, 1.45053974e06, 5.29960857e06],\n+        ],\n+        dims=(\"degree\", \"axis\"),\n+        coords={\"axis\": [0, 1, 2], \"degree\": [4, 3, 2, 1, 0]},\n+    )\n+\n+    actual = xr.polyval(azimuth_time, polyfit_coefficients)\n+\n+    expected = xr.DataArray(\n+        [\n+            [4447392.16, 1450539.74, 5299608.57],\n+            [4505537.25588366, 1448882.82238152, 5250846.359196],\n+            [4563174.92026797, 1446979.12250014, 5201491.44401733],\n+            [4620298.31815291, 1444829.59596699, 5151549.377964],\n+            [4676900.67053846, 1442435.23739315, 5101025.78153601],\n+            [4732975.25442459, 1439797.08038974, 5049926.34223336],\n+        ],\n+        dims=(\"azimuth_time\", \"axis\"),\n+        coords={\"azimuth_time\": values, \"axis\": [0, 1, 2]},\n+    )\n+\n+    assert_allclose(actual, expected)\n"
    },
    "pytest-dev__pytest-7982": {
        "reproduced_bug": true,
        "reproduced_bug_file": "testing/test_collection_symlinks.py",
        "reproduced_bug_commands": [
            "pytest testing/test_collection_symlinks.py"
        ],
        "reproduced_bug_patch": "diff --git a/testing/test_collection_symlinks.py b/testing/test_collection_symlinks.py\nnew file mode 100644\nindex 000000000..33bfd01ae\n--- /dev/null\n+++ b/testing/test_collection_symlinks.py\n@@ -0,0 +1,30 @@\n+import pytest\n+from _pytest.pytester import Testdir\n+from _pytest.pathlib import symlink_or_skip\n+\n+def test_collect_symlinked_dir_during_recursion(testdir: Testdir) -> None:\n+    \"\"\"\n+    Tests that pytest follows symlinks to directories during collection.\n+\n+    This reproduces the bug where symlinked directories inside a collection\n+    root are ignored.\n+    \"\"\"\n+    # 1. Create a directory with tests *outside* the main project root.\n+    real_tests_dir = testdir.mkdir(\"real_tests\")\n+    real_tests_dir.join(\"test_real.py\").write(\"def test_it(): pass\")\n+\n+    # 2. Create the project root for collection.\n+    project_dir = testdir.mkdir(\"project_root\")\n+\n+    # 3. Create a symlink from within the project to the external tests.\n+    symlink_path = project_dir.join(\"linked_tests\")\n+    symlink_or_skip(real_tests_dir, symlink_path)\n+\n+    # 4. Run pytest from the project root. The only way to find the test\n+    #    is to follow the symlink.\n+    result = testdir.runpytest(str(project_dir))\n+\n+    # 5. The bug causes pytest to not follow the symlink, finding 0 tests.\n+    #    This assertion will fail when the bug is present. When fixed,\n+    #    the symlink is followed, the test is found, and this passes.\n+    result.assert_outcomes(passed=1)\n"
    },
    "sphinx-doc__sphinx-10323": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "astropy__astropy-13398": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "django__django-14017": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/expressions/test_q_exists_operator.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py expressions.test_q_exists_operator"
        ],
        "reproduced_bug_patch": "diff --git a/tests/expressions/test_q_exists_operator.py b/tests/expressions/test_q_exists_operator.py\nnew file mode 100644\nindex 0000000000..598e2a4447\n--- /dev/null\n+++ b/tests/expressions/test_q_exists_operator.py\n@@ -0,0 +1,39 @@\n+from django.db.models import Exists, OuterRef, Q\n+from django.test import TestCase\n+\n+# Correctly import models from the 'expressions' app to avoid ImportError.\n+from expressions.models import Company, Employee\n+\n+\n+class QExistsCombinationTests(TestCase):\n+    @classmethod\n+    def setUpTestData(cls):\n+        \"\"\"\n+        Set up data for the test case.\n+        - A CEO employee.\n+        - A non-CEO employee.\n+        - A company run by the CEO.\n+        \"\"\"\n+        cls.ceo = Employee.objects.create(\n+            firstname='John', lastname='Doe', salary=50000\n+        )\n+        cls.non_ceo = Employee.objects.create(\n+            firstname='Jane', lastname='Smith', salary=40000\n+        )\n+        # Ensure all required fields for the Company model are provided.\n+        Company.objects.create(\n+            name='Django Inc.', num_employees=10, num_chairs=10, ceo=cls.ceo\n+        )\n+\n+    def test_q_and_exists_operator(self):\n+        \"\"\"\n+        Test that Q() & Exists() is a valid query and doesn't raise a\n+        TypeError. This reproduces the bug where the operation is not\n+        commutative.\n+        \"\"\"\n+        is_ceo_query = Company.objects.filter(ceo=OuterRef('pk'))\n+        # The following query construction raises a TypeError due to the bug.\n+        # When the bug is fixed, this filter should execute successfully.\n+        qs = Employee.objects.filter(Q() & Exists(is_ceo_query))\n+        # This assertion will pass once the TypeError is resolved.\n+        self.assertSequenceEqual(qs, [cls.ceo])\n"
    },
    "django__django-16877": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/template_tests/filter_tests/test_escapeseq.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py template_tests.filter_tests.test_escapeseq"
        ],
        "reproduced_bug_patch": "diff --git a/tests/template_tests/filter_tests/test_escapeseq.py b/tests/template_tests/filter_tests/test_escapeseq.py\nnew file mode 100644\nindex 0000000000..8476d787f5\n--- /dev/null\n+++ b/tests/template_tests/filter_tests/test_escapeseq.py\n@@ -0,0 +1,18 @@\n+from django.test import SimpleTestCase\n+\n+from ..utils import setup\n+\n+\n+class EscapeseqTests(SimpleTestCase):\n+    @setup(\n+        {\n+            \"escapeseq01\": (\n+                \"{% autoescape off %}\"\n+                \"{{ a|escapeseq|join:',' }}\"\n+                \"{% endautoescape %}\"\n+            )\n+        }\n+    )\n+    def test_escapeseq01(self):\n+        output = self.engine.render_to_string(\"escapeseq01\", {\"a\": [\"&\", \"<\"]})\n+        self.assertEqual(output, \"&amp;,&lt;\")\n"
    },
    "pydata__xarray-6721": {
        "reproduced_bug": true,
        "reproduced_bug_file": "xarray/tests/test_zarr.py",
        "reproduced_bug_commands": [
            "pytest xarray/tests/test_zarr.py"
        ],
        "reproduced_bug_patch": "diff --git a/xarray/tests/test_zarr.py b/xarray/tests/test_zarr.py\nnew file mode 100644\nindex 00000000..fb35dab6\n--- /dev/null\n+++ b/xarray/tests/test_zarr.py\n@@ -0,0 +1,24 @@\n+import numpy as np\n+import pytest\n+import xarray as xr\n+\n+from xarray.tests import requires_zarr\n+\n+\n+@requires_zarr\n+def test_accessing_chunks_does_not_load_data(tmp_path):\n+    \"\"\"\n+    Test that accessing the .chunks attribute does not load the entire\n+    array into memory. Regression test for GH issue #6522.\n+    \"\"\"\n+    ds = xr.Dataset({\"foo\": (\"x\", np.arange(10))})\n+    store_path = tmp_path / \"test.zarr\"\n+    ds.to_zarr(store_path)\n+\n+    with xr.open_dataset(store_path, engine=\"zarr\") as actual:\n+        assert not actual[\"foo\"].variable._in_memory\n+\n+        # Accessing chunks should not load data from disk\n+        _ = actual.chunks\n+\n+        assert not actual[\"foo\"].variable._in_memory\n"
    },
    "pytest-dev__pytest-8399": {
        "reproduced_bug": true,
        "reproduced_bug_file": "testing/test_unittest_fixtures.py",
        "reproduced_bug_commands": [
            "pytest -v testing/test_unittest_fixtures.py"
        ],
        "reproduced_bug_patch": "diff --git a/testing/test_unittest_fixtures.py b/testing/test_unittest_fixtures.py\nnew file mode 100644\nindex 000000000..2154550b4\n--- /dev/null\n+++ b/testing/test_unittest_fixtures.py\n@@ -0,0 +1,26 @@\n+import pytest\n+from _pytest.pytester import Pytester\n+\n+\n+def test_unittest_setup_class_fixture_is_private(pytester: Pytester) -> None:\n+    \"\"\"\n+    Check that unittest setUpClass fixtures are private.\n+\n+    The fixture generated for ``unittest.TestCase.setUpClass`` should\n+    be considered \"private\" and not be displayed by ``--fixtures`` by default.\n+    \"\"\"\n+    p = pytester.makepyfile(\n+        \"\"\"\n+        import unittest\n+\n+        class Tests(unittest.TestCase):\n+            @classmethod\n+            def setUpClass(cls):\n+                pass\n+\n+            def test_1(self):\n+                pass\n+        \"\"\"\n+    )\n+    result = pytester.runpytest(\"--fixtures\", p)\n+    result.stdout.no_fnmatch_line(\"*unittest_setUpClass_fixture_Tests*\")\n"
    },
    "sphinx-doc__sphinx-10435": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_latex_inline_code.py",
        "reproduced_bug_commands": [
            "mkdir tests/roots/test-latex-inline-code",
            "echo \"latex_documents = [('index', 'python.tex', 'test', 'test', 'manual')]\" > tests/roots/test-latex-inline-code/conf.py",
            "pytest tests/test_latex_inline_code.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_latex_inline_code.py b/tests/test_latex_inline_code.py\nnew file mode 100644\nindex 000000000..fd9920d38\n--- /dev/null\n+++ b/tests/test_latex_inline_code.py\n@@ -0,0 +1,32 @@\n+import pytest\n+import re\n+\n+@pytest.mark.sphinx('latex', testroot='latex-inline-code')\n+def test_inline_code_no_extra_whitespace(app, status, warning):\n+    \"\"\"\n+    Test for bug reported in issue #10296.\n+    Ensures that for LaTeX output, a space character is not inserted at the start\n+    and end of the inline code when using the 'code' role with syntax highlighting.\n+    This is verified by checking for the presence of '%' characters which are\n+    used in LaTeX to gobble unwanted whitespace.\n+    \"\"\"\n+    (app.srcdir / 'index.rst').write_text(\n+        \"\"\"\n+.. role:: python(code)\n+   :language: python\n+   :class: highlight\n+\n+Inline :python:`def foo(1 + 2 + None + \"abc\"): pass` code block\n+        \"\"\",\n+        encoding='utf8'\n+    )\n+\n+    app.builder.build_all()\n+    result = (app.outdir / 'python.tex').read_text(encoding='utf8')\n+\n+    expected = (\n+        'Inline \\\\sphinxcode{\\\\sphinxupquote{%\\n'\n+        '\\\\PYG{k}{def} \\\\PYG{n+nf}{foo}\\\\PYG{p}{(}\\\\PYG{l+m+mi}{1} \\\\PYG{o}{+} \\\\PYG{l+m+mi}{2} \\\\PYG{o}{+} \\\\PYG{k+kc}{None} \\\\PYG{o}{+} \\\\PYG{l+s+s2}{\\\\PYGZdq{}}\\\\PYG{l+s+s2}{abc}\\\\PYG{l+s+s2}{\\\\PYGZdq{}}\\\\PYG{p}{)}\\\\PYG{p}{:} \\\\PYG{k}{pass}%\\n'\n+        '}} code block'\n+    )\n+    assert expected in result\n"
    },
    "astropy__astropy-13453": {
        "reproduced_bug": true,
        "reproduced_bug_file": "astropy/io/ascii/tests/test_html_writer_formats.py",
        "reproduced_bug_commands": [
            "pytest astropy/io/ascii/tests/test_html_writer_formats.py"
        ],
        "reproduced_bug_patch": "diff --git a/astropy/io/ascii/tests/test_html_writer_formats.py b/astropy/io/ascii/tests/test_html_writer_formats.py\nnew file mode 100644\nindex 0000000000..9ae3ea6141\n--- /dev/null\n+++ b/astropy/io/ascii/tests/test_html_writer_formats.py\n@@ -0,0 +1,21 @@\n+from io import StringIO\n+\n+from astropy.table import Table\n+\n+\n+def test_html_write_formats():\n+    \"\"\"\n+    Test that the formats option is not ignored when writing to HTML.\n+    Regression test for https://github.com/astropy/astropy/issues/13530.\n+    \"\"\"\n+    # generate table from issue\n+    t = Table([(1.23875234858e-24, 3.2348748432e-15), (2, 4)], names=(\"a\", \"b\"))\n+\n+    with StringIO() as s:\n+        # write HTML table with \"a\" column formatted to show 2 decimal places\n+        t.write(s, format=\"html\", formats={\"a\": lambda x: f\"{x:.2e}\"})\n+        output = s.getvalue()\n+\n+    # The bug is that the format is ignored, so this fails.\n+    # The output contains '<td>1.23875234858e-24</td>' instead.\n+    assert \"<td>1.24e-24</td>\" in output\n"
    },
    "django__django-14034": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/forms_tests/field_tests/test_multivaluefield_validation.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py forms_tests.field_tests.test_multivaluefield_validation"
        ],
        "reproduced_bug_patch": "diff --git a/tests/forms_tests/field_tests/test_multivaluefield_validation.py b/tests/forms_tests/field_tests/test_multivaluefield_validation.py\nnew file mode 100644\nindex 0000000000..fe88bde398\n--- /dev/null\n+++ b/tests/forms_tests/field_tests/test_multivaluefield_validation.py\n@@ -0,0 +1,202 @@\n+from datetime import datetime\n+\n+from django.core.exceptions import ValidationError\n+from django.forms import (\n+    CharField, Form, MultipleChoiceField, MultiValueField, MultiWidget,\n+    SelectMultiple, SplitDateTimeField, SplitDateTimeWidget, TextInput,\n+)\n+from django.test import SimpleTestCase\n+\n+beatles = (('J', 'John'), ('P', 'Paul'), ('G', 'George'), ('R', 'Ringo'))\n+\n+\n+class ComplexMultiWidget(MultiWidget):\n+    def __init__(self, attrs=None):\n+        widgets = (\n+            TextInput(),\n+            SelectMultiple(choices=beatles),\n+            SplitDateTimeWidget(),\n+        )\n+        super().__init__(widgets, attrs)\n+\n+    def decompress(self, value):\n+        if value:\n+            data = value.split(',')\n+            return [\n+                data[0],\n+                list(data[1]),\n+                datetime.strptime(data[2], \"%Y-%m-%d %H:%M:%S\"),\n+            ]\n+        return [None, None, None]\n+\n+\n+class ComplexField(MultiValueField):\n+    def __init__(self, **kwargs):\n+        fields = (\n+            CharField(),\n+            MultipleChoiceField(choices=beatles),\n+            SplitDateTimeField(),\n+        )\n+        super().__init__(fields, **kwargs)\n+\n+    def compress(self, data_list):\n+        if data_list:\n+            return '%s,%s,%s' % (data_list[0], ''.join(data_list[1]), data_list[2])\n+        return None\n+\n+\n+class ComplexFieldForm(Form):\n+    field1 = ComplexField(widget=ComplexMultiWidget())\n+\n+\n+class MultiValueFieldTest(SimpleTestCase):\n+\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.field = ComplexField(widget=ComplexMultiWidget())\n+        super().setUpClass()\n+\n+    def test_clean(self):\n+        self.assertEqual(\n+            self.field.clean(['some text', ['J', 'P'], ['2007-04-25', '6:24:00']]),\n+            'some text,JP,2007-04-25 06:24:00',\n+        )\n+\n+    def test_clean_disabled_multivalue(self):\n+        class ComplexFieldForm(Form):\n+            f = ComplexField(disabled=True, widget=ComplexMultiWidget)\n+\n+        inputs = (\n+            'some text,JP,2007-04-25 06:24:00',\n+            ['some text', ['J', 'P'], ['2007-04-25', '6:24:00']],\n+        )\n+        for data in inputs:\n+            with self.subTest(data=data):\n+                form = ComplexFieldForm({}, initial={'f': data})\n+                form.full_clean()\n+                self.assertEqual(form.errors, {})\n+                self.assertEqual(form.cleaned_data, {'f': inputs[0]})\n+\n+    def test_bad_choice(self):\n+        msg = \"'Select a valid choice. X is not one of the available choices.'\"\n+        with self.assertRaisesMessage(ValidationError, msg):\n+            self.field.clean(['some text', ['X'], ['2007-04-25', '6:24:00']])\n+\n+    def test_no_value(self):\n+        \"\"\"\n+        If insufficient data is provided, None is substituted.\n+        \"\"\"\n+        msg = \"'This field is required.'\"\n+        with self.assertRaisesMessage(ValidationError, msg):\n+            self.field.clean(['some text', ['JP']])\n+\n+    def test_has_changed_no_initial(self):\n+        self.assertTrue(self.field.has_changed(None, ['some text', ['J', 'P'], ['2007-04-25', '6:24:00']]))\n+\n+    def test_has_changed_same(self):\n+        self.assertFalse(self.field.has_changed(\n+            'some text,JP,2007-04-25 06:24:00',\n+            ['some text', ['J', 'P'], ['2007-04-25', '6:24:00']],\n+        ))\n+\n+    def test_has_changed_first_widget(self):\n+        \"\"\"\n+        Test when the first widget's data has changed.\n+        \"\"\"\n+        self.assertTrue(self.field.has_changed(\n+            'some text,JP,2007-04-25 06:24:00',\n+            ['other text', ['J', 'P'], ['2007-04-25', '6:24:00']],\n+        ))\n+\n+    def test_has_changed_last_widget(self):\n+        \"\"\"\n+        Test when the last widget's data has changed. This ensures that it is\n+        not short circuiting while testing the widgets.\n+        \"\"\"\n+        self.assertTrue(self.field.has_changed(\n+            'some text,JP,2007-04-25 06:24:00',\n+            ['some text', ['J', 'P'], ['2009-04-25', '11:44:00']],\n+        ))\n+\n+    def test_disabled_has_changed(self):\n+        f = MultiValueField(fields=(CharField(), CharField()), disabled=True)\n+        self.assertIs(f.has_changed(['x', 'x'], ['y', 'y']), False)\n+\n+    def test_form_as_table(self):\n+        form = ComplexFieldForm()\n+        self.assertHTMLEqual(\n+            form.as_table(),\n+            \"\"\"\n+            <tr><th><label for=\"id_field1_0\">Field1:</label></th>\n+            <td><input type=\"text\" name=\"field1_0\" id=\"id_field1_0\" required>\n+            <select multiple name=\"field1_1\" id=\"id_field1_1\" required>\n+            <option value=\"J\">John</option>\n+            <option value=\"P\">Paul</option>\n+            <option value=\"G\">George</option>\n+            <option value=\"R\">Ringo</option>\n+            </select>\n+            <input type=\"text\" name=\"field1_2_0\" id=\"id_field1_2_0\" required>\n+            <input type=\"text\" name=\"field1_2_1\" id=\"id_field1_2_1\" required></td></tr>\n+            \"\"\",\n+        )\n+\n+    def test_form_as_table_data(self):\n+        form = ComplexFieldForm({\n+            'field1_0': 'some text',\n+            'field1_1': ['J', 'P'],\n+            'field1_2_0': '2007-04-25',\n+            'field1_2_1': '06:24:00',\n+        })\n+        self.assertHTMLEqual(\n+            form.as_table(),\n+            \"\"\"\n+            <tr><th><label for=\"id_field1_0\">Field1:</label></th>\n+            <td><input type=\"text\" name=\"field1_0\" value=\"some text\" id=\"id_field1_0\" required>\n+            <select multiple name=\"field1_1\" id=\"id_field1_1\" required>\n+            <option value=\"J\" selected>John</option>\n+            <option value=\"P\" selected>Paul</option>\n+            <option value=\"G\">George</option>\n+            <option value=\"R\">Ringo</option>\n+            </select>\n+            <input type=\"text\" name=\"field1_2_0\" value=\"2007-04-25\" id=\"id_field1_2_0\" required>\n+            <input type=\"text\" name=\"field1_2_1\" value=\"06:24:00\" id=\"id_field1_2_1\" required></td></tr>\n+            \"\"\",\n+        )\n+\n+    def test_form_cleaned_data(self):\n+        form = ComplexFieldForm({\n+            'field1_0': 'some text',\n+            'field1_1': ['J', 'P'],\n+            'field1_2_0': '2007-04-25',\n+            'field1_2_1': '06:24:00',\n+        })\n+        form.is_valid()\n+        self.assertEqual(form.cleaned_data['field1'], 'some text,JP,2007-04-25 06:24:00')\n+\n+    def test_required_subfield_not_validated_when_all_fields_empty(self):\n+        class MF(MultiValueField):\n+            def __init__(self, **kwargs):\n+                fields = [\n+                    CharField(required=False),\n+                    CharField(required=True),\n+                ]\n+                widget = MultiWidget(widgets=[f.widget for f in fields])\n+                super().__init__(\n+                    fields=fields,\n+                    widget=widget,\n+                    require_all_fields=False,\n+                    required=False,\n+                    **kwargs\n+                )\n+\n+            def compress(self, value):\n+                return value or []\n+\n+        class F(Form):\n+            mf = MF()\n+\n+        f = F({\n+            'mf_0': '',\n+            'mf_1': '',\n+        })\n+        self.assertFalse(f.is_valid())\n"
    },
    "django__django-16899": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "pydata__xarray-6744": {
        "reproduced_bug": true,
        "reproduced_bug_file": "xarray/tests/test_rolling_gh6738.py",
        "reproduced_bug_commands": [
            "pytest xarray/tests/test_rolling_gh6738.py"
        ],
        "reproduced_bug_patch": "diff --git a/xarray/tests/test_rolling_gh6738.py b/xarray/tests/test_rolling_gh6738.py\nnew file mode 100644\nindex 00000000..1c36f3b2\n--- /dev/null\n+++ b/xarray/tests/test_rolling_gh6738.py\n@@ -0,0 +1,28 @@\n+import numpy as np\n+import pytest\n+\n+import xarray as xr\n+from xarray import DataArray\n+from xarray.tests import assert_allclose\n+\n+\n+class TestDataArrayRolling:\n+    def test_rolling_iter_center(self):\n+        \"\"\"\n+        Test that iterating over a rolling object with center=True\n+        yields centered windows.\n+        Regression test for GH6738.\n+        \"\"\"\n+        # From the issue: https://github.com/pydata/xarray/discussions/6738\n+        my_data = xr.DataArray(np.arange(1, 10, dtype=float), dims=\"x\")\n+\n+        # The vectorized operation gives the correct, expected result\n+        expected = my_data.rolling(x=3, center=True).mean()\n+\n+        # The manual iteration gives the buggy result\n+        my_data_rolling = my_data.rolling(x=3, center=True)\n+        actual_values = [window.mean().item() for _, window in my_data_rolling]\n+        actual = xr.DataArray(actual_values, coords=my_data.coords)\n+\n+        # This assertion will fail until the bug is fixed\n+        assert_allclose(actual, expected)\n"
    },
    "scikit-learn__scikit-learn-10297": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/linear_model/tests/test_ridge_classifier_cv.py",
        "reproduced_bug_commands": [
            "pytest sklearn/linear_model/tests/test_ridge_classifier_cv.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/linear_model/tests/test_ridge_classifier_cv.py b/sklearn/linear_model/tests/test_ridge_classifier_cv.py\nnew file mode 100644\nindex 0000000000..cc5bd52c78\n--- /dev/null\n+++ b/sklearn/linear_model/tests/test_ridge_classifier_cv.py\n@@ -0,0 +1,25 @@\n+import numpy as np\n+\n+from sklearn.utils.testing import assert_equal\n+from sklearn.linear_model.ridge import RidgeClassifierCV\n+from sklearn import datasets\n+\n+\n+def test_ridge_classifier_cv_store_cv_values():\n+    \"\"\"Test that RidgeClassifierCV supports store_cv_values=True.\"\"\"\n+    iris = datasets.load_iris()\n+    X_iris = iris.data\n+    y_iris = iris.target\n+    n_samples = X_iris.shape[0]\n+    n_classes = len(np.unique(y_iris))\n+    alphas = [0.1, 1.0, 10.0]\n+\n+    # This call raises a TypeError in the buggy version.\n+    # When fixed, it should accept the argument and assign cv_values_.\n+    clf = RidgeClassifierCV(alphas=alphas, store_cv_values=True)\n+    clf.fit(X_iris, y_iris)\n+\n+    # This assertion will pass when the bug is fixed.\n+    # The shape is (n_samples, n_classes, n_alphas) because RidgeClassifierCV\n+    # uses a one-vs-all scheme, where each class gets a RidgeCV model.\n+    assert_equal(clf.cv_values_.shape, (n_samples, n_classes, len(alphas)))\n"
    },
    "sphinx-doc__sphinx-10449": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "astropy__astropy-13579": {
        "reproduced_bug": true,
        "reproduced_bug_file": "astropy/wcs/tests/test_regression.py",
        "reproduced_bug_commands": [
            "pytest test_bug.py"
        ],
        "reproduced_bug_patch": "diff --git a/astropy/wcs/tests/test_regression.py b/astropy/wcs/tests/test_regression.py\nnew file mode 100644\nindex 0000000000..44cb13262b\n--- /dev/null\n+++ b/astropy/wcs/tests/test_regression.py\n@@ -0,0 +1,61 @@\n+import numpy as np\n+from numpy.testing import assert_allclose\n+\n+import astropy.units as u\n+import astropy.wcs\n+from astropy.coordinates import SkyCoord\n+from astropy.wcs.wcsapi import SlicedLowLevelWCS, HighLevelWCSWrapper\n+import astropy.wcs.utils\n+\n+\n+def test_sliced_wcs_world_to_pixel_coupling():\n+    \"\"\"\n+    Regression test for an issue where world_to_pixel gives inconsistent\n+    results when slicing a WCS with coupled spectral and spatial axes.\n+\n+    See https://github.com/astropy/astropy/issues/13242\n+    \"\"\"\n+    nx = 100\n+    ny = 25\n+    wcs_header = {\n+        'WCSAXES': 3,\n+        'CRPIX1': (nx + 1) / 2,\n+        'CRPIX2': (ny + 1) / 2,\n+        'CRPIX3': 1.0,\n+        'PC1_1': 0.0,\n+        'PC1_2': -1.0,\n+        'PC1_3': 0.0,\n+        'PC2_1': 1.0,\n+        'PC2_2': 0.0,\n+        'PC2_3': -1.0,\n+        'CDELT1': 5,\n+        'CDELT2': 5,\n+        'CDELT3': 0.055,\n+        'CUNIT1': 'arcsec',\n+        'CUNIT2': 'arcsec',\n+        'CUNIT3': 'Angstrom',\n+        'CTYPE1': 'HPLN-TAN',\n+        'CTYPE2': 'HPLT-TAN',\n+        'CTYPE3': 'WAVE',\n+        'CRVAL1': 0.0,\n+        'CRVAL2': 0.0,\n+        'CRVAL3': 1.05,\n+        'DATE-OBS': '2023-10-25T00:00:00'\n+    }\n+    fits_wcs = astropy.wcs.WCS(header=wcs_header)\n+\n+    frame = astropy.wcs.utils.wcs_to_celestial_frame(fits_wcs)\n+    pt = SkyCoord(Tx=0 * u.arcsec, Ty=0 * u.arcsec, frame=frame)\n+\n+    # The slice is for the first wavelength. The '0' slices the first numpy\n+    # axis, which corresponds to the last FITS WCS axis (wavelength).\n+    ll_sliced_wcs = SlicedLowLevelWCS(fits_wcs, 0)\n+    hl_sliced_wcs = HighLevelWCSWrapper(ll_sliced_wcs)\n+\n+    pixel_coords = hl_sliced_wcs.world_to_pixel(pt)\n+\n+    # The expected result is the center of the spatial axes, which are 0-indexed.\n+    # CRPIX is 1-based, so we subtract 1.\n+    expected_coords = (wcs_header['CRPIX1'] - 1, wcs_header['CRPIX2'] - 1)\n+\n+    assert_allclose(pixel_coords, expected_coords, rtol=1e-5)\n"
    },
    "django__django-14053": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/staticfiles_tests/test_hashed_storage.py",
        "reproduced_bug_commands": [
            "./tests/runtests.py staticfiles_tests.test_hashed_storage"
        ],
        "reproduced_bug_patch": "diff --git a/tests/staticfiles_tests/test_hashed_storage.py b/tests/staticfiles_tests/test_hashed_storage.py\nnew file mode 100644\nindex 0000000000..2d14acda9d\n--- /dev/null\n+++ b/tests/staticfiles_tests/test_hashed_storage.py\n@@ -0,0 +1,541 @@\n+import os\n+import shutil\n+import sys\n+import tempfile\n+import unittest\n+from io import StringIO\n+from pathlib import Path\n+from unittest import mock\n+\n+from django.conf import settings\n+from django.contrib.staticfiles import finders, storage\n+from django.contrib.staticfiles.management.commands.collectstatic import (\n+    Command as CollectstaticCommand,\n+)\n+from django.core.management import call_command\n+from django.test import override_settings\n+\n+from .cases import CollectionTestCase\n+from .settings import TEST_ROOT\n+\n+\n+def hashed_file_path(test, path):\n+    fullpath = test.render_template(test.static_template_snippet(path))\n+    return fullpath.replace(settings.STATIC_URL, '')\n+\n+\n+class TestHashedFiles:\n+    hashed_file_path = hashed_file_path\n+\n+    def setUp(self):\n+        self._max_post_process_passes = storage.staticfiles_storage.max_post_process_passes\n+        super().setUp()\n+\n+    def tearDown(self):\n+        # Clear hashed files to avoid side effects among tests.\n+        storage.staticfiles_storage.hashed_files.clear()\n+        storage.staticfiles_storage.max_post_process_passes = self._max_post_process_passes\n+\n+    def assertPostCondition(self):\n+        \"\"\"\n+        Assert post conditions for a test are met. Must be manually called at\n+        the end of each test.\n+        \"\"\"\n+        pass\n+\n+    def test_template_tag_return(self):\n+        self.assertStaticRaises(ValueError, \"does/not/exist.png\", \"/static/does/not/exist.png\")\n+        self.assertStaticRenders(\"test/file.txt\", \"/static/test/file.dad0999e4f8f.txt\")\n+        self.assertStaticRenders(\"test/file.txt\", \"/static/test/file.dad0999e4f8f.txt\", asvar=True)\n+        self.assertStaticRenders(\"cached/styles.css\", \"/static/cached/styles.5e0040571e1a.css\")\n+        self.assertStaticRenders(\"path/\", \"/static/path/\")\n+        self.assertStaticRenders(\"path/?query\", \"/static/path/?query\")\n+        self.assertPostCondition()\n+\n+    def test_template_tag_simple_content(self):\n+        relpath = self.hashed_file_path(\"cached/styles.css\")\n+        self.assertEqual(relpath, \"cached/styles.5e0040571e1a.css\")\n+        with storage.staticfiles_storage.open(relpath) as relfile:\n+            content = relfile.read()\n+            self.assertNotIn(b\"cached/other.css\", content)\n+            self.assertIn(b\"other.d41d8cd98f00.css\", content)\n+        self.assertPostCondition()\n+\n+    def test_path_ignored_completely(self):\n+        relpath = self.hashed_file_path(\"cached/css/ignored.css\")\n+        self.assertEqual(relpath, \"cached/css/ignored.554da52152af.css\")\n+        with storage.staticfiles_storage.open(relpath) as relfile:\n+            content = relfile.read()\n+            self.assertIn(b'#foobar', content)\n+            self.assertIn(b'http:foobar', content)\n+            self.assertIn(b'https:foobar', content)\n+            self.assertIn(b'data:foobar', content)\n+            self.assertIn(b'chrome:foobar', content)\n+            self.assertIn(b'//foobar', content)\n+        self.assertPostCondition()\n+\n+    def test_path_with_querystring(self):\n+        relpath = self.hashed_file_path(\"cached/styles.css?spam=eggs\")\n+        self.assertEqual(relpath, \"cached/styles.5e0040571e1a.css?spam=eggs\")\n+        with storage.staticfiles_storage.open(\"cached/styles.5e0040571e1a.css\") as relfile:\n+            content = relfile.read()\n+            self.assertNotIn(b\"cached/other.css\", content)\n+            self.assertIn(b\"other.d41d8cd98f00.css\", content)\n+        self.assertPostCondition()\n+\n+    def test_path_with_fragment(self):\n+        relpath = self.hashed_file_path(\"cached/styles.css#eggs\")\n+        self.assertEqual(relpath, \"cached/styles.5e0040571e1a.css#eggs\")\n+        with storage.staticfiles_storage.open(\"cached/styles.5e0040571e1a.css\") as relfile:\n+            content = relfile.read()\n+            self.assertNotIn(b\"cached/other.css\", content)\n+            self.assertIn(b\"other.d41d8cd98f00.css\", content)\n+        self.assertPostCondition()\n+\n+    def test_path_with_querystring_and_fragment(self):\n+        relpath = self.hashed_file_path(\"cached/css/fragments.css\")\n+        self.assertEqual(relpath, \"cached/css/fragments.a60c0e74834f.css\")\n+        with storage.staticfiles_storage.open(relpath) as relfile:\n+            content = relfile.read()\n+            self.assertIn(b'fonts/font.b9b105392eb8.eot?#iefix', content)\n+            self.assertIn(b'fonts/font.b8d603e42714.svg#webfontIyfZbseF', content)\n+            self.assertIn(b'fonts/font.b8d603e42714.svg#path/to/../../fonts/font.svg', content)\n+            self.assertIn(b'data:font/woff;charset=utf-8;base64,d09GRgABAAAAADJoAA0AAAAAR2QAAQAAAAAAAAAAAAA', content)\n+            self.assertIn(b'#default#VML', content)\n+        self.assertPostCondition()\n+\n+    def test_template_tag_absolute(self):\n+        relpath = self.hashed_file_path(\"cached/absolute.css\")\n+        self.assertEqual(relpath, \"cached/absolute.eb04def9f9a4.css\")\n+        with storage.staticfiles_storage.open(relpath) as relfile:\n+            content = relfile.read()\n+            self.assertNotIn(b\"/static/cached/styles.css\", content)\n+            self.assertIn(b\"/static/cached/styles.5e0040571e1a.css\", content)\n+            self.assertNotIn(b\"/static/styles_root.css\", content)\n+            self.assertIn(b\"/static/styles_root.401f2509a628.css\", content)\n+            self.assertIn(b'/static/cached/img/relative.acae32e4532b.png', content)\n+        self.assertPostCondition()\n+\n+    def test_template_tag_absolute_root(self):\n+        \"\"\"\n+        Like test_template_tag_absolute, but for a file in STATIC_ROOT (#26249).\n+        \"\"\"\n+        relpath = self.hashed_file_path(\"absolute_root.css\")\n+        self.assertEqual(relpath, \"absolute_root.f821df1b64f7.css\")\n+        with storage.staticfiles_storage.open(relpath) as relfile:\n+            content = relfile.read()\n+            self.assertNotIn(b\"/static/styles_root.css\", content)\n+            self.assertIn(b\"/static/styles_root.401f2509a628.css\", content)\n+        self.assertPostCondition()\n+\n+    def test_template_tag_relative(self):\n+        relpath = self.hashed_file_path(\"cached/relative.css\")\n+        self.assertEqual(relpath, \"cached/relative.c3e9e1ea6f2e.css\")\n+        with storage.staticfiles_storage.open(relpath) as relfile:\n+            content = relfile.read()\n+            self.assertNotIn(b\"../cached/styles.css\", content)\n+            self.assertNotIn(b'@import \"styles.css\"', content)\n+            self.assertNotIn(b'url(img/relative.png)', content)\n+            self.assertIn(b'url(\"img/relative.acae32e4532b.png\")', content)\n+            self.assertIn(b\"../cached/styles.5e0040571e1a.css\", content)\n+        self.assertPostCondition()\n+\n+    def test_import_replacement(self):\n+        \"See #18050\"\n+        relpath = self.hashed_file_path(\"cached/import.css\")\n+        self.assertEqual(relpath, \"cached/import.f53576679e5a.css\")\n+        with storage.staticfiles_storage.open(relpath) as relfile:\n+            self.assertIn(b'import url(\"styles.5e0040571e1a.css\")', relfile.read())\n+        self.assertPostCondition()\n+\n+    def test_template_tag_deep_relative(self):\n+        relpath = self.hashed_file_path(\"cached/css/window.css\")\n+        self.assertEqual(relpath, \"cached/css/window.5d5c10836967.css\")\n+        with storage.staticfiles_storage.open(relpath) as relfile:\n+            content = relfile.read()\n+            self.assertNotIn(b'url(img/window.png)', content)\n+            self.assertIn(b'url(\"img/window.acae32e4532b.png\")', content)\n+        self.assertPostCondition()\n+\n+    def test_template_tag_url(self):\n+        relpath = self.hashed_file_path(\"cached/url.css\")\n+        self.assertEqual(relpath, \"cached/url.902310b73412.css\")\n+        with storage.staticfiles_storage.open(relpath) as relfile:\n+            self.assertIn(b\"https://\", relfile.read())\n+        self.assertPostCondition()\n+\n+    @override_settings(\n+        STATICFILES_DIRS=[os.path.join(TEST_ROOT, 'project', 'loop')],\n+        STATICFILES_FINDERS=['django.contrib.staticfiles.finders.FileSystemFinder'],\n+    )\n+    def test_import_loop(self):\n+        finders.get_finder.cache_clear()\n+        err = StringIO()\n+        with self.assertRaisesMessage(RuntimeError, 'Max post-process passes exceeded'):\n+            call_command('collectstatic', interactive=False, verbosity=0, stderr=err)\n+        self.assertEqual(\"Post-processing 'All' failed!\\n\\n\", err.getvalue())\n+        self.assertPostCondition()\n+\n+    def test_post_processing(self):\n+        \"\"\"\n+        post_processing behaves correctly.\n+\n+        Files that are alterable should always be post-processed; files that\n+        aren't should be skipped.\n+\n+        collectstatic has already been called once in setUp() for this testcase,\n+        therefore we check by verifying behavior on a second run.\n+        \"\"\"\n+        collectstatic_args = {\n+            'interactive': False,\n+            'verbosity': 0,\n+            'link': False,\n+            'clear': False,\n+            'dry_run': False,\n+            'post_process': True,\n+            'use_default_ignore_patterns': True,\n+            'ignore_patterns': ['*.ignoreme'],\n+        }\n+\n+        collectstatic_cmd = CollectstaticCommand()\n+        collectstatic_cmd.set_options(**collectstatic_args)\n+        stats = collectstatic_cmd.collect()\n+        self.assertIn(os.path.join('cached', 'css', 'window.css'), stats['post_processed'])\n+        self.assertIn(os.path.join('cached', 'css', 'img', 'window.png'), stats['unmodified'])\n+        self.assertIn(os.path.join('test', 'nonascii.css'), stats['post_processed'])\n+        self.assertPostCondition()\n+\n+    def test_css_import_case_insensitive(self):\n+        relpath = self.hashed_file_path(\"cached/styles_insensitive.css\")\n+        self.assertEqual(relpath, \"cached/styles_insensitive.3fa427592a53.css\")\n+        with storage.staticfiles_storage.open(relpath) as relfile:\n+            content = relfile.read()\n+            self.assertNotIn(b\"cached/other.css\", content)\n+            self.assertIn(b\"other.d41d8cd98f00.css\", content)\n+        self.assertPostCondition()\n+\n+    @override_settings(\n+        STATICFILES_DIRS=[os.path.join(TEST_ROOT, 'project', 'faulty')],\n+        STATICFILES_FINDERS=['django.contrib.staticfiles.finders.FileSystemFinder'],\n+    )\n+    def test_post_processing_failure(self):\n+        \"\"\"\n+        post_processing indicates the origin of the error when it fails.\n+        \"\"\"\n+        finders.get_finder.cache_clear()\n+        err = StringIO()\n+        with self.assertRaises(Exception):\n+            call_command('collectstatic', interactive=False, verbosity=0, stderr=err)\n+        self.assertEqual(\"Post-processing 'faulty.css' failed!\\n\\n\", err.getvalue())\n+        self.assertPostCondition()\n+\n+\n+@override_settings(STATICFILES_STORAGE='staticfiles_tests.storage.ExtraPatternsStorage')\n+class TestExtraPatternsStorage(CollectionTestCase):\n+\n+    def setUp(self):\n+        storage.staticfiles_storage.hashed_files.clear()  # avoid cache interference\n+        super().setUp()\n+\n+    def cached_file_path(self, path):\n+        fullpath = self.render_template(self.static_template_snippet(path))\n+        return fullpath.replace(settings.STATIC_URL, '')\n+\n+    def test_multi_extension_patterns(self):\n+        \"\"\"\n+        With storage classes having several file extension patterns, only the\n+        files matching a specific file pattern should be affected by the\n+        substitution (#19670).\n+        \"\"\"\n+        # CSS files shouldn't be touched by JS patterns.\n+        relpath = self.cached_file_path(\"cached/import.css\")\n+        self.assertEqual(relpath, \"cached/import.f53576679e5a.css\")\n+        with storage.staticfiles_storage.open(relpath) as relfile:\n+            self.assertIn(b'import url(\"styles.5e0040571e1a.css\")', relfile.read())\n+\n+        # Confirm JS patterns have been applied to JS files.\n+        relpath = self.cached_file_path(\"cached/test.js\")\n+        self.assertEqual(relpath, \"cached/test.388d7a790d46.js\")\n+        with storage.staticfiles_storage.open(relpath) as relfile:\n+            self.assertIn(b'JS_URL(\"import.f53576679e5a.css\")', relfile.read())\n+\n+\n+@override_settings(\n+    STATICFILES_STORAGE='django.contrib.staticfiles.storage.ManifestStaticFilesStorage',\n+)\n+class TestCollectionManifestStorage(TestHashedFiles, CollectionTestCase):\n+    \"\"\"\n+    Tests for the Cache busting storage\n+    \"\"\"\n+    def setUp(self):\n+        super().setUp()\n+\n+        temp_dir = tempfile.mkdtemp()\n+        os.makedirs(os.path.join(temp_dir, 'test'))\n+        self._clear_filename = os.path.join(temp_dir, 'test', 'cleared.txt')\n+        with open(self._clear_filename, 'w') as f:\n+            f.write('to be deleted in one test')\n+\n+        self.patched_settings = self.settings(\n+            STATICFILES_DIRS=settings.STATICFILES_DIRS + [temp_dir],\n+        )\n+        self.patched_settings.enable()\n+        self.addCleanup(shutil.rmtree, temp_dir)\n+        self._manifest_strict = storage.staticfiles_storage.manifest_strict\n+\n+    def tearDown(self):\n+        self.patched_settings.disable()\n+\n+        if os.path.exists(self._clear_filename):\n+            os.unlink(self._clear_filename)\n+\n+        storage.staticfiles_storage.manifest_strict = self._manifest_strict\n+        super().tearDown()\n+\n+    def assertPostCondition(self):\n+        hashed_files = storage.staticfiles_storage.hashed_files\n+        # The in-memory version of the manifest matches the one on disk\n+        # since a properly created manifest should cover all filenames.\n+        if hashed_files:\n+            manifest = storage.staticfiles_storage.load_manifest()\n+            self.assertEqual(hashed_files, manifest)\n+\n+    def test_manifest_exists(self):\n+        filename = storage.staticfiles_storage.manifest_name\n+        path = storage.staticfiles_storage.path(filename)\n+        self.assertTrue(os.path.exists(path))\n+\n+    def test_manifest_does_not_exist(self):\n+        storage.staticfiles_storage.manifest_name = 'does.not.exist.json'\n+        self.assertIsNone(storage.staticfiles_storage.read_manifest())\n+\n+    def test_manifest_does_not_ignore_permission_error(self):\n+        with mock.patch('builtins.open', side_effect=PermissionError):\n+            with self.assertRaises(PermissionError):\n+                storage.staticfiles_storage.read_manifest()\n+\n+    def test_loaded_cache(self):\n+        self.assertNotEqual(storage.staticfiles_storage.hashed_files, {})\n+        manifest_content = storage.staticfiles_storage.read_manifest()\n+        self.assertIn(\n+            '\"version\": \"%s\"' % storage.staticfiles_storage.manifest_version,\n+            manifest_content\n+        )\n+\n+    def test_parse_cache(self):\n+        hashed_files = storage.staticfiles_storage.hashed_files\n+        manifest = storage.staticfiles_storage.load_manifest()\n+        self.assertEqual(hashed_files, manifest)\n+\n+    def test_clear_empties_manifest(self):\n+        cleared_file_name = storage.staticfiles_storage.clean_name(os.path.join('test', 'cleared.txt'))\n+        # collect the additional file\n+        self.run_collectstatic()\n+\n+        hashed_files = storage.staticfiles_storage.hashed_files\n+        self.assertIn(cleared_file_name, hashed_files)\n+\n+        manifest_content = storage.staticfiles_storage.load_manifest()\n+        self.assertIn(cleared_file_name, manifest_content)\n+\n+        original_path = storage.staticfiles_storage.path(cleared_file_name)\n+        self.assertTrue(os.path.exists(original_path))\n+\n+        # delete the original file form the app, collect with clear\n+        os.unlink(self._clear_filename)\n+        self.run_collectstatic(clear=True)\n+\n+        self.assertFileNotFound(original_path)\n+\n+        hashed_files = storage.staticfiles_storage.hashed_files\n+        self.assertNotIn(cleared_file_name, hashed_files)\n+\n+        manifest_content = storage.staticfiles_storage.load_manifest()\n+        self.assertNotIn(cleared_file_name, manifest_content)\n+\n+    def test_missing_entry(self):\n+        missing_file_name = 'cached/missing.css'\n+        configured_storage = storage.staticfiles_storage\n+        self.assertNotIn(missing_file_name, configured_storage.hashed_files)\n+\n+        # File name not found in manifest\n+        with self.assertRaisesMessage(ValueError, \"Missing staticfiles manifest entry for '%s'\" % missing_file_name):\n+            self.hashed_file_path(missing_file_name)\n+\n+        configured_storage.manifest_strict = False\n+        # File doesn't exist on disk\n+        err_msg = \"The file '%s' could not be found with %r.\" % (missing_file_name, configured_storage._wrapped)\n+        with self.assertRaisesMessage(ValueError, err_msg):\n+            self.hashed_file_path(missing_file_name)\n+\n+        content = StringIO()\n+        content.write('Found')\n+        configured_storage.save(missing_file_name, content)\n+        # File exists on disk\n+        self.hashed_file_path(missing_file_name)\n+\n+    def test_intermediate_files(self):\n+        cached_files = os.listdir(os.path.join(settings.STATIC_ROOT, 'cached'))\n+        # Intermediate files shouldn't be created for reference.\n+        self.assertEqual(\n+            len([\n+                cached_file\n+                for cached_file in cached_files\n+                if cached_file.startswith('relative.')\n+            ]),\n+            2,\n+        )\n+\n+    def test_post_process_yields_each_file_only_once(self):\n+        \"\"\"\n+        HashedFilesMixin.post_process() should not yield the same file multiple\n+        times.\n+        \"\"\"\n+        # The base setup runs collectstatic once, but to get the stats back\n+        # from the command, we run it again.\n+        collectstatic_cmd = CollectstaticCommand()\n+        # The options are based on the existing test_post_processing test.\n+        collectstatic_cmd.set_options(\n+            interactive=False,\n+            verbosity=0,\n+            link=False,\n+            clear=False,\n+            dry_run=False,\n+            post_process=True,\n+            use_default_ignore_patterns=True,\n+            ignore_patterns=['*.ignoreme'],\n+        )\n+        stats = collectstatic_cmd.collect()\n+        post_processed_files = stats['post_processed']\n+        self.assertEqual(\n+            len(post_processed_files),\n+            len(set(post_processed_files)),\n+            \"post_process() yielded some files more than once.\"\n+        )\n+\n+\n+@override_settings(STATICFILES_STORAGE='staticfiles_tests.storage.NoneHashStorage')\n+class TestCollectionNoneHashStorage(CollectionTestCase):\n+    hashed_file_path = hashed_file_path\n+\n+    def test_hashed_name(self):\n+        relpath = self.hashed_file_path('cached/styles.css')\n+        self.assertEqual(relpath, 'cached/styles.css')\n+\n+\n+@override_settings(STATICFILES_STORAGE='staticfiles_tests.storage.SimpleStorage')\n+class TestCollectionSimpleStorage(CollectionTestCase):\n+    hashed_file_path = hashed_file_path\n+\n+    def setUp(self):\n+        storage.staticfiles_storage.hashed_files.clear()  # avoid cache interference\n+        super().setUp()\n+\n+    def test_template_tag_return(self):\n+        self.assertStaticRaises(ValueError, \"does/not/exist.png\", \"/static/does/not/exist.png\")\n+        self.assertStaticRenders(\"test/file.txt\", \"/static/test/file.deploy12345.txt\")\n+        self.assertStaticRenders(\"cached/styles.css\", \"/static/cached/styles.deploy12345.css\")\n+        self.assertStaticRenders(\"path/\", \"/static/path/\")\n+        self.assertStaticRenders(\"path/?query\", \"/static/path/?query\")\n+\n+    def test_template_tag_simple_content(self):\n+        relpath = self.hashed_file_path(\"cached/styles.css\")\n+        self.assertEqual(relpath, \"cached/styles.deploy12345.css\")\n+        with storage.staticfiles_storage.open(relpath) as relfile:\n+            content = relfile.read()\n+            self.assertNotIn(b\"cached/other.css\", content)\n+            self.assertIn(b\"other.deploy12345.css\", content)\n+\n+\n+class CustomStaticFilesStorage(storage.StaticFilesStorage):\n+    \"\"\"\n+    Used in TestStaticFilePermissions\n+    \"\"\"\n+    def __init__(self, *args, **kwargs):\n+        kwargs['file_permissions_mode'] = 0o640\n+        kwargs['directory_permissions_mode'] = 0o740\n+        super().__init__(*args, **kwargs)\n+\n+\n+@unittest.skipIf(sys.platform == 'win32', \"Windows only partially supports chmod.\")\n+class TestStaticFilePermissions(CollectionTestCase):\n+\n+    command_params = {\n+        'interactive': False,\n+        'verbosity': 0,\n+        'ignore_patterns': ['*.ignoreme'],\n+    }\n+\n+    def setUp(self):\n+        self.umask = 0o027\n+        self.old_umask = os.umask(self.umask)\n+        super().setUp()\n+\n+    def tearDown(self):\n+        os.umask(self.old_umask)\n+        super().tearDown()\n+\n+    # Don't run collectstatic command in this test class.\n+    def run_collectstatic(self, **kwargs):\n+        pass\n+\n+    @override_settings(\n+        FILE_UPLOAD_PERMISSIONS=0o655,\n+        FILE_UPLOAD_DIRECTORY_PERMISSIONS=0o765,\n+    )\n+    def test_collect_static_files_permissions(self):\n+        call_command('collectstatic', **self.command_params)\n+        static_root = Path(settings.STATIC_ROOT)\n+        test_file = static_root / 'test.txt'\n+        file_mode = test_file.stat().st_mode & 0o777\n+        self.assertEqual(file_mode, 0o655)\n+        tests = [\n+            static_root / 'subdir',\n+            static_root / 'nested',\n+            static_root / 'nested' / 'css',\n+        ]\n+        for directory in tests:\n+            with self.subTest(directory=directory):\n+                dir_mode = directory.stat().st_mode & 0o777\n+                self.assertEqual(dir_mode, 0o765)\n+\n+    @override_settings(\n+        FILE_UPLOAD_PERMISSIONS=None,\n+        FILE_UPLOAD_DIRECTORY_PERMISSIONS=None,\n+    )\n+    def test_collect_static_files_default_permissions(self):\n+        call_command('collectstatic', **self.command_params)\n+        static_root = Path(settings.STATIC_ROOT)\n+        test_file = static_root / 'test.txt'\n+        file_mode = test_file.stat().st_mode & 0o777\n+        self.assertEqual(file_mode, 0o666 & ~self.umask)\n+        tests = [\n+            static_root / 'subdir',\n+            static_root / 'nested',\n+            static_root / 'nested' / 'css',\n+        ]\n+        for directory in tests:\n+            with self.subTest(directory=directory):\n+                dir_mode = directory.stat().st_mode & 0o777\n+                self.assertEqual(dir_mode, 0o777 & ~self.umask)\n+\n+    @override_settings(\n+        FILE_UPLOAD_PERMISSIONS=0o655,\n+        FILE_UPLOAD_DIRECTORY_PERMISSIONS=0o765,\n+        STATICFILES_STORAGE='staticfiles_tests.test_hashed_storage.CustomStaticFilesStorage',\n+    )\n+    def test_collect_static_files_subclass_of_static_storage(self):\n+        call_command('collectstatic', **self.command_params)\n+        static_root = Path(settings.STATIC_ROOT)\n+        test_file = static_root / 'test.txt'\n+        file_mode = test_file.stat().st_mode & 0o777\n+        self.assertEqual(file_mode, 0o640)\n+        tests = [\n+            static_root / 'subdir',\n+            static_root / 'nested',\n+            static_root / 'nested' / 'css',\n+        ]\n+        for directory in tests:\n+            with self.subTest(directory=directory):\n+                dir_mode = directory.stat().st_mode & 0o777\n+                self.assertEqual(dir_mode, 0o740)\n"
    },
    "pydata__xarray-6938": {
        "reproduced_bug": true,
        "reproduced_bug_file": "xarray/tests/test_swap_dims.py",
        "reproduced_bug_commands": [
            "pytest xarray/tests/test_swap_dims.py"
        ],
        "reproduced_bug_patch": "diff --git a/xarray/tests/test_swap_dims.py b/xarray/tests/test_swap_dims.py\nnew file mode 100644\nindex 00000000..ade5683a\n--- /dev/null\n+++ b/xarray/tests/test_swap_dims.py\n@@ -0,0 +1,35 @@\n+import numpy as np\n+import pytest\n+import xarray as xr\n+\n+\n+def test_swap_dims_inplace_modification():\n+    \"\"\"\n+    Regression test for GH6795, where .swap_dims() can modify\n+    the original object in certain cases.\n+    \"\"\"\n+    nz = 11\n+    ds = xr.Dataset(\n+        data_vars={\n+            \"y\": (\"z\", np.random.rand(nz)),\n+            \"lev\": (\"z\", np.arange(nz) * 10),\n+        },\n+    )\n+\n+    # This sequence of operations, taken from the bug report, creates a\n+    # Dataset that looks like the original but triggers the bug.\n+    ds2 = (\n+        ds.swap_dims(z=\"lev\")\n+        .rename_dims(lev=\"z\")\n+        .reset_index(\"lev\")\n+        .reset_coords()\n+    )\n+\n+    # This call to .swap_dims() should return a new, modified Dataset\n+    # and leave `ds2` unchanged.\n+    ds2.swap_dims(z=\"lev\")\n+\n+    # The bug is that the dimensions of the 'lev' DataArray within `ds2`\n+    # are modified in place. The assertion checks that the dimensions\n+    # remain unchanged.\n+    assert ds2[\"lev\"].dims == (\"z\",)\n"
    },
    "scikit-learn__scikit-learn-10844": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/metrics/cluster/tests/test_fowlkes_mallows_score_overflow.py",
        "reproduced_bug_commands": [
            "pytest sklearn/metrics/cluster/tests/test_fowlkes_mallows_score_overflow.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/metrics/cluster/tests/test_fowlkes_mallows_score_overflow.py b/sklearn/metrics/cluster/tests/test_fowlkes_mallows_score_overflow.py\nnew file mode 100644\nindex 0000000000..6dd7a94ccb\n--- /dev/null\n+++ b/sklearn/metrics/cluster/tests/test_fowlkes_mallows_score_overflow.py\n@@ -0,0 +1,25 @@\n+import numpy as np\n+\n+from sklearn.metrics.cluster.supervised import fowlkes_mallows_score\n+from sklearn.utils.testing import assert_almost_equal\n+\n+\n+def test_fowlkes_mallows_score_overflow():\n+    \"\"\"Test for overflow in fowlkes_mallows_score with large clusters.\"\"\"\n+    # When the number of samples in clusters is large, the intermediate\n+    # values `pk` and `qk` in the fowlkes_mallows_score calculation can\n+    # become very large. Their product can overflow standard integer types,\n+    # leading to incorrect results (e.g., NaN).\n+    #\n+    # We create two large clusters to ensure the product `pk * qk` overflows\n+    # even 64-bit integers.\n+    n_samples_per_cluster = 80000\n+    labels = np.array([0] * n_samples_per_cluster + [1] * n_samples_per_cluster,\n+                      dtype=np.int32)\n+\n+    # For a perfect clustering, the score should be 1.0.\n+    # The buggy version calculates a large `pk` and `qk`, their product\n+    # overflows, resulting in a negative number under the square root,\n+    # and a final score of NaN.\n+    score = fowlkes_mallows_score(labels, labels)\n+    assert_almost_equal(score, 1.0)\n"
    },
    "sphinx-doc__sphinx-10466": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_build_gettext_catalog.py",
        "reproduced_bug_commands": [
            "pytest tests/test_build_gettext_catalog.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_build_gettext_catalog.py b/tests/test_build_gettext_catalog.py\nnew file mode 100644\nindex 000000000..9ff37c8b6\n--- /dev/null\n+++ b/tests/test_build_gettext_catalog.py\n@@ -0,0 +1,31 @@\n+import pytest\n+from unittest.mock import Mock\n+\n+from sphinx.builders.gettext import Catalog\n+\n+\n+def test_message_locations_are_deduplicated():\n+    \"\"\"Test that duplicate locations in a message are removed.\"\"\"\n+    catalog = Catalog()\n+    msgid = \"Type\"\n+\n+    # Simulate multiple origins pointing to the same file and line,\n+    # as described in the bug report.\n+    locations = [\n+        ('../../manual/render/shader_nodes/vector/vector_rotate.rst', 38),\n+        ('../../manual/modeling/hair.rst', 0),\n+        ('../../manual/modeling/hair.rst', 0),\n+        ('../../manual/modeling/hair.rst', 0),\n+        ('../../manual/modeling/metas/properties.rst', 92),\n+    ]\n+\n+    for i, (source, line) in enumerate(locations):\n+        origin = Mock(source=source, line=line, uid=f'uid{i}')\n+        catalog.add(msgid, origin)\n+\n+    messages = list(catalog)\n+    message = messages[0]\n+\n+    # Before fix, message.locations has 5 items because of duplicates.\n+    # After fix, it should have 3 unique items.\n+    assert len(message.locations) == 3\n"
    },
    "astropy__astropy-13977": {
        "reproduced_bug": true,
        "reproduced_bug_file": "astropy/units/tests/test_quantity_duck_typing.py",
        "reproduced_bug_commands": [
            "pytest astropy/units/tests/test_quantity_duck_typing.py"
        ],
        "reproduced_bug_patch": "diff --git a/astropy/units/tests/test_quantity_duck_typing.py b/astropy/units/tests/test_quantity_duck_typing.py\nnew file mode 100644\nindex 0000000000..b629b4072c\n--- /dev/null\n+++ b/astropy/units/tests/test_quantity_duck_typing.py\n@@ -0,0 +1,49 @@\n+import dataclasses\n+\n+import numpy as np\n+import pytest\n+\n+from astropy import units as u\n+\n+\n+# Per issue description: https://github.com/astropy/astropy/issues/11823\n+@dataclasses.dataclass\n+class DuckArray(np.lib.mixins.NDArrayOperatorsMixin):\n+    \"\"\"\n+    Minimal duck type of astropy.units.Quantity defined in the issue.\n+    See: https://github.com/astropy/astropy/issues/11823\n+    \"\"\"\n+\n+    ndarray: u.Quantity\n+\n+    @property\n+    def unit(self) -> u.UnitBase:\n+        return self.ndarray.unit\n+\n+    def __array_ufunc__(self, function, method, *inputs, **kwargs):\n+        inputs = [inp.ndarray if isinstance(inp, DuckArray) else inp for inp in inputs]\n+\n+        for inp in inputs:\n+            if isinstance(inp, np.ndarray):\n+                result = inp.__array_ufunc__(function, method, *inputs, **kwargs)\n+                if result is not NotImplemented:\n+                    return DuckArray(result)\n+\n+        return NotImplemented\n+\n+\n+def test_ufunc_duck_type_coercion_return_not_implemented():\n+    \"\"\"\n+    Test that Quantity.__array_ufunc__ returns NotImplemented for\n+    incompatible types, allowing for reflected operations on duck types.\n+    \"\"\"\n+    # This operation currently fails with a ValueError.\n+    # When fixed, Quantity.__array_ufunc__ should return NotImplemented,\n+    # which will then call the __radd__ of the DuckArray, which is implemented\n+    # via its own __array_ufunc__.\n+    result = (1 * u.m) + DuckArray(1 * u.mm)\n+\n+    # The result of the reflected operation should be a DuckArray\n+    # containing the correct value.\n+    expected = DuckArray(1001 * u.mm)\n+    assert result == expected\n"
    },
    "django__django-14089": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/utils_tests/test_orderedset.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py utils_tests.test_orderedset"
        ],
        "reproduced_bug_patch": "diff --git a/tests/utils_tests/test_orderedset.py b/tests/utils_tests/test_orderedset.py\nnew file mode 100644\nindex 0000000000..93fad43b8f\n--- /dev/null\n+++ b/tests/utils_tests/test_orderedset.py\n@@ -0,0 +1,22 @@\n+\"\"\"\n+Tests for stuff in django.utils.datastructures.\n+\"\"\"\n+\n+import copy\n+import pickle\n+\n+from django.test import SimpleTestCase\n+from django.utils.datastructures import (\n+    CaseInsensitiveMapping, DictWrapper, ImmutableList, MultiValueDict,\n+    MultiValueDictKeyError, OrderedSet,\n+)\n+\n+\n+class OrderedSetTests(SimpleTestCase):\n+\n+    def test_reversed(self):\n+        \"\"\"\n+        reversed() can be called on an OrderedSet.\n+        \"\"\"\n+        s = OrderedSet([1, 2, 3, 4])\n+        self.assertEqual(list(reversed(s)), [4, 3, 2, 1])\n"
    },
    "django__django-16901": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "pydata__xarray-6992": {
        "reproduced_bug": true,
        "reproduced_bug_file": "xarray/tests/test_reset_index.py",
        "reproduced_bug_commands": [
            "pytest xarray/tests/test_reset_index.py"
        ],
        "reproduced_bug_patch": "diff --git a/xarray/tests/test_reset_index.py b/xarray/tests/test_reset_index.py\nnew file mode 100644\nindex 00000000..e427c85e\n--- /dev/null\n+++ b/xarray/tests/test_reset_index.py\n@@ -0,0 +1,21 @@\n+import numpy as np\n+import xarray as xr\n+\n+\n+def test_reset_index_drop_true_data_vars_len():\n+    \"\"\"\n+    Regression test for GH5921.\n+\n+    This test ensures that creating a multi-index and then resetting it with\n+    `drop=True` does not leave the Dataset in a corrupted state where\n+    accessing the length of the data variables would fail.\n+    \"\"\"\n+    ds = xr.Dataset(coords={\"a\": (\"x\", [1, 2, 3]), \"b\": (\"x\", [\"a\", \"b\", \"c\"])})\n+    actual = ds.set_index(z=[\"a\", \"b\"]).reset_index(\"z\", drop=True)\n+\n+    # The bug causes `len(actual.data_vars)` to raise a `ValueError` because\n+    # the internal `__len__` method returns a negative number. This test\n+    # will fail with that `ValueError`.\n+    # When the bug is fixed, `len(actual.data_vars)` will return a\n+    # non-negative integer, and the assertion will pass.\n+    assert len(actual.data_vars) >= 0\n"
    },
    "scikit-learn__scikit-learn-10908": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/feature_extraction/tests/test_text_issue_6488.py",
        "reproduced_bug_commands": [
            "pytest sklearn/feature_extraction/tests/test_text_issue_6488.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/feature_extraction/tests/test_text_issue_6488.py b/sklearn/feature_extraction/tests/test_text_issue_6488.py\nnew file mode 100644\nindex 0000000000..ddd24aa84e\n--- /dev/null\n+++ b/sklearn/feature_extraction/tests/test_text_issue_6488.py\n@@ -0,0 +1,21 @@\n+from sklearn.feature_extraction.text import CountVectorizer\n+from sklearn.utils.testing import assert_equal\n+\n+\n+def test_get_feature_names_with_vocabulary_before_fit():\n+    \"\"\"Test get_feature_names with vocabulary before fitting the vectorizer.\n+\n+    Checks that CountVectorizer.get_feature_names does not raise a\n+    NotFittedError if the vectorizer has not been fit, but was\n+    instantiated with a vocabulary.\n+\n+    This is a non-regression test for:\n+    https://github.com/scikit-learn/scikit-learn/issues/6488\n+    \"\"\"\n+    vocab = ['and', 'document', 'first', 'is', 'one',\n+             'second', 'the', 'third', 'this']\n+    vectorizer = CountVectorizer(vocabulary=vocab)\n+\n+    # Currently this raises a NotFittedError.\n+    feature_names = vectorizer.get_feature_names()\n+    assert_equal(feature_names, vocab)\n"
    },
    "sphinx-doc__sphinx-10614": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_ext_inheritance_diagram_dirhtml.py",
        "reproduced_bug_commands": [
            "pytest tests/test_ext_inheritance_diagram_dirhtml.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_ext_inheritance_diagram_dirhtml.py b/tests/test_ext_inheritance_diagram_dirhtml.py\nnew file mode 100644\nindex 000000000..ee9cab6c7\n--- /dev/null\n+++ b/tests/test_ext_inheritance_diagram_dirhtml.py\n@@ -0,0 +1,43 @@\n+import pytest\n+import re\n+\n+\n+@pytest.mark.sphinx(\n+    'dirhtml',\n+    testroot='ext-inheritance_diagram',\n+    confoverrides={'graphviz_output_format': 'svg'}\n+)\n+@pytest.mark.usefixtures('if_graphviz_found')\n+def test_inheritance_diagram_svg_links_in_nested_dirhtml(app, status, warning):\n+    \"\"\"\n+    Test that links in an inheritance diagram SVG are correct for nested\n+    documents when using the dirhtml builder.\n+    \"\"\"\n+    # Create a nested document with an inheritance diagram.\n+    # The `ext-inheritance_diagram` testroot provides the `test` module.\n+    (app.srcdir / 'foo').mkdir()\n+    (app.srcdir / 'foo' / 'index.rst').write_text(\n+        'Foo Page\\n========\\n\\n'\n+        '.. inheritance-diagram:: test.Bar\\n\\n'\n+        '.. autoclass:: test.Bar\\n',\n+        encoding='utf8'\n+    )\n+\n+    app.build()\n+\n+    html_path = app.outdir / 'foo' / 'index.html'\n+    content = html_path.read_text(encoding='utf8')\n+\n+    # Find the relative path to the SVG file from the <object> tag.\n+    match = re.search(r'<object data=\"([^\"]+)\"', content)\n+    assert match is not None\n+    svg_rel_path = match.group(1)\n+\n+    # The SVG's path is relative to the directory of the HTML file.\n+    svg_path = (html_path.parent / svg_rel_path).resolve()\n+    svg_content = svg_path.read_text(encoding='utf8')\n+\n+    # The link to `test.Bar` inside the SVG must be relative to the SVG's\n+    # location (in `_images/`), not the HTML file's location (`foo/`).\n+    # The correct link should go up one level from `_images/` and then into `foo/`.\n+    assert 'href=\"../foo/#test.Bar\"' in svg_content\n"
    },
    "astropy__astropy-14096": {
        "reproduced_bug": true,
        "reproduced_bug_file": "astropy/coordinates/tests/test_skycoord_subclass.py",
        "reproduced_bug_commands": [
            "pytest astropy/coordinates/tests/test_skycoord_subclass.py"
        ],
        "reproduced_bug_patch": "diff --git a/astropy/coordinates/tests/test_skycoord_subclass.py b/astropy/coordinates/tests/test_skycoord_subclass.py\nnew file mode 100644\nindex 0000000000..66ba9d714e\n--- /dev/null\n+++ b/astropy/coordinates/tests/test_skycoord_subclass.py\n@@ -0,0 +1,25 @@\n+import pytest\n+\n+from astropy import units as u\n+from astropy.coordinates import SkyCoord\n+\n+\n+def test_subclass_attribute_error():\n+    \"\"\"\n+    Test that a subclass of SkyCoord with a property that accesses a non-existent\n+    attribute provides a clear error message. This is a regression test for\n+    a bug where the error message was misleadingly reporting that the property\n+    itself did not exist.\n+    \"\"\"\n+\n+    class CustomCoord(SkyCoord):\n+        @property\n+        def prop(self):\n+            return self.random_attr\n+\n+    c = CustomCoord(\"00h42m30s\", \"+41d12m00s\", frame=\"icrs\")\n+\n+    with pytest.raises(AttributeError) as excinfo:\n+        c.prop\n+\n+    assert \"has no attribute 'random_attr'\" in str(excinfo.value)\n"
    },
    "django__django-14122": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "django__django-16938": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/serializers/test_m2m_select_related_serialization.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py serializers.test_m2m_select_related_serialization"
        ],
        "reproduced_bug_patch": "diff --git a/tests/serializers/test_m2m_select_related_serialization.py b/tests/serializers/test_m2m_select_related_serialization.py\nnew file mode 100644\nindex 0000000000..6e59b8953a\n--- /dev/null\n+++ b/tests/serializers/test_m2m_select_related_serialization.py\n@@ -0,0 +1,45 @@\n+from django.core import serializers\n+from django.core.exceptions import FieldError\n+from django.db import models\n+from django.test import TestCase\n+\n+\n+# Models inspired by the bug report.\n+class TestTagManager(models.Manager):\n+    def get_queryset(self):\n+        return super().get_queryset().select_related(\"master\")\n+\n+\n+class TestTagMaster(models.Model):\n+    name = models.CharField(max_length=120)\n+\n+\n+class TestTag(models.Model):\n+    objects = TestTagManager()\n+    name = models.CharField(max_length=120)\n+    master = models.ForeignKey(\n+        TestTagMaster, on_delete=models.SET_NULL, null=True, blank=True\n+    )\n+\n+\n+class TestModel(models.Model):\n+    name = models.CharField(max_length=120)\n+    tags = models.ManyToManyField(TestTag, blank=True)\n+\n+\n+class SerializationM2MSelectRelatedTests(TestCase):\n+    def test_serialization_of_m2m_with_custom_manager_using_select_related(self):\n+        \"\"\"\n+        Tests that serializing a M2M relation with a custom manager that\n+        uses select_related does not cause a FieldError. This test will fail\n+        until the bug is fixed.\n+        \"\"\"\n+        tag_master = TestTagMaster.objects.create(name=\"master\")\n+        tag = TestTag.objects.create(name=\"tag\", master=tag_master)\n+        test_obj = TestModel.objects.create(name=\"test\")\n+        test_obj.tags.add(tag)\n+\n+        # This call raises a FieldError due to the bug, which will cause this\n+        # test to fail. Once the bug is fixed, this line will execute\n+        # without error, and the test will pass.\n+        serializers.serialize(\"json\", [test_obj])\n"
    },
    "pydata__xarray-7229": {
        "reproduced_bug": true,
        "reproduced_bug_file": "xarray/tests/test_where.py",
        "reproduced_bug_commands": [
            "pytest xarray/tests/test_where.py"
        ],
        "reproduced_bug_patch": "diff --git a/xarray/tests/test_where.py b/xarray/tests/test_where.py\nnew file mode 100644\nindex 00000000..47efc295\n--- /dev/null\n+++ b/xarray/tests/test_where.py\n@@ -0,0 +1,17 @@\n+import pytest\n+import xarray as xr\n+from xarray.testing import assert_identical\n+\n+\n+def test_where_keep_attrs_coord_attributes():\n+    \"\"\"\n+    Test that ``xr.where`` with ``keep_attrs=True`` preserves coordinate\n+    attributes.\n+\n+    Regression test for GH6982.\n+    \"\"\"\n+    ds = xr.tutorial.load_dataset(\"air_temperature\")\n+    expected_coord = ds.air.time\n+    actual = xr.where(True, ds.air, ds.air, keep_attrs=True)\n+\n+    assert_identical(expected_coord, actual.time)\n"
    },
    "scikit-learn__scikit-learn-11310": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/model_selection/tests/test_refit_time.py",
        "reproduced_bug_commands": [
            "pytest sklearn/model_selection/tests/test_refit_time.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/model_selection/tests/test_refit_time.py b/sklearn/model_selection/tests/test_refit_time.py\nnew file mode 100644\nindex 0000000000..5954828847\n--- /dev/null\n+++ b/sklearn/model_selection/tests/test_refit_time.py\n@@ -0,0 +1,27 @@\n+import pytest\n+from sklearn.datasets import load_iris\n+from sklearn.ensemble import RandomForestClassifier\n+from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n+\n+\n+def test_search_cv_refit_time():\n+    \"\"\"Test that refit_time_ is recorded for BaseSearchCV.\"\"\"\n+    X, y = load_iris(return_X_y=True)\n+\n+    search_configs = [\n+        (GridSearchCV, {'param_grid': {'n_estimators': [2, 3]}}),\n+        (RandomizedSearchCV, {'param_distributions': {'n_estimators': [2, 3]},\n+                              'n_iter': 1})\n+    ]\n+\n+    for SearchCV, params in search_configs:\n+        search = SearchCV(\n+            estimator=RandomForestClassifier(random_state=0),\n+            **params,\n+            cv=3\n+        )\n+        search.fit(X, y)\n+\n+        assert hasattr(search, 'refit_time_')\n+        assert isinstance(search.refit_time_, float)\n+        assert search.refit_time_ >= 0\n"
    },
    "sphinx-doc__sphinx-10673": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_toctree_special_pages.py",
        "reproduced_bug_commands": [
            "mkdir -p tests/roots/test-toctree-special",
            "echo '.. toctree::\\n\\n   :maxdepth: 1\\n\\n   :caption: Indices and tables\\n\\n   genindex\\n\\n   modindex\\n\\n   search' > tests/roots/test-toctree-special/index.rst",
            "touch tests/roots/test-toctree-special/conf.py",
            "python -X dev -X warn_default_encoding -m pytest --durations 25 tests/test_toctree_special_pages.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_toctree_special_pages.py b/tests/test_toctree_special_pages.py\nnew file mode 100644\nindex 000000000..4fb1f4561\n--- /dev/null\n+++ b/tests/test_toctree_special_pages.py\n@@ -0,0 +1,14 @@\n+import pytest\n+\n+@pytest.mark.sphinx('html', testroot='toctree-special')\n+def test_toctree_should_not_warn_for_special_pages(app, status, warning):\n+    \"\"\"\n+    Test that including 'genindex', 'modindex', and 'search' in a toctree\n+    does not generate \"nonexisting document\" warnings.\n+\n+    This test is based on the issue where Sphinx incorrectly warns about\n+    these special pages not existing when they are included in a toctree.\n+    The test will pass if no warnings are emitted during the build.\n+    \"\"\"\n+    app.builder.build_all()\n+    assert warning.getvalue() == ''\n"
    },
    "astropy__astropy-14182": {
        "reproduced_bug": true,
        "reproduced_bug_file": "astropy/io/ascii/tests/test_write_rst.py",
        "reproduced_bug_commands": [
            "pytest astropy/io/ascii/tests/test_write_rst.py"
        ],
        "reproduced_bug_patch": "diff --git a/astropy/io/ascii/tests/test_write_rst.py b/astropy/io/ascii/tests/test_write_rst.py\nnew file mode 100644\nindex 0000000000..e00fab3b58\n--- /dev/null\n+++ b/astropy/io/ascii/tests/test_write_rst.py\n@@ -0,0 +1,32 @@\n+from io import StringIO\n+\n+import pytest\n+from astropy.table import QTable\n+import astropy.units as u\n+\n+from astropy.io import ascii\n+from astropy.io.ascii.tests.common import assert_equal\n+\n+\n+def assert_equal_splitlines(arg1, arg2):\n+    assert_equal(arg1.splitlines(), arg2.splitlines())\n+\n+\n+def test_write_rst_header_rows():\n+    \"\"\"\n+    Test writing a table with header_rows to the rst format.\n+    This failed with a TypeError in https://github.com/astropy/astropy/issues/11326.\n+    \"\"\"\n+    tbl = QTable({\"wave\": [350, 950] * u.nm, \"response\": [0.7, 1.2] * u.count})\n+    out = StringIO()\n+    tbl.write(out, format=\"ascii.rst\", header_rows=[\"name\", \"unit\"])\n+    expected = \"\"\"\\\n+======= ==========\n+  wave   response\n+    nm         ct\n+======= ==========\n+ 350.0       0.7\n+ 950.0       1.2\n+======= ==========\n+\"\"\"\n+    assert_equal_splitlines(out.getvalue(), expected)\n"
    },
    "django__django-14140": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/queries/test_q_combinatorics.py",
        "reproduced_bug_commands": [
            "./tests/runtests.py --verbosity 2 tests.queries.test_q_combinatorics"
        ],
        "reproduced_bug_patch": "diff --git a/tests/queries/test_q_combinatorics.py b/tests/queries/test_q_combinatorics.py\nnew file mode 100644\nindex 0000000000..093447bdee\n--- /dev/null\n+++ b/tests/queries/test_q_combinatorics.py\n@@ -0,0 +1,121 @@\n+from django.contrib.auth import get_user_model\n+from django.db.models import Exists, F, Q\n+from django.test import SimpleTestCase\n+\n+\n+class QTests(SimpleTestCase):\n+    def test_combine_and_empty(self):\n+        q = Q(x=1)\n+        self.assertEqual(q & Q(), q)\n+        self.assertEqual(Q() & q, q)\n+\n+        q = Q(x__in={}.keys())\n+        self.assertEqual(q & Q(), q)\n+        self.assertEqual(Q() & q, q)\n+\n+    def test_combine_and_both_empty(self):\n+        self.assertEqual(Q() & Q(), Q())\n+\n+    def test_combine_or_empty(self):\n+        q = Q(x=1)\n+        self.assertEqual(q | Q(), q)\n+        self.assertEqual(Q() | q, q)\n+\n+        q = Q(x__in={}.keys())\n+        self.assertEqual(q | Q(), q)\n+        self.assertEqual(Q() | q, q)\n+\n+    def test_combine_or_both_empty(self):\n+        self.assertEqual(Q() | Q(), Q())\n+\n+    def test_combine_not_q_object(self):\n+        obj = object()\n+        q = Q(x=1)\n+        with self.assertRaisesMessage(TypeError, str(obj)):\n+            q | obj\n+        with self.assertRaisesMessage(TypeError, str(obj)):\n+            q & obj\n+\n+    def test_deconstruct(self):\n+        q = Q(price__gt=F('discounted_price'))\n+        path, args, kwargs = q.deconstruct()\n+        self.assertEqual(path, 'django.db.models.Q')\n+        self.assertEqual(args, ())\n+        self.assertEqual(kwargs, {'price__gt': F('discounted_price')})\n+\n+    def test_deconstruct_negated(self):\n+        q = ~Q(price__gt=F('discounted_price'))\n+        path, args, kwargs = q.deconstruct()\n+        self.assertEqual(args, ())\n+        self.assertEqual(kwargs, {\n+            'price__gt': F('discounted_price'),\n+            '_negated': True,\n+        })\n+\n+    def test_deconstruct_or(self):\n+        q1 = Q(price__gt=F('discounted_price'))\n+        q2 = Q(price=F('discounted_price'))\n+        q = q1 | q2\n+        path, args, kwargs = q.deconstruct()\n+        self.assertEqual(args, (\n+            ('price__gt', F('discounted_price')),\n+            ('price', F('discounted_price')),\n+        ))\n+        self.assertEqual(kwargs, {'_connector': 'OR'})\n+\n+    def test_deconstruct_and(self):\n+        q1 = Q(price__gt=F('discounted_price'))\n+        q2 = Q(price=F('discounted_price'))\n+        q = q1 & q2\n+        path, args, kwargs = q.deconstruct()\n+        self.assertEqual(args, (\n+            ('price__gt', F('discounted_price')),\n+            ('price', F('discounted_price')),\n+        ))\n+        self.assertEqual(kwargs, {})\n+\n+    def test_deconstruct_multiple_kwargs(self):\n+        q = Q(price__gt=F('discounted_price'), price=F('discounted_price'))\n+        path, args, kwargs = q.deconstruct()\n+        self.assertEqual(args, (\n+            ('price', F('discounted_price')),\n+            ('price__gt', F('discounted_price')),\n+        ))\n+        self.assertEqual(kwargs, {})\n+\n+    def test_deconstruct_nested(self):\n+        q = Q(Q(price__gt=F('discounted_price')))\n+        path, args, kwargs = q.deconstruct()\n+        self.assertEqual(args, (Q(price__gt=F('discounted_price')),))\n+        self.assertEqual(kwargs, {})\n+\n+    def test_reconstruct(self):\n+        q = Q(price__gt=F('discounted_price'))\n+        path, args, kwargs = q.deconstruct()\n+        self.assertEqual(Q(*args, **kwargs), q)\n+\n+    def test_reconstruct_negated(self):\n+        q = ~Q(price__gt=F('discounted_price'))\n+        path, args, kwargs = q.deconstruct()\n+        self.assertEqual(Q(*args, **kwargs), q)\n+\n+    def test_reconstruct_or(self):\n+        q1 = Q(price__gt=F('discounted_price'))\n+        q2 = Q(price=F('discounted_price'))\n+        q = q1 | q2\n+        path, args, kwargs = q.deconstruct()\n+        self.assertEqual(Q(*args, **kwargs), q)\n+\n+    def test_reconstruct_and(self):\n+        q1 = Q(price__gt=F('discounted_price'))\n+        q2 = Q(price=F('discounted_price'))\n+        q = q1 & q2\n+        path, args, kwargs = q.deconstruct()\n+        self.assertEqual(Q(*args, **kwargs), q)\n+\n+    def test_deconstruct_exists(self):\n+        q = Q(Exists(get_user_model().objects.filter(username='jim')))\n+        path, args, kwargs = q.deconstruct()\n+        self.assertEqual(path, 'django.db.models.Q')\n+        self.assertEqual(args, (Exists(get_user_model().objects.filter(username='jim')),))\n+        self.assertEqual(kwargs, {})\n"
    },
    "django__django-16950": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "pydata__xarray-7233": {
        "reproduced_bug": true,
        "reproduced_bug_file": "xarray/tests/test_coarsen_nondim_coords.py",
        "reproduced_bug_commands": [
            "pytest xarray/tests/test_coarsen\nn_nondim_coords.py"
        ],
        "reproduced_bug_patch": "diff --git a/xarray/tests/test_coarsen_nondim_coords.py b/xarray/tests/test_coarsen_nondim_coords.py\nnew file mode 100644\nindex 00000000..6019c94a\n--- /dev/null\n+++ b/xarray/tests/test_coarsen_nondim_coords.py\n@@ -0,0 +1,16 @@\n+import numpy as np\n+import xarray as xr\n+\n+\n+def test_coarsen_construct_keeps_nondim_coords():\n+    \"\"\"\n+    Test that ds.Coarsen.construct does not demote non-dimensional\n+    coordinates to variables.\n+    \"\"\"\n+    da = xr.DataArray(np.arange(24), dims=[\"time\"])\n+    da = da.assign_coords(day=365 * da)\n+    ds = da.to_dataset(name=\"T\")\n+\n+    actual = ds.coarsen(time=12).construct(time=(\"year\", \"month\"))\n+\n+    assert \"day\" in actual.coords\n"
    },
    "scikit-learn__scikit-learn-11578": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/linear_model/tests/test_logistic_cv.py",
        "reproduced_bug_commands": [
            "pytest sklearn/linear_model/tests/test_logistic_cv.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/linear_model/tests/test_logistic_cv.py b/sklearn/linear_model/tests/test_logistic_cv.py\nnew file mode 100644\nindex 0000000000..7cce9700c9\n--- /dev/null\n+++ b/sklearn/linear_model/tests/test_logistic_cv.py\n@@ -0,0 +1,59 @@\n+import numpy as np\n+import pytest\n+\n+from sklearn import preprocessing, linear_model\n+from sklearn.metrics import log_loss\n+from sklearn.utils import extmath\n+from sklearn.utils.testing import assert_almost_equal\n+\n+\n+def test_logistic_cv_multinomial_scoring():\n+    \"\"\"\n+    Test for bug #8720.\n+\n+    `LogisticRegressionCV(multi_class='multinomial')` with a probabilistic\n+    scorer should use the multinomial (softmax) function, not the OvR\n+    approach to calculate probabilities. This test checks that the score\n+    returned by the internal scoring function `_log_reg_scoring_path`\n+    matches the score calculated manually using the softmax function.\n+    \"\"\"\n+    # Based on the minimal example from the issue description\n+    np.random.seed(seed=1234)\n+    samples = 200\n+    features = 5\n+    scorer = 'neg_log_loss'\n+\n+    X = np.random.random(size=(samples, features))\n+    y = np.random.choice(['a', 'b', 'c'], size=samples)\n+\n+    test_size = int(samples / 10.0)\n+    test = np.random.choice(range(samples), size=test_size, replace=False)\n+    train = [idx for idx in range(samples) if idx not in test]\n+    X_test, y_test = X[test], y[test]\n+\n+    # Get the score from the internal scoring path function, which is\n+    # what LogisticRegressionCV uses.\n+    coefs, _, scores, _ = linear_model.logistic._log_reg_scoring_path(\n+        X, y, train, test, fit_intercept=True, scoring=scorer,\n+        multi_class='multinomial')\n+\n+    # We only care about the first C value for this test\n+    c_index = 0\n+    score_from_path = scores[c_index]\n+    coef_path = coefs[c_index]\n+\n+    # Manually calculate the score that *should* be returned, using the\n+    # multinomial (softmax) approach.\n+    classes = np.unique(y)\n+    log_reg = linear_model.LogisticRegression(multi_class='multinomial')\n+    log_reg.coef_ = coef_path[:, :-1]\n+    log_reg.intercept_ = coef_path[:, -1]\n+    log_reg.classes_ = classes\n+\n+    decision = log_reg.decision_function(X_test)\n+    probas = extmath.softmax(decision)\n+    correct_score = -log_loss(y_test, probas, labels=classes)\n+\n+    # This assertion will fail before the fix because score_from_path is\n+    # calculated using the 'ovr' method instead of 'multinomial'.\n+    assert_almost_equal(score_from_path, correct_score)\n"
    },
    "astropy__astropy-14309": {
        "reproduced_bug": true,
        "reproduced_bug_file": "astropy/io/registry/tests/test_regression.py",
        "reproduced_bug_commands": [
            "pytest astropy/io/registry/tests/test_regression.py"
        ],
        "reproduced_bug_patch": "diff --git a/astropy/io/registry/tests/test_regression.py b/astropy/io/registry/tests/test_regression.py\nnew file mode 100644\nindex 0000000000..2df366e336\n--- /dev/null\n+++ b/astropy/io/registry/tests/test_regression.py\n@@ -0,0 +1,19 @@\n+# Licensed under a 3-clause BSD style license - see LICENSE.rst\n+\"\"\"\n+Regression test for https://github.com/astropy/astropy/issues/14319\n+\"\"\"\n+\n+import pytest\n+from astropy.io.registry import identify_format\n+from astropy.table import Table\n+\n+\n+def test_identify_format_index_error_on_write():\n+    \"\"\"\n+    Test that identify_format does not raise an IndexError on write.\n+\n+    The FITS identifier was incorrectly trying to access args[0]\n+    when no args were passed.\n+    \"\"\"\n+    formats = identify_format(\"write\", Table, \"bububu.ecsv\", None, [], {})\n+    assert \"ascii.ecsv\" in formats\n"
    },
    "django__django-14155": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/urlpatterns/test_resolvermatch.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py tests.urlpatterns.test_resolvermatch"
        ],
        "reproduced_bug_patch": "diff --git a/tests/urlpatterns/test_resolvermatch.py b/tests/urlpatterns/test_resolvermatch.py\nnew file mode 100644\nindex 0000000000..30d46979ea\n--- /dev/null\n+++ b/tests/urlpatterns/test_resolvermatch.py\n@@ -0,0 +1,26 @@\n+import functools\n+\n+from django.http import HttpResponse\n+from django.test import SimpleTestCase\n+from django.urls.resolvers import ResolverMatch\n+\n+# View function defined locally for self-containment of the test case.\n+# In a real scenario, this would be in `urlpatterns.views`.\n+def empty_view(request, *args, **kwargs):\n+    return HttpResponse()\n+empty_view.__module__ = 'urlpatterns.views'\n+\n+\n+class ResolverMatchTests(SimpleTestCase):\n+    def test_repr_with_functools_partial(self):\n+        \"\"\"\n+        __repr__() should be able to unwrap functools.partial objects.\n+        \"\"\"\n+        p = functools.partial(empty_view, 'arg1', kwarg1='kwarg1')\n+        match = ResolverMatch(p, ('arg2',), {'kwarg2': 'kwarg2'})\n+        self.assertEqual(\n+            repr(match),\n+            \"ResolverMatch(func=urlpatterns.views.empty_view, \"\n+            \"args=('arg1', 'arg2'), kwargs={'kwarg1': 'kwarg1', 'kwarg2': 'kwarg2'}, \"\n+            \"url_name=None, app_names=[], namespaces=[], route=None)\"\n+        )\n"
    },
    "django__django-17029": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/apps/test_registry.py",
        "reproduced_bug_commands": [
            "python runtests.py tests.apps.test_registry"
        ],
        "reproduced_bug_patch": "diff --git a/tests/apps/test_registry.py b/tests/apps/test_registry.py\nnew file mode 100644\nindex 0000000000..ad96c0fcbb\n--- /dev/null\n+++ b/tests/apps/test_registry.py\n@@ -0,0 +1,28 @@\n+from unittest.mock import patch\n+\n+from django.apps import apps\n+from django.apps.registry import Apps\n+from django.test import SimpleTestCase, override_settings\n+\n+\n+class AppsCacheTests(SimpleTestCase):\n+    @override_settings(\n+        INSTALLED_APPS=[\n+            \"django.contrib.auth\",\n+            \"django.contrib.contenttypes\",\n+            \"swappable_models\",\n+        ],\n+        TEST_ARTICLE_MODEL=\"swappable_models.AlternateArticle\",\n+    )\n+    def test_clear_cache_clears_swappable_settings_cache(self):\n+        \"\"\"\n+        Apps.clear_cache() should clear the get_swappable_settings_name()\n+        cache.\n+        \"\"\"\n+        # Populate get_swappable_settings_name() cache.\n+        apps.get_swappable_settings_name(\"swappable_models.article\")\n+        with patch.object(\n+            Apps.get_swappable_settings_name, \"cache_clear\"\n+        ) as mock_cache_clear:\n+            apps.clear_cache()\n+        mock_cache_clear.assert_called_once()\n"
    },
    "pydata__xarray-7393": {
        "reproduced_bug": true,
        "reproduced_bug_file": "xarray/tests/test_stack.py",
        "reproduced_bug_commands": [
            "pytest xarray/tests/test_stack.py"
        ],
        "reproduced_bug_patch": "diff --git a/xarray/tests/test_stack.py b/xarray/tests/test_stack.py\nnew file mode 100644\nindex 00000000..12459556\n--- /dev/null\n+++ b/xarray/tests/test_stack.py\n@@ -0,0 +1,20 @@\n+import numpy as np\n+import xarray as xr\n+\n+\n+def test_stack_preserves_int32_coord_dtype():\n+    \"\"\"\n+    Test that stacking a coordinate with int32 dtype preserves the dtype.\n+\n+    This is a regression test for a bug where stacking a coordinate with an\n+    int32 dtype would cause it to be upcast to int64 in the resulting\n+    MultiIndex.\n+    \"\"\"\n+    ds = xr.Dataset(coords={\"a\": np.array([0], dtype=\"i4\")})\n+    stacked = ds.stack(b=(\"a\",))\n+\n+    # Directly check the dtype of the level in the underlying pandas.MultiIndex\n+    actual_dtype = stacked.indexes[\"b\"].get_level_values(\"a\").dtype\n+    expected_dtype = np.dtype(\"i4\")\n+\n+    assert actual_dtype == expected_dtype\n"
    },
    "scikit-learn__scikit-learn-12585": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/tests/test_clone.py",
        "reproduced_bug_commands": [
            "pytest sklearn/tests/test_clone.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/tests/test_clone.py b/sklearn/tests/test_clone.py\nnew file mode 100644\nindex 0000000000..a56eab19c1\n--- /dev/null\n+++ b/sklearn/tests/test_clone.py\n@@ -0,0 +1,36 @@\n+import numpy as np\n+import scipy.sparse as sp\n+\n+import sklearn\n+from sklearn.utils.testing import assert_array_equal\n+from sklearn.utils.testing import assert_true\n+from sklearn.utils.testing import assert_false\n+from sklearn.utils.testing import assert_equal\n+from sklearn.utils.testing import assert_not_equal\n+from sklearn.utils.testing import assert_raises\n+from sklearn.utils.testing import assert_no_warnings\n+from sklearn.utils.testing import assert_warns_message\n+from sklearn.utils.testing import assert_dict_equal\n+from sklearn.utils.testing import ignore_warnings\n+\n+from sklearn.base import BaseEstimator, clone, is_classifier\n+from sklearn.svm import SVC\n+from sklearn.pipeline import Pipeline\n+from sklearn.model_selection import GridSearchCV\n+from sklearn.preprocessing import StandardScaler\n+\n+from sklearn.tree import DecisionTreeClassifier\n+from sklearn.tree import DecisionTreeRegressor\n+from sklearn import datasets\n+\n+from sklearn.base import TransformerMixin\n+from sklearn.utils.mocking import MockDataFrame\n+import pickle\n+\n+\n+def test_clone_estimator_types_as_parameter():\n+    \"\"\"Test that clone works for parameters that are estimator types.\"\"\"\n+    # This was a bug in 0.20.0, see #12482\n+    estimator = StandardScaler(with_mean=StandardScaler)\n+    cloned_estimator = clone(estimator)\n+    assert cloned_estimator.with_mean is StandardScaler\n"
    },
    "sphinx-doc__sphinx-11445": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_environment_adapters_toctree.py",
        "reproduced_bug_commands": [
            "pytest tests/test_environment_adapters_toctree.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_environment_adapters_toctree.py b/tests/test_environment_adapters_toctree.py\nnew file mode 100644\nindex 000000000..096ed83b1\n--- /dev/null\n+++ b/tests/test_environment_adapters_toctree.py\n@@ -0,0 +1,412 @@\n+import pytest\n+from docutils import nodes\n+from docutils.nodes import bullet_list, comment, list_item, literal, reference, title\n+\n+from sphinx import addnodes\n+from sphinx.addnodes import compact_paragraph, only\n+from sphinx.builders.html import StandaloneHTMLBuilder\n+from sphinx.environment.adapters.toctree import TocTree\n+from sphinx.testing.util import assert_node\n+\n+\n+@pytest.mark.sphinx('xml', testroot='toctree')\n+@pytest.mark.test_params(shared_result='test_environment_toctree_basic')\n+def test_process_doc(app):\n+    app.build()\n+    # tocs\n+    toctree = app.env.tocs['index']\n+    assert_node(toctree,\n+                [bullet_list, ([list_item, (compact_paragraph,  # [0][0]\n+                                            [bullet_list, (addnodes.toctree,  # [0][1][0]\n+                                                           only,  # [0][1][1]\n+                                                           list_item)])],  # [0][1][2]\n+                               [list_item, (compact_paragraph,  # [1][0]\n+                                            [bullet_list, (addnodes.toctree,  # [1][1][0]\n+                                                           addnodes.toctree)])],  # [1][1][1]\n+                               list_item)])\n+\n+    assert_node(toctree[0][0],\n+                [compact_paragraph, reference, \"Welcome to Sphinx Tests’s documentation!\"])\n+    assert_node(toctree[0][0][0], reference, anchorname='')\n+    assert_node(toctree[0][1][0], addnodes.toctree,\n+                caption=\"Table of Contents\", glob=False, hidden=False,\n+                titlesonly=False, maxdepth=2, numbered=999,\n+                entries=[(None, 'foo'), (None, 'bar'), (None, 'http://sphinx-doc.org/'),\n+                         (None, 'self')],\n+                includefiles=['foo', 'bar'])\n+\n+    # only branch\n+    assert_node(toctree[0][1][1], addnodes.only, expr=\"html\")\n+    assert_node(toctree[0][1][1],\n+                [only, list_item, ([compact_paragraph, reference, \"Section for HTML\"],\n+                                   [bullet_list, addnodes.toctree])])\n+    assert_node(toctree[0][1][1][0][0][0], reference, anchorname='#section-for-html')\n+    assert_node(toctree[0][1][1][0][1][0], addnodes.toctree,\n+                caption=None, glob=False, hidden=False, entries=[(None, 'baz')],\n+                includefiles=['baz'], titlesonly=False, maxdepth=-1, numbered=0)\n+    assert_node(toctree[0][1][2],\n+                ([compact_paragraph, reference, \"subsection\"],\n+                 [bullet_list, list_item, compact_paragraph, reference, \"subsubsection\"]))\n+\n+    assert_node(toctree[1][0],\n+                [compact_paragraph, reference, \"Test for issue #1157\"])\n+    assert_node(toctree[1][0][0], reference, anchorname='#test-for-issue-1157')\n+    assert_node(toctree[1][1][0], addnodes.toctree,\n+                caption=None, entries=[], glob=False, hidden=False,\n+                titlesonly=False, maxdepth=-1, numbered=0)\n+    assert_node(toctree[1][1][1], addnodes.toctree,\n+                caption=None, glob=False, hidden=True,\n+                titlesonly=False, maxdepth=-1, numbered=0,\n+                entries=[('Latest reference', 'http://sphinx-doc.org/latest/'),\n+                         ('Python', 'http://python.org/')])\n+\n+    assert_node(toctree[2][0],\n+                [compact_paragraph, reference, \"Indices and tables\"])\n+\n+    # other collections\n+    assert app.env.toc_num_entries['index'] == 6\n+    assert app.env.toctree_includes['index'] == ['foo', 'bar', 'baz']\n+    assert app.env.files_to_rebuild['foo'] == {'index'}\n+    assert app.env.files_to_rebuild['bar'] == {'index'}\n+    assert app.env.files_to_rebuild['baz'] == {'index'}\n+    assert app.env.glob_toctrees == set()\n+    assert app.env.numbered_toctrees == {'index'}\n+\n+    # qux has no section title\n+    assert len(app.env.tocs['qux']) == 0\n+    assert_node(app.env.tocs['qux'], nodes.bullet_list)\n+    assert app.env.toc_num_entries['qux'] == 0\n+    assert 'qux' not in app.env.toctree_includes\n+\n+\n+@pytest.mark.sphinx('dummy', testroot='toctree-glob')\n+def test_glob(app):\n+    includefiles = ['foo', 'bar/index', 'bar/bar_1', 'bar/bar_2',\n+                    'bar/bar_3', 'baz', 'qux/index']\n+\n+    app.build()\n+\n+    # tocs\n+    toctree = app.env.tocs['index']\n+    assert_node(toctree,\n+                [bullet_list, list_item, (compact_paragraph,  # [0][0]\n+                                          [bullet_list, (list_item,  # [0][1][0]\n+                                                         list_item)])])  # [0][1][1]\n+\n+    assert_node(toctree[0][0],\n+                [compact_paragraph, reference, \"test-toctree-glob\"])\n+    assert_node(toctree[0][1][0],\n+                [list_item, ([compact_paragraph, reference, \"normal order\"],\n+                             [bullet_list, addnodes.toctree])])  # [0][1][0][1][0]\n+    assert_node(toctree[0][1][0][1][0], addnodes.toctree, caption=None,\n+                glob=True, hidden=False, titlesonly=False,\n+                maxdepth=-1, numbered=0, includefiles=includefiles,\n+                entries=[(None, 'foo'), (None, 'bar/index'), (None, 'bar/bar_1'),\n+                         (None, 'bar/bar_2'), (None, 'bar/bar_3'), (None, 'baz'),\n+                         (None, 'qux/index'),\n+                         ('hyperref', 'https://sphinx-doc.org/?q=sphinx')])\n+    assert_node(toctree[0][1][1],\n+                [list_item, ([compact_paragraph, reference, \"reversed order\"],\n+                             [bullet_list, addnodes.toctree])])  # [0][1][1][1][0]\n+    assert_node(toctree[0][1][1][1][0], addnodes.toctree, caption=None,\n+                glob=True, hidden=False, titlesonly=False,\n+                maxdepth=-1, numbered=0, includefiles=list(reversed(includefiles)),\n+                entries=[(None, 'qux/index'), (None, 'baz'), (None, 'bar/bar_3'),\n+                         (None, 'bar/bar_2'), (None, 'bar/bar_1'), (None, 'bar/index'),\n+                         (None, 'foo')])\n+\n+    # other collections\n+    assert app.env.toc_num_entries['index'] == 3\n+    assert app.env.toctree_includes['index'] == includefiles + list(reversed(includefiles))\n+    for file in includefiles:\n+        assert 'index' in app.env.files_to_rebuild[file]\n+    assert 'index' in app.env.glob_toctrees\n+    assert app.env.numbered_toctrees == set()\n+\n+\n+@pytest.mark.sphinx('dummy', testroot='toctree-domain-objects')\n+def test_domain_objects(app):\n+    includefiles = ['domains']\n+\n+    app.build()\n+\n+    assert app.env.toc_num_entries['index'] == 0\n+    assert app.env.toc_num_entries['domains'] == 9\n+    assert app.env.toctree_includes['index'] == includefiles\n+    for file in includefiles:\n+        assert 'index' in app.env.files_to_rebuild[file]\n+    assert app.env.glob_toctrees == set()\n+    assert app.env.numbered_toctrees == {'index'}\n+\n+    # tocs\n+    toctree = app.env.tocs['domains']\n+    assert_node(toctree,\n+                [bullet_list, list_item, (compact_paragraph,  # [0][0]\n+                                          [bullet_list, (list_item,  # [0][1][0]\n+                                                         [list_item,  # [0][1][1]\n+                                                          (compact_paragraph,  # [0][1][1][0]\n+                                                           [bullet_list, (list_item,  # [0][1][1][1][0]\n+                                                                          list_item,\n+                                                                          list_item,\n+                                                                          list_item)])],  # [0][1][1][1][3]\n+                                                         list_item,\n+                                                         list_item)])])  # [0][1][1]\n+\n+    assert_node(toctree[0][0],\n+                [compact_paragraph, reference, \"test-domain-objects\"])\n+\n+    assert_node(toctree[0][1][0],\n+                [list_item, ([compact_paragraph, reference, literal, \"world()\"])])\n+\n+    assert_node(toctree[0][1][1][1][3],\n+                [list_item, ([compact_paragraph, reference, literal, \"HelloWorldPrinter.print()\"])])\n+\n+\n+@pytest.mark.sphinx('xml', testroot='toctree')\n+@pytest.mark.test_params(shared_result='test_environment_toctree_basic')\n+def test_get_toc_for(app):\n+    app.build()\n+    toctree = TocTree(app.env).get_toc_for('index', app.builder)\n+\n+    assert_node(toctree,\n+                [bullet_list, ([list_item, (compact_paragraph,  # [0][0]\n+                                            [bullet_list, (addnodes.toctree,  # [0][1][0]\n+                                                           comment,  # [0][1][1]\n+                                                           list_item)])],  # [0][1][2]\n+                               [list_item, (compact_paragraph,  # [1][0]\n+                                            [bullet_list, (addnodes.toctree,\n+                                                           addnodes.toctree)])],\n+                               [list_item, compact_paragraph])])  # [2][0]\n+    assert_node(toctree[0][0],\n+                [compact_paragraph, reference, \"Welcome to Sphinx Tests’s documentation!\"])\n+    assert_node(toctree[0][1][2],\n+                ([compact_paragraph, reference, \"subsection\"],\n+                 [bullet_list, list_item, compact_paragraph, reference, \"subsubsection\"]))\n+    assert_node(toctree[1][0],\n+                [compact_paragraph, reference, \"Test for issue #1157\"])\n+    assert_node(toctree[2][0],\n+                [compact_paragraph, reference, \"Indices and tables\"])\n+\n+\n+@pytest.mark.sphinx('xml', testroot='toctree')\n+@pytest.mark.test_params(shared_result='test_environment_toctree_basic')\n+def test_get_toc_for_only(app):\n+    app.build()\n+    builder = StandaloneHTMLBuilder(app, app.env)\n+    toctree = TocTree(app.env).get_toc_for('index', builder)\n+\n+    assert_node(toctree,\n+                [bullet_list, ([list_item, (compact_paragraph,  # [0][0]\n+                                            [bullet_list, (addnodes.toctree,  # [0][1][0]\n+                                                           list_item,  # [0][1][1]\n+                                                           list_item)])],  # [0][1][2]\n+                               [list_item, (compact_paragraph,  # [1][0]\n+                                            [bullet_list, (addnodes.toctree,\n+                                                           addnodes.toctree)])],\n+                               [list_item, compact_paragraph])])  # [2][0]\n+    assert_node(toctree[0][0],\n+                [compact_paragraph, reference, \"Welcome to Sphinx Tests’s documentation!\"])\n+    assert_node(toctree[0][1][1],\n+                ([compact_paragraph, reference, \"Section for HTML\"],\n+                 [bullet_list, addnodes.toctree]))\n+    assert_node(toctree[0][1][2],\n+                ([compact_paragraph, reference, \"subsection\"],\n+                 [bullet_list, list_item, compact_paragraph, reference, \"subsubsection\"]))\n+    assert_node(toctree[1][0],\n+                [compact_paragraph, reference, \"Test for issue #1157\"])\n+    assert_node(toctree[2][0],\n+                [compact_paragraph, reference, \"Indices and tables\"])\n+\n+\n+@pytest.mark.sphinx('xml', testroot='toctree')\n+@pytest.mark.test_params(shared_result='test_environment_toctree_basic')\n+def test_get_toc_for_tocdepth(app):\n+    app.build()\n+    toctree = TocTree(app.env).get_toc_for('tocdepth', app.builder)\n+\n+    assert_node(toctree,\n+                [bullet_list, list_item, (compact_paragraph,  # [0][0]\n+                                          bullet_list)])  # [0][1]\n+    assert_node(toctree[0][0],\n+                [compact_paragraph, reference, \"level 1\"])\n+    assert_node(toctree[0][1],\n+                [bullet_list, list_item, compact_paragraph, reference, \"level 2\"])\n+\n+\n+@pytest.mark.sphinx('xml', testroot='toctree')\n+@pytest.mark.test_params(shared_result='test_environment_toctree_basic')\n+def test_get_toctree_for(app):\n+    app.build()\n+    toctree = TocTree(app.env).get_toctree_for('index', app.builder, collapse=False)\n+    assert_node(toctree,\n+                [compact_paragraph, ([title, \"Table of Contents\"],\n+                                     bullet_list,\n+                                     bullet_list,\n+                                     bullet_list)])\n+\n+    assert_node(toctree[1],\n+                ([list_item, ([compact_paragraph, reference, \"foo\"],\n+                              bullet_list)],\n+                 [list_item, compact_paragraph, reference, \"bar\"],\n+                 [list_item, compact_paragraph, reference, \"http://sphinx-doc.org/\"],\n+                 [list_item, compact_paragraph, reference,\n+                  \"Welcome to Sphinx Tests’s documentation!\"]))\n+    assert_node(toctree[1][0][1],\n+                ([list_item, compact_paragraph, reference, \"quux\"],\n+                 [list_item, compact_paragraph, reference, \"foo.1\"],\n+                 [list_item, compact_paragraph, reference, \"foo.2\"]))\n+\n+    assert_node(toctree[1][0][0][0], reference, refuri=\"foo\", secnumber=[1])\n+    assert_node(toctree[1][0][1][0][0][0], reference, refuri=\"quux\", secnumber=[1, 1])\n+    assert_node(toctree[1][0][1][1][0][0], reference, refuri=\"foo#foo-1\", secnumber=[1, 2])\n+    assert_node(toctree[1][0][1][2][0][0], reference, refuri=\"foo#foo-2\", secnumber=[1, 3])\n+    assert_node(toctree[1][1][0][0], reference, refuri=\"bar\", secnumber=[2])\n+    assert_node(toctree[1][2][0][0], reference, refuri=\"http://sphinx-doc.org/\")\n+    assert_node(toctree[1][3][0][0], reference, refuri=\"\")\n+\n+    assert_node(toctree[2],\n+                [bullet_list, list_item, compact_paragraph, reference, \"baz\"])\n+    assert_node(toctree[3],\n+                ([list_item, compact_paragraph, reference, \"Latest reference\"],\n+                 [list_item, compact_paragraph, reference, \"Python\"]))\n+    assert_node(toctree[3][0][0][0], reference, refuri=\"http://sphinx-doc.org/latest/\")\n+    assert_node(toctree[3][1][0][0], reference, refuri=\"http://python.org/\")\n+\n+\n+@pytest.mark.sphinx('xml', testroot='toctree')\n+@pytest.mark.test_params(shared_result='test_environment_toctree_basic')\n+def test_get_toctree_for_collapse(app):\n+    app.build()\n+    toctree = TocTree(app.env).get_toctree_for('index', app.builder, collapse=True)\n+    assert_node(toctree,\n+                [compact_paragraph, ([title, \"Table of Contents\"],\n+                                     bullet_list,\n+                                     bullet_list,\n+                                     bullet_list)])\n+\n+    assert_node(toctree[1],\n+                ([list_item, compact_paragraph, reference, \"foo\"],\n+                 [list_item, compact_paragraph, reference, \"bar\"],\n+                 [list_item, compact_paragraph, reference, \"http://sphinx-doc.org/\"],\n+                 [list_item, compact_paragraph, reference,\n+                  \"Welcome to Sphinx Tests’s documentation!\"]))\n+    assert_node(toctree[1][0][0][0], reference, refuri=\"foo\", secnumber=[1])\n+    assert_node(toctree[1][1][0][0], reference, refuri=\"bar\", secnumber=[2])\n+    assert_node(toctree[1][2][0][0], reference, refuri=\"http://sphinx-doc.org/\")\n+    assert_node(toctree[1][3][0][0], reference, refuri=\"\")\n+\n+    assert_node(toctree[2],\n+                [bullet_list, list_item, compact_paragraph, reference, \"baz\"])\n+    assert_node(toctree[3],\n+                ([list_item, compact_paragraph, reference, \"Latest reference\"],\n+                 [list_item, compact_paragraph, reference, \"Python\"]))\n+    assert_node(toctree[3][0][0][0], reference, refuri=\"http://sphinx-doc.org/latest/\")\n+    assert_node(toctree[3][1][0][0], reference, refuri=\"http://python.org/\")\n+\n+\n+@pytest.mark.sphinx('xml', testroot='toctree')\n+@pytest.mark.test_params(shared_result='test_environment_toctree_basic')\n+def test_get_toctree_for_maxdepth(app):\n+    app.build()\n+    toctree = TocTree(app.env).get_toctree_for('index', app.builder,\n+                                               collapse=False, maxdepth=3)\n+    assert_node(toctree,\n+                [compact_paragraph, ([title, \"Table of Contents\"],\n+                                     bullet_list,\n+                                     bullet_list,\n+                                     bullet_list)])\n+\n+    assert_node(toctree[1],\n+                ([list_item, ([compact_paragraph, reference, \"foo\"],\n+                              bullet_list)],\n+                 [list_item, compact_paragraph, reference, \"bar\"],\n+                 [list_item, compact_paragraph, reference, \"http://sphinx-doc.org/\"],\n+                 [list_item, compact_paragraph, reference,\n+                  \"Welcome to Sphinx Tests’s documentation!\"]))\n+    assert_node(toctree[1][0][1],\n+                ([list_item, compact_paragraph, reference, \"quux\"],\n+                 [list_item, ([compact_paragraph, reference, \"foo.1\"],\n+                              bullet_list)],\n+                 [list_item, compact_paragraph, reference, \"foo.2\"]))\n+    assert_node(toctree[1][0][1][1][1],\n+                [bullet_list, list_item, compact_paragraph, reference, \"foo.1-1\"])\n+\n+    assert_node(toctree[1][0][0][0], reference, refuri=\"foo\", secnumber=[1])\n+    assert_node(toctree[1][0][1][0][0][0], reference, refuri=\"quux\", secnumber=[1, 1])\n+    assert_node(toctree[1][0][1][1][0][0], reference, refuri=\"foo#foo-1\", secnumber=[1, 2])\n+    assert_node(toctree[1][0][1][1][1][0][0][0],\n+                reference, refuri=\"foo#foo-1-1\", secnumber=[1, 2, 1])\n+    assert_node(toctree[1][0][1][2][0][0], reference, refuri=\"foo#foo-2\", secnumber=[1, 3])\n+    assert_node(toctree[1][1][0][0], reference, refuri=\"bar\", secnumber=[2])\n+    assert_node(toctree[1][2][0][0], reference, refuri=\"http://sphinx-doc.org/\")\n+    assert_node(toctree[1][3][0][0], reference, refuri=\"\")\n+\n+    assert_node(toctree[2],\n+                [bullet_list, list_item, compact_paragraph, reference, \"baz\"])\n+    assert_node(toctree[3],\n+                ([list_item, compact_paragraph, reference, \"Latest reference\"],\n+                 [list_item, compact_paragraph, reference, \"Python\"]))\n+    assert_node(toctree[3][0][0][0], reference, refuri=\"http://sphinx-doc.org/latest/\")\n+    assert_node(toctree[3][1][0][0], reference, refuri=\"http://python.org/\")\n+\n+\n+@pytest.mark.sphinx('xml', testroot='toctree')\n+@pytest.mark.test_params(shared_result='test_environment_toctree_basic')\n+def test_get_toctree_for_includehidden(app):\n+    app.build()\n+    toctree = TocTree(app.env).get_toctree_for('index', app.builder, collapse=False,\n+                                               includehidden=False)\n+    assert_node(toctree,\n+                [compact_paragraph, ([title, \"Table of Contents\"],\n+                                     bullet_list,\n+                                     bullet_list)])\n+\n+    assert_node(toctree[1],\n+                ([list_item, ([compact_paragraph, reference, \"foo\"],\n+                              bullet_list)],\n+                 [list_item, compact_paragraph, reference, \"bar\"],\n+                 [list_item, compact_paragraph, reference, \"http://sphinx-doc.org/\"],\n+                 [list_item, compact_paragraph, reference,\n+                  \"Welcome to Sphinx Tests’s documentation!\"]))\n+    assert_node(toctree[1][0][1],\n+                ([list_item, compact_paragraph, reference, \"quux\"],\n+                 [list_item, compact_paragraph, reference, \"foo.1\"],\n+                 [list_item, compact_paragraph, reference, \"foo.2\"]))\n+\n+    assert_node(toctree[1][0][0][0], reference, refuri=\"foo\", secnumber=[1])\n+    assert_node(toctree[1][0][1][0][0][0], reference, refuri=\"quux\", secnumber=[1, 1])\n+    assert_node(toctree[1][0][1][1][0][0], reference, refuri=\"foo#foo-1\", secnumber=[1, 2])\n+    assert_node(toctree[1][0][1][2][0][0], reference, refuri=\"foo#foo-2\", secnumber=[1, 3])\n+    assert_node(toctree[1][1][0][0], reference, refuri=\"bar\", secnumber=[2])\n+    assert_node(toctree[1][2][0][0], reference, refuri=\"http://sphinx-doc.org/\")\n+\n+    assert_node(toctree[2],\n+                [bullet_list, list_item, compact_paragraph, reference, \"baz\"])\n+\n+\n+@pytest.mark.sphinx('xml', testroot='toctree-index')\n+def test_toctree_index(app):\n+    app.build()\n+    toctree = app.env.tocs['index']\n+    assert_node(toctree,\n+                [bullet_list, ([list_item, (compact_paragraph,  # [0][0]\n+                                            [bullet_list, (addnodes.toctree,  # [0][1][0]\n+                                                           addnodes.toctree)])])])  # [0][1][1]\n+    assert_node(toctree[0][1][1], addnodes.toctree,\n+                caption=\"Indices\", glob=False, hidden=False,\n+                titlesonly=False, maxdepth=-1, numbered=0,\n+                entries=[(None, 'genindex'), (None, 'modindex'), (None, 'search')])\n+\n+\n+@pytest.mark.sphinx(\n+    'html',\n+    confoverrides={'rst_prolog': '.. |foo| replace:: bar'}\n+)\n+def test_rst_prolog_with_domain_directive_heading(app):\n+    \"\"\"Test that a domain directive in a heading is not lost when rst_prolog is used.\"\"\"\n+    (app.srcdir / 'index.rst').write_text('.. toctree::\\n\\n   mypackage\\n')\n+    (app.srcdir / 'mypackage.rst').write_text(':mod:`mypackage`\\n=================\\n\\nContent\\n')\n+    app.build()\n+\n+    toc = app.env.tocs['mypackage']\n+    assert len(toc) == 1\n"
    },
    "astropy__astropy-14365": {
        "reproduced_bug": true,
        "reproduced_bug_file": "astropy/io/ascii/tests/test_qdp_lowercase_command_regression.py",
        "reproduced_bug_commands": [
            "pytest astropy/io/ascii/tests/test_qdp_lowercase_command_regression.py"
        ],
        "reproduced_bug_patch": "diff --git a/astropy/io/ascii/tests/test_qdp_lowercase_command_regression.py b/astropy/io/ascii/tests/test_qdp_lowercase_command_regression.py\nnew file mode 100644\nindex 0000000000..12198789ba\n--- /dev/null\n+++ b/astropy/io/ascii/tests/test_qdp_lowercase_command_regression.py\n@@ -0,0 +1,27 @@\n+import numpy as np\n+import pytest\n+\n+from astropy.io import ascii\n+from astropy.table import Table\n+from astropy.utils.exceptions import AstropyUserWarning\n+\n+\n+def test_read_qdp_lowercase_command():\n+    \"\"\"\n+    Test that QDP files with lowercase commands can be read.\n+\n+    This is a regression test for the issue where commands were\n+    assumed to be uppercase, causing a ValueError. The test handles\n+    an expected warning about 'table_id' to ensure the underlying\n+    ValueError is reached and reported.\n+    \"\"\"\n+    qdp_file_content = \"\"\"read serr 1 2\n+1 0.5 1 0.5\n+\"\"\"\n+    with pytest.warns(AstropyUserWarning, match=\"table_id not specified\"):\n+        t = Table.read(qdp_file_content, format=\"ascii.qdp\")\n+\n+    # These assertions will pass once the lowercase command is recognized\n+    # and the table is parsed correctly.\n+    assert np.allclose(t[\"col1\"], [1.0])\n+    assert np.allclose(t[\"col1_err\"], [0.5])\n"
    },
    "django__django-14170": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/db_functions/datetime/test_iso_year.py",
        "reproduced_bug_commands": [
            "cd tests && python runtests.py db_functions.datetime.test_iso_year"
        ],
        "reproduced_bug_patch": "diff --git a/tests/db_functions/datetime/test_iso_year.py b/tests/db_functions/datetime/test_iso_year.py\nnew file mode 100644\nindex 0000000000..df4efadd2d\n--- /dev/null\n+++ b/tests/db_functions/datetime/test_iso_year.py\n@@ -0,0 +1,62 @@\n+import pytz\n+from datetime import datetime, timedelta, timezone as datetime_timezone\n+\n+try:\n+    import zoneinfo\n+except ImportError:\n+    try:\n+        from backports import zoneinfo\n+    except ImportError:\n+        zoneinfo = None\n+\n+from django.conf import settings\n+from django.db.models import (\n+    DateField, DateTimeField, F, IntegerField, Max, OuterRef, Subquery,\n+    TimeField,\n+)\n+from django.db.models.functions import (\n+    Extract, ExtractDay, ExtractHour, ExtractIsoWeekDay, ExtractIsoYear,\n+    ExtractMinute, ExtractMonth, ExtractQuarter, ExtractSecond, ExtractWeek,\n+    ExtractWeekDay, ExtractYear, Trunc, TruncDate, TruncDay, TruncHour,\n+    TruncMinute, TruncMonth, TruncQuarter, TruncSecond, TruncTime, TruncWeek,\n+    TruncYear,\n+)\n+from django.test import (\n+    TestCase, override_settings, skipIfDBFeature, skipUnlessDBFeature,\n+)\n+from django.utils import timezone\n+\n+from ..models import Author, DTModel, Fan\n+\n+ZONE_CONSTRUCTORS = (pytz.timezone,)\n+if zoneinfo is not None:\n+    ZONE_CONSTRUCTORS += (zoneinfo.ZoneInfo,)\n+\n+\n+@override_settings(USE_TZ=False)\n+class DateFunctionTests(TestCase):\n+\n+    def create_model(self, start_datetime, end_datetime):\n+        return DTModel.objects.create(\n+            name=start_datetime.isoformat() if start_datetime else 'None',\n+            start_datetime=start_datetime,\n+            end_datetime=end_datetime,\n+            start_date=start_datetime.date() if start_datetime else None,\n+            end_date=end_datetime.date() if end_datetime else None,\n+            start_time=start_datetime.time() if start_datetime else None,\n+            end_time=end_datetime.time() if end_datetime else None,\n+            duration=(end_datetime - start_datetime) if start_datetime and end_datetime else None,\n+        )\n+\n+    def test_filter_iso_year_on_boundary(self):\n+        \"\"\"\n+        The __iso_year lookup must use EXTRACT and not the BETWEEN optimization\n+        used by the __year lookup.\n+        \"\"\"\n+        # 2021-01-01 is a Friday, so it belongs to ISO year 2020.\n+        start_datetime = datetime(2021, 1, 1)\n+        self.create_model(start_datetime, start_datetime)\n+        # A filter for iso_year=2021 should not include this date. The faulty\n+        # BETWEEN optimization would include it.\n+        qs = DTModel.objects.filter(start_datetime__iso_year=2021)\n+        self.assertEqual(qs.count(), 0)\n"
    },
    "django__django-17084": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/expressions_window/test_aggregation.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py expressions_window.test_aggregation"
        ],
        "reproduced_bug_patch": "diff --git a/tests/expressions_window/test_aggregation.py b/tests/expressions_window/test_aggregation.py\nnew file mode 100644\nindex 0000000000..51956ed6e8\n--- /dev/null\n+++ b/tests/expressions_window/test_aggregation.py\n@@ -0,0 +1,78 @@\n+import datetime\n+from decimal import Decimal\n+\n+from django.db.models import F, Sum, Window\n+from django.db.models.functions import Coalesce\n+from django.test import TestCase, skipUnlessDBFeature\n+\n+from .models import Classification, Employee, PastEmployeeDepartment\n+\n+\n+@skipUnlessDBFeature(\"supports_over_clause\")\n+class WindowFunctionTests(TestCase):\n+    @classmethod\n+    def setUpTestData(cls):\n+        classification = Classification.objects.create()\n+        Employee.objects.bulk_create(\n+            [\n+                Employee(\n+                    name=e[0],\n+                    salary=e[1],\n+                    department=e[2],\n+                    hire_date=e[3],\n+                    age=e[4],\n+                    bonus=Decimal(e[1]) / 400,\n+                    classification=classification,\n+                )\n+                for e in [\n+                    (\"Jones\", 45000, \"Accounting\", datetime.datetime(2005, 11, 1), 20),\n+                    (\n+                        \"Williams\",\n+                        37000,\n+                        \"Accounting\",\n+                        datetime.datetime(2009, 6, 1),\n+                        20,\n+                    ),\n+                    (\"Jenson\", 45000, \"Accounting\", datetime.datetime(2008, 4, 1), 20),\n+                    (\"Adams\", 50000, \"Accounting\", datetime.datetime(2013, 7, 1), 50),\n+                    (\"Smith\", 55000, \"Sales\", datetime.datetime(2007, 6, 1), 30),\n+                    (\"Brown\", 53000, \"Sales\", datetime.datetime(2009, 9, 1), 30),\n+                    (\"Johnson\", 40000, \"Marketing\", datetime.datetime(2012, 3, 1), 30),\n+                    (\"Smith\", 38000, \"Marketing\", datetime.datetime(2009, 10, 1), 20),\n+                    (\"Wilkinson\", 60000, \"IT\", datetime.datetime(2011, 3, 1), 40),\n+                    (\"Moore\", 34000, \"IT\", datetime.datetime(2013, 8, 1), 40),\n+                    (\"Miller\", 100000, \"Management\", datetime.datetime(2005, 6, 1), 40),\n+                    (\"Johnson\", 80000, \"Management\", datetime.datetime(2005, 7, 1), 50),\n+                ]\n+            ]\n+        )\n+        employees = list(Employee.objects.order_by(\"pk\"))\n+        PastEmployeeDepartment.objects.bulk_create(\n+            [\n+                PastEmployeeDepartment(employee=employees[6], department=\"Sales\"),\n+                PastEmployeeDepartment(employee=employees[10], department=\"IT\"),\n+            ]\n+        )\n+\n+    def test_aggregate_over_window_function(self):\n+        \"\"\"\n+        Test that aggregating over a Window function annotation does not raise\n+        an error.\n+        \"\"\"\n+        queryset = Employee.objects.annotate(\n+            cumulative_salary=Coalesce(\n+                Window(expression=Sum(\"salary\"), order_by=F(\"hire_date\").asc()),\n+                0,\n+            )\n+        )\n+        aggregated = queryset.aggregate(\n+            total_salary=Sum(\"salary\"),\n+            total_cumulative_salary=Sum(\"cumulative_salary\"),\n+        )\n+        self.assertEqual(\n+            aggregated,\n+            {\n+                \"total_salary\": 637000,\n+                \"total_cumulative_salary\": 4646000,\n+            },\n+        )\n"
    },
    "pylint-dev__pylint-4551": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/unittest_pyreverse_inspector_issue_1539.py",
        "reproduced_bug_commands": [
            "pytest tests/unittest_pyreverse_inspector_issue_1539.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/unittest_pyreverse_inspector_issue_1539.py b/tests/unittest_pyreverse_inspector_issue_1539.py\nnew file mode 100644\nindex 000000000..e580bd1eb\n--- /dev/null\n+++ b/tests/unittest_pyreverse_inspector_issue_1539.py\n@@ -0,0 +1,42 @@\n+import astroid\n+\n+from pylint.pyreverse import inspector\n+\n+\n+def test_type_hint_in_init_with_none_default_is_used():\n+    \"\"\"\n+    Test that the Linker correctly infers the type of an instance\n+    attribute from a type-hinted __init__ argument with a default\n+    value of None.\n+\n+    This reproduces the bug described in https://github.com/PyCQA/pylint/issues/1539\n+    \"\"\"\n+    module_node = astroid.parse(\n+        \"\"\"\n+    class C:\n+        def __init__(self, a: str = None):\n+            self.a = a\n+    \"\"\"\n+    )\n+    class_node = module_node[\"C\"]\n+\n+    # The Linker is a visitor that populates class information. For a single\n+    # module test, the module node itself can act as the project context.\n+    linker = inspector.Linker(module_node)\n+    linker.visit(module_node)\n+\n+    # After visiting, the instance_attrs_type dictionary on the class node\n+    # should be populated with type information.\n+    assert hasattr(class_node, \"instance_attrs_type\")\n+    attrs_type = class_node.instance_attrs_type\n+\n+    # The type for attribute 'a' should be inferred from the 'str' hint.\n+    assert \"a\" in attrs_type\n+    inferred_types = attrs_type[\"a\"]\n+    # Before the fix, this would likely be inferred as None or be empty.\n+    assert len(inferred_types) == 1\n+\n+    # The inferred type for 'str' should be an astroid ClassDef node.\n+    inferred_type = inferred_types[0]\n+    assert isinstance(inferred_type, astroid.nodes.ClassDef)\n+    assert inferred_type.name == \"str\"\n"
    },
    "scikit-learn__scikit-learn-12682": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/decomposition/tests/test_sparse_coder.py",
        "reproduced_bug_commands": [
            "pytest sklearn/decomposition/tests/test_sparse_coder.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/decomposition/tests/test_sparse_coder.py b/sklearn/decomposition/tests/test_sparse_coder.py\nnew file mode 100644\nindex 0000000000..4ce6fc9372\n--- /dev/null\n+++ b/sklearn/decomposition/tests/test_sparse_coder.py\n@@ -0,0 +1,40 @@\n+import pytest\n+\n+import numpy as np\n+import itertools\n+\n+from sklearn.exceptions import ConvergenceWarning\n+\n+from sklearn.utils import check_array\n+\n+from sklearn.utils.testing import assert_array_almost_equal\n+from sklearn.utils.testing import assert_array_equal\n+from sklearn.utils.testing import assert_equal\n+from sklearn.utils.testing import assert_less\n+from sklearn.utils.testing import assert_raises\n+from sklearn.utils.testing import ignore_warnings\n+from sklearn.utils.testing import TempMemmap\n+\n+from sklearn.decomposition import DictionaryLearning\n+from sklearn.decomposition import MiniBatchDictionaryLearning\n+from sklearn.decomposition import SparseCoder\n+from sklearn.decomposition import dict_learning\n+from sklearn.decomposition import dict_learning_online\n+from sklearn.decomposition import sparse_encode\n+\n+\n+rng_global = np.random.RandomState(0)\n+n_samples, n_features = 10, 8\n+X = rng_global.randn(n_samples, n_features)\n+\n+\n+def test_sparse_coder_lasso_cd_max_iter():\n+    n_components = 12\n+    rng = np.random.RandomState(0)\n+    V = rng.randn(n_components, n_features)\n+    # This will raise a TypeError because max_iter is not a valid argument.\n+    # When the bug is fixed, this should work without errors.\n+    coder = SparseCoder(dictionary=V, transform_algorithm='lasso_cd',\n+                        transform_alpha=0.001, max_iter=1)\n+    with ignore_warnings(category=ConvergenceWarning):\n+        coder.transform(X)\n"
    },
    "sphinx-doc__sphinx-11510": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_source_read_on_include.py",
        "reproduced_bug_commands": [
            "python -m pytest tests/test_source_read_on_include.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_source_read_on_include.py b/tests/test_source_read_on_include.py\nnew file mode 100644\nindex 000000000..725b2abdc\n--- /dev/null\n+++ b/tests/test_source_read_on_include.py\n@@ -0,0 +1,82 @@\n+import pytest\n+import sys\n+from pathlib import Path\n+\n+@pytest.fixture\n+def source_read_test_root(tmp_path: Path) -> Path:\n+    \"\"\"Creates a test root directory for the source-read on include bug.\"\"\"\n+    src_dir = tmp_path / \"test-source-read-include\"\n+    src_dir.mkdir()\n+\n+    # conf.py\n+    (src_dir / \"conf.py\").write_text(\n+        '''\n+import sys\n+import os\n+sys.path.insert(0, os.path.abspath('.'))\n+extensions = ['my_extension']\n+''',\n+        encoding='utf-8'\n+    )\n+\n+    # my_extension.py\n+    (src_dir / \"my_extension.py\").write_text(\n+        '''\n+from sphinx.application import Sphinx\n+\n+__version__ = '1.0'\n+\n+def subst_vars_replace(app: Sphinx, docname: str, source: list[str]) -> None:\n+    source[0] = source[0].replace(\"&REPLACE_ME;\", \"REPLACED\")\n+\n+def setup(app: Sphinx):\n+    app.connect('source-read', subst_vars_replace)\n+    return dict(\n+        version=__version__,\n+        parallel_read_safe=True,\n+        parallel_write_safe=True\n+    )\n+''',\n+        encoding='utf-8'\n+    )\n+\n+    # index.rst\n+    (src_dir / \"index.rst\").write_text(\n+        '''\n+This is a test\n+==============\n+\n+.. include:: something-to-include.rst\n+\n+&REPLACE_ME;\n+''',\n+        encoding='utf-8'\n+    )\n+\n+    # something-to-include.rst\n+    (src_dir / \"something-to-include.rst\").write_text(\n+        '''\n+Testing\n+=======\n+\n+&REPLACE_ME;\n+''',\n+        encoding='utf-8'\n+    )\n+    return src_dir\n+\n+\n+def test_source_read_event_on_included_files(make_app, source_read_test_root: Path):\n+    \"\"\"\n+    Tests that the source-read event also modifies included files.\n+\n+    This test reproduces a bug where content replacement from a custom extension\n+    does not apply to files included with the `.. include::` directive.\n+    \"\"\"\n+    app = make_app('html', srcdir=source_read_test_root)\n+    app.build()\n+    result = (app.outdir / 'index.html').read_text(encoding='utf-8')\n+\n+    # This assertion will fail as long as the bug is present because\n+    # the placeholder in the included file is not replaced.\n+    assert '&amp;REPLACE_ME;' not in result\n"
    },
    "astropy__astropy-14369": {
        "reproduced_bug": true,
        "reproduced_bug_file": "astropy/io/ascii/tests/test_cds_composite_units_parsing.py",
        "reproduced_bug_commands": [
            "pytest astropy/io/ascii/tests/test_cds_composite_units_parsing.py"
        ],
        "reproduced_bug_patch": "diff --git a/astropy/io/ascii/tests/test_cds_composite_units_parsing.py b/astropy/io/ascii/tests/test_cds_composite_units_parsing.py\nnew file mode 100644\nindex 0000000000..f4327f649e\n--- /dev/null\n+++ b/astropy/io/ascii/tests/test_cds_composite_units_parsing.py\n@@ -0,0 +1,38 @@\n+import pytest\n+from astropy.io import ascii\n+from astropy import units as u\n+\n+\n+def test_cds_composite_units_parsing():\n+    \"\"\"\n+    Test for incorrect parsing of composite units from a CDS/MRT file.\n+    The issue is that units like '10+3J/m/s/kpc2' are misread,\n+    particularly the order of division.\n+    \"\"\"\n+    mrt_data = \"\"\"Title:\n+Authors:\n+Table:\n+================================================================================\n+Byte-by-byte Description of file: tab.txt\n+--------------------------------------------------------------------------------\n+   Bytes Format Units          \t\tLabel      Explanations\n+--------------------------------------------------------------------------------\n+   1- 10 A10    ---            \t\tID         ID\n+  12- 21 F10.5  10+3J/m/s/kpc2    \tSBCONT     Cont surface brightness\n+  23- 32 F10.5  10-7J/s/kpc2 \t\tSBLINE     Line surface brightness\n+--------------------------------------------------------------------------------\n+ID0001     70.99200   38.51040\n+ID0001     13.05120   28.19240\n+ID0001     3.83610    10.98370\n+ID0001     1.99101    6.78822\n+ID0001     1.31142    5.01932\n+\"\"\"\n+    dat = ascii.read(mrt_data, format=\"cds\")\n+\n+    # According to the bug report, the unit for SBCONT is incorrectly parsed as\n+    # '1e+3 J s / (kpc2 m)'. We assert against the correctly formed unit.\n+    # The expected unit is constructed programmatically to be independent of\n+    # the potentially buggy string parser.\n+    expected_unit = 1e3 * u.J / (u.m * u.s * u.kpc**2)\n+\n+    assert dat[\"SBCONT\"].unit == expected_unit\n"
    },
    "django__django-14238": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/model_options/test_default_auto_field.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py model_options.test_default_auto_field"
        ],
        "reproduced_bug_patch": "diff --git a/tests/model_options/test_default_auto_field.py b/tests/model_options/test_default_auto_field.py\nnew file mode 100644\nindex 0000000000..096ca0bb51\n--- /dev/null\n+++ b/tests/model_options/test_default_auto_field.py\n@@ -0,0 +1,66 @@\n+from django.core.exceptions import ImproperlyConfigured\n+from django.db import models\n+from django.test import SimpleTestCase, override_settings\n+from django.test.utils import isolate_apps\n+\n+\n+# Define classes at the module level to make them importable.\n+class MyBigAutoField(models.BigAutoField):\n+    pass\n+\n+\n+class MySmallAutoField(models.SmallAutoField):\n+    pass\n+\n+\n+@isolate_apps('model_options')\n+class TestDefaultPK(SimpleTestCase):\n+    @override_settings(DEFAULT_AUTO_FIELD='django.db.models.NonexistentAutoField')\n+    def test_default_auto_field_setting_nonexistent(self):\n+        msg = (\n+            \"DEFAULT_AUTO_FIELD refers to the module \"\n+            \"'django.db.models.NonexistentAutoField' that could not be \"\n+            \"imported.\"\n+        )\n+        with self.assertRaisesMessage(ImproperlyConfigured, msg):\n+            class Model(models.Model):\n+                pass\n+\n+    @isolate_apps('model_options.apps.ModelPKNonexistentConfig')\n+    def test_app_default_auto_field_nonexistent(self):\n+        msg = (\n+            \"model_options.apps.ModelPKNonexistentConfig.default_auto_field \"\n+            \"refers to the module 'django.db.models.NonexistentAutoField' \"\n+            \"that could not be imported.\"\n+        )\n+        with self.assertRaisesMessage(ImproperlyConfigured, msg):\n+            class Model(models.Model):\n+                pass\n+\n+    @override_settings(DEFAULT_AUTO_FIELD='django.db.models.TextField')\n+    def test_default_auto_field_setting_non_auto(self):\n+        msg = (\n+            \"Primary key 'django.db.models.TextField' referred by \"\n+            \"DEFAULT_AUTO_FIELD must subclass AutoField.\"\n+        )\n+        with self.assertRaisesMessage(ValueError, msg):\n+            class Model(models.Model):\n+                pass\n+\n+    def test_default_auto_field_subclasses(self):\n+        \"\"\"\n+        Subclasses of BigAutoField and SmallAutoField can be used for\n+        DEFAULT_AUTO_FIELD.\n+        \"\"\"\n+        module_path = __name__\n+        for field_name, field_class in (\n+            ('MyBigAutoField', MyBigAutoField),\n+            ('MySmallAutoField', MySmallAutoField),\n+        ):\n+            field_path = f'{module_path}.{field_name}'\n+            with self.subTest(field=field_path):\n+                with override_settings(DEFAULT_AUTO_FIELD=field_path):\n+                    class Model(models.Model):\n+                        pass\n+\n+                    self.assertIsInstance(Model._meta.pk, field_class)\n"
    },
    "django__django-17087": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "pylint-dev__pylint-4604": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/functional/r/regression/regression_4510_unused_import_type_comment.py",
        "reproduced_bug_commands": [
            "python3 tests/test_functional.py -k regression_4510_unused_import_type_comment"
        ],
        "reproduced_bug_patch": "diff --git a/tests/functional/r/regression/regression_4510_unused_import_type_comment.py b/tests/functional/r/regression/regression_4510_unused_import_type_comment.py\nnew file mode 100644\nindex 000000000..80b6038ec\n--- /dev/null\n+++ b/tests/functional/r/regression/regression_4510_unused_import_type_comment.py\n@@ -0,0 +1,12 @@\n+# pylint: disable=invalid-name,missing-docstring\n+\"\"\"\n+Regression test for unused-import false positive when a\n+module is used in a type comment.\n+https://github.com/PyCQA/pylint/issues/4510\n+\"\"\"\n+\n+import abc\n+from abc import ABC\n+\n+X = ...  # type: abc.ABC\n+Y = ...  # type: ABC\n"
    },
    "scikit-learn__scikit-learn-12973": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/linear_model/tests/test_lassolarsic_copy_x_bug.py",
        "reproduced_bug_commands": [
            "pytest sklearn/linear_model/tests/test_lassolarsic_copy_x_bug.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/linear_model/tests/test_lassolarsic_copy_x_bug.py b/sklearn/linear_model/tests/test_lassolarsic_copy_x_bug.py\nnew file mode 100644\nindex 0000000000..518f230a26\n--- /dev/null\n+++ b/sklearn/linear_model/tests/test_lassolarsic_copy_x_bug.py\n@@ -0,0 +1,45 @@\n+import pytest\n+import numpy as np\n+\n+from sklearn import linear_model\n+from sklearn.utils.testing import assert_array_equal\n+from sklearn import datasets\n+\n+def test_lassolarsic_copy_x_is_overwritten():\n+    \"\"\"\n+    Test that LassoLarsIC's fit method incorrectly overwrites constructor's copy_X.\n+\n+    The bug is that the `copy_X=True` default in the `fit` method signature\n+    overrides the `copy_X` value provided to the constructor. This test\n+    verifies that when `copy_X=False` is set in the constructor, the input\n+    array `X` is NOT modified in-place by the underlying `lars_path`\n+    function as it should be.\n+\n+    We engineer a dataset where the last column is most correlated with y.\n+    A correct in-place fit would swap this last column to the first position in X.\n+    The test asserts that the first column of X is NOT the original last column,\n+    which will be true if the bug exists, causing the test to fail.\n+    \"\"\"\n+    # Create a dataset where the last feature is the most correlated.\n+    # This forces lars_path to swap the last column to the first position\n+    # if it modifies the array in-place.\n+    rng = np.random.RandomState(0)\n+    X_train = rng.randn(10, 5)\n+    y_train = 2 * X_train[:, -1]\n+\n+    # Keep a copy of the original last column to check against later\n+    original_last_col = X_train[:, -1].copy()\n+\n+    # We expect lars_path to operate on X_train in-place because copy_X=False.\n+    # fit_intercept=False is used to prevent in-place centering, simplifying\n+    # the test to only check for the effect of lars_path's column swapping.\n+    estimator = linear_model.LassoLarsIC(copy_X=False, fit_intercept=False)\n+    estimator.fit(X_train, y_train)\n+\n+    # With the bug, `fit` calls `lars_path` with `copy_X=True`, so a copy\n+    # is made inside `lars_path` and the original `X_train` is not modified.\n+    # Therefore, the first column of X_train will not have been swapped with the last.\n+    # This assertion will FAIL because the columns are not equal, thus\n+    # demonstrating the bug. When the bug is fixed, the swap will occur,\n+    # and the assertion will pass.\n+    assert_array_equal(X_train[:, 0], original_last_col)\n"
    },
    "sphinx-doc__sphinx-7440": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_directive_glossary.py",
        "reproduced_bug_commands": [
            "pytest tests/test_directive_glossary.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_directive_glossary.py b/tests/test_directive_glossary.py\nnew file mode 100644\nindex 000000000..cdc53c8d1\n--- /dev/null\n+++ b/tests/test_directive_glossary.py\n@@ -0,0 +1,25 @@\n+import pytest\n+\n+from docutils import nodes\n+from docutils.nodes import definition, definition_list, definition_list_item, term\n+\n+from sphinx import addnodes\n+from sphinx.addnodes import glossary, index\n+from sphinx.testing import restructuredtext\n+from sphinx.testing.util import assert_node\n+\n+\n+def test_glossary_duplicate_term_with_different_case(app, status, warning):\n+    \"\"\"\n+    Tests that the glossary directive does not incorrectly report duplicate\n+    terms when they differ in case.\n+    \"\"\"\n+    text = (\".. glossary::\\n\"\n+            \"\\n\"\n+            \"   mysql\\n\"\n+            \"       A relational database management system.\\n\"\n+            \"\\n\"\n+            \"   MySQL\\n\"\n+            \"       A relational database management system.\\n\")\n+    restructuredtext.parse(app, text)\n+    assert warning.getvalue() == \"\"\n"
    },
    "astropy__astropy-14508": {
        "reproduced_bug": true,
        "reproduced_bug_file": "astropy/io/fits/tests/test_card.py",
        "reproduced_bug_commands": [
            "pytest astropy/io/fits/tests/test_card.py"
        ],
        "reproduced_bug_patch": "diff --git a/astropy/io/fits/tests/test_card.py b/astropy/io/fits/tests/test_card.py\nnew file mode 100644\nindex 0000000000..c6f7e2e538\n--- /dev/null\n+++ b/astropy/io/fits/tests/test_card.py\n@@ -0,0 +1,21 @@\n+import pytest\n+from astropy.io import fits\n+\n+\n+def test_float_card_correctly_formatted_to_avoid_truncation():\n+    \"\"\"\n+    Regression test for a bug where an unnecessarily long string\n+    representation of a float value would cause the card's comment\n+    to be truncated.\n+    \"\"\"\n+    keyword = \"HIERARCH ESO IFM CL RADIUS\"\n+    value = 0.009125\n+    comment = \"[m] radius arround actuator to avoid\"\n+\n+    card = fits.Card(keyword, value, comment)\n+\n+    expected_image = (\n+        \"HIERARCH ESO IFM CL RADIUS = 0.009125 / [m] radius arround actuator to avoid  \"\n+    )\n+\n+    assert str(card) == expected_image\n"
    },
    "django__django-14311": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "django__django-7530": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "pylint-dev__pylint-4661": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_xdg_data_directory.py",
        "reproduced_bug_commands": [
            "pytest tests/test_xdg_data_directory.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_xdg_data_directory.py b/tests/test_xdg_data_directory.py\nnew file mode 100644\nindex 000000000..31d76b8b3\n--- /dev/null\n+++ b/tests/test_xdg_data_directory.py\n@@ -0,0 +1,38 @@\n+import importlib\n+import os\n+\n+from pylint import config\n+\n+\n+def test_pylint_data_directory_follows_xdg_specification(tmp_path, monkeypatch):\n+    \"\"\"\n+    Test that pylint creates its data directory according to the XDG Base\n+    Directory Specification.\n+\n+    This test will fail until the bug is fixed. The desired behavior is for\n+    pylint to create its data directory inside ~/.local/share/pylint/\n+    when XDG_DATA_HOME is not set.\n+    \"\"\"\n+    # 1. Set up a fake home directory for the test\n+    home_dir = tmp_path / \"home\"\n+    home_dir.mkdir()\n+    expected_xdg_data_dir = home_dir / \".local\" / \"share\" / \"pylint\"\n+\n+    # 2. Patch environment variables to simulate a clean user environment\n+    #    - Set HOME to our fake home directory.\n+    #    - Unset PYLINTHOME and XDG_DATA_HOME to test the default behavior.\n+    monkeypatch.setenv(\"HOME\", str(home_dir))\n+    monkeypatch.delenv(\"PYLINTHOME\", raising=False)\n+    monkeypatch.delenv(\"XDG_DATA_HOME\", raising=False)\n+\n+    # 3. Reload the config module to pick up the patched environment variables.\n+    #    This is necessary because PYLINT_HOME is determined at import time.\n+    importlib.reload(config)\n+\n+    # 4. Call a function that triggers the creation of the data directory.\n+    config.save_results(results={}, base=\"test_run\")\n+\n+    # 5. Assert that the XDG-compliant data directory is created.\n+    #    This assertion will fail because pylint currently creates ~/.pylint.d\n+    #    instead. It will pass once the bug is fixed.\n+    assert expected_xdg_data_dir.is_dir()\n"
    },
    "scikit-learn__scikit-learn-13124": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/model_selection/tests/test_stratified_kfold_bug_13114.py",
        "reproduced_bug_commands": [
            "pytest sklearn/model_selection/tests/test_stratified_kfold_bug_13114.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/model_selection/tests/test_stratified_kfold_bug_13114.py b/sklearn/model_selection/tests/test_stratified_kfold_bug_13114.py\nnew file mode 100644\nindex 0000000000..e01df66036\n--- /dev/null\n+++ b/sklearn/model_selection/tests/test_stratified_kfold_bug_13114.py\n@@ -0,0 +1,33 @@\n+import numpy as np\n+from sklearn.model_selection import StratifiedKFold\n+from sklearn.utils.testing import assert_not_equal\n+\n+\n+def test_stratified_kfold_shuffle_bug_13114():\n+    # Test for bug #13114\n+    # StratifiedKFold with shuffle=True should shuffle samples inside each\n+    # stratum. The bug is that it shuffles the order of the folds,\n+    # and not the samples in each stratum.\n+    samples_per_class = 10\n+    X = np.zeros(samples_per_class * 2)\n+    y = np.concatenate((np.ones(samples_per_class),\n+                        np.zeros(samples_per_class)), axis=0)\n+    n_splits = 10\n+\n+    # With shuffle=True, different random_state should lead to different\n+    # splits, not just a different ordering of the same splits.\n+    skf_1 = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1)\n+    splits_1 = [test for _, test in skf_1.split(X, y)]\n+\n+    skf_2 = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2)\n+    splits_2 = [test for _, test in skf_2.split(X, y)]\n+\n+    # The bug is that the set of folds is identical, only the order changes.\n+    # After the fix, the sets of folds should be different.\n+    # We sort the indices within each fold and then convert to a tuple to make\n+    # them hashable for the set.\n+    set_of_folds_1 = {tuple(np.sort(s)) for s in splits_1}\n+    set_of_folds_2 = {tuple(np.sort(s)) for s in splits_2}\n+\n+    # This assertion will fail if the bug is present, and pass when fixed.\n+    assert_not_equal(set_of_folds_1, set_of_folds_2)\n"
    },
    "sphinx-doc__sphinx-7454": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_ext_autodoc_typehints.py",
        "reproduced_bug_commands": [
            "pytest tests/test_ext_autodoc_typehints.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_ext_autodoc_typehints.py b/tests/test_ext_autodoc_typehints.py\nnew file mode 100644\nindex 000000000..c632d6c19\n--- /dev/null\n+++ b/tests/test_ext_autodoc_typehints.py\n@@ -0,0 +1,37 @@\n+import pytest\n+\n+@pytest.mark.sphinx(\n+    'html',\n+    testroot='ext-autodoc',\n+    confoverrides={\n+        'autodoc_typehints': 'signature',\n+        'intersphinx_mapping': {'python': ('https://docs.python.org/3', None)},\n+    }\n+)\n+def test_autodoc_typehints_signature_none_return_type(app):\n+    \"\"\"\n+    Test that a return type of None is linked correctly when\n+    autodoc_typehints is 'signature'. This reproduces the bug where `None`\n+    return types are not linked.\n+    \"\"\"\n+    # Create a minimal rst file to document a method that returns None.\n+    # The 'ext-autodoc' test root provides the 'target.typehints' module,\n+    # which contains 'Math.nothing() -> None'.\n+    (app.srcdir / 'index.rst').write_text(\n+        '.. automethod:: target.typehints.Math.nothing'\n+    )\n+\n+    # Build the documentation.\n+    app.build()\n+\n+    # Read the generated HTML.\n+    content = (app.outdir / 'index.html').read_text()\n+\n+    # Check that the return type \"None\" is a link to the python docs.\n+    # The expected HTML for '-> None' is '→ <a ...>None</a>'.\n+    # This assertion will fail if the link is not generated.\n+    expected_link_html = (\n+        '&#x2192; <a class=\"reference external\" '\n+        'href=\"https://docs.python.org/3/library/constants.html#None\"'\n+    )\n+    assert expected_link_html in content\n"
    },
    "astropy__astropy-14539": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "django__django-14315": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "django__django-9296": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/pagination/test_iterator.py",
        "reproduced_bug_commands": [
            "runtests.py pagination"
        ],
        "reproduced_bug_patch": "diff --git a/tests/pagination/test_iterator.py b/tests/pagination/test_iterator.py\nnew file mode 100644\nindex 0000000000..47e3e1fd9c\n--- /dev/null\n+++ b/tests/pagination/test_iterator.py\n@@ -0,0 +1,16 @@\n+from django.core.paginator import Paginator\n+from django.test import SimpleTestCase\n+\n+\n+class PaginationIteratorTest(SimpleTestCase):\n+    \"\"\"\n+    Test case for Paginator iteration as requested in issue description.\n+    \"\"\"\n+\n+    def test_paginator_is_iterable(self):\n+        \"\"\"\n+        Test that a Paginator object can be iterated over to yield pages.\n+        \"\"\"\n+        paginator = Paginator([1, 2, 3, 4, 5], 2)\n+        page_contents = [p.object_list for p in paginator]\n+        self.assertEqual(page_contents, [[1, 2], [3, 4], [5]])\n"
    },
    "pylint-dev__pylint-4970": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/checkers/test_min_similarity_lines_zero.py",
        "reproduced_bug_commands": [
            "pytest tests/checkers/test_min_similarity_lines_zero.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/checkers/test_min_similarity_lines_zero.py b/tests/checkers/test_min_similarity_lines_zero.py\nnew file mode 100644\nindex 000000000..9833e846c\n--- /dev/null\n+++ b/tests/checkers/test_min_similarity_lines_zero.py\n@@ -0,0 +1,49 @@\n+from pathlib import Path\n+\n+import pytest\n+\n+from pylint.checkers import similar\n+from pylint.lint import PyLinter\n+from pylint.testutils import GenericTestReporter as Reporter\n+\n+\n+def test_min_similarity_lines_zero_disables_check(tmp_path: Path) -> None:\n+    \"\"\"Test that min-similarity-lines=0 disables the similarity check.\n+\n+    Setting min-similarity-lines to 0 should disable the duplicate code\n+    check entirely. This test ensures that when the option is set to 0,\n+    no 'duplicate-code' messages are emitted for files with obvious\n+    similarities.\n+    \"\"\"\n+    file1_content = \"\"\"\n+import one\n+from two import two\n+three\n+four\n+five\n+six\n+\"\"\"\n+    file2_content = \"\"\"\n+import one\n+from two import two\n+three\n+four\n+five\n+seven\n+\"\"\"\n+    file1 = tmp_path / \"file1.py\"\n+    file1.write_text(file1_content, encoding=\"utf-8\")\n+    file2 = tmp_path / \"file2.py\"\n+    file2.write_text(file2_content, encoding=\"utf-8\")\n+\n+    linter = PyLinter()\n+    reporter = Reporter()\n+    linter.set_reporter(reporter)\n+    checker = similar.SimilarChecker(linter)\n+    linter.register_checker(checker)\n+    linter.load_configuration()\n+    checker.config.min_similarity_lines = 0\n+\n+    linter.check([str(file1), str(file2)])\n+\n+    assert not reporter.messages\n"
    },
    "scikit-learn__scikit-learn-13135": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/preprocessing/tests/test_kbins_discretizer_bug.py",
        "reproduced_bug_commands": [
            "pytest sklearn/preprocessing/tests/test_kbins_discretizer_bug.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/preprocessing/tests/test_kbins_discretizer_bug.py b/sklearn/preprocessing/tests/test_kbins_discretizer_bug.py\nnew file mode 100644\nindex 0000000000..ded29523c2\n--- /dev/null\n+++ b/sklearn/preprocessing/tests/test_kbins_discretizer_bug.py\n@@ -0,0 +1,19 @@\n+import numpy as np\n+import pytest\n+\n+from sklearn.preprocessing import KBinsDiscretizer\n+from sklearn.utils.testing import assert_array_equal\n+\n+\n+def test_kmeans_discretizer_unsorted_bins():\n+    \"\"\"Test for bug #13684.\n+\n+    KBinsDiscretizer with strategy='kmeans' should not fail with unsorted\n+    bin edges.\n+    \"\"\"\n+    X = np.array([0, 0.5, 2, 3, 9, 10]).reshape(-1, 1)\n+\n+    # with 5 bins\n+    est = KBinsDiscretizer(n_bins=5, strategy='kmeans', encode='ordinal')\n+    # This line should not raise a ValueError\n+    est.fit_transform(X)\n"
    },
    "sphinx-doc__sphinx-7462": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_domain_py_annotations.py",
        "reproduced_bug_commands": [
            "pytest tests/test_domain_py_annotations.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_domain_py_annotations.py b/tests/test_domain_py_annotations.py\nnew file mode 100644\nindex 000000000..e1d21eed0\n--- /dev/null\n+++ b/tests/test_domain_py_annotations.py\n@@ -0,0 +1,28 @@\n+import sys\n+from unittest.mock import Mock\n+\n+import pytest\n+from docutils import nodes\n+\n+from sphinx import addnodes\n+from sphinx.addnodes import (\n+    desc, desc_addname, desc_annotation, desc_content, desc_name, desc_optional,\n+    desc_parameter, desc_parameterlist, desc_returns, desc_signature,\n+    desc_sig_name, desc_sig_operator, desc_sig_punctuation, pending_xref,\n+)\n+from sphinx.domains import IndexEntry\n+from sphinx.domains.python import (\n+    py_sig_re, _parse_annotation, _pseudo_parse_arglist, PythonDomain, PythonModuleIndex\n+)\n+from sphinx.testing import restructuredtext\n+from sphinx.testing.util import assert_node\n+\n+\n+def test_parse_annotation_empty_tuple():\n+    \"\"\"Test parsing of empty tuple annotation ``Tuple[()]``.\"\"\"\n+    doctree = _parse_annotation(\"Tuple[()]\")\n+    assert_node(doctree, ([pending_xref, \"Tuple\"],\n+                          [desc_sig_punctuation, \"[\"],\n+                          [desc_sig_punctuation, \"(\"],\n+                          [desc_sig_punctuation, \")\"],\n+                          [desc_sig_punctuation, \"]\"]))\n"
    },
    "astropy__astropy-14598": {
        "reproduced_bug": true,
        "reproduced_bug_file": "astropy/io/fits/tests/test_regression.py",
        "reproduced_bug_commands": [
            "pytest astropy/io/fits/tests/test_regression.py"
        ],
        "reproduced_bug_patch": "diff --git a/astropy/io/fits/tests/test_regression.py b/astropy/io/fits/tests/test_regression.py\nnew file mode 100644\nindex 0000000000..575e36d04c\n--- /dev/null\n+++ b/astropy/io/fits/tests/test_regression.py\n@@ -0,0 +1,17 @@\n+import pytest\n+from astropy.io import fits\n+\n+\n+@pytest.mark.parametrize(\"n\", [65, 67, 68, 69])\n+def test_long_string_with_double_single_quote(n):\n+    \"\"\"\n+    Regression test for issue where a double single-quote in a long string\n+    is not preserved when converting a Card to a string and back.\n+\n+    This issue occurs at specific string lengths where the double single-quote\n+    interacts incorrectly with the long string continuation logic.\n+    \"\"\"\n+    value = \"x\" * n + \"''\"\n+    card1 = fits.Card(\"CONFIG\", value)\n+    card2 = fits.Card.fromstring(str(card1))\n+    assert card2.value == card1.value\n"
    },
    "django__django-14349": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/forms_tests/tests/test_urlvalidator.py",
        "reproduced_bug_commands": [
            "python3 tests/runtests.py forms_tests.tests.test_urlvalidator"
        ],
        "reproduced_bug_patch": "diff --git a/tests/forms_tests/tests/test_urlvalidator.py b/tests/forms_tests/tests/test_urlvalidator.py\nnew file mode 100644\nindex 0000000000..1089c84dee\n--- /dev/null\n+++ b/tests/forms_tests/tests/test_urlvalidator.py\n@@ -0,0 +1,21 @@\n+from django.core.exceptions import ValidationError\n+from django.core.validators import URLValidator\n+from django.test import SimpleTestCase\n+\n+\n+class URLValidatorTest(SimpleTestCase):\n+    def test_url_with_newline_is_invalid(self):\n+        \"\"\"\n+        A URL containing a newline should not be considered valid. The underlying\n+        urllib.parse.urlsplit() was changed in Python 3.9+ to strip leading\n+        and trailing whitespace, which includes newlines.\n+        \"\"\"\n+        validator = URLValidator()\n+        urls = [\n+            \"http://www.djangoproject.com/\\n\",\n+            \"http://[::ffff:192.9.5.5]\\n\",\n+        ]\n+        for url in urls:\n+            with self.subTest(url=url):\n+                with self.assertRaises(ValidationError):\n+                    validator(url)\n"
    },
    "matplotlib__matplotlib-13989": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_hist.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_hist.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_hist.py b/lib/matplotlib/tests/test_hist.py\nnew file mode 100644\nindex 0000000000..5ea28fc5ee\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_hist.py\n@@ -0,0 +1,17 @@\n+import numpy as np\n+import pytest\n+import matplotlib.pyplot as plt\n+from numpy.testing import assert_allclose\n+\n+\n+def test_hist_density_range():\n+    \"\"\"\n+    Test that hist() respects the range parameter when density=True.\n+\n+    This is a regression test for\n+    https://github.com/matplotlib/matplotlib/issues/14272\n+    \"\"\"\n+    np.random.seed(19680801)  # Make test reproducible.\n+    _, bins, _ = plt.hist(np.random.rand(10), bins=\"auto\",\n+                          range=(0, 1), density=True)\n+    assert_allclose([bins[0], bins[-1]], [0, 1])\n"
    },
    "scikit-learn__scikit-learn-13142": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/mixture/tests/test_gaussian_mixture_issue_13201.py",
        "reproduced_bug_commands": [
            "pytest sklearn/mixture/tests/test_gaussian_mixture_issue_13201.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/mixture/tests/test_gaussian_mixture_issue_13201.py b/sklearn/mixture/tests/test_gaussian_mixture_issue_13201.py\nnew file mode 100644\nindex 0000000000..eed9f3c8c6\n--- /dev/null\n+++ b/sklearn/mixture/tests/test_gaussian_mixture_issue_13201.py\n@@ -0,0 +1,48 @@\n+import sys\n+import copy\n+import warnings\n+import pytest\n+\n+import numpy as np\n+from scipy import stats, linalg\n+\n+from sklearn.covariance import EmpiricalCovariance\n+from sklearn.datasets.samples_generator import make_spd_matrix\n+from io import StringIO\n+from sklearn.metrics.cluster import adjusted_rand_score\n+from sklearn.mixture.gaussian_mixture import GaussianMixture\n+from sklearn.mixture.gaussian_mixture import (\n+    _estimate_gaussian_covariances_full,\n+    _estimate_gaussian_covariances_tied,\n+    _estimate_gaussian_covariances_diag,\n+    _estimate_gaussian_covariances_spherical)\n+from sklearn.mixture.gaussian_mixture import _compute_precision_cholesky\n+from sklearn.mixture.gaussian_mixture import _compute_log_det_cholesky\n+from sklearn.exceptions import ConvergenceWarning, NotFittedError\n+from sklearn.utils.extmath import fast_logdet\n+from sklearn.utils.testing import assert_allclose\n+from sklearn.utils.testing import assert_almost_equal\n+from sklearn.utils.testing import assert_array_almost_equal\n+from sklearn.utils.testing import assert_array_equal\n+from sklearn.utils.testing import assert_equal\n+from sklearn.utils.testing import assert_greater\n+from sklearn.utils.testing import assert_greater_equal\n+from sklearn.utils.testing import assert_raise_message\n+from sklearn.utils.testing import assert_warns_message\n+from sklearn.utils.testing import ignore_warnings\n+\n+\n+def test_gaussian_mixture_fit_predict_n_init():\n+    # Non-regression test for issue #13201.\n+    # Checks that fit_predict and predict give same results when n_init > 1.\n+    rng = np.random.RandomState(0)\n+    X = rng.randn(1000, 5)\n+\n+    gm = GaussianMixture(n_components=5, n_init=5, random_state=rng)\n+\n+    # The result of fit_predict should be the same as predict on the same\n+    # fitted model.\n+    y_fit_predict = gm.fit_predict(X)\n+    y_predict = gm.predict(X)\n+\n+    assert_array_equal(y_fit_predict, y_predict)\n"
    },
    "sphinx-doc__sphinx-7590": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_domain_cpp_user_defined_literals.py",
        "reproduced_bug_commands": [
            "pytest tests/test_domain_cpp_user_defined_literals.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_domain_cpp_user_defined_literals.py b/tests/test_domain_cpp_user_defined_literals.py\nnew file mode 100644\nindex 000000000..eab0600a9\n--- /dev/null\n+++ b/tests/test_domain_cpp_user_defined_literals.py\n@@ -0,0 +1,89 @@\n+import re\n+\n+import pytest\n+\n+from sphinx import addnodes\n+from sphinx.domains.cpp import DefinitionParser, DefinitionError, NoOldIdError\n+from sphinx.domains.cpp import Symbol, _max_id, _id_prefix\n+\n+\n+def parse(name, string):\n+    class Config:\n+        cpp_id_attributes = [\"id_attr\"]\n+        cpp_paren_attributes = [\"paren_attr\"]\n+    parser = DefinitionParser(string, location=None, config=Config())\n+    parser.allowFallbackExpressionParsing = False\n+    ast = parser.parse_declaration(name, name)\n+    parser.assert_end()\n+    # The scopedness would usually have been set by CPPEnumObject\n+    if name == \"enum\":\n+        ast.scoped = None  # simulate unscoped enum\n+    return ast\n+\n+\n+def _check(name, input, idDict, output):\n+    # first a simple check of the AST\n+    ast = parse(name, input)\n+    res = str(ast)\n+    if res != output:\n+        print(\"\")\n+        print(\"Input:    \", input)\n+        print(\"Result:   \", res)\n+        print(\"Expected: \", output)\n+        raise DefinitionError(\"\")\n+    rootSymbol = Symbol(None, None, None, None, None, None)\n+    symbol = rootSymbol.add_declaration(ast, docname=\"TestDoc\")\n+    parentNode = addnodes.desc()\n+    signode = addnodes.desc_signature(input, '')\n+    parentNode += signode\n+    ast.describe_signature(signode, 'lastIsName', symbol, options={})\n+\n+    idExpected = [None]\n+    for i in range(1, _max_id + 1):\n+        if i in idDict:\n+            idExpected.append(idDict[i])\n+        else:\n+            idExpected.append(idExpected[i - 1])\n+    idActual = [None]\n+    for i in range(1, _max_id + 1):\n+        try:\n+            id = ast.get_id(version=i)\n+            assert id is not None\n+            idActual.append(id[len(_id_prefix[i]):])\n+        except NoOldIdError:\n+            idActual.append(None)\n+\n+    res = [True]\n+    for i in range(1, _max_id + 1):\n+        res.append(idExpected[i] == idActual[i])\n+\n+    if not all(res):\n+        print(\"input:    %s\" % input.rjust(20))\n+        for i in range(1, _max_id + 1):\n+            if res[i]:\n+                continue\n+            print(\"Error in id version %d.\" % i)\n+            print(\"result:   %s\" % idActual[i])\n+            print(\"expected: %s\" % idExpected[i])\n+        print(rootSymbol.dump(0))\n+        raise DefinitionError(\"\")\n+\n+\n+def check(name, input, idDict, output=None):\n+    if output is None:\n+        output = input\n+    # First, check without semicolon\n+    _check(name, input, idDict, output)\n+    # Second, check with semicolon\n+    _check(name, input + ' ;', idDict, output + ';')\n+\n+\n+def test_user_defined_literal_in_variable_declaration():\n+    \"\"\"Tests parsing of a variable declaration with user-defined literals.\n+\n+    This was not supported and caused a parsing error.\n+    \"\"\"\n+    check('member',\n+          'constexpr auto planck_constant = 6.62607015e-34q_J * 1q_s',\n+          {1: 'planck_constant__auto', 2: '17planck_constant'},\n+          'constexpr auto planck_constant = 6.62607015e-34q_J * 1q_s')\n"
    },
    "astropy__astropy-14995": {
        "reproduced_bug": true,
        "reproduced_bug_file": "astropy/nddata/tests/test_regression.py",
        "reproduced_bug_commands": [
            "pytest astropy/nddata/tests/test_regression.py"
        ],
        "reproduced_bug_patch": "diff --git a/astropy/nddata/tests/test_regression.py b/astropy/nddata/tests/test_regression.py\nnew file mode 100644\nindex 0000000000..b6e7cbccad\n--- /dev/null\n+++ b/astropy/nddata/tests/test_regression.py\n@@ -0,0 +1,24 @@\n+import numpy as np\n+import pytest\n+from numpy.testing import assert_array_equal\n+\n+from astropy.nddata import NDDataRef\n+\n+\n+def test_bitwise_or_mask_propagation_with_no_mask_operand():\n+    \"\"\"\n+    Regression test for a bug where mask propagation with `np.bitwise_or`\n+    failed if one of the operands did not have a mask.\n+\n+    See https://github.com/astropy/astropy/issues/15166\n+    \"\"\"\n+    array = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]])\n+    mask = np.array([[0, 1, 64], [8, 0, 1], [2, 1, 0]])\n+\n+    nref_mask = NDDataRef(array, mask=mask)\n+    nref_nomask = NDDataRef(array)\n+\n+    # This failed when multiplying an NDDataRef with a mask by another\n+    # NDDataRef that has no mask, and a function handle for the mask.\n+    result = nref_mask.multiply(nref_nomask, handle_mask=np.bitwise_or)\n+    assert_array_equal(result.mask, mask)\n"
    },
    "matplotlib__matplotlib-14623": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_log_scale_inversion.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_log_scale_inversion.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_log_scale_inversion.py b/lib/matplotlib/tests/test_log_scale_inversion.py\nnew file mode 100644\nindex 0000000000..225560aa04\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_log_scale_inversion.py\n@@ -0,0 +1,21 @@\n+import numpy as np\n+import matplotlib.pyplot as plt\n+import pytest\n+\n+\n+def test_log_scale_inverted_ylim():\n+    \"\"\"\n+    Test that setting inverted limits on a log scale axis inverts the axis.\n+\n+    For log scales, ``set_ylim(bottom, top)`` with ``bottom > top`` should result\n+    in an inverted axis, but starting in v3.1.0 it does not.\n+    \"\"\"\n+    fig, ax = plt.subplots()\n+    y = np.linspace(1000e2, 1, 100)\n+    x = np.exp(-np.linspace(0, 1, y.size))\n+\n+    ax.plot(x, y)\n+    ax.set_yscale('log')\n+    ax.set_ylim(y.max(), y.min())\n+\n+    assert ax.yaxis_inverted()\n"
    },
    "django__django-14351": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/queries/test_or_m2m_subquery.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py queries.test_or_m2m_subquery"
        ],
        "reproduced_bug_patch": "diff --git a/tests/queries/test_or_m2m_subquery.py b/tests/queries/test_or_m2m_subquery.py\nnew file mode 100644\nindex 0000000000..f35819fd55\n--- /dev/null\n+++ b/tests/queries/test_or_m2m_subquery.py\n@@ -0,0 +1,60 @@\n+from operator import attrgetter\n+\n+from django.db import models\n+from django.db.models import Count, Q\n+from django.test import TestCase\n+\n+\n+class PropertyGroup(models.Model):\n+    name = models.CharField(max_length=50)\n+\n+\n+class Agent(models.Model):\n+    name = models.CharField(max_length=50)\n+    property_groups = models.ManyToManyField('queries.PropertyGroup', blank=True)\n+\n+\n+class Ticket(models.Model):\n+    name = models.CharField(max_length=50)\n+    agent = models.ForeignKey('queries.Agent', models.CASCADE)\n+\n+    class Meta:\n+        ordering = ['name']\n+\n+\n+class OrM2MSubqueryTest(TestCase):\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.pg1 = PropertyGroup.objects.create(name='PG1')\n+        cls.pg2 = PropertyGroup.objects.create(name='PG2')\n+\n+        cls.agent1 = Agent.objects.create(name='Agent 1')\n+        cls.agent1.property_groups.add(cls.pg1)\n+\n+        cls.agent2 = Agent.objects.create(name='Agent 2')\n+\n+        cls.agent3 = Agent.objects.create(name='Agent 3')\n+        cls.agent3.property_groups.add(cls.pg2)\n+\n+        cls.ticket1 = Ticket.objects.create(name='Ticket 1', agent=cls.agent1)\n+        cls.ticket2 = Ticket.objects.create(name='Ticket 2', agent=cls.agent2)\n+        Ticket.objects.create(name='Ticket 3', agent=cls.agent3)\n+\n+    def test_or_with_m2m_subquery(self):\n+        \"\"\"\n+        A filter combining a subquery lookup on an M2M with an annotation\n+        count was generating a subquery that selected all columns instead of\n+        just the PK.\n+        \"\"\"\n+        property_groups = PropertyGroup.objects.filter(pk=self.pg1.pk)\n+        qs = Ticket.objects.annotate(\n+            agent__property_groups__count=Count('agent__property_groups')\n+        ).filter(\n+            Q(agent__property_groups__in=property_groups) | Q(agent__property_groups__count=0)\n+        ).distinct()\n+\n+        self.assertQuerysetEqual(\n+            qs,\n+            ['Ticket 1', 'Ticket 2'],\n+            attrgetter('name')\n+        )\n"
    },
    "pylint-dev__pylint-6386": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/config/test_command_line_options.py",
        "reproduced_bug_commands": [
            "pytest tests/config/test_command_line_options.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/config/test_command_line_options.py b/tests/config/test_command_line_options.py\nnew file mode 100644\nindex 000000000..49982a14d\n--- /dev/null\n+++ b/tests/config/test_command_line_options.py\n@@ -0,0 +1,16 @@\n+import pytest\n+from pylint.lint import Run\n+\n+def test_short_verbose_option_no_argument(tmp_path):\n+    \"\"\"\n+    Test that the short verbose option '-v' does not require an argument.\n+\n+    This is a regression test for https://github.com/pylint-dev/pylint/issues/5753.\n+    The bug causes pylint to exit with an argparse error when '-v' is used\n+    without a value. A successful run should exit with code 0.\n+    \"\"\"\n+    module = tmp_path / \"mytest.py\"\n+    module.touch()\n+    with pytest.raises(SystemExit) as ex:\n+        Run([str(module), \"-v\"])\n+    assert ex.value.code == 0\n"
    },
    "django__django-11885": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/delete/test_on_delete.py",
        "reproduced_bug_commands": [
            "python runtests.py delete.test_on_delete"
        ],
        "reproduced_bug_patch": "diff --git a/tests/delete/test_on_delete.py b/tests/delete/test_on_delete.py\nnew file mode 100644\nindex 0000000000..60a865e9c8\n--- /dev/null\n+++ b/tests/delete/test_on_delete.py\n@@ -0,0 +1,539 @@\n+import math\n+from math import ceil\n+\n+from django.db import IntegrityError, connection, models\n+from django.db.models.deletion import Collector\n+from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE\n+from django.test import TestCase, skipIfDBFeature, skipUnlessDBFeature\n+\n+from .models import (\n+    MR, A, Avatar, Base, Child, HiddenUser, HiddenUserProfile, M, M2MFrom,\n+    M2MTo, MRNull, Origin, Parent, R, RChild, RChildChild, Referrer, S, T,\n+    User, create_a, get_default_r, SecondReferrer,\n+)\n+\n+\n+class OnDeleteTests(TestCase):\n+    def setUp(self):\n+        self.DEFAULT = get_default_r()\n+\n+    def test_auto(self):\n+        a = create_a('auto')\n+        a.auto.delete()\n+        self.assertFalse(A.objects.filter(name='auto').exists())\n+\n+    def test_non_callable(self):\n+        msg = 'on_delete must be callable.'\n+        with self.assertRaisesMessage(TypeError, msg):\n+            models.ForeignKey('self', on_delete=None)\n+        with self.assertRaisesMessage(TypeError, msg):\n+            models.OneToOneField('self', on_delete=None)\n+\n+    def test_auto_nullable(self):\n+        a = create_a('auto_nullable')\n+        a.auto_nullable.delete()\n+        self.assertFalse(A.objects.filter(name='auto_nullable').exists())\n+\n+    def test_setvalue(self):\n+        a = create_a('setvalue')\n+        a.setvalue.delete()\n+        a = A.objects.get(pk=a.pk)\n+        self.assertEqual(self.DEFAULT, a.setvalue.pk)\n+\n+    def test_setnull(self):\n+        a = create_a('setnull')\n+        a.setnull.delete()\n+        a = A.objects.get(pk=a.pk)\n+        self.assertIsNone(a.setnull)\n+\n+    def test_setdefault(self):\n+        a = create_a('setdefault')\n+        a.setdefault.delete()\n+        a = A.objects.get(pk=a.pk)\n+        self.assertEqual(self.DEFAULT, a.setdefault.pk)\n+\n+    def test_setdefault_none(self):\n+        a = create_a('setdefault_none')\n+        a.setdefault_none.delete()\n+        a = A.objects.get(pk=a.pk)\n+        self.assertIsNone(a.setdefault_none)\n+\n+    def test_cascade(self):\n+        a = create_a('cascade')\n+        a.cascade.delete()\n+        self.assertFalse(A.objects.filter(name='cascade').exists())\n+\n+    def test_cascade_nullable(self):\n+        a = create_a('cascade_nullable')\n+        a.cascade_nullable.delete()\n+        self.assertFalse(A.objects.filter(name='cascade_nullable').exists())\n+\n+    def test_protect(self):\n+        a = create_a('protect')\n+        msg = (\n+            \"Cannot delete some instances of model 'R' because they are \"\n+            \"referenced through a protected foreign key: 'A.protect'\"\n+        )\n+        with self.assertRaisesMessage(IntegrityError, msg):\n+            a.protect.delete()\n+\n+    def test_do_nothing(self):\n+        # Testing DO_NOTHING is a bit harder: It would raise IntegrityError for a normal model,\n+        # so we connect to pre_delete and set the fk to a known value.\n+        replacement_r = R.objects.create()\n+\n+        def check_do_nothing(sender, **kwargs):\n+            obj = kwargs['instance']\n+            obj.donothing_set.update(donothing=replacement_r)\n+        models.signals.pre_delete.connect(check_do_nothing)\n+        a = create_a('do_nothing')\n+        a.donothing.delete()\n+        a = A.objects.get(pk=a.pk)\n+        self.assertEqual(replacement_r, a.donothing)\n+        models.signals.pre_delete.disconnect(check_do_nothing)\n+\n+    def test_do_nothing_qscount(self):\n+        \"\"\"\n+        A models.DO_NOTHING relation doesn't trigger a query.\n+        \"\"\"\n+        b = Base.objects.create()\n+        with self.assertNumQueries(1):\n+            # RelToBase should not be queried.\n+            b.delete()\n+        self.assertEqual(Base.objects.count(), 0)\n+\n+    def test_inheritance_cascade_up(self):\n+        child = RChild.objects.create()\n+        child.delete()\n+        self.assertFalse(R.objects.filter(pk=child.pk).exists())\n+\n+    def test_inheritance_cascade_down(self):\n+        child = RChild.objects.create()\n+        parent = child.r_ptr\n+        parent.delete()\n+        self.assertFalse(RChild.objects.filter(pk=child.pk).exists())\n+\n+    def test_cascade_from_child(self):\n+        a = create_a('child')\n+        a.child.delete()\n+        self.assertFalse(A.objects.filter(name='child').exists())\n+        self.assertFalse(R.objects.filter(pk=a.child_id).exists())\n+\n+    def test_cascade_from_parent(self):\n+        a = create_a('child')\n+        R.objects.get(pk=a.child_id).delete()\n+        self.assertFalse(A.objects.filter(name='child').exists())\n+        self.assertFalse(RChild.objects.filter(pk=a.child_id).exists())\n+\n+    def test_setnull_from_child(self):\n+        a = create_a('child_setnull')\n+        a.child_setnull.delete()\n+        self.assertFalse(R.objects.filter(pk=a.child_setnull_id).exists())\n+\n+        a = A.objects.get(pk=a.pk)\n+        self.assertIsNone(a.child_setnull)\n+\n+    def test_setnull_from_parent(self):\n+        a = create_a('child_setnull')\n+        R.objects.get(pk=a.child_setnull_id).delete()\n+        self.assertFalse(RChild.objects.filter(pk=a.child_setnull_id).exists())\n+\n+        a = A.objects.get(pk=a.pk)\n+        self.assertIsNone(a.child_setnull)\n+\n+    def test_o2o_setnull(self):\n+        a = create_a('o2o_setnull')\n+        a.o2o_setnull.delete()\n+        a = A.objects.get(pk=a.pk)\n+        self.assertIsNone(a.o2o_setnull)\n+\n+\n+class DeletionTests(TestCase):\n+\n+    def test_m2m(self):\n+        m = M.objects.create()\n+        r = R.objects.create()\n+        MR.objects.create(m=m, r=r)\n+        r.delete()\n+        self.assertFalse(MR.objects.exists())\n+\n+        r = R.objects.create()\n+        MR.objects.create(m=m, r=r)\n+        m.delete()\n+        self.assertFalse(MR.objects.exists())\n+\n+        m = M.objects.create()\n+        r = R.objects.create()\n+        m.m2m.add(r)\n+        r.delete()\n+        through = M._meta.get_field('m2m').remote_field.through\n+        self.assertFalse(through.objects.exists())\n+\n+        r = R.objects.create()\n+        m.m2m.add(r)\n+        m.delete()\n+        self.assertFalse(through.objects.exists())\n+\n+        m = M.objects.create()\n+        r = R.objects.create()\n+        MRNull.objects.create(m=m, r=r)\n+        r.delete()\n+        self.assertFalse(not MRNull.objects.exists())\n+        self.assertFalse(m.m2m_through_null.exists())\n+\n+    def test_bulk(self):\n+        s = S.objects.create(r=R.objects.create())\n+        for i in range(2 * GET_ITERATOR_CHUNK_SIZE):\n+            T.objects.create(s=s)\n+        #   1 (select related `T` instances)\n+        # + 1 (select related `U` instances)\n+        # + 2 (delete `T` instances in batches)\n+        # + 1 (delete `s`)\n+        self.assertNumQueries(5, s.delete)\n+        self.assertFalse(S.objects.exists())\n+\n+    def test_instance_update(self):\n+        deleted = []\n+        related_setnull_sets = []\n+\n+        def pre_delete(sender, **kwargs):\n+            obj = kwargs['instance']\n+            deleted.append(obj)\n+            if isinstance(obj, R):\n+                related_setnull_sets.append([a.pk for a in obj.setnull_set.all()])\n+\n+        models.signals.pre_delete.connect(pre_delete)\n+        a = create_a('update_setnull')\n+        a.setnull.delete()\n+\n+        a = create_a('update_cascade')\n+        a.cascade.delete()\n+\n+        for obj in deleted:\n+            self.assertIsNone(obj.pk)\n+\n+        for pk_list in related_setnull_sets:\n+            for a in A.objects.filter(id__in=pk_list):\n+                self.assertIsNone(a.setnull)\n+\n+        models.signals.pre_delete.disconnect(pre_delete)\n+\n+    def test_deletion_order(self):\n+        pre_delete_order = []\n+        post_delete_order = []\n+\n+        def log_post_delete(sender, **kwargs):\n+            pre_delete_order.append((sender, kwargs['instance'].pk))\n+\n+        def log_pre_delete(sender, **kwargs):\n+            post_delete_order.append((sender, kwargs['instance'].pk))\n+\n+        models.signals.post_delete.connect(log_post_delete)\n+        models.signals.pre_delete.connect(log_pre_delete)\n+\n+        r = R.objects.create(pk=1)\n+        s1 = S.objects.create(pk=1, r=r)\n+        s2 = S.objects.create(pk=2, r=r)\n+        T.objects.create(pk=1, s=s1)\n+        T.objects.create(pk=2, s=s2)\n+        RChild.objects.create(r_ptr=r)\n+        r.delete()\n+        self.assertEqual(\n+            pre_delete_order, [(T, 2), (T, 1), (RChild, 1), (S, 2), (S, 1), (R, 1)]\n+        )\n+        self.assertEqual(\n+            post_delete_order, [(T, 1), (T, 2), (RChild, 1), (S, 1), (S, 2), (R, 1)]\n+        )\n+\n+        models.signals.post_delete.disconnect(log_post_delete)\n+        models.signals.pre_delete.disconnect(log_pre_delete)\n+\n+    def test_relational_post_delete_signals_happen_before_parent_object(self):\n+        deletions = []\n+\n+        def log_post_delete(instance, **kwargs):\n+            self.assertTrue(R.objects.filter(pk=instance.r_id))\n+            self.assertIs(type(instance), S)\n+            deletions.append(instance.id)\n+\n+        r = R.objects.create(pk=1)\n+        S.objects.create(pk=1, r=r)\n+\n+        models.signals.post_delete.connect(log_post_delete, sender=S)\n+\n+        try:\n+            r.delete()\n+        finally:\n+            models.signals.post_delete.disconnect(log_post_delete)\n+\n+        self.assertEqual(len(deletions), 1)\n+        self.assertEqual(deletions[0], 1)\n+\n+    @skipUnlessDBFeature(\"can_defer_constraint_checks\")\n+    def test_can_defer_constraint_checks(self):\n+        u = User.objects.create(\n+            avatar=Avatar.objects.create()\n+        )\n+        a = Avatar.objects.get(pk=u.avatar_id)\n+        # 1 query to find the users for the avatar.\n+        # 1 query to delete the user\n+        # 1 query to delete the avatar\n+        # The important thing is that when we can defer constraint checks there\n+        # is no need to do an UPDATE on User.avatar to null it out.\n+\n+        # Attach a signal to make sure we will not do fast_deletes.\n+        calls = []\n+\n+        def noop(*args, **kwargs):\n+            calls.append('')\n+        models.signals.post_delete.connect(noop, sender=User)\n+\n+        self.assertNumQueries(3, a.delete)\n+        self.assertFalse(User.objects.exists())\n+        self.assertFalse(Avatar.objects.exists())\n+        self.assertEqual(len(calls), 1)\n+        models.signals.post_delete.disconnect(noop, sender=User)\n+\n+    @skipIfDBFeature(\"can_defer_constraint_checks\")\n+    def test_cannot_defer_constraint_checks(self):\n+        u = User.objects.create(\n+            avatar=Avatar.objects.create()\n+        )\n+        # Attach a signal to make sure we will not do fast_deletes.\n+        calls = []\n+\n+        def noop(*args, **kwargs):\n+            calls.append('')\n+        models.signals.post_delete.connect(noop, sender=User)\n+\n+        a = Avatar.objects.get(pk=u.avatar_id)\n+        # The below doesn't make sense... Why do we need to null out\n+        # user.avatar if we are going to delete the user immediately after it,\n+        # and there are no more cascades.\n+        # 1 query to find the users for the avatar.\n+        # 1 query to delete the user\n+        # 1 query to null out user.avatar, because we can't defer the constraint\n+        # 1 query to delete the avatar\n+        self.assertNumQueries(4, a.delete)\n+        self.assertFalse(User.objects.exists())\n+        self.assertFalse(Avatar.objects.exists())\n+        self.assertEqual(len(calls), 1)\n+        models.signals.post_delete.disconnect(noop, sender=User)\n+\n+    def test_hidden_related(self):\n+        r = R.objects.create()\n+        h = HiddenUser.objects.create(r=r)\n+        HiddenUserProfile.objects.create(user=h)\n+\n+        r.delete()\n+        self.assertEqual(HiddenUserProfile.objects.count(), 0)\n+\n+    def test_large_delete(self):\n+        TEST_SIZE = 2000\n+        objs = [Avatar() for i in range(0, TEST_SIZE)]\n+        Avatar.objects.bulk_create(objs)\n+        # Calculate the number of queries needed.\n+        batch_size = connection.ops.bulk_batch_size(['pk'], objs)\n+        # The related fetches are done in batches.\n+        batches = ceil(len(objs) / batch_size)\n+        # One query for Avatar.objects.all() and then one related fast delete for\n+        # each batch.\n+        fetches_to_mem = 1 + batches\n+        # The Avatar objects are going to be deleted in batches of GET_ITERATOR_CHUNK_SIZE\n+        queries = fetches_to_mem + TEST_SIZE // GET_ITERATOR_CHUNK_SIZE\n+        self.assertNumQueries(queries, Avatar.objects.all().delete)\n+        self.assertFalse(Avatar.objects.exists())\n+\n+    def test_large_delete_related(self):\n+        TEST_SIZE = 2000\n+        s = S.objects.create(r=R.objects.create())\n+        for i in range(TEST_SIZE):\n+            T.objects.create(s=s)\n+\n+        batch_size = max(connection.ops.bulk_batch_size(['pk'], range(TEST_SIZE)), 1)\n+\n+        # TEST_SIZE / batch_size (select related `T` instances)\n+        # + 1 (select related `U` instances)\n+        # + TEST_SIZE / GET_ITERATOR_CHUNK_SIZE (delete `T` instances in batches)\n+        # + 1 (delete `s`)\n+        expected_num_queries = ceil(TEST_SIZE / batch_size)\n+        expected_num_queries += ceil(TEST_SIZE / GET_ITERATOR_CHUNK_SIZE) + 2\n+\n+        self.assertNumQueries(expected_num_queries, s.delete)\n+        self.assertFalse(S.objects.exists())\n+        self.assertFalse(T.objects.exists())\n+\n+    def test_delete_with_keeping_parents(self):\n+        child = RChild.objects.create()\n+        parent_id = child.r_ptr_id\n+        child.delete(keep_parents=True)\n+        self.assertFalse(RChild.objects.filter(id=child.id).exists())\n+        self.assertTrue(R.objects.filter(id=parent_id).exists())\n+\n+    def test_delete_with_keeping_parents_relationships(self):\n+        child = RChild.objects.create()\n+        parent_id = child.r_ptr_id\n+        parent_referent_id = S.objects.create(r=child.r_ptr).pk\n+        child.delete(keep_parents=True)\n+        self.assertFalse(RChild.objects.filter(id=child.id).exists())\n+        self.assertTrue(R.objects.filter(id=parent_id).exists())\n+        self.assertTrue(S.objects.filter(pk=parent_referent_id).exists())\n+\n+        childchild = RChildChild.objects.create()\n+        parent_id = childchild.rchild_ptr.r_ptr_id\n+        child_id = childchild.rchild_ptr_id\n+        parent_referent_id = S.objects.create(r=childchild.rchild_ptr.r_ptr).pk\n+        childchild.delete(keep_parents=True)\n+        self.assertFalse(RChildChild.objects.filter(id=childchild.id).exists())\n+        self.assertTrue(RChild.objects.filter(id=child_id).exists())\n+        self.assertTrue(R.objects.filter(id=parent_id).exists())\n+        self.assertTrue(S.objects.filter(pk=parent_referent_id).exists())\n+\n+    def test_queryset_delete_returns_num_rows(self):\n+        \"\"\"\n+        QuerySet.delete() should return the number of deleted rows and a\n+        dictionary with the number of deletions for each object type.\n+        \"\"\"\n+        Avatar.objects.bulk_create([Avatar(desc='a'), Avatar(desc='b'), Avatar(desc='c')])\n+        avatars_count = Avatar.objects.count()\n+        deleted, rows_count = Avatar.objects.all().delete()\n+        self.assertEqual(deleted, avatars_count)\n+\n+        # more complex example with multiple object types\n+        r = R.objects.create()\n+        h1 = HiddenUser.objects.create(r=r)\n+        HiddenUser.objects.create(r=r)\n+        HiddenUserProfile.objects.create(user=h1)\n+        existed_objs = {\n+            R._meta.label: R.objects.count(),\n+            HiddenUser._meta.label: HiddenUser.objects.count(),\n+            A._meta.label: A.objects.count(),\n+            MR._meta.label: MR.objects.count(),\n+            HiddenUserProfile._meta.label: HiddenUserProfile.objects.count(),\n+        }\n+        deleted, deleted_objs = R.objects.all().delete()\n+        for k, v in existed_objs.items():\n+            self.assertEqual(deleted_objs[k], v)\n+\n+    def test_model_delete_returns_num_rows(self):\n+        \"\"\"\n+        Model.delete() should return the number of deleted rows and a\n+        dictionary with the number of deletions for each object type.\n+        \"\"\"\n+        r = R.objects.create()\n+        h1 = HiddenUser.objects.create(r=r)\n+        h2 = HiddenUser.objects.create(r=r)\n+        HiddenUser.objects.create(r=r)\n+        HiddenUserProfile.objects.create(user=h1)\n+        HiddenUserProfile.objects.create(user=h2)\n+        m1 = M.objects.create()\n+        m2 = M.objects.create()\n+        MR.objects.create(r=r, m=m1)\n+        r.m_set.add(m1)\n+        r.m_set.add(m2)\n+        r.save()\n+        existed_objs = {\n+            R._meta.label: R.objects.count(),\n+            HiddenUser._meta.label: HiddenUser.objects.count(),\n+            A._meta.label: A.objects.count(),\n+            MR._meta.label: MR.objects.count(),\n+            HiddenUserProfile._meta.label: HiddenUserProfile.objects.count(),\n+            M.m2m.through._meta.label: M.m2m.through.objects.count(),\n+        }\n+        deleted, deleted_objs = r.delete()\n+        self.assertEqual(deleted, sum(existed_objs.values()))\n+        for k, v in existed_objs.items():\n+            self.assertEqual(deleted_objs[k], v)\n+\n+    def test_proxied_model_duplicate_queries(self):\n+        \"\"\"\n+        #25685 - Deleting instances of a model with existing proxy\n+        classes should not issue multiple queries during cascade\n+        deletion of referring models.\n+        \"\"\"\n+        avatar = Avatar.objects.create()\n+        # One query for the Avatar table and a second for the User one.\n+        with self.assertNumQueries(2):\n+            avatar.delete()\n+\n+    def test_only_referenced_fields_selected(self):\n+        \"\"\"\n+        Only referenced fields are selected during cascade deletion SELECT\n+        unless deletion signals are connected.\n+        \"\"\"\n+        origin = Origin.objects.create()\n+        expected_sql = str(\n+            Referrer.objects.only(\n+                # Both fields are referenced by SecondReferrer.\n+                'id', 'unique_field',\n+            ).filter(origin__in=[origin]).query\n+        )\n+        with self.assertNumQueries(2) as ctx:\n+            origin.delete()\n+        self.assertEqual(ctx.captured_queries[0]['sql'], expected_sql)\n+\n+        def receiver(instance, **kwargs):\n+            pass\n+\n+        # All fields are selected if deletion signals are connected.\n+        for signal_name in ('pre_delete', 'post_delete'):\n+            with self.subTest(signal=signal_name):\n+                origin = Origin.objects.create()\n+                signal = getattr(models.signals, signal_name)\n+                signal.connect(receiver, sender=Referrer)\n+                with self.assertNumQueries(2) as ctx:\n+                    origin.delete()\n+                self.assertIn(\n+                    connection.ops.quote_name('large_field'),\n+                    ctx.captured_queries[0]['sql'],\n+                )\n+                signal.disconnect(receiver, sender=Referrer)\n+\n+\n+class FastDeleteTests(TestCase):\n+\n+    def test_fast_delete_fk(self):\n+        u = User.objects.create(\n+            avatar=Avatar.objects.create()\n+        )\n+        a = Avatar.objects.get(pk=u.avatar_id)\n+        # 1 query to fast-delete the user\n+        # 1 query to delete the avatar\n+        self.assertNumQueries(2, a.delete)\n+        self.assertFalse(User.objects.exists())\n+        self.assertFalse(Avatar.objects.exists())\n+\n+    def test_combined_fast_delete_fk(self):\n+        \"\"\"\n+        Fast deletes for multiple CASCADE relations to the same model should be\n+        combined into a single query.\n+        \"\"\"\n+        origin = Origin.objects.create()\n+        ref = Referrer.objects.create(origin=origin, unique_field=1)\n+        SecondReferrer.objects.create(referrer=ref, other_referrer=ref)\n+        # Two fast delete queries (for SecondReferrer.referrer and\n+        # SecondReferrer.other_referrer) should be combined into one.\n+        # 1. DELETE FROM SecondReferrer WHERE ... OR ...\n+        # 2. DELETE FROM Referrer WHERE ...\n+        self.assertNumQueries(2, ref.delete)\n+        self.assertFalse(Referrer.objects.filter(pk=ref.pk).exists())\n+        self.assertFalse(SecondReferrer.objects.exists())\n+\n+    def test_fast_delete_m2m(self):\n+        t = M2MTo.objects.create()\n+        f1 = M2MFrom.objects.create()\n+        f1.m2m.add(t)\n+        # 1 query to fast-delete the m2m\n+        # 1 query to delete the M2MTo\n+        self.assertNumQueries(2, t.delete)\n+        self.assertFalse(M2MFrom.objects.get(pk=f1.pk).m2m.exists())\n+\n+    def test_fast_delete_joined_qs(self):\n+        a = Avatar.objects.create(desc='a')\n+        User.objects.create(avatar=a)\n+        u2 = User.objects.create()\n+        expected_queries = 1 if connection.features.update_can_self_select else 2\n+        self.assertNumQueries(expected_queries,\n+                              User.objects.filter(avatar__desc='a').delete)\n+        self.assertEqual(User.objects.count(), 1)\n+        self.assertTrue(User.objects.filter(pk=u2.pk).exists())\n"
    },
    "django__django-14493": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/staticfiles_tests/test_max_post_process_passes.py",
        "reproduced_bug_commands": [
            "./tests/runtests.py staticfiles_tests.test_max_post_process_passes"
        ],
        "reproduced_bug_patch": "diff --git a/tests/staticfiles_tests/test_max_post_process_passes.py b/tests/staticfiles_tests/test_max_post_process_passes.py\nnew file mode 100644\nindex 0000000000..6f6b3d4d0d\n--- /dev/null\n+++ b/tests/staticfiles_tests/test_max_post_process_passes.py\n@@ -0,0 +1,23 @@\n+from django.contrib.staticfiles.storage import ManifestStaticFilesStorage\n+from django.test import override_settings\n+\n+from .cases import CollectionTestCase\n+\n+\n+class ZeroPassesManifestStaticFilesStorage(ManifestStaticFilesStorage):\n+    max_post_process_passes = 0\n+\n+\n+@override_settings(\n+    STATICFILES_STORAGE='staticfiles_tests.test_max_post_process_passes.ZeroPassesManifestStaticFilesStorage'\n+)\n+class TestMaxPostProcessPasses(CollectionTestCase):\n+    def test_max_post_process_passes_zero(self):\n+        \"\"\"\n+        collectstatic with ManifestStaticFilesStorage shouldn't crash when\n+        max_post_process_passes is 0.\n+        \"\"\"\n+        # The collectstatic command is run in CollectionTestCase.setUp().\n+        # An UnboundLocalError is raised if the bug is present.\n+        # This test passes if no exception is raised.\n+        pass\n"
    },
    "django__django-16485": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/template_tests/filter_tests/test_floatformat_regression.py",
        "reproduced_bug_commands": [
            "python",
            "tests/runtests.py",
            "--noinput",
            "--failfast",
            "-v",
            "2",
            "template_tests.filter_tests.test_floatformat_regression"
        ],
        "reproduced_bug_patch": "diff --git a/tests/template_tests/filter_tests/test_floatformat_regression.py b/tests/template_tests/filter_tests/test_floatformat_regression.py\nnew file mode 100644\nindex 0000000000..9e828765b2\n--- /dev/null\n+++ b/tests/template_tests/filter_tests/test_floatformat_regression.py\n@@ -0,0 +1,13 @@\n+from decimal import Decimal\n+\n+from django.template.defaultfilters import floatformat\n+from django.test import SimpleTestCase\n+\n+\n+class FunctionTests(SimpleTestCase):\n+    def test_floatformat_zero_value_zero_precision(self):\n+        \"\"\"\n+        floatformat() shouldn't crash on \"0.00\" with 0 precision.\n+        \"\"\"\n+        self.assertEqual(floatformat(\"0.00\", 0), \"0\")\n+        self.assertEqual(floatformat(Decimal(\"0.00\"), 0), \"0\")\n"
    },
    "pytest-dev__pytest-5809": {
        "reproduced_bug": true,
        "reproduced_bug_file": "testing/test_pastebin_lexer.py",
        "reproduced_bug_commands": [
            "pytest testing/test_pastebin_lexer.py"
        ],
        "reproduced_bug_patch": "diff --git a/testing/test_pastebin_lexer.py b/testing/test_pastebin_lexer.py\nnew file mode 100644\nindex 000000000..5572dac02\n--- /dev/null\n+++ b/testing/test_pastebin_lexer.py\n@@ -0,0 +1,67 @@\n+# -*- coding: utf-8 -*-\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+import sys\n+\n+import pytest\n+\n+\n+class TestPaste(object):\n+    @pytest.fixture\n+    def pastebin(self, request):\n+        return request.config.pluginmanager.getplugin(\"pastebin\")\n+\n+    def test_pastebin_lexer_for_arbitrary_text(self, pastebin, monkeypatch):\n+        \"\"\"\n+        Tests that pastebin uploads use 'text' lexer to avoid HTTP errors.\n+\n+        The bpaste.net service can fail with a HTTP 400 error if the content\n+        of the paste is not valid for the specified lexer. Pytest terminal\n+        output is not Python code, so 'python3' or 'python' lexers are\n+        inappropriate. This test mocks urlopen to simulate this failure, and\n+        will pass when the correct 'text' lexer is used.\n+        \"\"\"\n+\n+        def mock_urlopen_bpaste(url, data):\n+            if sys.version_info >= (3, 0):\n+                from urllib.parse import parse_qs\n+                from urllib.error import HTTPError\n+                from io import BytesIO\n+\n+                params = parse_qs(data.decode(\"ascii\"))\n+                fp = BytesIO(b\"\")\n+            else:\n+                from urlparse import parse_qs\n+                from urllib2 import HTTPError\n+\n+                params = parse_qs(data)\n+                fp = None\n+\n+            lexer = params.get(\"lexer\", [None])[0]\n+            if lexer and lexer != \"text\":\n+                raise HTTPError(url, 400, \"Bad Request\", {}, fp)\n+\n+            class DummyFile:\n+                def read(self):\n+                    return b'View <a href=\"/raw/3c0c6750bd\">raw</a>.'\n+\n+            return DummyFile()\n+\n+        if sys.version_info < (3, 0):\n+            import urllib\n+\n+            monkeypatch.setattr(urllib, \"urlopen\", mock_urlopen_bpaste)\n+        else:\n+            import urllib.request\n+\n+            monkeypatch.setattr(urllib.request, \"urlopen\", mock_urlopen_bpaste)\n+\n+        # Some content that is not valid python.\n+        content = b\"=== 1 failed, 1 passed in 0.12s ===\"\n+\n+        # This call will raise HTTPError with the current buggy code.\n+        # With the fix (lexer='text'), it should pass.\n+        result = pastebin.create_new_paste(content)\n+        assert result == \"https://bpaste.net/show/3c0c6750bd\"\n"
    },
    "sympy__sympy-13974": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/physics/quantum/tests/test_tensorproduct_power.py",
        "reproduced_bug_commands": [
            "pytest sympy/physics/quantum/tests/test_tensorproduct_power.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/physics/quantum/tests/test_tensorproduct_power.py b/sympy/physics/quantum/tests/test_tensorproduct_power.py\nnew file mode 100644\nindex 0000000000..26a1b061d9\n--- /dev/null\n+++ b/sympy/physics/quantum/tests/test_tensorproduct_power.py\n@@ -0,0 +1,110 @@\n+from sympy import I, symbols, Matrix\n+\n+from sympy.physics.quantum.commutator import Commutator as Comm\n+from sympy.physics.quantum.tensorproduct import TensorProduct\n+from sympy.physics.quantum.tensorproduct import TensorProduct as TP\n+from sympy.physics.quantum.tensorproduct import tensor_product_simp\n+from sympy.physics.quantum.dagger import Dagger\n+from sympy.physics.quantum.qubit import Qubit, QubitBra\n+from sympy.physics.quantum.operator import OuterProduct\n+from sympy.physics.quantum.density import Density\n+from sympy.physics.paulialgebra import Pauli\n+from sympy.core.trace import Tr\n+\n+A, B, C = symbols('A,B,C', commutative=False)\n+x = symbols('x')\n+\n+mat1 = Matrix([[1, 2*I], [1 + I, 3]])\n+mat2 = Matrix([[2*I, 3], [4*I, 2]])\n+\n+\n+def test_tensor_product_dagger():\n+    assert Dagger(TensorProduct(I*A, B)) ==         -I*TensorProduct(Dagger(A), Dagger(B))\n+    assert Dagger(TensorProduct(mat1, mat2)) ==         TensorProduct(Dagger(mat1), Dagger(mat2))\n+\n+\n+def test_tensor_product_abstract():\n+\n+    assert TP(x*A, 2*B) == x*2*TP(A, B)\n+    assert TP(A, B) != TP(B, A)\n+    assert TP(A, B).is_commutative is False\n+    assert isinstance(TP(A, B), TP)\n+    assert TP(A, B).subs(A, C) == TP(C, B)\n+\n+\n+def test_tensor_product_expand():\n+    assert TP(A + B, B + C).expand(tensorproduct=True) ==         TP(A, B) + TP(A, C) + TP(B, B) + TP(B, C)\n+\n+\n+def test_tensor_product_commutator():\n+    assert TP(Comm(A, B), C).doit().expand(tensorproduct=True) ==         TP(A*B, C) - TP(B*A, C)\n+    assert Comm(TP(A, B), TP(B, C)).doit() ==         TP(A, B)*TP(B, C) - TP(B, C)*TP(A, B)\n+\n+\n+def test_tensor_product_simp():\n+    assert tensor_product_simp(TP(A, B)*TP(B, C)) == TP(A*B, B*C)\n+\n+\n+def test_issue_5923():\n+    # most of the issue regarding sympification of args has been handled\n+    # and is tested internally by the use of args_cnc through the quantum\n+    # module, but the following is a test from the issue that used to raise.\n+    assert TensorProduct(1, Qubit('1')*Qubit('1').dual) ==         TensorProduct(1, OuterProduct(Qubit(1), QubitBra(1)))\n+\n+\n+def test_eval_trace():\n+    # This test includes tests with dependencies between TensorProducts\n+    #and density operators. Since, the test is more to test the behavior of\n+    #TensorProducts it remains here\n+\n+    A, B, C, D, E, F = symbols('A B C D E F', commutative=False)\n+\n+    # Density with simple tensor products as args\n+    t = TensorProduct(A, B)\n+    d = Density([t, 1.0])\n+    tr = Tr(d)\n+    assert tr.doit() == 1.0*Tr(A*Dagger(A))*Tr(B*Dagger(B))\n+\n+    ## partial trace with simple tensor products as args\n+    t = TensorProduct(A, B, C)\n+    d = Density([t, 1.0])\n+    tr = Tr(d, [1])\n+    assert tr.doit() == 1.0*A*Dagger(A)*Tr(B*Dagger(B))*C*Dagger(C)\n+\n+    tr = Tr(d, [0, 2])\n+    assert tr.doit() == 1.0*Tr(A*Dagger(A))*B*Dagger(B)*Tr(C*Dagger(C))\n+\n+    # Density with multiple Tensorproducts as states\n+    t2 = TensorProduct(A, B)\n+    t3 = TensorProduct(C, D)\n+\n+    d = Density([t2, 0.5], [t3, 0.5])\n+    t = Tr(d)\n+    assert t.doit() == (0.5*Tr(A*Dagger(A))*Tr(B*Dagger(B)) +\n+                        0.5*Tr(C*Dagger(C))*Tr(D*Dagger(D)))\n+\n+    t = Tr(d, [0])\n+    assert t.doit() == (0.5*Tr(A*Dagger(A))*B*Dagger(B) +\n+                        0.5*Tr(C*Dagger(C))*D*Dagger(D))\n+\n+    #Density with mixed states\n+    d = Density([t2 + t3, 1.0])\n+    t = Tr(d)\n+    assert t.doit() == ( 1.0*Tr(A*Dagger(A))*Tr(B*Dagger(B)) +\n+                        1.0*Tr(A*Dagger(C))*Tr(B*Dagger(D)) +\n+                        1.0*Tr(C*Dagger(A))*Tr(D*Dagger(B)) +\n+                        1.0*Tr(C*Dagger(C))*Tr(D*Dagger(D)))\n+\n+    t = Tr(d, [1] )\n+    assert t.doit() == ( 1.0*A*Dagger(A)*Tr(B*Dagger(B)) +\n+                        1.0*A*Dagger(C)*Tr(B*Dagger(D)) +\n+                        1.0*C*Dagger(A)*Tr(D*Dagger(B)) +\n+                        1.0*C*Dagger(C)*Tr(D*Dagger(D)))\n+\n+\n+def test_tensor_product_power_evaluation():\n+    \"\"\"Test that powers of TensorProduct are simplified correctly.\"\"\"\n+    t = TensorProduct(1, Pauli(3)) * TensorProduct(1, Pauli(3))\n+    # This should be evaluated to TensorProduct(1*1, Pauli(3)*Pauli(3)),\n+    # which, since Pauli(3)**2 == 1, is TensorProduct(1, 1).\n+    assert tensor_product_simp(t) == TensorProduct(1, 1)\n"
    },
    "django__django-11951": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "django__django-14500": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/migrations/test_executor_squashed.py",
        "reproduced_bug_commands": [
            "python",
            "tests/runtests.py",
            "migrations.test_executor_squashed.ExecutorSquashedTests.test_unapply_squashed_migration_removes_record"
        ],
        "reproduced_bug_patch": "diff --git a/tests/migrations/test_executor_squashed.py b/tests/migrations/test_executor_squashed.py\nnew file mode 100644\nindex 0000000000..ffff878f7b\n--- /dev/null\n+++ b/tests/migrations/test_executor_squashed.py\n@@ -0,0 +1,31 @@\n+from django.db import connection\n+from django.db.migrations.executor import MigrationExecutor\n+from django.db.migrations.recorder import MigrationRecorder\n+from django.test import override_settings\n+\n+from .test_base import MigrationTestBase\n+\n+\n+class ExecutorSquashedTests(MigrationTestBase):\n+    available_apps = [\n+        \"migrations\",\n+        \"django.contrib.auth\",\n+        \"django.contrib.contenttypes\",\n+    ]\n+\n+    @override_settings(MIGRATION_MODULES={\"migrations\": \"migrations.test_migrations_squashed\"})\n+    def test_unapply_squashed_migration_removes_record(self):\n+        \"\"\"\n+        When a squashed migration is unapplied and the replaced migration\n+        files are present, the squashed migration is marked as unapplied.\n+        \"\"\"\n+        executor = MigrationExecutor(connection)\n+        # Apply the squashed migration.\n+        executor.migrate([(\"migrations\", \"0001_squashed_0002\")])\n+        # Unapply all migrations.\n+        executor.loader.build_graph()\n+        executor.migrate([(\"migrations\", None)])\n+        # After unapplying, the squashed migration should be marked as unapplied.\n+        recorder = MigrationRecorder(connection)\n+        applied_migrations = recorder.applied_migrations()\n+        self.assertNotIn((\"migrations\", \"0001_squashed_0002\"), applied_migrations)\n"
    },
    "django__django-16493": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/field_deconstruction/test_file_field.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py -v 2 field_deconstruction.test_file_field"
        ],
        "reproduced_bug_patch": "diff --git a/tests/field_deconstruction/test_file_field.py b/tests/field_deconstruction/test_file_field.py\nnew file mode 100644\nindex 0000000000..68813da410\n--- /dev/null\n+++ b/tests/field_deconstruction/test_file_field.py\n@@ -0,0 +1,24 @@\n+import unittest\n+\n+from django.core.files.storage import default_storage\n+from django.db import models\n+from django.test import SimpleTestCase\n+\n+\n+# For the purposes of this test, this function must be defined at the module\n+# level so that it can be imported by the migration framework.\n+def deconstruct_test_storage():\n+    return default_storage\n+\n+\n+class FieldDeconstructionTests(SimpleTestCase):\n+    def test_file_field_with_callable_storage_returning_default(self):\n+        \"\"\"\n+        A callable storage that returns default_storage is deconstructed\n+        correctly.\n+        \"\"\"\n+        field = models.FileField(storage=deconstruct_test_storage)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.FileField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"storage\": deconstruct_test_storage})\n"
    },
    "pytest-dev__pytest-5840": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "sympy__sympy-14248": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/matrices/expressions/tests/test_printing.py",
        "reproduced_bug_commands": [
            "pytest sympy/matrices/expressions/tests/test_printing.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/matrices/expressions/tests/test_printing.py b/sympy/matrices/expressions/tests/test_printing.py\nnew file mode 100644\nindex 0000000000..505a1a1964\n--- /dev/null\n+++ b/sympy/matrices/expressions/tests/test_printing.py\n@@ -0,0 +1,27 @@\n+import pytest\n+from sympy import MatrixSymbol, pretty, latex\n+\n+def test_matrix_difference_printing():\n+    \"\"\"\n+    Test printing the difference of MatrixSymbols.\n+\n+    This test case reproduces the issue where the difference of MatrixSymbols\n+    is printed as a sum with a (-1) coefficient, rather than using a minus sign.\n+    It checks the output of str, pretty, and latex printers.\n+\n+    Based on Stack Overflow post: https://stackoverflow.com/q/48826611\n+    \"\"\"\n+    A = MatrixSymbol('A', 2, 2)\n+    B = MatrixSymbol('B', 2, 2)\n+    expr = A - A*B - B\n+\n+    # The current str output is \"(-1)*B + (-1)*A*B + A\"\n+    # The correct output should respect term order and use minus signs.\n+    assert str(expr) == \"-B - A*B + A\"\n+\n+    # The current pretty output is \"-B + -A*B + A\"\n+    assert pretty(expr, use_unicode=False) == \"-B - A*B + A\"\n+    assert pretty(expr, use_unicode=True) == u'-B - A⋅B + A'\n+\n+    # The current latex output is \"-1 B + -1 A B + A\"\n+    assert latex(expr) == \"-B - A B + A\"\n"
    },
    "django__django-11964": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/model_enums/test_coercion.py",
        "reproduced_bug_commands": [
            "python3 tests/runtests.py model_enums.test_coercion"
        ],
        "reproduced_bug_patch": "diff --git a/tests/model_enums/test_coercion.py b/tests/model_enums/test_coercion.py\nnew file mode 100644\nindex 0000000000..4ddbb206e3\n--- /dev/null\n+++ b/tests/model_enums/test_coercion.py\n@@ -0,0 +1,27 @@\n+from django.db import models\n+from django.test import SimpleTestCase\n+from django.utils.translation import gettext_lazy as _\n+\n+\n+class MyChoice(models.TextChoices):\n+    FIRST_CHOICE = \"first\", _(\"The first choice, it is\")\n+    SECOND_CHOICE = \"second\", _(\"The second choice, it is\")\n+\n+\n+class MyObject(models.Model):\n+    my_str_value = models.CharField(max_length=10, choices=MyChoice.choices)\n+\n+\n+class EnumValueCoercionTest(SimpleTestCase):\n+    def test_created_object_is_str(self):\n+        \"\"\"\n+        The value of a TextChoices field on a model instance should be a\n+        string, not the enum member itself.\n+        \"\"\"\n+        # Instantiate the model without saving it. The bug occurs on the\n+        # instance itself, before any database interaction.\n+        my_object = MyObject(my_str_value=MyChoice.FIRST_CHOICE)\n+        # This assertion reproduces the failure from the bug report.\n+        # str(my_object.my_str_value) returns 'MyChoice.FIRST_CHOICE'\n+        # instead of 'first', causing the AssertionError.\n+        self.assertEqual(str(my_object.my_str_value), \"first\")\n"
    },
    "django__django-14534": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/forms_tests/widget_tests/test_bound_widget_id_for_label.py",
        "reproduced_bug_commands": [
            "PYTHONPATH=. DJANGO_SETTINGS_MODULE=tests.auth_tests.settings python -m django test tests.forms_tests.widget_tests.test_bound_widget_id_for_label"
        ],
        "reproduced_bug_patch": "diff --git a/tests/forms_tests/widget_tests/test_bound_widget_id_for_label.py b/tests/forms_tests/widget_tests/test_bound_widget_id_for_label.py\nnew file mode 100644\nindex 0000000000..40c3f57943\n--- /dev/null\n+++ b/tests/forms_tests/widget_tests/test_bound_widget_id_for_label.py\n@@ -0,0 +1,229 @@\n+import datetime\n+\n+from django import forms\n+from django.forms import CheckboxSelectMultiple\n+from django.test import override_settings\n+\n+from .base import WidgetTest\n+\n+\n+class CheckboxSelectMultipleTest(WidgetTest):\n+    widget = CheckboxSelectMultiple\n+\n+    def test_render_value(self):\n+        self.check_html(self.widget(choices=self.beatles), 'beatles', ['J'], html=(\n+            \"\"\"<ul>\n+            <li><label><input checked type=\"checkbox\" name=\"beatles\" value=\"J\"> John</label></li>\n+            <li><label><input type=\"checkbox\" name=\"beatles\" value=\"P\"> Paul</label></li>\n+            <li><label><input type=\"checkbox\" name=\"beatles\" value=\"G\"> George</label></li>\n+            <li><label><input type=\"checkbox\" name=\"beatles\" value=\"R\"> Ringo</label></li>\n+            </ul>\"\"\"\n+        ))\n+\n+    def test_render_value_multiple(self):\n+        self.check_html(self.widget(choices=self.beatles), 'beatles', ['J', 'P'], html=(\n+            \"\"\"<ul>\n+            <li><label><input checked type=\"checkbox\" name=\"beatles\" value=\"J\"> John</label></li>\n+            <li><label><input checked type=\"checkbox\" name=\"beatles\" value=\"P\"> Paul</label></li>\n+            <li><label><input type=\"checkbox\" name=\"beatles\" value=\"G\"> George</label></li>\n+            <li><label><input type=\"checkbox\" name=\"beatles\" value=\"R\"> Ringo</label></li>\n+            </ul>\"\"\"\n+        ))\n+\n+    def test_render_none(self):\n+        \"\"\"\n+        If the value is None, none of the options are selected, even if the\n+        choices have an empty option.\n+        \"\"\"\n+        self.check_html(self.widget(choices=(('', 'Unknown'),) + self.beatles), 'beatles', None, html=(\n+            \"\"\"<ul>\n+            <li><label><input type=\"checkbox\" name=\"beatles\" value=\"\"> Unknown</label></li>\n+            <li><label><input type=\"checkbox\" name=\"beatles\" value=\"J\"> John</label></li>\n+            <li><label><input type=\"checkbox\" name=\"beatles\" value=\"P\"> Paul</label></li>\n+            <li><label><input type=\"checkbox\" name=\"beatles\" value=\"G\"> George</label></li>\n+            <li><label><input type=\"checkbox\" name=\"beatles\" value=\"R\"> Ringo</label></li>\n+            </ul>\"\"\"\n+        ))\n+\n+    def test_nested_choices(self):\n+        nested_choices = (\n+            ('unknown', 'Unknown'),\n+            ('Audio', (('vinyl', 'Vinyl'), ('cd', 'CD'))),\n+            ('Video', (('vhs', 'VHS'), ('dvd', 'DVD'))),\n+        )\n+        html = \"\"\"\n+        <ul id=\"media\">\n+        <li>\n+        <label for=\"media_0\"><input id=\"media_0\" name=\"nestchoice\" type=\"checkbox\" value=\"unknown\"> Unknown</label>\n+        </li>\n+        <li>Audio<ul id=\"media_1\">\n+        <li>\n+        <label for=\"media_1_0\">\n+        <input checked id=\"media_1_0\" name=\"nestchoice\" type=\"checkbox\" value=\"vinyl\"> Vinyl\n+        </label>\n+        </li>\n+        <li>\n+        <label for=\"media_1_1\"><input id=\"media_1_1\" name=\"nestchoice\" type=\"checkbox\" value=\"cd\"> CD</label>\n+        </li>\n+        </ul></li>\n+        <li>Video<ul id=\"media_2\">\n+        <li>\n+        <label for=\"media_2_0\"><input id=\"media_2_0\" name=\"nestchoice\" type=\"checkbox\" value=\"vhs\"> VHS</label>\n+        </li>\n+        <li>\n+        <label for=\"media_2_1\">\n+        <input checked id=\"media_2_1\" name=\"nestchoice\" type=\"checkbox\" value=\"dvd\"> DVD\n+        </label>\n+        </li>\n+        </ul></li>\n+        </ul>\n+        \"\"\"\n+        self.check_html(\n+            self.widget(choices=nested_choices), 'nestchoice', ('vinyl', 'dvd'),\n+            attrs={'id': 'media'}, html=html,\n+        )\n+\n+    def test_nested_choices_without_id(self):\n+        nested_choices = (\n+            ('unknown', 'Unknown'),\n+            ('Audio', (('vinyl', 'Vinyl'), ('cd', 'CD'))),\n+            ('Video', (('vhs', 'VHS'), ('dvd', 'DVD'))),\n+        )\n+        html = \"\"\"\n+        <ul>\n+        <li>\n+        <label><input name=\"nestchoice\" type=\"checkbox\" value=\"unknown\"> Unknown</label>\n+        </li>\n+        <li>Audio<ul>\n+        <li>\n+        <label>\n+        <input checked name=\"nestchoice\" type=\"checkbox\" value=\"vinyl\"> Vinyl\n+        </label>\n+        </li>\n+        <li>\n+        <label><input name=\"nestchoice\" type=\"checkbox\" value=\"cd\"> CD</label>\n+        </li>\n+        </ul></li>\n+        <li>Video<ul>\n+        <li>\n+        <label><input name=\"nestchoice\" type=\"checkbox\" value=\"vhs\"> VHS</label>\n+        </li>\n+        <li>\n+        <label>\n+        <input checked name=\"nestchoice\" type=\"checkbox\" value=\"dvd\"> DVD\n+        </label>\n+        </li>\n+        </ul></li>\n+        </ul>\n+        \"\"\"\n+        self.check_html(self.widget(choices=nested_choices), 'nestchoice', ('vinyl', 'dvd'), html=html)\n+\n+    def test_separate_ids(self):\n+        \"\"\"\n+        Each input gets a separate ID.\n+        \"\"\"\n+        choices = [('a', 'A'), ('b', 'B'), ('c', 'C')]\n+        html = \"\"\"\n+        <ul id=\"abc\">\n+        <li>\n+        <label for=\"abc_0\"><input checked type=\"checkbox\" name=\"letters\" value=\"a\" id=\"abc_0\"> A</label>\n+        </li>\n+        <li><label for=\"abc_1\"><input type=\"checkbox\" name=\"letters\" value=\"b\" id=\"abc_1\"> B</label></li>\n+        <li>\n+        <label for=\"abc_2\"><input checked type=\"checkbox\" name=\"letters\" value=\"c\" id=\"abc_2\"> C</label>\n+        </li>\n+        </ul>\n+        \"\"\"\n+        self.check_html(self.widget(choices=choices), 'letters', ['a', 'c'], attrs={'id': 'abc'}, html=html)\n+\n+    def test_separate_ids_constructor(self):\n+        \"\"\"\n+        Each input gets a separate ID when the ID is passed to the constructor.\n+        \"\"\"\n+        widget = CheckboxSelectMultiple(attrs={'id': 'abc'}, choices=[('a', 'A'), ('b', 'B'), ('c', 'C')])\n+        html = \"\"\"\n+        <ul id=\"abc\">\n+        <li>\n+        <label for=\"abc_0\"><input checked type=\"checkbox\" name=\"letters\" value=\"a\" id=\"abc_0\"> A</label>\n+        </li>\n+        <li><label for=\"abc_1\"><input type=\"checkbox\" name=\"letters\" value=\"b\" id=\"abc_1\"> B</label></li>\n+        <li>\n+        <label for=\"abc_2\"><input checked type=\"checkbox\" name=\"letters\" value=\"c\" id=\"abc_2\"> C</label>\n+        </li>\n+        </ul>\n+        \"\"\"\n+        self.check_html(widget, 'letters', ['a', 'c'], html=html)\n+\n+    @override_settings(USE_L10N=True, USE_THOUSAND_SEPARATOR=True)\n+    def test_doesnt_localize_input_value(self):\n+        choices = [\n+            (1, 'One'),\n+            (1000, 'One thousand'),\n+            (1000000, 'One million'),\n+        ]\n+        html = \"\"\"\n+        <ul>\n+        <li><label><input type=\"checkbox\" name=\"numbers\" value=\"1\"> One</label></li>\n+        <li><label><input type=\"checkbox\" name=\"numbers\" value=\"1000\"> One thousand</label></li>\n+        <li><label><input type=\"checkbox\" name=\"numbers\" value=\"1000000\"> One million</label></li>\n+        </ul>\n+        \"\"\"\n+        self.check_html(self.widget(choices=choices), 'numbers', None, html=html)\n+\n+        choices = [\n+            (datetime.time(0, 0), 'midnight'),\n+            (datetime.time(12, 0), 'noon'),\n+        ]\n+        html = \"\"\"\n+        <ul>\n+        <li><label><input type=\"checkbox\" name=\"times\" value=\"00:00:00\"> midnight</label></li>\n+        <li><label><input type=\"checkbox\" name=\"times\" value=\"12:00:00\"> noon</label></li>\n+        </ul>\n+        \"\"\"\n+        self.check_html(self.widget(choices=choices), 'times', None, html=html)\n+\n+    def test_use_required_attribute(self):\n+        widget = self.widget(choices=self.beatles)\n+        # Always False because browser validation would require all checkboxes\n+        # to be checked instead of at least one.\n+        self.assertIs(widget.use_required_attribute(None), False)\n+        self.assertIs(widget.use_required_attribute([]), False)\n+        self.assertIs(widget.use_required_attribute(['J', 'P']), False)\n+\n+    def test_value_omitted_from_data(self):\n+        widget = self.widget(choices=self.beatles)\n+        self.assertIs(widget.value_omitted_from_data({}, {}, 'field'), False)\n+        self.assertIs(widget.value_omitted_from_data({'field': 'value'}, {}, 'field'), False)\n+\n+    def test_label(self):\n+        \"\"\"\n+        CheckboxSelectMultiple doesn't contain 'for=\"field_0\"' in the <label>\n+        because clicking that would toggle the first checkbox.\n+        \"\"\"\n+        class TestForm(forms.Form):\n+            f = forms.MultipleChoiceField(widget=CheckboxSelectMultiple)\n+\n+        bound_field = TestForm()['f']\n+        self.assertEqual(bound_field.field.widget.id_for_label('id'), '')\n+        self.assertEqual(bound_field.label_tag(), '<label>F:</label>')\n+\n+    def test_bound_widget_id_for_label(self):\n+        \"\"\"\n+        BoundWidget.id_for_label() should use the widget's attrs['id']\n+        that is passed from BoundField.subwidgets().\n+        \"\"\"\n+        class TestForm(forms.Form):\n+            field = forms.MultipleChoiceField(\n+                choices=(('a', 'A'), ('b', 'B')),\n+                widget=CheckboxSelectMultiple,\n+            )\n+        form = TestForm(auto_id='test_%s')\n+        bound_field = form['field']\n+        # The 'for' attribute of the label should be based on auto_id.\n+        # The bug is that BoundWidget.id_for_label() generates its own ID\n+        # ('id_field_0') instead of using the one passed to the widget\n+        # ('test_field_0').\n+        self.assertInHTML(\n+            '<label for=\"test_field_0\">',\n+            str(list(bound_field)[0])\n+        )\n"
    },
    "django__django-16502": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/servers/test_runserver_head.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py servers.test_runserver_head"
        ],
        "reproduced_bug_patch": "diff --git a/tests/servers/test_runserver_head.py b/tests/servers/test_runserver_head.py\nnew file mode 100644\nindex 0000000000..acb83287a8\n--- /dev/null\n+++ b/tests/servers/test_runserver_head.py\n@@ -0,0 +1,48 @@\n+import os\n+import socket\n+\n+from django.test import LiveServerTestCase, override_settings\n+\n+TEST_ROOT = os.path.dirname(__file__)\n+TEST_SETTINGS = {\n+    \"MEDIA_URL\": \"media/\",\n+    \"MEDIA_ROOT\": os.path.join(TEST_ROOT, \"media\"),\n+    \"STATIC_URL\": \"static/\",\n+    \"STATIC_ROOT\": os.path.join(TEST_ROOT, \"static\"),\n+}\n+\n+\n+@override_settings(ROOT_URLCONF=\"servers.urls\", **TEST_SETTINGS)\n+class LiveServerViews(LiveServerTestCase):\n+    available_apps = [\n+        \"servers\",\n+        \"django.contrib.auth\",\n+        \"django.contrib.contenttypes\",\n+        \"django.contrib.sessions\",\n+    ]\n+\n+    def test_head_request_no_body(self):\n+        \"\"\"\n+        runserver must not send a message body on HTTP HEAD requests. This is\n+        tested at the socket level to bypass client-side body stripping.\n+        \"\"\"\n+        host, port = self.server_thread.host, self.server_thread.port\n+        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n+            s.connect((host, port))\n+            request = (\n+                b\"HEAD /example_view/ HTTP/1.1\\r\\n\"\n+                b\"Host: %s:%d\\r\\n\"\n+                b\"Connection: close\\r\\n\"\n+                b\"\\r\\n\"\n+            ) % (host.encode(), port)\n+            s.sendall(request)\n+\n+            response_data = b\"\"\n+            while True:\n+                chunk = s.recv(4096)\n+                if not chunk:\n+                    break\n+                response_data += chunk\n+\n+        headers, _, body = response_data.partition(b\"\\r\\n\\r\\n\")\n+        self.assertEqual(body, b\"\")\n"
    },
    "pytest-dev__pytest-6197": {
        "reproduced_bug": true,
        "reproduced_bug_file": "testing/test_collect_init.py",
        "reproduced_bug_commands": [
            "pytest testing/test_collect_init.py"
        ],
        "reproduced_bug_patch": "diff --git a/testing/test_collect_init.py b/testing/test_collect_init.py\nnew file mode 100644\nindex 000000000..c13ab3ee6\n--- /dev/null\n+++ b/testing/test_collect_init.py\n@@ -0,0 +1,27 @@\n+import pytest\n+from _pytest.main import ExitCode\n+\n+\n+def test_dont_collect_init_from_unrelated_pkg(testdir):\n+    \"\"\"\n+    pytest should not collect/import __init__.py files from packages that\n+    are not part of the test discovery.\n+\n+    Regression test for issue #5976.\n+    \"\"\"\n+    # Recreate the scenario from the bug report: a directory with a failing\n+    # __init__.py, which shouldn't be collected.\n+    testdir.mkpydir(\"foobar\")\n+    testdir.tmpdir.join(\"foobar\", \"__init__.py\").write(\"assert False\")\n+\n+    # Add a test file so the run doesn't fail with \"no tests collected\".\n+    testdir.makepyfile(\"def test_ok(): pass\")\n+\n+    # When the bug is present, pytest tries to import foobar/__init__.py\n+    # and fails with a collection error.\n+    # When fixed, pytest should ignore it and run the tests.\n+    result = testdir.runpytest()\n+\n+    # The correct behavior is for one test to pass. This assertion will fail\n+    # until the bug is fixed.\n+    result.assert_outcomes(passed=1)\n"
    },
    "sympy__sympy-14531": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/printing/tests/test_str_issue_10231.py",
        "reproduced_bug_commands": [
            "pytest sympy/printing/tests/test_str_issue_10231.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/printing/tests/test_str_issue_10231.py b/sympy/printing/tests/test_str_issue_10231.py\nnew file mode 100644\nindex 0000000000..d84ff94e4b\n--- /dev/null\n+++ b/sympy/printing/tests/test_str_issue_10231.py\n@@ -0,0 +1,11 @@\n+from sympy import Eq, S, symbols\n+from sympy.printing.str import sstr\n+\n+\n+def test_str_sympy_integers_in_subexpressions():\n+    \"\"\"\n+    Test for issue where StrPrinter settings are not respected in subexpressions.\n+    From https://github.com/sympy/sympy/issues/10231\n+    \"\"\"\n+    x = symbols('x')\n+    assert sstr(Eq(x, S(1)/2), sympy_integers=True) == 'Eq(x, S(1)/2)'\n"
    },
    "django__django-11999": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/model_fields/test_get_field_display.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py model_fields.GetFieldDisplayOverrideTests"
        ],
        "reproduced_bug_patch": "diff --git a/tests/model_fields/test_get_field_display.py b/tests/model_fields/test_get_field_display.py\nnew file mode 100644\nindex 0000000000..d9c8830d64\n--- /dev/null\n+++ b/tests/model_fields/test_get_field_display.py\n@@ -0,0 +1,24 @@\n+from django.db import models\n+from django.test import SimpleTestCase\n+from django.utils.translation import gettext_lazy as _\n+\n+# Model based on the user's example in the issue description.\n+class FooBar(models.Model):\n+    foo_bar = models.CharField(_(\"foo\"), max_length=10, choices=[(1, 'foo'), (2, 'bar')])\n+\n+    def get_foo_bar_display(self):\n+        return \"something\"\n+\n+    class Meta:\n+        # app_label is needed for tests that define models locally.\n+        app_label = 'model_fields'\n+\n+\n+class GetFieldDisplayOverrideTests(SimpleTestCase):\n+    def test_override_get_field_display(self):\n+        \"\"\"\n+        Tests that get_FIELD_display() can be overridden on a model.\n+        \"\"\"\n+        instance = FooBar(foo_bar=1)\n+        # This will fail in Django 2.2+, returning 'foo' instead of 'something'.\n+        self.assertEqual(instance.get_foo_bar_display(), \"something\")\n"
    },
    "django__django-14539": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/template_tests/filter_tests/test_urlize_regression.py",
        "reproduced_bug_commands": [
            "python runtests.py template_tests.filter_tests.test_urlize_regression"
        ],
        "reproduced_bug_patch": "diff --git a/tests/template_tests/filter_tests/test_urlize_regression.py b/tests/template_tests/filter_tests/test_urlize_regression.py\nnew file mode 100644\nindex 0000000000..91d76f319f\n--- /dev/null\n+++ b/tests/template_tests/filter_tests/test_urlize_regression.py\n@@ -0,0 +1,397 @@\n+from django.template.defaultfilters import urlize\n+from django.test import SimpleTestCase\n+from django.utils.functional import lazy\n+from django.utils.safestring import mark_safe\n+\n+from ..utils import setup\n+\n+\n+class UrlizeTests(SimpleTestCase):\n+\n+    @setup({'urlize01': '{% autoescape off %}{{ a|urlize }} {{ b|urlize }}{% endautoescape %}'})\n+    def test_urlize01(self):\n+        output = self.engine.render_to_string(\n+            'urlize01',\n+            {'a': 'http://example.com/?x=&y=', 'b': mark_safe('http://example.com?x=&amp;y=&lt;2&gt;')},\n+        )\n+        self.assertEqual(\n+            output,\n+            '<a href=\"http://example.com/?x=&amp;y=\" rel=\"nofollow\">http://example.com/?x=&y=</a> '\n+            '<a href=\"http://example.com?x=&amp;y=%3C2%3E\" rel=\"nofollow\">http://example.com?x=&amp;y=&lt;2&gt;</a>'\n+        )\n+\n+    @setup({'urlize02': '{{ a|urlize }} {{ b|urlize }}'})\n+    def test_urlize02(self):\n+        output = self.engine.render_to_string(\n+            'urlize02',\n+            {'a': \"http://example.com/?x=&y=\", 'b': mark_safe(\"http://example.com?x=&amp;y=\")},\n+        )\n+        self.assertEqual(\n+            output,\n+            '<a href=\"http://example.com/?x=&amp;y=\" rel=\"nofollow\">http://example.com/?x=&amp;y=</a> '\n+            '<a href=\"http://example.com?x=&amp;y=\" rel=\"nofollow\">http://example.com?x=&amp;y=</a>'\n+        )\n+\n+    @setup({'urlize03': '{% autoescape off %}{{ a|urlize }}{% endautoescape %}'})\n+    def test_urlize03(self):\n+        output = self.engine.render_to_string('urlize03', {'a': mark_safe(\"a &amp; b\")})\n+        self.assertEqual(output, 'a &amp; b')\n+\n+    @setup({'urlize04': '{{ a|urlize }}'})\n+    def test_urlize04(self):\n+        output = self.engine.render_to_string('urlize04', {'a': mark_safe(\"a &amp; b\")})\n+        self.assertEqual(output, 'a &amp; b')\n+\n+    # This will lead to a nonsense result, but at least it won't be\n+    # exploitable for XSS purposes when auto-escaping is on.\n+    @setup({'urlize05': '{% autoescape off %}{{ a|urlize }}{% endautoescape %}'})\n+    def test_urlize05(self):\n+        output = self.engine.render_to_string('urlize05', {'a': \"<script>alert('foo')</script>\"})\n+        self.assertEqual(output, \"<script>alert('foo')</script>\")\n+\n+    @setup({'urlize06': '{{ a|urlize }}'})\n+    def test_urlize06(self):\n+        output = self.engine.render_to_string('urlize06', {'a': \"<script>alert('foo')</script>\"})\n+        self.assertEqual(output, '&lt;script&gt;alert(&#x27;foo&#x27;)&lt;/script&gt;')\n+\n+    # mailto: testing for urlize\n+    @setup({'urlize07': '{{ a|urlize }}'})\n+    def test_urlize07(self):\n+        output = self.engine.render_to_string('urlize07', {'a': \"Email me at me@example.com\"})\n+        self.assertEqual(\n+            output,\n+            'Email me at <a href=\"mailto:me@example.com\">me@example.com</a>',\n+        )\n+\n+    @setup({'urlize08': '{{ a|urlize }}'})\n+    def test_urlize08(self):\n+        output = self.engine.render_to_string('urlize08', {'a': \"Email me at <me@example.com>\"})\n+        self.assertEqual(\n+            output,\n+            'Email me at &lt;<a href=\"mailto:me@example.com\">me@example.com</a>&gt;',\n+        )\n+\n+    @setup({'urlize09': '{% autoescape off %}{{ a|urlize }}{% endautoescape %}'})\n+    def test_urlize09(self):\n+        output = self.engine.render_to_string('urlize09', {'a': \"http://example.com/?x=&amp;y=&lt;2&gt;\"})\n+        self.assertEqual(\n+            output,\n+            '<a href=\"http://example.com/?x=&amp;y=%3C2%3E\" rel=\"nofollow\">http://example.com/?x=&amp;y=&lt;2&gt;</a>',\n+        )\n+\n+\n+class FunctionTests(SimpleTestCase):\n+\n+    def test_urls(self):\n+        self.assertEqual(\n+            urlize('http://google.com'),\n+            '<a href=\"http://google.com\" rel=\"nofollow\">http://google.com</a>',\n+        )\n+        self.assertEqual(\n+            urlize('http://google.com/'),\n+            '<a href=\"http://google.com/\" rel=\"nofollow\">http://google.com/</a>',\n+        )\n+        self.assertEqual(\n+            urlize('www.google.com'),\n+            '<a href=\"http://www.google.com\" rel=\"nofollow\">www.google.com</a>',\n+        )\n+        self.assertEqual(\n+            urlize('djangoproject.org'),\n+            '<a href=\"http://djangoproject.org\" rel=\"nofollow\">djangoproject.org</a>',\n+        )\n+        self.assertEqual(\n+            urlize('djangoproject.org/'),\n+            '<a href=\"http://djangoproject.org/\" rel=\"nofollow\">djangoproject.org/</a>',\n+        )\n+\n+    def test_url_split_chars(self):\n+        # Quotes (single and double) and angle brackets shouldn't be considered\n+        # part of URLs.\n+        self.assertEqual(\n+            urlize('www.server.com\"abc'),\n+            '<a href=\"http://www.server.com\" rel=\"nofollow\">www.server.com</a>&quot;abc',\n+        )\n+        self.assertEqual(\n+            urlize('www.server.com\\'abc'),\n+            '<a href=\"http://www.server.com\" rel=\"nofollow\">www.server.com</a>&#x27;abc',\n+        )\n+        self.assertEqual(\n+            urlize('www.server.com<abc'),\n+            '<a href=\"http://www.server.com\" rel=\"nofollow\">www.server.com</a>&lt;abc',\n+        )\n+        self.assertEqual(\n+            urlize('www.server.com>abc'),\n+            '<a href=\"http://www.server.com\" rel=\"nofollow\">www.server.com</a>&gt;abc',\n+        )\n+\n+    def test_email(self):\n+        self.assertEqual(\n+            urlize('info@djangoproject.org'),\n+            '<a href=\"mailto:info@djangoproject.org\">info@djangoproject.org</a>',\n+        )\n+\n+    def test_word_with_dot(self):\n+        self.assertEqual(urlize('some.organization'), 'some.organization'),\n+\n+    def test_https(self):\n+        self.assertEqual(\n+            urlize('https://google.com'),\n+            '<a href=\"https://google.com\" rel=\"nofollow\">https://google.com</a>',\n+        )\n+\n+    def test_quoting(self):\n+        \"\"\"\n+        #9655 - Check urlize doesn't overquote already quoted urls. The\n+        teststring is the urlquoted version of 'http://hi.baidu.com/重新开始'\n+        \"\"\"\n+        self.assertEqual(\n+            urlize('http://hi.baidu.com/%E9%87%8D%E6%96%B0%E5%BC%80%E5%A7%8B'),\n+            '<a href=\"http://hi.baidu.com/%E9%87%8D%E6%96%B0%E5%BC%80%E5%A7%8B\" rel=\"nofollow\">'\n+            'http://hi.baidu.com/%E9%87%8D%E6%96%B0%E5%BC%80%E5%A7%8B</a>',\n+        )\n+\n+    def test_urlencoded(self):\n+        self.assertEqual(\n+            urlize('www.mystore.com/30%OffCoupons!'),\n+            '<a href=\"http://www.mystore.com/30%25OffCoupons\" rel=\"nofollow\">'\n+            'www.mystore.com/30%OffCoupons</a>!',\n+        )\n+        self.assertEqual(\n+            urlize('https://en.wikipedia.org/wiki/Caf%C3%A9'),\n+            '<a href=\"https://en.wikipedia.org/wiki/Caf%C3%A9\" rel=\"nofollow\">'\n+            'https://en.wikipedia.org/wiki/Caf%C3%A9</a>',\n+        )\n+\n+    def test_unicode(self):\n+        self.assertEqual(\n+            urlize('https://en.wikipedia.org/wiki/Café'),\n+            '<a href=\"https://en.wikipedia.org/wiki/Caf%C3%A9\" rel=\"nofollow\">'\n+            'https://en.wikipedia.org/wiki/Café</a>',\n+        )\n+\n+    def test_parenthesis(self):\n+        \"\"\"\n+        #11911 - Check urlize keeps balanced parentheses\n+        \"\"\"\n+        self.assertEqual(\n+            urlize('https://en.wikipedia.org/wiki/Django_(web_framework)'),\n+            '<a href=\"https://en.wikipedia.org/wiki/Django_(web_framework)\" rel=\"nofollow\">'\n+            'https://en.wikipedia.org/wiki/Django_(web_framework)</a>',\n+        )\n+        self.assertEqual(\n+            urlize('(see https://en.wikipedia.org/wiki/Django_(web_framework))'),\n+            '(see <a href=\"https://en.wikipedia.org/wiki/Django_(web_framework)\" rel=\"nofollow\">'\n+            'https://en.wikipedia.org/wiki/Django_(web_framework)</a>)',\n+        )\n+\n+    def test_nofollow(self):\n+        \"\"\"\n+        #12183 - Check urlize adds nofollow properly - see #12183\n+        \"\"\"\n+        self.assertEqual(\n+            urlize('foo@bar.com or www.bar.com'),\n+            '<a href=\"mailto:foo@bar.com\">foo@bar.com</a> or '\n+            '<a href=\"http://www.bar.com\" rel=\"nofollow\">www.bar.com</a>',\n+        )\n+\n+    def test_idn(self):\n+        \"\"\"\n+        #13704 - Check urlize handles IDN correctly\n+        \"\"\"\n+        self.assertEqual(urlize('http://c✶.ws'), '<a href=\"http://xn--c-lgq.ws\" rel=\"nofollow\">http://c✶.ws</a>')\n+        self.assertEqual(urlize('www.c✶.ws'), '<a href=\"http://www.xn--c-lgq.ws\" rel=\"nofollow\">www.c✶.ws</a>')\n+        self.assertEqual(urlize('c✶.org'), '<a href=\"http://xn--c-lgq.org\" rel=\"nofollow\">c✶.org</a>')\n+        self.assertEqual(urlize('info@c✶.org'), '<a href=\"mailto:info@xn--c-lgq.org\">info@c✶.org</a>')\n+\n+    def test_malformed(self):\n+        \"\"\"\n+        #16395 - Check urlize doesn't highlight malformed URIs\n+        \"\"\"\n+        self.assertEqual(urlize('http:///www.google.com'), 'http:///www.google.com')\n+        self.assertEqual(urlize('http://.google.com'), 'http://.google.com')\n+        self.assertEqual(urlize('http://@foo.com'), 'http://@foo.com')\n+\n+    def test_tlds(self):\n+        \"\"\"\n+        #16656 - Check urlize accepts more TLDs\n+        \"\"\"\n+        self.assertEqual(urlize('usa.gov'), '<a href=\"http://usa.gov\" rel=\"nofollow\">usa.gov</a>')\n+\n+    def test_invalid_email(self):\n+        \"\"\"\n+        #17592 - Check urlize don't crash on invalid email with dot-starting\n+        domain\n+        \"\"\"\n+        self.assertEqual(urlize('email@.stream.ru'), 'email@.stream.ru')\n+\n+    def test_uppercase(self):\n+        \"\"\"\n+        #18071 - Check urlize accepts uppercased URL schemes\n+        \"\"\"\n+        self.assertEqual(\n+            urlize('HTTPS://github.com/'),\n+            '<a href=\"https://github.com/\" rel=\"nofollow\">HTTPS://github.com/</a>',\n+        )\n+\n+    def test_trailing_period(self):\n+        \"\"\"\n+        #18644 - Check urlize trims trailing period when followed by parenthesis\n+        \"\"\"\n+        self.assertEqual(\n+            urlize('(Go to http://www.example.com/foo.)'),\n+            '(Go to <a href=\"http://www.example.com/foo\" rel=\"nofollow\">http://www.example.com/foo</a>.)',\n+        )\n+\n+    def test_trailing_multiple_punctuation(self):\n+        self.assertEqual(\n+            urlize('A test http://testing.com/example..'),\n+            'A test <a href=\"http://testing.com/example\" rel=\"nofollow\">http://testing.com/example</a>..'\n+        )\n+        self.assertEqual(\n+            urlize('A test http://testing.com/example!!'),\n+            'A test <a href=\"http://testing.com/example\" rel=\"nofollow\">http://testing.com/example</a>!!'\n+        )\n+        self.assertEqual(\n+            urlize('A test http://testing.com/example!!!'),\n+            'A test <a href=\"http://testing.com/example\" rel=\"nofollow\">http://testing.com/example</a>!!!'\n+        )\n+        self.assertEqual(\n+            urlize('A test http://testing.com/example.,:;)\"!'),\n+            'A test <a href=\"http://testing.com/example\" rel=\"nofollow\">http://testing.com/example</a>.,:;)&quot;!'\n+        )\n+\n+    def test_brackets(self):\n+        \"\"\"\n+        #19070 - Check urlize handles brackets properly\n+        \"\"\"\n+        self.assertEqual(\n+            urlize('[see www.example.com]'),\n+            '[see <a href=\"http://www.example.com\" rel=\"nofollow\">www.example.com</a>]',\n+        )\n+        self.assertEqual(\n+            urlize('see test[at[example.com'),\n+            'see <a href=\"http://test[at[example.com\" rel=\"nofollow\">test[at[example.com</a>',\n+        )\n+        self.assertEqual(\n+            urlize('[http://168.192.0.1](http://168.192.0.1)'),\n+            '[<a href=\"http://168.192.0.1](http://168.192.0.1)\" rel=\"nofollow\">'\n+            'http://168.192.0.1](http://168.192.0.1)</a>',\n+        )\n+\n+    def test_wrapping_characters(self):\n+        wrapping_chars = (\n+            ('()', ('(', ')')),\n+            ('<>', ('&lt;', '&gt;')),\n+            ('[]', ('[', ']')),\n+            ('\"\"', ('&quot;', '&quot;')),\n+            (\"''\", ('&#x27;', '&#x27;')),\n+        )\n+        for wrapping_in, (start_out, end_out) in wrapping_chars:\n+            with self.subTest(wrapping_in=wrapping_in):\n+                start_in, end_in = wrapping_in\n+                self.assertEqual(\n+                    urlize(start_in + 'https://www.example.org/' + end_in),\n+                    start_out +\n+                    '<a href=\"https://www.example.org/\" rel=\"nofollow\">https://www.example.org/</a>' +\n+                    end_out,\n+                )\n+\n+    def test_ipv4(self):\n+        self.assertEqual(\n+            urlize('http://192.168.0.15/api/9'),\n+            '<a href=\"http://192.168.0.15/api/9\" rel=\"nofollow\">http://192.168.0.15/api/9</a>',\n+        )\n+\n+    def test_ipv6(self):\n+        self.assertEqual(\n+            urlize('http://[2001:db8:cafe::2]/api/9'),\n+            '<a href=\"http://[2001:db8:cafe::2]/api/9\" rel=\"nofollow\">http://[2001:db8:cafe::2]/api/9</a>',\n+        )\n+\n+    def test_quotation_marks(self):\n+        \"\"\"\n+        #20364 - Check urlize correctly include quotation marks in links\n+        \"\"\"\n+        self.assertEqual(\n+            urlize('before \"hi@example.com\" afterwards', autoescape=False),\n+            'before \"<a href=\"mailto:hi@example.com\">hi@example.com</a>\" afterwards',\n+        )\n+        self.assertEqual(\n+            urlize('before hi@example.com\" afterwards', autoescape=False),\n+            'before <a href=\"mailto:hi@example.com\">hi@example.com</a>\" afterwards',\n+        )\n+        self.assertEqual(\n+            urlize('before \"hi@example.com afterwards', autoescape=False),\n+            'before \"<a href=\"mailto:hi@example.com\">hi@example.com</a> afterwards',\n+        )\n+        self.assertEqual(\n+            urlize('before \\'hi@example.com\\' afterwards', autoescape=False),\n+            'before \\'<a href=\"mailto:hi@example.com\">hi@example.com</a>\\' afterwards',\n+        )\n+        self.assertEqual(\n+            urlize('before hi@example.com\\' afterwards', autoescape=False),\n+            'before <a href=\"mailto:hi@example.com\">hi@example.com</a>\\' afterwards',\n+        )\n+        self.assertEqual(\n+            urlize('before \\'hi@example.com afterwards', autoescape=False),\n+            'before \\'<a href=\"mailto:hi@example.com\">hi@example.com</a> afterwards',\n+        )\n+\n+    def test_quote_commas(self):\n+        \"\"\"\n+        #20364 - Check urlize copes with commas following URLs in quotes\n+        \"\"\"\n+        self.assertEqual(\n+            urlize('Email us at \"hi@example.com\", or phone us at +xx.yy', autoescape=False),\n+            'Email us at \"<a href=\"mailto:hi@example.com\">hi@example.com</a>\", or phone us at +xx.yy',\n+        )\n+\n+    def test_exclamation_marks(self):\n+        \"\"\"\n+        #23715 - Check urlize correctly handles exclamation marks after TLDs\n+        or query string\n+        \"\"\"\n+        self.assertEqual(\n+            urlize('Go to djangoproject.com! and enjoy.'),\n+            'Go to <a href=\"http://djangoproject.com\" rel=\"nofollow\">djangoproject.com</a>! and enjoy.',\n+        )\n+        self.assertEqual(\n+            urlize('Search for google.com/?q=! and see.'),\n+            'Search for <a href=\"http://google.com/?q=\" rel=\"nofollow\">google.com/?q=</a>! and see.',\n+        )\n+        self.assertEqual(\n+            urlize('Search for google.com/?q=dj!`? and see.'),\n+            'Search for <a href=\"http://google.com/?q=dj%21%60%3F\" rel=\"nofollow\">google.com/?q=dj!`?</a> and see.',\n+        )\n+        self.assertEqual(\n+            urlize('Search for google.com/?q=dj!`?! and see.'),\n+            'Search for <a href=\"http://google.com/?q=dj%21%60%3F\" rel=\"nofollow\">google.com/?q=dj!`?</a>! and see.',\n+        )\n+\n+    def test_html_escaped_string_and_trailing_punctuation(self):\n+        self.assertEqual(\n+            urlize('Search for google.com/?q=1&lt! and see.', autoescape=False),\n+            'Search for <a href=\"http://google.com/?q=1%3C\" rel=\"nofollow\">google.com/?q=1&lt;</a>! and see.'\n+        )\n+\n+    def test_non_string_input(self):\n+        self.assertEqual(urlize(123), '123')\n+\n+    def test_autoescape(self):\n+        self.assertEqual(\n+            urlize('foo<a href=\" google.com \">bar</a>buz'),\n+            'foo&lt;a href=&quot; <a href=\"http://google.com\" rel=\"nofollow\">google.com</a> &quot;&gt;bar&lt;/a&gt;buz'\n+        )\n+\n+    def test_autoescape_off(self):\n+        self.assertEqual(\n+            urlize('foo<a href=\" google.com \">bar</a>buz', autoescape=False),\n+            'foo<a href=\" <a href=\"http://google.com\" rel=\"nofollow\">google.com</a> \">bar</a>buz',\n+        )\n+\n+    def test_lazystring(self):\n+        prepend_www = lazy(lambda url: 'www.' + url, str)\n+        self.assertEqual(\n+            urlize(prepend_www('google.com')),\n+            '<a href=\"http://www.google.com\" rel=\"nofollow\">www.google.com</a>',\n+        )\n"
    },
    "django__django-16527": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/admin_views/test_permissions.py",
        "reproduced_bug_commands": [
            "python manage.py test admin_views"
        ],
        "reproduced_bug_patch": "diff --git a/tests/admin_views/test_permissions.py b/tests/admin_views/test_permissions.py\nnew file mode 100644\nindex 0000000000..18438084d1\n--- /dev/null\n+++ b/tests/admin_views/test_permissions.py\n@@ -0,0 +1,65 @@\n+from django.contrib.auth import get_permission_codename\n+from django.contrib.auth.models import Permission, User\n+from django.contrib.contenttypes.models import ContentType\n+from django.test import TestCase, override_settings\n+from django.urls import reverse\n+\n+from .models import Person\n+\n+\n+def get_perm(model, codename):\n+    \"\"\"\n+    Return the Permission object for a given model and codename.\n+    \"\"\"\n+    return Permission.objects.get(\n+        content_type=ContentType.objects.get_for_model(model),\n+        codename=codename,\n+    )\n+\n+\n+@override_settings(\n+    ROOT_URLCONF=\"admin_views.urls\",\n+    TEMPLATES=[\n+        {\n+            \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n+            \"APP_DIRS\": True,\n+            \"OPTIONS\": {\n+                \"context_processors\": [\n+                    \"django.template.context_processors.request\",\n+                    \"django.contrib.auth.context_processors.auth\",\n+                    \"django.contrib.messages.context_processors.messages\",\n+                ],\n+            },\n+        }\n+    ],\n+)\n+class AdminViewPermissionsTest(TestCase):\n+    @classmethod\n+    def setUpTestData(cls):\n+        \"\"\"\n+        Set up a user with change permission but no add permission.\n+        \"\"\"\n+        cls.changeuser = User.objects.create_user(\n+            username=\"changeuser\", password=\"secret\", is_staff=True\n+        )\n+        # Grant change permission for Person model, which has save_as=True.\n+        cls.changeuser.user_permissions.add(\n+            get_perm(Person, get_permission_codename(\"change\", Person._meta))\n+        )\n+        cls.person = Person.objects.create(name=\"test person\")\n+\n+    def test_save_as_new_requires_add_permission(self):\n+        \"\"\"\n+        The \"Save as new\" button is not displayed if the user doesn't have\n+        add permission.\n+        \"\"\"\n+        self.client.force_login(self.changeuser)\n+        # The PersonAdmin has `save_as = True`, so the button would normally\n+        # be shown if permissions were not an issue.\n+        url = reverse(\"admin:admin_views_person_change\", args=(self.person.pk,))\n+        response = self.client.get(url)\n+\n+        self.assertEqual(response.status_code, 200)\n+        # This assertion fails because of the bug. \"Save as new\" is an add\n+        # operation, so it should not be available without add permission.\n+        self.assertFalse(response.context[\"show_save_as_new\"])\n"
    },
    "pytest-dev__pytest-6202": {
        "reproduced_bug": true,
        "reproduced_bug_file": "testing/test_nodeid_reporting.py",
        "reproduced_bug_commands": [
            "pytest testing/test_nodeid_reporting.py"
        ],
        "reproduced_bug_patch": "diff --git a/testing/test_nodeid_reporting.py b/testing/test_nodeid_reporting.py\nnew file mode 100644\nindex 000000000..22c57cc0d\n--- /dev/null\n+++ b/testing/test_nodeid_reporting.py\n@@ -0,0 +1,30 @@\n+import pytest\n+\n+\n+def test_nodeid_special_chars_in_parametrize(testdir):\n+    \"\"\"\n+    Tests that node IDs with special characters from parametrization are not\n+    incorrectly modified in the report header.\n+\n+    This is a regression test for a bug where \"..[\" in a parameter name\n+    was being replaced by \".[\", causing an incorrect test headline.\n+    \"\"\"\n+    testdir.makepyfile(\n+        \"\"\"\n+        import pytest\n+        @pytest.mark.parametrize(\"a\", [\"..[\"])\n+        def test_boo(a):\n+            assert 0\n+        \"\"\"\n+    )\n+    result = testdir.inline_run()\n+\n+    # The result object contains reports for setup, call, and teardown.\n+    # We are interested in the 'call' report, which is the second one.\n+    reports = result.getreports(\"pytest_runtest_logreport\")\n+    call_report = reports[1]\n+\n+    # The report's `location` attribute is a tuple (path, lineno, name).\n+    # The `name` part is used for the test report headline and is where the bug manifests.\n+    # We assert that the name is the expected 'test_boo[..[]' and not the buggy 'test_boo[.[]'.\n+    assert call_report.location[2] == \"test_boo[..[]\"\n"
    },
    "sympy__sympy-14711": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/physics/vector/tests/test_vector_bug.py",
        "reproduced_bug_commands": [
            "pytest sympy/physics/vector/tests/test_vector_bug.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/physics/vector/tests/test_vector_bug.py b/sympy/physics/vector/tests/test_vector_bug.py\nnew file mode 100644\nindex 0000000000..93e74cb5be\n--- /dev/null\n+++ b/sympy/physics/vector/tests/test_vector_bug.py\n@@ -0,0 +1,9 @@\n+from sympy import symbols\n+from sympy.physics.vector import ReferenceFrame, Vector\n+\n+def test_vector_add_0_error():\n+    \"\"\"Test for issue https://github.com/sympy/sympy/pull/9548\"\"\"\n+    N = ReferenceFrame('N')\n+    # This was raising a TypeError, because `0 * N.x` resulted in `0`\n+    # instead of a zero vector.\n+    assert sum([N.x, (0 * N.x)]) == N.x\n"
    },
    "django__django-12039": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/backends/test_ddl_references_fix.py",
        "reproduced_bug_commands": [
            "./runtests.py --settings=tests.settings backends.test_ddl_references_fix"
        ],
        "reproduced_bug_patch": "diff --git a/tests/backends/test_ddl_references_fix.py b/tests/backends/test_ddl_references_fix.py\nnew file mode 100644\nindex 0000000000..e2b807e01f\n--- /dev/null\n+++ b/tests/backends/test_ddl_references_fix.py\n@@ -0,0 +1,196 @@\n+from django.db.backends.ddl_references import (\n+    Columns, ForeignKeyName, IndexName, Statement, Table,\n+)\n+from django.test import SimpleTestCase\n+\n+\n+class TableTests(SimpleTestCase):\n+    def setUp(self):\n+        self.reference = Table('table', lambda table: table.upper())\n+\n+    def test_references_table(self):\n+        self.assertIs(self.reference.references_table('table'), True)\n+        self.assertIs(self.reference.references_table('other'), False)\n+\n+    def test_rename_table_references(self):\n+        self.reference.rename_table_references('other', 'table')\n+        self.assertIs(self.reference.references_table('table'), True)\n+        self.assertIs(self.reference.references_table('other'), False)\n+        self.reference.rename_table_references('table', 'other')\n+        self.assertIs(self.reference.references_table('table'), False)\n+        self.assertIs(self.reference.references_table('other'), True)\n+\n+    def test_repr(self):\n+        self.assertEqual(repr(self.reference), \"<Table 'TABLE'>\")\n+\n+    def test_str(self):\n+        self.assertEqual(str(self.reference), 'TABLE')\n+\n+\n+class ColumnsTests(SimpleTestCase):\n+    def setUp(self):\n+        self.reference = Columns(\n+            'table', ['first_column', 'second_column'], lambda column: column.upper()\n+        )\n+\n+    def test_references_column(self):\n+        self.assertIs(self.reference.references_column('other', 'first_column'), False)\n+        self.assertIs(self.reference.references_column('table', 'third_column'), False)\n+        self.assertIs(self.reference.references_column('table', 'first_column'), True)\n+\n+    def test_rename_column_references(self):\n+        self.reference.rename_column_references('other', 'first_column', 'third_column')\n+        self.assertIs(self.reference.references_column('table', 'first_column'), True)\n+        self.assertIs(self.reference.references_column('table', 'third_column'), False)\n+        self.assertIs(self.reference.references_column('other', 'third_column'), False)\n+        self.reference.rename_column_references('table', 'third_column', 'first_column')\n+        self.assertIs(self.reference.references_column('table', 'first_column'), True)\n+        self.assertIs(self.reference.references_column('table', 'third_column'), False)\n+        self.reference.rename_column_references('table', 'first_column', 'third_column')\n+        self.assertIs(self.reference.references_column('table', 'first_column'), False)\n+        self.assertIs(self.reference.references_column('table', 'third_column'), True)\n+\n+    def test_repr(self):\n+        self.assertEqual(repr(self.reference), \"<Columns 'FIRST_COLUMN, SECOND_COLUMN'>\")\n+\n+    def test_str(self):\n+        self.assertEqual(str(self.reference), 'FIRST_COLUMN, SECOND_COLUMN')\n+\n+    def test_str_with_suffixes(self):\n+        \"\"\"Test whitespace around column suffixes.\"\"\"\n+        # DESC should be preceded by a space.\n+        reference = Columns(\n+            'table', ['name'], lambda x: f'\"{x}\"', col_suffixes=['DESC']\n+        )\n+        self.assertEqual(str(reference), '\"name\" DESC')\n+        # opclasses should be preceded by a space and not have a trailing space.\n+        reference = Columns(\n+            'table', ['name'], lambda x: f'\"{x}\"', col_suffixes=['text_pattern_ops']\n+        )\n+        self.assertEqual(str(reference), '\"name\" text_pattern_ops')\n+\n+\n+class IndexNameTests(ColumnsTests):\n+    def setUp(self):\n+        def create_index_name(table_name, column_names, suffix):\n+            return ', '.join(\"%s_%s_%s\" % (table_name, column_name, suffix) for column_name in column_names)\n+        self.reference = IndexName(\n+            'table', ['first_column', 'second_column'], 'suffix', create_index_name\n+        )\n+\n+    def test_repr(self):\n+        self.assertEqual(repr(self.reference), \"<IndexName 'table_first_column_suffix, table_second_column_suffix'>\")\n+\n+    def test_str(self):\n+        self.assertEqual(str(self.reference), 'table_first_column_suffix, table_second_column_suffix')\n+\n+\n+class ForeignKeyNameTests(IndexNameTests):\n+    def setUp(self):\n+        def create_foreign_key_name(table_name, column_names, suffix):\n+            return ', '.join(\"%s_%s_%s\" % (table_name, column_name, suffix) for column_name in column_names)\n+        self.reference = ForeignKeyName(\n+            'table', ['first_column', 'second_column'],\n+            'to_table', ['to_first_column', 'to_second_column'],\n+            '%(to_table)s_%(to_column)s_fk',\n+            create_foreign_key_name,\n+        )\n+\n+    def test_references_table(self):\n+        super().test_references_table()\n+        self.assertIs(self.reference.references_table('to_table'), True)\n+\n+    def test_references_column(self):\n+        super().test_references_column()\n+        self.assertIs(self.reference.references_column('to_table', 'second_column'), False)\n+        self.assertIs(self.reference.references_column('to_table', 'to_second_column'), True)\n+\n+    def test_rename_table_references(self):\n+        super().test_rename_table_references()\n+        self.reference.rename_table_references('to_table', 'other_to_table')\n+        self.assertIs(self.reference.references_table('other_to_table'), True)\n+        self.assertIs(self.reference.references_table('to_table'), False)\n+\n+    def test_rename_column_references(self):\n+        super().test_rename_column_references()\n+        self.reference.rename_column_references('to_table', 'second_column', 'third_column')\n+        self.assertIs(self.reference.references_column('table', 'second_column'), True)\n+        self.assertIs(self.reference.references_column('to_table', 'to_second_column'), True)\n+        self.reference.rename_column_references('to_table', 'to_first_column', 'to_third_column')\n+        self.assertIs(self.reference.references_column('to_table', 'to_first_column'), False)\n+        self.assertIs(self.reference.references_column('to_table', 'to_third_column'), True)\n+\n+    def test_repr(self):\n+        self.assertEqual(\n+            repr(self.reference),\n+            \"<ForeignKeyName 'table_first_column_to_table_to_first_column_fk, \"\n+            \"table_second_column_to_table_to_first_column_fk'>\"\n+        )\n+\n+    def test_str(self):\n+        self.assertEqual(\n+            str(self.reference),\n+            'table_first_column_to_table_to_first_column_fk, '\n+            'table_second_column_to_table_to_first_column_fk'\n+        )\n+\n+\n+class MockReference:\n+    def __init__(self, representation, referenced_tables, referenced_columns):\n+        self.representation = representation\n+        self.referenced_tables = referenced_tables\n+        self.referenced_columns = referenced_columns\n+\n+    def references_table(self, table):\n+        return table in self.referenced_tables\n+\n+    def references_column(self, table, column):\n+        return (table, column) in self.referenced_columns\n+\n+    def rename_table_references(self, old_table, new_table):\n+        if old_table in self.referenced_tables:\n+            self.referenced_tables.remove(old_table)\n+            self.referenced_tables.add(new_table)\n+\n+    def rename_column_references(self, table, old_column, new_column):\n+        column = (table, old_column)\n+        if column in self.referenced_columns:\n+            self.referenced_columns.remove(column)\n+            self.referenced_columns.add((table, new_column))\n+\n+    def __str__(self):\n+        return self.representation\n+\n+\n+class StatementTests(SimpleTestCase):\n+    def test_references_table(self):\n+        statement = Statement('', reference=MockReference('', {'table'}, {}), non_reference='')\n+        self.assertIs(statement.references_table('table'), True)\n+        self.assertIs(statement.references_table('other'), False)\n+\n+    def test_references_column(self):\n+        statement = Statement('', reference=MockReference('', {}, {('table', 'column')}), non_reference='')\n+        self.assertIs(statement.references_column('table', 'column'), True)\n+        self.assertIs(statement.references_column('other', 'column'), False)\n+\n+    def test_rename_table_references(self):\n+        reference = MockReference('', {'table'}, {})\n+        statement = Statement('', reference=reference, non_reference='')\n+        statement.rename_table_references('table', 'other')\n+        self.assertEqual(reference.referenced_tables, {'other'})\n+\n+    def test_rename_column_references(self):\n+        reference = MockReference('', {}, {('table', 'column')})\n+        statement = Statement('', reference=reference, non_reference='')\n+        statement.rename_column_references('table', 'column', 'other')\n+        self.assertEqual(reference.referenced_columns, {('table', 'other')})\n+\n+    def test_repr(self):\n+        reference = MockReference('reference', {}, {})\n+        statement = Statement(\"%(reference)s - %(non_reference)s\", reference=reference, non_reference='non_reference')\n+        self.assertEqual(repr(statement), \"<Statement 'reference - non_reference'>\")\n+\n+    def test_str(self):\n+        reference = MockReference('reference', {}, {})\n+        statement = Statement(\"%(reference)s - %(non_reference)s\", reference=reference, non_reference='non_reference')\n+        self.assertEqual(str(statement), 'reference - non_reference')\n"
    },
    "django__django-14559": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/queries/test_bulk_update_regressions.py",
        "reproduced_bug_commands": [
            "./tests/runtests.py queries.test_bulk_update_regressions"
        ],
        "reproduced_bug_patch": "diff --git a/tests/queries/test_bulk_update_regressions.py b/tests/queries/test_bulk_update_regressions.py\nnew file mode 100644\nindex 0000000000..457b7fcd34\n--- /dev/null\n+++ b/tests/queries/test_bulk_update_regressions.py\n@@ -0,0 +1,251 @@\n+import datetime\n+\n+from django.core.exceptions import FieldDoesNotExist\n+from django.db.models import F\n+from django.db.models.functions import Lower\n+from django.test import TestCase, skipUnlessDBFeature\n+\n+from .models import (\n+    Article, CustomDbColumn, CustomPk, Detail, Individual, JSONFieldNullable,\n+    Member, Note, Number, Order, Paragraph, SpecialCategory, Tag, Valid,\n+)\n+\n+\n+class BulkUpdateNoteTests(TestCase):\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.notes = [\n+            Note.objects.create(note=str(i), misc=str(i))\n+            for i in range(10)\n+        ]\n+\n+    def create_tags(self):\n+        self.tags = [\n+            Tag.objects.create(name=str(i))\n+            for i in range(10)\n+        ]\n+\n+    def test_simple(self):\n+        for note in self.notes:\n+            note.note = 'test-%s' % note.id\n+        with self.assertNumQueries(1):\n+            Note.objects.bulk_update(self.notes, ['note'])\n+        self.assertCountEqual(\n+            Note.objects.values_list('note', flat=True),\n+            [cat.note for cat in self.notes]\n+        )\n+\n+    def test_return_value(self):\n+        \"\"\"\n+        bulk_update() should return the number of rows updated.\n+        \"\"\"\n+        for note in self.notes:\n+            note.note = 'test-%s' % note.id\n+        num_updated = Note.objects.bulk_update(self.notes, ['note'])\n+        self.assertEqual(num_updated, len(self.notes))\n+\n+    def test_multiple_fields(self):\n+        for note in self.notes:\n+            note.note = 'test-%s' % note.id\n+            note.misc = 'misc-%s' % note.id\n+        with self.assertNumQueries(1):\n+            Note.objects.bulk_update(self.notes, ['note', 'misc'])\n+        self.assertCountEqual(\n+            Note.objects.values_list('note', flat=True),\n+            [cat.note for cat in self.notes]\n+        )\n+        self.assertCountEqual(\n+            Note.objects.values_list('misc', flat=True),\n+            [cat.misc for cat in self.notes]\n+        )\n+\n+    def test_batch_size(self):\n+        with self.assertNumQueries(len(self.notes)):\n+            Note.objects.bulk_update(self.notes, fields=['note'], batch_size=1)\n+\n+    def test_unsaved_models(self):\n+        objs = self.notes + [Note(note='test', misc='test')]\n+        msg = 'All bulk_update() objects must have a primary key set.'\n+        with self.assertRaisesMessage(ValueError, msg):\n+            Note.objects.bulk_update(objs, fields=['note'])\n+\n+    def test_foreign_keys_do_not_lookup(self):\n+        self.create_tags()\n+        for note, tag in zip(self.notes, self.tags):\n+            note.tag = tag\n+        with self.assertNumQueries(1):\n+            Note.objects.bulk_update(self.notes, ['tag'])\n+        self.assertSequenceEqual(Note.objects.filter(tag__isnull=False), self.notes)\n+\n+    def test_set_field_to_null(self):\n+        self.create_tags()\n+        Note.objects.update(tag=self.tags[0])\n+        for note in self.notes:\n+            note.tag = None\n+        Note.objects.bulk_update(self.notes, ['tag'])\n+        self.assertCountEqual(Note.objects.filter(tag__isnull=True), self.notes)\n+\n+    def test_set_mixed_fields_to_null(self):\n+        self.create_tags()\n+        midpoint = len(self.notes) // 2\n+        top, bottom = self.notes[:midpoint], self.notes[midpoint:]\n+        for note in top:\n+            note.tag = None\n+        for note in bottom:\n+            note.tag = self.tags[0]\n+        Note.objects.bulk_update(self.notes, ['tag'])\n+        self.assertCountEqual(Note.objects.filter(tag__isnull=True), top)\n+        self.assertCountEqual(Note.objects.filter(tag__isnull=False), bottom)\n+\n+    def test_functions(self):\n+        Note.objects.update(note='TEST')\n+        for note in self.notes:\n+            note.note = Lower('note')\n+        Note.objects.bulk_update(self.notes, ['note'])\n+        self.assertEqual(set(Note.objects.values_list('note', flat=True)), {'test'})\n+\n+    # Tests that use self.notes go here, otherwise put them in another class.\n+\n+\n+class BulkUpdateTests(TestCase):\n+    def test_no_fields(self):\n+        msg = 'Field names must be given to bulk_update().'\n+        with self.assertRaisesMessage(ValueError, msg):\n+            Note.objects.bulk_update([], fields=[])\n+\n+    def test_invalid_batch_size(self):\n+        msg = 'Batch size must be a positive integer.'\n+        with self.assertRaisesMessage(ValueError, msg):\n+            Note.objects.bulk_update([], fields=['note'], batch_size=-1)\n+\n+    def test_nonexistent_field(self):\n+        with self.assertRaisesMessage(FieldDoesNotExist, \"Note has no field named 'nonexistent'\"):\n+            Note.objects.bulk_update([], ['nonexistent'])\n+\n+    pk_fields_error = 'bulk_update() cannot be used with primary key fields.'\n+\n+    def test_update_primary_key(self):\n+        with self.assertRaisesMessage(ValueError, self.pk_fields_error):\n+            Note.objects.bulk_update([], ['id'])\n+\n+    def test_update_custom_primary_key(self):\n+        with self.assertRaisesMessage(ValueError, self.pk_fields_error):\n+            CustomPk.objects.bulk_update([], ['name'])\n+\n+    def test_empty_objects(self):\n+        with self.assertNumQueries(0):\n+            Note.objects.bulk_update([], ['note'])\n+\n+    def test_large_batch(self):\n+        Note.objects.bulk_create([\n+            Note(note=str(i), misc=str(i))\n+            for i in range(0, 2000)\n+        ])\n+        notes = list(Note.objects.all())\n+        Note.objects.bulk_update(notes, ['note'])\n+\n+    def test_only_concrete_fields_allowed(self):\n+        obj = Valid.objects.create(valid='test')\n+        detail = Detail.objects.create(data='test')\n+        paragraph = Paragraph.objects.create(text='test')\n+        Member.objects.create(name='test', details=detail)\n+        msg = 'bulk_update() can only be used with concrete fields.'\n+        with self.assertRaisesMessage(ValueError, msg):\n+            Detail.objects.bulk_update([detail], fields=['member'])\n+        with self.assertRaisesMessage(ValueError, msg):\n+            Paragraph.objects.bulk_update([paragraph], fields=['page'])\n+        with self.assertRaisesMessage(ValueError, msg):\n+            Valid.objects.bulk_update([obj], fields=['parent'])\n+\n+    def test_custom_db_columns(self):\n+        model = CustomDbColumn.objects.create(custom_column=1)\n+        model.custom_column = 2\n+        CustomDbColumn.objects.bulk_update([model], fields=['custom_column'])\n+        model.refresh_from_db()\n+        self.assertEqual(model.custom_column, 2)\n+\n+    def test_custom_pk(self):\n+        custom_pks = [\n+            CustomPk.objects.create(name='pk-%s' % i, extra='')\n+            for i in range(10)\n+        ]\n+        for model in custom_pks:\n+            model.extra = 'extra-%s' % model.pk\n+        CustomPk.objects.bulk_update(custom_pks, ['extra'])\n+        self.assertCountEqual(\n+            CustomPk.objects.values_list('extra', flat=True),\n+            [cat.extra for cat in custom_pks]\n+        )\n+\n+    def test_falsey_pk_value(self):\n+        order = Order.objects.create(pk=0, name='test')\n+        order.name = 'updated'\n+        Order.objects.bulk_update([order], ['name'])\n+        order.refresh_from_db()\n+        self.assertEqual(order.name, 'updated')\n+\n+    def test_inherited_fields(self):\n+        special_categories = [\n+            SpecialCategory.objects.create(name=str(i), special_name=str(i))\n+            for i in range(10)\n+        ]\n+        for category in special_categories:\n+            category.name = 'test-%s' % category.id\n+            category.special_name = 'special-test-%s' % category.special_name\n+        SpecialCategory.objects.bulk_update(special_categories, ['name', 'special_name'])\n+        self.assertCountEqual(\n+            SpecialCategory.objects.values_list('name', flat=True),\n+            [cat.name for cat in special_categories]\n+        )\n+        self.assertCountEqual(\n+            SpecialCategory.objects.values_list('special_name', flat=True),\n+            [cat.special_name for cat in special_categories]\n+        )\n+\n+    def test_field_references(self):\n+        numbers = [Number.objects.create(num=0) for _ in range(10)]\n+        for number in numbers:\n+            number.num = F('num') + 1\n+        Number.objects.bulk_update(numbers, ['num'])\n+        self.assertCountEqual(Number.objects.filter(num=1), numbers)\n+\n+    def test_booleanfield(self):\n+        individuals = [Individual.objects.create(alive=False) for _ in range(10)]\n+        for individual in individuals:\n+            individual.alive = True\n+        Individual.objects.bulk_update(individuals, ['alive'])\n+        self.assertCountEqual(Individual.objects.filter(alive=True), individuals)\n+\n+    def test_ipaddressfield(self):\n+        for ip in ('2001::1', '1.2.3.4'):\n+            with self.subTest(ip=ip):\n+                models = [\n+                    CustomDbColumn.objects.create(ip_address='0.0.0.0')\n+                    for _ in range(10)\n+                ]\n+                for model in models:\n+                    model.ip_address = ip\n+                CustomDbColumn.objects.bulk_update(models, ['ip_address'])\n+                self.assertCountEqual(CustomDbColumn.objects.filter(ip_address=ip), models)\n+\n+    def test_datetime_field(self):\n+        articles = [\n+            Article.objects.create(name=str(i), created=datetime.datetime.today())\n+            for i in range(10)\n+        ]\n+        point_in_time = datetime.datetime(1991, 10, 31)\n+        for article in articles:\n+            article.created = point_in_time\n+        Article.objects.bulk_update(articles, ['created'])\n+        self.assertCountEqual(Article.objects.filter(created=point_in_time), articles)\n+\n+    @skipUnlessDBFeature('supports_json_field')\n+    def test_json_field(self):\n+        JSONFieldNullable.objects.bulk_create([\n+            JSONFieldNullable(json_field={'a': i}) for i in range(10)\n+        ])\n+        objs = JSONFieldNullable.objects.all()\n+        for obj in objs:\n+            obj.json_field = {'c': obj.json_field['a'] + 1}\n+        JSONFieldNullable.objects.bulk_update(objs, ['json_field'])\n+        self.assertCountEqual(JSONFieldNullable.objects.filter(json_field__has_key='c'), objs)\n"
    },
    "django__django-16560": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/constraints/test_violation_error_code.py",
        "reproduced_bug_commands": [
            "./tests/runtests.py constraints.test_violation_error_code"
        ],
        "reproduced_bug_patch": "diff --git a/tests/constraints/test_violation_error_code.py b/tests/constraints/test_violation_error_code.py\nnew file mode 100644\nindex 0000000000..64a30cfbcb\n--- /dev/null\n+++ b/tests/constraints/test_violation_error_code.py\n@@ -0,0 +1,35 @@\n+from django.core.exceptions import ValidationError\n+from django.db import connection, models\n+from django.test import TestCase\n+\n+\n+class BaseConstraintViolationErrorCodeTest(TestCase):\n+    def test_custom_violation_error_code(self):\n+        \"\"\"\n+        Test that a custom error code can be specified for a constraint\n+        validation error.\n+        \"\"\"\n+\n+        class Product(models.Model):\n+            name = models.CharField(max_length=255)\n+\n+            class Meta:\n+                app_label = \"constraints\"\n+                constraints = [\n+                    models.UniqueConstraint(\n+                        fields=[\"name\"],\n+                        name=\"name_uniq\",\n+                        violation_error_code=\"custom_code\",\n+                    )\n+                ]\n+\n+        with connection.schema_editor() as schema_editor:\n+            schema_editor.create_model(Product)\n+        self.addCleanup(connection.schema_editor().delete_model, Product)\n+\n+        Product.objects.create(name=\"test\")\n+        instance = Product(name=\"test\")\n+        with self.assertRaises(ValidationError) as cm:\n+            instance.validate_constraints()\n+\n+        self.assertEqual(cm.exception.error_dict[\"__all__\"][0].code, \"custom_code\")\n"
    },
    "pytest-dev__pytest-7205": {
        "reproduced_bug": true,
        "reproduced_bug_file": "testing/test_show_fixtures.py",
        "reproduced_bug_commands": [
            "python3 -bb -m pytest --setup-show testing/test_show_fixtures.py"
        ],
        "reproduced_bug_patch": "diff --git a/testing/test_show_fixtures.py b/testing/test_show_fixtures.py\nnew file mode 100644\nindex 000000000..95f54c1bf\n--- /dev/null\n+++ b/testing/test_show_fixtures.py\n@@ -0,0 +1,33 @@\n+import pytest\n+import sys\n+\n+\n+def test_show_fixtures_with_bytes_parameter(testdir):\n+    \"\"\"\n+    A BytesWarning is raised when using --setup-show with a bytes parameter.\n+\n+    The -bb flag is used to treat BytesWarning as an error, which is how the\n+    bug is triggered in the issue report. The test should fail with a non-zero\n+    exit code and report the BytesWarning in stderr.\n+\n+    This test was corrected to pass the '-bb' flag to the python interpreter\n+    instead of to pytest.\n+    \"\"\"\n+    p = testdir.makepyfile(\n+        \"\"\"\n+        import pytest\n+\n+        @pytest.mark.parametrize('data', [b'Hello World'])\n+        def test_data(data):\n+            pass\n+        \"\"\"\n+    )\n+\n+    # The command `python -bb -m pytest ...` is constructed manually to ensure\n+    # -bb is passed to the interpreter.\n+    result = testdir.run(sys.executable, \"-bb\", \"-m\", \"pytest\", \"--setup-show\", p.strpath)\n+\n+    # The -bb flag promotes the BytesWarning to an error, so pytest should exit\n+    # with a non-zero status code.\n+    assert result.ret != 0\n+    result.stderr.fnmatch_lines([\"*BytesWarning: str() on a bytes instance*\"])\n"
    },
    "sympy__sympy-14976": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/utilities/tests/test_lambdify_rational.py",
        "reproduced_bug_commands": [
            "bin/test sympy/utilities/tests/test_lambdify_rational.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/utilities/tests/test_lambdify_rational.py b/sympy/utilities/tests/test_lambdify_rational.py\nnew file mode 100644\nindex 0000000000..4f02932f88\n--- /dev/null\n+++ b/sympy/utilities/tests/test_lambdify_rational.py\n@@ -0,0 +1,32 @@\n+import mpmath\n+import inspect\n+from sympy.utilities.pytest import XFAIL, raises\n+from sympy import (\n+    symbols, lambdify, sqrt, sin, cos, tan, pi, acos, acosh, Rational,\n+    Float, Matrix, Lambda, Piecewise, exp, Integral, oo, I, Abs, Function,\n+    true, false, And, Or, Not, ITE, Min, Max, floor, diff, IndexedBase, Sum,\n+    DotProduct, Eq, Dummy, sinc, S)\n+from sympy.printing.lambdarepr import LambdaPrinter\n+from sympy.utilities.lambdify import implemented_function\n+from sympy.utilities.pytest import skip\n+from sympy.utilities.decorator import conserve_mpmath_dps\n+from sympy.external import import_module\n+from sympy.functions.special.gamma_functions import uppergamma, lowergamma, RisingFactorial\n+\n+w, x, y, z = symbols('w,x,y,z')\n+\n+def test_lambdify_mpmath_rational():\n+    \"\"\"\n+    Test that lambdify with mpmath module wraps rationals.\n+\n+    Based on https://github.com/sympy/sympy/pull/14971, where rationals\n+    were not being converted to mpmath objects, resulting in precision loss.\n+    \"\"\"\n+    expr = RisingFactorial(18, x) - (77 + S(1)/3)\n+    f = lambdify(x, expr, 'mpmath')\n+    src = inspect.getsource(f)\n+\n+    # The bug causes the rational to be printed as a standard Python float division\n+    # which results in precision loss.\n+    # A fixed version should use mpmath's high-precision objects.\n+    assert '232/3' not in src\n"
    },
    "django__django-12050": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/lookup/test_exact_lookup_type_coercion.py",
        "reproduced_bug_commands": [
            "tests/runtests.py lookup.test_exact_lookup_type_coercion"
        ],
        "reproduced_bug_patch": "diff --git a/tests/lookup/test_exact_lookup_type_coercion.py b/tests/lookup/test_exact_lookup_type_coercion.py\nnew file mode 100644\nindex 0000000000..155ba69635\n--- /dev/null\n+++ b/tests/lookup/test_exact_lookup_type_coercion.py\n@@ -0,0 +1,52 @@\n+import pickle\n+\n+from django.db import models\n+from django.test import TestCase\n+\n+\n+# A minimal PickledField is required to demonstrate the bug, as it's one of\n+# the few field types that distinguishes between a list and a tuple.\n+class PickledField(models.BinaryField):\n+    \"\"\"A field that pickles Python objects for database storage.\"\"\"\n+\n+    def get_prep_value(self, value):\n+        \"\"\"Pickle the value before sending it to the database.\"\"\"\n+        if value is not None:\n+            value = pickle.dumps(value)\n+        return super().get_prep_value(value)\n+\n+    def from_db_value(self, value, expression, connection):\n+        \"\"\"Unpickle the value when retrieving it from the database.\"\"\"\n+        if value is not None:\n+            return pickle.loads(value)\n+        return value\n+\n+\n+class PickledModel(models.Model):\n+    \"\"\"A model using the PickledField for testing.\"\"\"\n+    field = PickledField()\n+\n+    class Meta:\n+        # Add app_label to avoid \"no such table\" errors in standalone tests.\n+        app_label = 'lookup'\n+\n+\n+class ExactLookupTypeCoercionTest(TestCase):\n+    \"\"\"\n+    Tests that list values in lookups are not incorrectly coerced to tuples.\n+    \"\"\"\n+    @classmethod\n+    def setUpTestData(cls):\n+        \"\"\"Create a test object with a list stored in a PickledField.\"\"\"\n+        cls.obj = PickledModel.objects.create(field=['value1', 'value2'])\n+\n+    def test_exact_lookup_preserves_list_type(self):\n+        \"\"\"\n+        An exact lookup with a list should not coerce it into a tuple,\n+        which would cause the lookup to fail for type-sensitive fields.\n+        \"\"\"\n+        # This query will fail if the ['value1', 'value2'] list is coerced to a\n+        # tuple, because the pickled representation of a list is different\n+        # from that of a tuple.\n+        qs = PickledModel.objects.filter(field=['value1', 'value2'])\n+        self.assertEqual(qs.get(), self.obj)\n"
    },
    "django__django-14580": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/migrations/test_writer_bug.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py migrations -k test_writer_bug"
        ],
        "reproduced_bug_patch": "diff --git a/tests/migrations/test_writer_bug.py b/tests/migrations/test_writer_bug.py\nnew file mode 100644\nindex 0000000000..c36591fe1f\n--- /dev/null\n+++ b/tests/migrations/test_writer_bug.py\n@@ -0,0 +1,256 @@\n+import datetime\n+import decimal\n+import enum\n+import functools\n+import math\n+import os\n+import pathlib\n+import re\n+import sys\n+import uuid\n+from unittest import mock\n+\n+import custom_migration_operations.more_operations\n+import custom_migration_operations.operations\n+\n+from django import get_version\n+from django.conf import SettingsReference, settings\n+from django.core.validators import EmailValidator, RegexValidator\n+from django.db import migrations, models\n+from django.db.migrations.serializer import BaseSerializer\n+from django.db.migrations.writer import MigrationWriter, OperationWriter\n+from django.test import SimpleTestCase\n+from django.utils.deconstruct import deconstructible\n+from django.utils.functional import SimpleLazyObject\n+from django.utils.timezone import get_default_timezone, get_fixed_timezone, utc\n+from django.utils.translation import gettext_lazy as _\n+\n+from .models import FoodManager, FoodQuerySet\n+\n+\n+class DeconstructibleInstances:\n+    def deconstruct(self):\n+        return ('DeconstructibleInstances', [], {})\n+\n+\n+class Money(decimal.Decimal):\n+    def deconstruct(self):\n+        return (\n+            '%s.%s' % (self.__class__.__module__, self.__class__.__name__),\n+            [str(self)],\n+            {}\n+        )\n+\n+\n+class TestModel1:\n+    def upload_to(self):\n+        return '/somewhere/dynamic/'\n+    thing = models.FileField(upload_to=upload_to)\n+\n+\n+class TextEnum(enum.Enum):\n+    A = 'a-value'\n+    B = 'value-b'\n+\n+\n+class TextTranslatedEnum(enum.Enum):\n+    A = _('a-value')\n+    B = _('value-b')\n+\n+\n+class BinaryEnum(enum.Enum):\n+    A = b'a-value'\n+    B = b'value-b'\n+\n+\n+class IntEnum(enum.IntEnum):\n+    A = 1\n+    B = 2\n+\n+\n+# Helper classes for the regression test.\n+class NameErrorMixin:\n+    pass\n+\n+\n+class NameErrorField(models.TextField):\n+    pass\n+\n+\n+class OperationWriterTests(SimpleTestCase):\n+\n+    def test_empty_signature(self):\n+        operation = custom_migration_operations.operations.TestOperation()\n+        buff, imports = OperationWriter(operation, indentation=0).serialize()\n+        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n+        self.assertEqual(\n+            buff,\n+            'custom_migration_operations.operations.TestOperation(\\n'\n+            '),'\n+        )\n+\n+    def test_args_signature(self):\n+        operation = custom_migration_operations.operations.ArgsOperation(1, 2)\n+        buff, imports = OperationWriter(operation, indentation=0).serialize()\n+        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n+        self.assertEqual(\n+            buff,\n+            'custom_migration_operations.operations.ArgsOperation(\\n'\n+            '    arg1=1,\\n'\n+            '    arg2=2,\\n'\n+            '),'\n+        )\n+\n+    def test_kwargs_signature(self):\n+        operation = custom_migration_operations.operations.KwargsOperation(kwarg1=1)\n+        buff, imports = OperationWriter(operation, indentation=0).serialize()\n+        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n+        self.assertEqual(\n+            buff,\n+            'custom_migration_operations.operations.KwargsOperation(\\n'\n+            '    kwarg1=1,\\n'\n+            '),'\n+        )\n+\n+    def test_args_kwargs_signature(self):\n+        operation = custom_migration_operations.operations.ArgsKwargsOperation(1, 2, kwarg2=4)\n+        buff, imports = OperationWriter(operation, indentation=0).serialize()\n+        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n+        self.assertEqual(\n+            buff,\n+            'custom_migration_operations.operations.ArgsKwargsOperation(\\n'\n+            '    arg1=1,\\n'\n+            '    arg2=2,\\n'\n+            '    kwarg2=4,\\n'\n+            '),'\n+        )\n+\n+    def test_nested_args_signature(self):\n+        operation = custom_migration_operations.operations.ArgsOperation(\n+            custom_migration_operations.operations.ArgsOperation(1, 2),\n+            custom_migration_operations.operations.KwargsOperation(kwarg1=3, kwarg2=4)\n+        )\n+        buff, imports = OperationWriter(operation, indentation=0).serialize()\n+        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n+        self.assertEqual(\n+            buff,\n+            'custom_migration_operations.operations.ArgsOperation(\\n'\n+            '    arg1=custom_migration_operations.operations.ArgsOperation(\\n'\n+            '        arg1=1,\\n'\n+            '        arg2=2,\\n'\n+            '    ),\\n'\n+            '    arg2=custom_migration_operations.operations.KwargsOperation(\\n'\n+            '        kwarg1=3,\\n'\n+            '        kwarg2=4,\\n'\n+            '    ),\\n'\n+            '),'\n+        )\n+\n+    def test_multiline_args_signature(self):\n+        operation = custom_migration_operations.operations.ArgsOperation(\"test\\n    arg1\", \"test\\narg2\")\n+        buff, imports = OperationWriter(operation, indentation=0).serialize()\n+        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n+        self.assertEqual(\n+            buff,\n+            \"custom_migration_operations.operations.ArgsOperation(\\n\"\n+            \"    arg1='test\\\\n    arg1',\\n\"\n+            \"    arg2='test\\\\narg2',\\n\"\n+            \"),\"\n+        )\n+\n+    def test_expand_args_signature(self):\n+        operation = custom_migration_operations.operations.ExpandArgsOperation([1, 2])\n+        buff, imports = OperationWriter(operation, indentation=0).serialize()\n+        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n+        self.assertEqual(\n+            buff,\n+            'custom_migration_operations.operations.ExpandArgsOperation(\\n'\n+            '    arg=[\\n'\n+            '        1,\\n'\n+            '        2,\\n'\n+            '    ],\\n'\n+            '),'\n+        )\n+\n+    def test_nested_operation_expand_args_signature(self):\n+        operation = custom_migration_operations.operations.ExpandArgsOperation(\n+            arg=[\n+                custom_migration_operations.operations.KwargsOperation(\n+                    kwarg1=1,\n+                    kwarg2=2,\n+                ),\n+            ]\n+        )\n+        buff, imports = OperationWriter(operation, indentation=0).serialize()\n+        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n+        self.assertEqual(\n+            buff,\n+            'custom_migration_operations.operations.ExpandArgsOperation(\\n'\n+            '    arg=[\\n'\n+            '        custom_migration_operations.operations.KwargsOperation(\\n'\n+            '            kwarg1=1,\\n'\n+            '            kwarg2=2,\\n'\n+            '        ),\\n'\n+            '    ],\\n'\n+            '),'\n+        )\n+\n+\n+class WriterTests(SimpleTestCase):\n+    \"\"\"\n+    Tests the migration writer (makes migration files from Migration instances)\n+    \"\"\"\n+    class NestedEnum(enum.IntEnum):\n+        A = 1\n+        B = 2\n+\n+    class NestedChoices(models.TextChoices):\n+        X = 'X', 'X value'\n+        Y = 'Y', 'Y value'\n+\n+    def safe_exec(self, string, value=None):\n+        d = {}\n+        try:\n+            exec(string, globals(), d)\n+        except Exception as e:\n+            if value:\n+                self.fail(\"Could not exec %r (from value %r): %s\" % (string.strip(), value, e))\n+            else:\n+                self.fail(\"Could not exec %r: %s\" % (string.strip(), e))\n+        return d\n+\n+    def serialize_round_trip(self, value):\n+        string, imports = MigrationWriter.serialize(value)\n+        return self.safe_exec(\"%s\\ntest_value_result = %s\" % (\"\\n\".join(imports), string), value)['test_value_result']\n+\n+    def assertSerializedEqual(self, value):\n+        self.assertEqual(self.serialize_round_trip(value), value)\n+\n+    def assertSerializedResultEqual(self, value, target):\n+        self.assertEqual(MigrationWriter.serialize(value), target)\n+\n+    def assertSerializedFieldEqual(self, value):\n+        new_value = self.serialize_round_trip(value)\n+        self.assertEqual(value.__class__, new_value.__class__)\n+        self.assertEqual(value.max_length, new_value.max_length)\n+        self.assertEqual(value.null, new_value.null)\n+        self.assertEqual(value.unique, new_value.unique)\n+\n+    def test_model_import_for_bases(self):\n+        \"\"\"\n+        `from django.db import models` should be added when `models.Model` is\n+        present in the `bases` of a `CreateModel` operation.\n+        \"\"\"\n+        migration = type('Migration', (migrations.Migration,), {\n+            'operations': [\n+                migrations.CreateModel(\n+                    'MyModel',\n+                    fields=[('name', NameErrorField(primary_key=True, serialize=False))],\n+                    bases=(NameErrorMixin, models.Model),\n+                ),\n+            ],\n+            'dependencies': [],\n+        })\n+        writer = MigrationWriter(migration)\n+        output = writer.as_string()\n+        self.assertIn('from django.db import models', output)\n"
    },
    "django__django-16569": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/forms_tests/tests/test_formset_add_fields.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py forms_tests.tests.test_formset_add_fields"
        ],
        "reproduced_bug_patch": "diff --git a/tests/forms_tests/tests/test_formset_add_fields.py b/tests/forms_tests/tests/test_formset_add_fields.py\nnew file mode 100644\nindex 0000000000..c8d38f49a2\n--- /dev/null\n+++ b/tests/forms_tests/tests/test_formset_add_fields.py\n@@ -0,0 +1,23 @@\n+from django.forms import CharField, Form, formset_factory\n+from django.test import SimpleTestCase\n+\n+\n+class MyFieldForm(Form):\n+    my_field = CharField()\n+\n+\n+class FormsFormsetTestCase(SimpleTestCase):\n+    def test_add_fields_index_none(self):\n+        \"\"\"\n+        add_fields() shouldn't fail when index is None, can_delete=True, and\n+        can_delete_extra=False.\n+        \"\"\"\n+        MyFormSet = formset_factory(\n+            form=MyFieldForm,\n+            can_delete=True,\n+            can_delete_extra=False,\n+        )\n+        my_formset = MyFormSet(initial=None)\n+        # Accessing empty_form shouldn't raise a TypeError.\n+        empty_form = my_formset.empty_form\n+        self.assertNotIn(\"DELETE\", empty_form.fields)\n"
    },
    "pytest-dev__pytest-7236": {
        "reproduced_bug": true,
        "reproduced_bug_file": "testing/test_unittest_skip_pdb.py",
        "reproduced_bug_commands": [
            "echo -e 'import unittest\\n\\nclass MyTestCase(unittest.TestCase):\\n    def setUp(self):\\n        xxx\\n    @unittest.skip(\"hello\")\\n    def test_one(self):\\n        pass\\n    def tearDown(self):\\n        xxx' > test_repro.py",
            "echo \"q\" | pytest --pdb test_repro.py"
        ],
        "reproduced_bug_patch": "diff --git a/testing/test_unittest_skip_pdb.py b/testing/test_unittest_skip_pdb.py\nnew file mode 100644\nindex 000000000..08549b345\n--- /dev/null\n+++ b/testing/test_unittest_skip_pdb.py\n@@ -0,0 +1,27 @@\n+import pytest\n+\n+def test_teardown_on_skipped_test_with_pdb(testdir):\n+    \"\"\"\n+    tearDown is executed on skipped tests when running --pdb.\n+    \"\"\"\n+    testdir.makepyfile(\n+        \"\"\"\n+        import unittest\n+\n+        class MyTestCase(unittest.TestCase):\n+            def setUp(self):\n+                xxx\n+            @unittest.skip(\"hello\")\n+            def test_one(self):\n+                pass\n+            def tearDown(self):\n+                xxx\n+    \"\"\"\n+    )\n+    result = testdir.runpytest(\"--pdb\")\n+\n+    # The bug causes an ERROR because tearDown is called on the skipped test.\n+    # A correct run should only show the test as skipped.\n+    # assert_outcomes checks for exact counts, so it will fail if there are\n+    # unexpected errors.\n+    result.assert_outcomes(skipped=1)\n"
    },
    "sympy__sympy-15017": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/tensor/array/tests/test_ndim_array.py",
        "reproduced_bug_commands": [
            "pytest sympy/tensor/array/tests/test_ndim_array.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/tensor/array/tests/test_ndim_array.py b/sympy/tensor/array/tests/test_ndim_array.py\nnew file mode 100644\nindex 0000000000..a46a6cc981\n--- /dev/null\n+++ b/sympy/tensor/array/tests/test_ndim_array.py\n@@ -0,0 +1,11 @@\n+from sympy import Array\n+\n+def test_len_of_rank_zero_array():\n+    \"\"\"\n+    Tests that `len` of a rank-0 array is 1.\n+    \n+    This was returning 0, which is inconsistent with the number of elements\n+    and with the behavior of libraries like numpy.\n+    \"\"\"\n+    rank_zero_array = Array(3)\n+    assert len(rank_zero_array) == 1\n"
    },
    "django__django-12125": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/field_deconstruction/test_nested_field_deconstruction.py",
        "reproduced_bug_commands": [
            "python -m django test field_deconstruction"
        ],
        "reproduced_bug_patch": "diff --git a/tests/field_deconstruction/test_nested_field_deconstruction.py b/tests/field_deconstruction/test_nested_field_deconstruction.py\nnew file mode 100644\nindex 0000000000..05d06e3650\n--- /dev/null\n+++ b/tests/field_deconstruction/test_nested_field_deconstruction.py\n@@ -0,0 +1,511 @@\n+from django.apps import apps\n+from django.db import models\n+from django.test import SimpleTestCase, override_settings\n+from django.test.utils import isolate_lru_cache\n+\n+\n+class FieldDeconstructionTests(SimpleTestCase):\n+    \"\"\"\n+    Tests the deconstruct() method on all core fields.\n+    \"\"\"\n+\n+    def test_name(self):\n+        \"\"\"\n+        Tests the outputting of the correct name if assigned one.\n+        \"\"\"\n+        # First try using a \"normal\" field\n+        field = models.CharField(max_length=65)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertIsNone(name)\n+        field.set_attributes_from_name(\"is_awesome_test\")\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(name, \"is_awesome_test\")\n+        # Now try with a ForeignKey\n+        field = models.ForeignKey(\"some_fake.ModelName\", models.CASCADE)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertIsNone(name)\n+        field.set_attributes_from_name(\"author\")\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(name, \"author\")\n+\n+    def test_deconstruct_nested_field(self):\n+        \"\"\"\n+        A nested field class should deconstruct to a qualified path.\n+        \"\"\"\n+        class Outer:\n+            class Inner(models.CharField):\n+                pass\n+\n+        field = Outer.Inner(max_length=20)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, 'field_deconstruction.tests.Outer.Inner')\n+\n+    def test_db_tablespace(self):\n+        field = models.Field()\n+        _, _, args, kwargs = field.deconstruct()\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {})\n+        # With a DEFAULT_DB_TABLESPACE.\n+        with self.settings(DEFAULT_DB_TABLESPACE='foo'):\n+            _, _, args, kwargs = field.deconstruct()\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {})\n+        # With a db_tablespace.\n+        field = models.Field(db_tablespace='foo')\n+        _, _, args, kwargs = field.deconstruct()\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {'db_tablespace': 'foo'})\n+        # With a db_tablespace equal to DEFAULT_DB_TABLESPACE.\n+        with self.settings(DEFAULT_DB_TABLESPACE='foo'):\n+            _, _, args, kwargs = field.deconstruct()\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {'db_tablespace': 'foo'})\n+\n+    def test_auto_field(self):\n+        field = models.AutoField(primary_key=True)\n+        field.set_attributes_from_name(\"id\")\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.AutoField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"primary_key\": True})\n+\n+    def test_big_integer_field(self):\n+        field = models.BigIntegerField()\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.BigIntegerField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {})\n+\n+    def test_boolean_field(self):\n+        field = models.BooleanField()\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.BooleanField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {})\n+        field = models.BooleanField(default=True)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.BooleanField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"default\": True})\n+\n+    def test_char_field(self):\n+        field = models.CharField(max_length=65)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.CharField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"max_length\": 65})\n+        field = models.CharField(max_length=65, null=True, blank=True)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.CharField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"max_length\": 65, \"null\": True, \"blank\": True})\n+\n+    def test_char_field_choices(self):\n+        field = models.CharField(max_length=1, choices=((\"A\", \"One\"), (\"B\", \"Two\")))\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.CharField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"choices\": [(\"A\", \"One\"), (\"B\", \"Two\")], \"max_length\": 1})\n+\n+    def test_csi_field(self):\n+        field = models.CommaSeparatedIntegerField(max_length=100)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.CommaSeparatedIntegerField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"max_length\": 100})\n+\n+    def test_date_field(self):\n+        field = models.DateField()\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.DateField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {})\n+        field = models.DateField(auto_now=True)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.DateField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"auto_now\": True})\n+\n+    def test_datetime_field(self):\n+        field = models.DateTimeField()\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.DateTimeField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {})\n+        field = models.DateTimeField(auto_now_add=True)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.DateTimeField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"auto_now_add\": True})\n+        # Bug #21785\n+        field = models.DateTimeField(auto_now=True, auto_now_add=True)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.DateTimeField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"auto_now_add\": True, \"auto_now\": True})\n+\n+    def test_decimal_field(self):\n+        field = models.DecimalField(max_digits=5, decimal_places=2)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.DecimalField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"max_digits\": 5, \"decimal_places\": 2})\n+\n+    def test_decimal_field_0_decimal_places(self):\n+        \"\"\"\n+        A DecimalField with decimal_places=0 should work (#22272).\n+        \"\"\"\n+        field = models.DecimalField(max_digits=5, decimal_places=0)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.DecimalField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"max_digits\": 5, \"decimal_places\": 0})\n+\n+    def test_email_field(self):\n+        field = models.EmailField()\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.EmailField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"max_length\": 254})\n+        field = models.EmailField(max_length=255)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.EmailField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"max_length\": 255})\n+\n+    def test_file_field(self):\n+        field = models.FileField(upload_to=\"foo/bar\")\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.FileField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"upload_to\": \"foo/bar\"})\n+        # Test max_length\n+        field = models.FileField(upload_to=\"foo/bar\", max_length=200)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.FileField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"upload_to\": \"foo/bar\", \"max_length\": 200})\n+\n+    def test_file_path_field(self):\n+        field = models.FilePathField(match=r\".*\\.txt$\")\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.FilePathField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"match\": r\".*\\.txt$\"})\n+        field = models.FilePathField(recursive=True, allow_folders=True, max_length=123)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.FilePathField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"recursive\": True, \"allow_folders\": True, \"max_length\": 123})\n+\n+    def test_float_field(self):\n+        field = models.FloatField()\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.FloatField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {})\n+\n+    def test_foreign_key(self):\n+        # Test basic pointing\n+        from django.contrib.auth.models import Permission\n+        field = models.ForeignKey(\"auth.Permission\", models.CASCADE)\n+        field.remote_field.model = Permission\n+        field.remote_field.field_name = \"id\"\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.ForeignKey\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"auth.Permission\", \"on_delete\": models.CASCADE})\n+        self.assertFalse(hasattr(kwargs['to'], \"setting_name\"))\n+        # Test swap detection for swappable model\n+        field = models.ForeignKey(\"auth.User\", models.CASCADE)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.ForeignKey\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"auth.User\", \"on_delete\": models.CASCADE})\n+        self.assertEqual(kwargs['to'].setting_name, \"AUTH_USER_MODEL\")\n+        # Test nonexistent (for now) model\n+        field = models.ForeignKey(\"something.Else\", models.CASCADE)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.ForeignKey\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"something.Else\", \"on_delete\": models.CASCADE})\n+        # Test on_delete\n+        field = models.ForeignKey(\"auth.User\", models.SET_NULL)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.ForeignKey\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"auth.User\", \"on_delete\": models.SET_NULL})\n+        # Test to_field preservation\n+        field = models.ForeignKey(\"auth.Permission\", models.CASCADE, to_field=\"foobar\")\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.ForeignKey\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"auth.Permission\", \"to_field\": \"foobar\", \"on_delete\": models.CASCADE})\n+        # Test related_name preservation\n+        field = models.ForeignKey(\"auth.Permission\", models.CASCADE, related_name=\"foobar\")\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.ForeignKey\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"auth.Permission\", \"related_name\": \"foobar\", \"on_delete\": models.CASCADE})\n+        # Test related_query_name\n+        field = models.ForeignKey(\"auth.Permission\", models.CASCADE, related_query_name=\"foobar\")\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.ForeignKey\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(\n+            kwargs,\n+            {\"to\": \"auth.Permission\", \"related_query_name\": \"foobar\", \"on_delete\": models.CASCADE}\n+        )\n+        # Test limit_choices_to\n+        field = models.ForeignKey(\"auth.Permission\", models.CASCADE, limit_choices_to={'foo': 'bar'})\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.ForeignKey\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(\n+            kwargs,\n+            {\"to\": \"auth.Permission\", \"limit_choices_to\": {'foo': 'bar'}, \"on_delete\": models.CASCADE}\n+        )\n+        # Test unique\n+        field = models.ForeignKey(\"auth.Permission\", models.CASCADE, unique=True)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.ForeignKey\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"auth.Permission\", \"unique\": True, \"on_delete\": models.CASCADE})\n+\n+    @override_settings(AUTH_USER_MODEL=\"auth.Permission\")\n+    def test_foreign_key_swapped(self):\n+        with isolate_lru_cache(apps.get_swappable_settings_name):\n+            # It doesn't matter that we swapped out user for permission;\n+            # there's no validation. We just want to check the setting stuff works.\n+            field = models.ForeignKey(\"auth.Permission\", models.CASCADE)\n+            name, path, args, kwargs = field.deconstruct()\n+\n+        self.assertEqual(path, \"django.db.models.ForeignKey\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"auth.Permission\", \"on_delete\": models.CASCADE})\n+        self.assertEqual(kwargs['to'].setting_name, \"AUTH_USER_MODEL\")\n+\n+    def test_one_to_one(self):\n+        # Test basic pointing\n+        from django.contrib.auth.models import Permission\n+        field = models.OneToOneField(\"auth.Permission\", models.CASCADE)\n+        field.remote_field.model = Permission\n+        field.remote_field.field_name = \"id\"\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.OneToOneField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"auth.Permission\", \"on_delete\": models.CASCADE})\n+        self.assertFalse(hasattr(kwargs['to'], \"setting_name\"))\n+        # Test swap detection for swappable model\n+        field = models.OneToOneField(\"auth.User\", models.CASCADE)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.OneToOneField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"auth.User\", \"on_delete\": models.CASCADE})\n+        self.assertEqual(kwargs['to'].setting_name, \"AUTH_USER_MODEL\")\n+        # Test nonexistent (for now) model\n+        field = models.OneToOneField(\"something.Else\", models.CASCADE)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.OneToOneField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"something.Else\", \"on_delete\": models.CASCADE})\n+        # Test on_delete\n+        field = models.OneToOneField(\"auth.User\", models.SET_NULL)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.OneToOneField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"auth.User\", \"on_delete\": models.SET_NULL})\n+        # Test to_field\n+        field = models.OneToOneField(\"auth.Permission\", models.CASCADE, to_field=\"foobar\")\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.OneToOneField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"auth.Permission\", \"to_field\": \"foobar\", \"on_delete\": models.CASCADE})\n+        # Test related_name\n+        field = models.OneToOneField(\"auth.Permission\", models.CASCADE, related_name=\"foobar\")\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.OneToOneField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"auth.Permission\", \"related_name\": \"foobar\", \"on_delete\": models.CASCADE})\n+        # Test related_query_name\n+        field = models.OneToOneField(\"auth.Permission\", models.CASCADE, related_query_name=\"foobar\")\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.OneToOneField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(\n+            kwargs,\n+            {\"to\": \"auth.Permission\", \"related_query_name\": \"foobar\", \"on_delete\": models.CASCADE}\n+        )\n+        # Test limit_choices_to\n+        field = models.OneToOneField(\"auth.Permission\", models.CASCADE, limit_choices_to={'foo': 'bar'})\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.OneToOneField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(\n+            kwargs,\n+            {\"to\": \"auth.Permission\", \"limit_choices_to\": {'foo': 'bar'}, \"on_delete\": models.CASCADE}\n+        )\n+        # Test unique\n+        field = models.OneToOneField(\"auth.Permission\", models.CASCADE, unique=True)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.OneToOneField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"auth.Permission\", \"on_delete\": models.CASCADE})\n+\n+    def test_image_field(self):\n+        field = models.ImageField(upload_to=\"foo/barness\", width_field=\"width\", height_field=\"height\")\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.ImageField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"upload_to\": \"foo/barness\", \"width_field\": \"width\", \"height_field\": \"height\"})\n+\n+    def test_integer_field(self):\n+        field = models.IntegerField()\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.IntegerField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {})\n+\n+    def test_ip_address_field(self):\n+        field = models.IPAddressField()\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.IPAddressField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {})\n+\n+    def test_generic_ip_address_field(self):\n+        field = models.GenericIPAddressField()\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.GenericIPAddressField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {})\n+        field = models.GenericIPAddressField(protocol=\"IPv6\")\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.GenericIPAddressField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"protocol\": \"IPv6\"})\n+\n+    def test_many_to_many_field(self):\n+        # Test normal\n+        field = models.ManyToManyField(\"auth.Permission\")\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.ManyToManyField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"auth.Permission\"})\n+        self.assertFalse(hasattr(kwargs['to'], \"setting_name\"))\n+        # Test swappable\n+        field = models.ManyToManyField(\"auth.User\")\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.ManyToManyField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"auth.User\"})\n+        self.assertEqual(kwargs['to'].setting_name, \"AUTH_USER_MODEL\")\n+        # Test through\n+        field = models.ManyToManyField(\"auth.Permission\", through=\"auth.Group\")\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.ManyToManyField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"auth.Permission\", \"through\": \"auth.Group\"})\n+        # Test custom db_table\n+        field = models.ManyToManyField(\"auth.Permission\", db_table=\"custom_table\")\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.ManyToManyField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"auth.Permission\", \"db_table\": \"custom_table\"})\n+        # Test related_name\n+        field = models.ManyToManyField(\"auth.Permission\", related_name=\"custom_table\")\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.ManyToManyField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"auth.Permission\", \"related_name\": \"custom_table\"})\n+        # Test related_query_name\n+        field = models.ManyToManyField(\"auth.Permission\", related_query_name=\"foobar\")\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.ManyToManyField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"auth.Permission\", \"related_query_name\": \"foobar\"})\n+        # Test limit_choices_to\n+        field = models.ManyToManyField(\"auth.Permission\", limit_choices_to={'foo': 'bar'})\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.ManyToManyField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"auth.Permission\", \"limit_choices_to\": {'foo': 'bar'}})\n+\n+    @override_settings(AUTH_USER_MODEL=\"auth.Permission\")\n+    def test_many_to_many_field_swapped(self):\n+        with isolate_lru_cache(apps.get_swappable_settings_name):\n+            # It doesn't matter that we swapped out user for permission;\n+            # there's no validation. We just want to check the setting stuff works.\n+            field = models.ManyToManyField(\"auth.Permission\")\n+            name, path, args, kwargs = field.deconstruct()\n+\n+        self.assertEqual(path, \"django.db.models.ManyToManyField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"to\": \"auth.Permission\"})\n+        self.assertEqual(kwargs['to'].setting_name, \"AUTH_USER_MODEL\")\n+\n+    def test_null_boolean_field(self):\n+        field = models.NullBooleanField()\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.NullBooleanField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {})\n+\n+    def test_positive_integer_field(self):\n+        field = models.PositiveIntegerField()\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.PositiveIntegerField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {})\n+\n+    def test_positive_small_integer_field(self):\n+        field = models.PositiveSmallIntegerField()\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.PositiveSmallIntegerField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {})\n+\n+    def test_positive_big_integer_field(self):\n+        field = models.PositiveBigIntegerField()\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, 'django.db.models.PositiveBigIntegerField')\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {})\n+\n+    def test_slug_field(self):\n+        field = models.SlugField()\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.SlugField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {})\n+        field = models.SlugField(db_index=False, max_length=231)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.SlugField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\"db_index\": False, \"max_length\": 231})\n+\n+    def test_small_integer_field(self):\n+        field = models.SmallIntegerField()\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.SmallIntegerField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {})\n+\n+    def test_text_field(self):\n+        field = models.TextField()\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.TextField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {})\n+\n+    def test_time_field(self):\n+        field = models.TimeField()\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.TimeField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {})\n+\n+        field = models.TimeField(auto_now=True)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {'auto_now': True})\n"
    },
    "django__django-14608": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/forms_tests/tests/test_formset_non_form_errors.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py forms_tests.tests.test_formset_non_form_errors"
        ],
        "reproduced_bug_patch": "diff --git a/tests/forms_tests/tests/test_formset_non_form_errors.py b/tests/forms_tests/tests/test_formset_non_form_errors.py\nnew file mode 100644\nindex 0000000000..a656ca94e7\n--- /dev/null\n+++ b/tests/forms_tests/tests/test_formset_non_form_errors.py\n@@ -0,0 +1,45 @@\n+from django.core.exceptions import ValidationError\n+from django.forms import (\n+    CharField,\n+    Form,\n+)\n+from django.forms.formsets import BaseFormSet, formset_factory\n+from django.test import SimpleTestCase\n+\n+\n+class FavoriteDrinkForm(Form):\n+    name = CharField()\n+\n+\n+class BaseFavoriteDrinksFormSet(BaseFormSet):\n+    def clean(self):\n+        seen_drinks = []\n+        for drink in self.cleaned_data:\n+            if drink.get(\"name\") in seen_drinks:\n+                raise ValidationError(\"You may only specify a drink once.\")\n+            if drink.get(\"name\"):\n+                seen_drinks.append(drink.get(\"name\"))\n+\n+\n+FavoriteDrinksFormSet = formset_factory(\n+    FavoriteDrinkForm, formset=BaseFavoriteDrinksFormSet, extra=2\n+)\n+\n+\n+class FormsetNonFormErrorTest(SimpleTestCase):\n+    def test_non_form_errors_have_nonform_class(self):\n+        \"\"\"\n+        Formset non-form errors should be rendered with a 'nonform' CSS class.\n+        \"\"\"\n+        data = {\n+            \"form-TOTAL_FORMS\": \"2\",\n+            \"form-INITIAL_FORMS\": \"0\",\n+            \"form-0-name\": \"Gin\",\n+            \"form-1-name\": \"Gin\",  # Duplicate\n+        }\n+        formset = FavoriteDrinksFormSet(data, prefix=\"form\")\n+        self.assertFalse(formset.is_valid())\n+        self.assertHTMLEqual(\n+            formset.non_form_errors().as_ul(),\n+            '<ul class=\"errorlist nonform\"><li>You may only specify a drink once.</li></ul>',\n+        )\n"
    },
    "django__django-16595": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/migrations/test_optimizer_bug.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py migrations.test_optimizer_bug"
        ],
        "reproduced_bug_patch": "diff --git a/tests/migrations/test_optimizer_bug.py b/tests/migrations/test_optimizer_bug.py\nnew file mode 100644\nindex 0000000000..add231a07f\n--- /dev/null\n+++ b/tests/migrations/test_optimizer_bug.py\n@@ -0,0 +1,80 @@\n+from django.db import migrations, models\n+from django.db.migrations.optimizer import MigrationOptimizer\n+from django.db.migrations.serializer import serializer_factory\n+from django.test import SimpleTestCase\n+\n+from .models import EmptyManager, UnicodeModel\n+\n+\n+class OptimizerTests(SimpleTestCase):\n+    \"\"\"\n+    Tests the migration optimizer.\n+    \"\"\"\n+\n+    def optimize(self, operations, app_label):\n+        \"\"\"\n+        Handy shortcut for getting results + number of loops\n+        \"\"\"\n+        optimizer = MigrationOptimizer()\n+        return optimizer.optimize(operations, app_label), optimizer._iterations\n+\n+    def serialize(self, value):\n+        return serializer_factory(value).serialize()[0]\n+\n+    def assertOptimizesTo(\n+        self, operations, expected, exact=None, less_than=None, app_label=None\n+    ):\n+        result, iterations = self.optimize(operations, app_label or \"migrations\")\n+        result = [self.serialize(f) for f in result]\n+        expected = [self.serialize(f) for f in expected]\n+        self.assertEqual(expected, result)\n+        if exact is not None and iterations != exact:\n+            raise self.failureException(\n+                \"Optimization did not take exactly %s iterations (it took %s)\"\n+                % (exact, iterations)\n+            )\n+        if less_than is not None and iterations >= less_than:\n+            raise self.failureException(\n+                \"Optimization did not take less than %s iterations (it took %s)\"\n+                % (less_than, iterations)\n+            )\n+\n+    def assertDoesNotOptimize(self, operations, **kwargs):\n+        self.assertOptimizesTo(operations, operations, **kwargs)\n+\n+    def test_multiple_alter_field(self):\n+        \"\"\"\n+        Multiple AlterField operations on the same field should be optimized\n+        into a single, final AlterField.\n+        \"\"\"\n+        self.assertOptimizesTo(\n+            [\n+                migrations.AlterField(\n+                    model_name=\"book\",\n+                    name=\"title\",\n+                    field=models.CharField(max_length=128, null=True),\n+                ),\n+                migrations.AlterField(\n+                    model_name=\"book\",\n+                    name=\"title\",\n+                    field=models.CharField(max_length=128, null=True, help_text=\"help\"),\n+                ),\n+                migrations.AlterField(\n+                    model_name=\"book\",\n+                    name=\"title\",\n+                    field=models.CharField(\n+                        max_length=128, null=True, help_text=\"help\", default=None\n+                    ),\n+                ),\n+            ],\n+            [\n+                migrations.AlterField(\n+                    model_name=\"book\",\n+                    name=\"title\",\n+                    field=models.CharField(\n+                        max_length=128, null=True, help_text=\"help\", default=None\n+                    ),\n+                ),\n+            ],\n+            app_label=\"books\",\n+        )\n"
    },
    "scikit-learn__scikit-learn-13328": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/linear_model/tests/test_huber_regressor_boolean_input.py",
        "reproduced_bug_commands": [
            "pytest sklearn/linear_model/tests/test_huber_regressor_boolean_input.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/linear_model/tests/test_huber_regressor_boolean_input.py b/sklearn/linear_model/tests/test_huber_regressor_boolean_input.py\nnew file mode 100644\nindex 0000000000..99d719e35e\n--- /dev/null\n+++ b/sklearn/linear_model/tests/test_huber_regressor_boolean_input.py\n@@ -0,0 +1,26 @@\n+import numpy as np\n+import pytest\n+\n+from sklearn.datasets import make_regression\n+from sklearn.linear_model import HuberRegressor\n+\n+\n+def test_huber_regressor_handles_boolean_input():\n+    \"\"\"\n+    Test that HuberRegressor can be fitted on boolean data without raising a TypeError.\n+    This is a non-regression test for the bug described in the issue, where\n+    fitting with a boolean `X` array caused a TypeError.\n+    \"\"\"\n+    # As described in the issue, generate data and a boolean version of it.\n+    X, y, _ = make_regression(\n+        n_samples=200, n_features=2, noise=4.0, coef=True, random_state=0\n+    )\n+    X_bool = X > 0\n+\n+    # The following line is expected to fail with a TypeError before the fix.\n+    # After the fix, it should run without raising an exception.\n+    huber = HuberRegressor().fit(X_bool, y)\n+\n+    # Minimal assertion: check that the model has been fitted by verifying\n+    # the existence of the `coef_` attribute.\n+    assert hasattr(huber, \"coef_\")\n"
    },
    "sympy__sympy-15345": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/printing/tests/test_mathematica_2.py",
        "reproduced_bug_commands": [
            "pytest sympy/printing/tests/test_mathematica_2.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/printing/tests/test_mathematica_2.py b/sympy/printing/tests/test_mathematica_2.py\nnew file mode 100644\nindex 0000000000..3a868ff0ff\n--- /dev/null\n+++ b/sympy/printing/tests/test_mathematica_2.py\n@@ -0,0 +1,8 @@\n+from sympy.core import symbols\n+from sympy.functions import Max\n+from sympy import mathematica_code as mcode\n+\n+\n+def test_Max():\n+    x = symbols('x')\n+    assert mcode(Max(x, 2)) == 'Max[x, 2]'\n"
    },
    "django__django-12143": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "django__django-14631": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/forms_tests/tests/test_initial.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py forms_tests.tests.test_initial"
        ],
        "reproduced_bug_patch": "diff --git a/tests/forms_tests/tests/test_initial.py b/tests/forms_tests/tests/test_initial.py\nnew file mode 100644\nindex 0000000000..1f71bb94c7\n--- /dev/null\n+++ b/tests/forms_tests/tests/test_initial.py\n@@ -0,0 +1,20 @@\n+import datetime\n+\n+from django.forms import DateTimeField, Form\n+from django.test import SimpleTestCase\n+\n+\n+class CleanFieldsInitialTests(SimpleTestCase):\n+    def test_datetime_clean_initial_callable_disabled(self):\n+        \"\"\"\n+        form.cleaned_data[name] should be equal to form[name].initial for a\n+        disabled field with a callable initial value.\n+        \"\"\"\n+        initial_dt = lambda: datetime.datetime(2022, 1, 1, 12, 0, 0, 123)\n+\n+        class DateTimeForm(Form):\n+            dt = DateTimeField(initial=initial_dt, disabled=True)\n+\n+        form = DateTimeForm({})\n+        form.full_clean()\n+        self.assertEqual(form.cleaned_data[\"dt\"], form[\"dt\"].initial)\n"
    },
    "django__django-16612": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/admin_views/test_catchall_view.py",
        "reproduced_bug_commands": [
            "./tests/runtests.py admin_views.test_catchall_view"
        ],
        "reproduced_bug_patch": "diff --git a/tests/admin_views/test_catchall_view.py b/tests/admin_views/test_catchall_view.py\nnew file mode 100644\nindex 0000000000..0407c45a93\n--- /dev/null\n+++ b/tests/admin_views/test_catchall_view.py\n@@ -0,0 +1,38 @@\n+from django.contrib.auth.models import User\n+from django.test import TestCase, override_settings\n+from django.urls import reverse\n+\n+\n+@override_settings(ROOT_URLCONF=\"admin_views.urls\")\n+class AdminSiteFinalCatchAllPatternTests(TestCase):\n+    \"\"\"\n+    Verifies the behaviour of the admin catch-all view.\n+    \"\"\"\n+\n+    @override_settings(APPEND_SLASH=True)\n+    def test_redirect_for_missing_slash_preserves_query_string(self):\n+        \"\"\"\n+        The catch-all view should preserve the query string when redirecting\n+        to append a slash.\n+        \"\"\"\n+        superuser = User.objects.create_superuser(\n+            \"super\", \"super@example.com\", \"secret\"\n+        )\n+        self.client.force_login(superuser)\n+\n+        # The example from the bug report is /admin/auth/foo?id=123. 'foo' is not a\n+        # real model, so we use 'user' which is. The catch_all_view only\n+        # redirects if the URL with a slash resolves.\n+        url_with_slash = reverse(\"admin:auth_user_changelist\")\n+        url_without_slash = url_with_slash[:-1]\n+\n+        url_to_test = f\"{url_without_slash}?id=123\"\n+        expected_redirect_url = f\"{url_with_slash}?id=123\"\n+\n+        response = self.client.get(url_to_test)\n+        self.assertRedirects(\n+            response,\n+            expected_redirect_url,\n+            status_code=301,\n+            target_status_code=200,\n+        )\n"
    },
    "scikit-learn__scikit-learn-13439": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/tests/test_pipeline_len.py",
        "reproduced_bug_commands": [
            "pytest sklearn/tests/test_pipeline_len.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/tests/test_pipeline_len.py b/sklearn/tests/test_pipeline_len.py\nnew file mode 100644\nindex 0000000000..8b35ad60f9\n--- /dev/null\n+++ b/sklearn/tests/test_pipeline_len.py\n@@ -0,0 +1,11 @@\n+from sklearn.svm import SVC\n+from sklearn.feature_selection import SelectKBest, f_regression\n+from sklearn.pipeline import Pipeline\n+\n+\n+def test_pipeline_len():\n+    \"\"\"Test that pipeline implements __len__.\"\"\"\n+    anova_filter = SelectKBest(f_regression, k=5)\n+    clf = SVC(kernel='linear')\n+    pipe = Pipeline([('anova', anova_filter), ('svc', clf)])\n+    assert len(pipe) == 2\n"
    },
    "sympy__sympy-15349": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/algebras/tests/test_rotation.py",
        "reproduced_bug_commands": [
            "pytest sympy/algebras/tests/test_rotation.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/algebras/tests/test_rotation.py b/sympy/algebras/tests/test_rotation.py\nnew file mode 100644\nindex 0000000000..df1e0a45f8\n--- /dev/null\n+++ b/sympy/algebras/tests/test_rotation.py\n@@ -0,0 +1,19 @@\n+from sympy.algebras.quaternion import Quaternion\n+from sympy import symbols, re, im, Add, Mul, I, Abs\n+from sympy import cos, sin, sqrt, conjugate, exp, log, acos, E, pi\n+from sympy.utilities.pytest import raises\n+from sympy import Matrix\n+from sympy import diff, integrate, trigsimp\n+from sympy import S, Rational\n+\n+def test_to_rotation_matrix_x_axis():\n+    \"\"\"Test for issue with x-axis rotation in to_rotation_matrix.\"\"\"\n+    x = symbols('x')\n+    q = Quaternion(cos(x/2), sin(x/2), 0, 0)\n+    # This is the corrected matrix. The original implementation returned a matrix\n+    # with sin(x) in position (1, 2) instead of -sin(x).\n+    expected_matrix = Matrix([\n+        [1,      0,       0],\n+        [0, cos(x), -sin(x)],\n+        [0, sin(x),  cos(x)]])\n+    assert trigsimp(q.to_rotation_matrix()) == expected_matrix\n"
    },
    "django__django-12155": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/admin_docs/test_trim_docstring.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py admin_docs.test_trim_docstring"
        ],
        "reproduced_bug_patch": "diff --git a/tests/admin_docs/test_trim_docstring.py b/tests/admin_docs/test_trim_docstring.py\nnew file mode 100644\nindex 0000000000..03154a1149\n--- /dev/null\n+++ b/tests/admin_docs/test_trim_docstring.py\n@@ -0,0 +1,19 @@\n+import unittest\n+\n+from django.contrib.admindocs.utils import (\n+    docutils_is_available, trim_docstring,\n+)\n+from django.test import SimpleTestCase\n+\n+\n+@unittest.skipUnless(docutils_is_available, \"no docutils installed.\")\n+class TrimDocstringTests(SimpleTestCase):\n+\n+    def test_trim_docstring_first_line_not_empty(self):\n+        \"\"\"\n+        trim_docstring() correctly handles docstrings where the first line of\n+        content has no preceding newline.\n+        \"\"\"\n+        docstring = \"First line summary.\\n\\n    Second line body.\"\n+        expected = \"First line summary.\\n\\nSecond line body.\"\n+        self.assertEqual(trim_docstring(docstring), expected)\n"
    },
    "django__django-14672": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/proxy_models/test_checks.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py proxy_models.test_checks"
        ],
        "reproduced_bug_patch": "diff --git a/tests/proxy_models/test_checks.py b/tests/proxy_models/test_checks.py\nnew file mode 100644\nindex 0000000000..9ce9fdad1e\n--- /dev/null\n+++ b/tests/proxy_models/test_checks.py\n@@ -0,0 +1,50 @@\n+from django.core import checks\n+from django.db import models\n+from django.test import SimpleTestCase\n+from django.test.utils import isolate_apps\n+\n+\n+class M2MProxyCheckTests(SimpleTestCase):\n+    @isolate_apps(\"proxy_models\")\n+    def test_m2m_through_fields_hashable(self):\n+        \"\"\"\n+        Check that ManyToManyRel.through_fields is made hashable for proxy\n+        model checks (#32765).\n+        \"\"\"\n+\n+        class Parent(models.Model):\n+            name = models.CharField(max_length=256)\n+\n+            class Meta:\n+                app_label = \"proxy_models\"\n+\n+        class ProxyParent(Parent):\n+            class Meta:\n+                proxy = True\n+                app_label = \"proxy_models\"\n+\n+        class Child(models.Model):\n+            parent = models.ForeignKey(Parent, on_delete=models.CASCADE)\n+            many_to_many_field = models.ManyToManyField(\n+                to=Parent,\n+                through=\"ManyToManyModel\",\n+                through_fields=[\"child\", \"parent\"],\n+                related_name=\"something\",\n+            )\n+\n+            class Meta:\n+                app_label = \"proxy_models\"\n+\n+        class ManyToManyModel(models.Model):\n+            parent = models.ForeignKey(\n+                Parent, on_delete=models.CASCADE, related_name=\"+\"\n+            )\n+            child = models.ForeignKey(Child, on_delete=models.CASCADE, related_name=\"+\")\n+            second_child = models.ForeignKey(\n+                Child, on_delete=models.CASCADE, null=True, default=None\n+            )\n+\n+            class Meta:\n+                app_label = \"proxy_models\"\n+\n+        self.assertEqual(ProxyParent.check(), [])\n"
    },
    "django__django-16631": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/auth_tests/test_session_authentication.py",
        "reproduced_bug_commands": [
            "cat <<'EOF' > my_settings.py\nSECRET_KEY = 'a-secret-key'\nDATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.sqlite3',\n        'NAME': ':memory:',\n    }\n}\nINSTALLED_APPS = [\n    'django.contrib.contenttypes',\n    'django.contrib.auth',\n    'django.contrib.sites',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.admin',\n    'django.contrib.staticfiles',\n    'auth_tests',\n]\nROOT_URLCONF = 'my_urls'\nSTATIC_URL = '/static/'\nMIGRATION_MODULES = {\n    'auth': None,\n    'contenttypes': None,\n    'sessions': None,\n    'auth_tests': None,\n}\nTEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'django.template.context_processors.request',\n                'django.contrib.auth.context_processors.auth',\n                'django.contrib.messages.context_processors.messages',\n            ],\n        },\n    },\n]\nMIDDLEWARE = [\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n]\nSITE_ID = 1\nEOF",
            "cat <<'EOF' > my_urls.py\nfrom django.contrib import admin\nfrom django.urls import path, include\n\nurlpatterns = [\n    path('admin/', admin.site.urls),\n]\nEOF",
            "PYTHONPATH=tests python -m django test --settings=my_settings auth_tests.test_session_authentication"
        ],
        "reproduced_bug_patch": "diff --git a/tests/auth_tests/test_session_authentication.py b/tests/auth_tests/test_session_authentication.py\nnew file mode 100644\nindex 0000000000..22ce967220\n--- /dev/null\n+++ b/tests/auth_tests/test_session_authentication.py\n@@ -0,0 +1,45 @@\n+from django.contrib.auth import SESSION_KEY\n+from django.contrib.auth.models import User\n+from django.test import TestCase, override_settings\n+from django.urls import reverse\n+\n+\n+class SessionAuthenticationTest(TestCase):\n+    \"\"\"\n+    Tests for session authentication with SECRET_KEY rotation.\n+    \"\"\"\n+\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.username = \"testuser\"\n+        cls.password = \"testpass\"\n+        # is_staff=True is required to access the admin index.\n+        cls.user = User.objects.create_user(\n+            username=cls.username,\n+            password=cls.password,\n+            is_staff=True,\n+        )\n+\n+    @override_settings(SECRET_KEY=\"old-secret\")\n+    def test_secret_key_fallback_is_used_for_session(self):\n+        \"\"\"\n+        Tests that SECRET_KEY_FALLBACKS is used for session authentication,\n+        allowing users to stay logged in after a key rotation.\n+        \"\"\"\n+        # Log in with the old secret key.\n+        self.client.login(username=self.username, password=self.password)\n+        # Sanity check that the user is logged in.\n+        self.assertEqual(self.client.session[SESSION_KEY], str(self.user.pk))\n+\n+        # After key rotation, the session should still be valid by using the\n+        # fallback key.\n+        with override_settings(\n+            SECRET_KEY=\"new-secret\",\n+            SECRET_KEY_FALLBACKS=[\"old-secret\"],\n+        ):\n+            # A request to a view that accesses request.user will trigger the\n+            # session auth hash check.\n+            response = self.client.get(reverse(\"admin:index\"), follow=True)\n+            # This assertion fails because the session hash isn't validated\n+            # against the fallback keys, logging the user out.\n+            self.assertTrue(response.context[\"user\"].is_authenticated)\n"
    },
    "scikit-learn__scikit-learn-13496": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/ensemble/tests/test_warm_start.py",
        "reproduced_bug_commands": [
            "pytest sklearn/ensemble/tests/test_warm_start.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/ensemble/tests/test_warm_start.py b/sklearn/ensemble/tests/test_warm_start.py\nnew file mode 100644\nindex 0000000000..cf79fd39f9\n--- /dev/null\n+++ b/sklearn/ensemble/tests/test_warm_start.py\n@@ -0,0 +1,25 @@\n+import pytest\n+from sklearn.datasets import make_hastie_10_2\n+from sklearn.ensemble import IsolationForest\n+from sklearn.utils._testing import assert_array_equal\n+\n+\n+def test_isolation_forest_warm_start():\n+    \"\"\"Test warm-start for IsolationForest.\n+\n+    A TypeError should be raised because warm_start is not in __init__.\n+    When the parameter is exposed, this test should pass.\n+    \"\"\"\n+    X, y = make_hastie_10_2(random_state=0)\n+\n+    clf_warm = IsolationForest(n_estimators=5, warm_start=True, random_state=42)\n+    clf_warm.fit(X, y)\n+\n+    clf_warm.set_params(n_estimators=10)\n+    clf_warm.fit(X, y)\n+\n+    clf_cold = IsolationForest(n_estimators=10, warm_start=False, random_state=42)\n+    clf_cold.fit(X, y)\n+\n+    # The two forests should be identical.\n+    assert_array_equal(clf_warm.apply(X), clf_cold.apply(X))\n"
    },
    "sympy__sympy-15599": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/core/tests/test_mod.py",
        "reproduced_bug_commands": [
            "python -m pytest sympy/core/tests/test_mod.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/core/tests/test_mod.py b/sympy/core/tests/test_mod.py\nnew file mode 100644\nindex 0000000000..4651b2af66\n--- /dev/null\n+++ b/sympy/core/tests/test_mod.py\n@@ -0,0 +1,9 @@\n+from sympy import Mod, Symbol\n+\n+\n+def test_mod_integer_coefficient_simplification():\n+    \"\"\"\n+    Test for https://github.com/sympy/sympy/issues/15493\n+    \"\"\"\n+    i = Symbol('i', integer=True)\n+    assert Mod(3*i, 2) == Mod(i, 2)\n"
    },
    "django__django-12193": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/postgres_tests/test_forms.py",
        "reproduced_bug_commands": [
            "tests/runtests.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/postgres_tests/test_forms.py b/tests/postgres_tests/test_forms.py\nnew file mode 100644\nindex 0000000000..be02e40e2f\n--- /dev/null\n+++ b/tests/postgres_tests/test_forms.py\n@@ -0,0 +1,43 @@\n+import unittest\n+from django import forms\n+from django.test import SimpleTestCase\n+\n+try:\n+    from django.contrib.postgres.forms import SplitArrayField\n+except ImportError:\n+    # If psycopg2 is not installed, this test will be skipped.\n+    SplitArrayField = None\n+\n+\n+# In the Django test suite, this would be `from . import PostgreSQLWidgetTestCase`.\n+# For a self-contained example, SimpleTestCase is sufficient as no DB is needed.\n+class PostgreSQLWidgetTestCase(SimpleTestCase):\n+    pass\n+\n+\n+@unittest.skipIf(SplitArrayField is None, 'psycopg2 is not installed')\n+class TestSplitArrayFieldWidget(PostgreSQLWidgetTestCase):\n+    def test_boolean_field_attrs_mutation(self):\n+        \"\"\"\n+        SplitArrayField with a BooleanField should not have its attributes\n+        mutated by the CheckboxInput widget when preparing the context.\n+        \"\"\"\n+        class ArrayForm(forms.Form):\n+            field = SplitArrayField(forms.BooleanField(required=False), size=2)\n+\n+        form = ArrayForm(initial={'field': [True, False]})\n+        widget = form.fields['field'].widget\n+\n+        # Get the context data that would be passed to the template.\n+        # This avoids the TemplateDoesNotExist error by not rendering the template.\n+        context = widget.get_context(name='field', value=[True, False], attrs=None)\n+\n+        # The context for subwidgets is where the mutated 'checked' attribute appears.\n+        subwidgets_context = context['widget']['subwidgets']\n+\n+        # The bug is that CheckboxInput.get_context() modifies the attrs\n+        # dict. SplitArrayWidget reuses this dict, so after the first True\n+        # value, 'checked' is present for all subsequent subwidgets.\n+        # This assertion will fail because 'checked' will be in the attrs\n+        # for the second widget, which corresponds to the 'False' value.\n+        self.assertNotIn('checked', subwidgets_context[1]['attrs'])\n"
    },
    "django__django-14725": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/model_formsets/test_disallow_new_object_creation.py",
        "reproduced_bug_commands": [
            "PYTHONPATH=tests python tests/runtests.py model_formsets.test_disallow_new_object_creation"
        ],
        "reproduced_bug_patch": "diff --git a/tests/model_formsets/test_disallow_new_object_creation.py b/tests/model_formsets/test_disallow_new_object_creation.py\nnew file mode 100644\nindex 0000000000..883f89648f\n--- /dev/null\n+++ b/tests/model_formsets/test_disallow_new_object_creation.py\n@@ -0,0 +1,30 @@\n+from django.forms.models import modelformset_factory\n+from django.test import TestCase\n+\n+from .models import Author\n+\n+\n+class ModelFormsetTests(TestCase):\n+    def test_modelformset_disallow_new_object_creation(self):\n+        \"\"\"\n+        A model formset can be configured to be \"edit only\" by using\n+        extra=0 and validate_max=True. This should prevent new objects from\n+        being created when a user adds extra forms via client-side code.\n+        \"\"\"\n+        author = Author.objects.create(name='Charles Baudelaire')\n+        AuthorFormSet = modelformset_factory(\n+            Author, fields=('name',), extra=0, validate_max=True\n+        )\n+        # This data simulates a user submitting an extra form to add a new\n+        # author, which should not be allowed.\n+        data = {\n+            'form-TOTAL_FORMS': '2',\n+            'form-INITIAL_FORMS': '1',\n+            'form-MAX_NUM_FORMS': '',\n+            'form-0-id': str(author.pk),\n+            'form-0-name': 'Charles Baudelaire',\n+            'form-1-name': 'Paul Verlaine',\n+        }\n+        formset = AuthorFormSet(data, queryset=Author.objects.all())\n+        self.assertFalse(formset.is_valid())\n+        self.assertEqual(formset.non_form_errors(), ['Please submit at most 1 form.'])\n"
    },
    "matplotlib__matplotlib-20488": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_colors_lognorm.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_colors_lognorm.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_colors_lognorm.py b/lib/matplotlib/tests/test_colors_lognorm.py\nnew file mode 100644\nindex 0000000000..2dd122e5e9\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_colors_lognorm.py\n@@ -0,0 +1,22 @@\n+import numpy as np\n+import pytest\n+\n+from matplotlib import pyplot as plt\n+from matplotlib import colors\n+\n+\n+def test_huge_range_log_draw():\n+    \"\"\"\n+    Test that drawing an image with LogNorm and a huge range does not error.\n+\n+    This is a regression test for an intermittent bug that caused ``LogNorm``\n+    to fail with ``ValueError: Invalid vmin or vmax``, particularly in CI.\n+    The test simply needs to complete a draw without raising an exception.\n+    \"\"\"\n+    fig, ax = plt.subplots()\n+    data = np.full((5, 5), -1, dtype=np.float64)\n+    data[0:2, :] = 1E20\n+    ax.imshow(data, norm=colors.LogNorm(vmin=100, vmax=data.max()))\n+    fig.canvas.draw()\n+    # No explicit assertion needed. The test fails if draw() raises an\n+    # exception, and passes if it completes without error.\n"
    },
    "scikit-learn__scikit-learn-13779": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/ensemble/tests/test_voting_none_estimator.py",
        "reproduced_bug_commands": [
            "pytest sklearn/ensemble/tests/test_voting_none_estimator.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/ensemble/tests/test_voting_none_estimator.py b/sklearn/ensemble/tests/test_voting_none_estimator.py\nnew file mode 100644\nindex 0000000000..85439cea67\n--- /dev/null\n+++ b/sklearn/ensemble/tests/test_voting_none_estimator.py\n@@ -0,0 +1,42 @@\n+import pytest\n+import numpy as np\n+\n+from sklearn.utils.testing import assert_almost_equal, assert_array_equal\n+from sklearn.utils.testing import assert_array_almost_equal\n+from sklearn.utils.testing import assert_equal\n+from sklearn.utils.testing import assert_raise_message\n+from sklearn.exceptions import NotFittedError\n+from sklearn.linear_model import LogisticRegression\n+from sklearn.naive_bayes import GaussianNB\n+from sklearn.ensemble import RandomForestClassifier\n+from sklearn.ensemble import VotingClassifier, VotingRegressor\n+from sklearn.model_selection import GridSearchCV\n+from sklearn import datasets\n+from sklearn.model_selection import cross_val_score, train_test_split\n+from sklearn.datasets import make_multilabel_classification\n+from sklearn.svm import SVC\n+from sklearn.multiclass import OneVsRestClassifier\n+from sklearn.neighbors import KNeighborsClassifier\n+from sklearn.base import BaseEstimator, ClassifierMixin\n+from sklearn.dummy import DummyRegressor\n+\n+\n+# Load datasets\n+iris = datasets.load_iris()\n+X, y = iris.data[:, 1:3], iris.target\n+\n+\n+def test_fit_with_sample_weight_and_none_estimator():\n+    \"\"\"Check that fit with sample_weight works with an estimator set to None.\"\"\"\n+    X, y = datasets.load_iris(return_X_y=True)\n+    voter = VotingClassifier(\n+        estimators=[('lr', LogisticRegression()),\n+                    ('rf', RandomForestClassifier())]\n+    )\n+    voter.set_params(lr=None)\n+    # This call fails with \"AttributeError: 'NoneType' object has no\n+    # attribute 'fit'\" when the bug is present.\n+    voter.fit(X, y, sample_weight=np.ones(y.shape))\n+\n+    # When the bug is fixed, `fit` will succeed and this assertion will pass.\n+    assert len(voter.estimators_) == 1\n"
    },
    "sympy__sympy-15809": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/functions/elementary/tests/test_empty_min_max.py",
        "reproduced_bug_commands": [
            "pytest sympy/functions/elementary/tests/test_empty_min_max.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/functions/elementary/tests/test_empty_min_max.py b/sympy/functions/elementary/tests/test_empty_min_max.py\nnew file mode 100644\nindex 0000000000..c56b074353\n--- /dev/null\n+++ b/sympy/functions/elementary/tests/test_empty_min_max.py\n@@ -0,0 +1,10 @@\n+from sympy.core.numbers import oo\n+from sympy.functions.elementary.miscellaneous import Min, Max\n+\n+\n+def test_empty_min_max():\n+    \"\"\"\n+    Test that Min() and Max() on an empty set return oo and -oo, respectively.\n+    \"\"\"\n+    assert Min() == oo\n+    assert Max() == -oo\n"
    },
    "django__django-12209": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/model_fields/test_uuid_pk.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py model_fields.test_uuid_pk"
        ],
        "reproduced_bug_patch": "diff --git a/tests/model_fields/test_uuid_pk.py b/tests/model_fields/test_uuid_pk.py\nnew file mode 100644\nindex 0000000000..46863eea6d\n--- /dev/null\n+++ b/tests/model_fields/test_uuid_pk.py\n@@ -0,0 +1,85 @@\n+import uuid\n+\n+from django.db import IntegrityError\n+from django.test import TestCase, TransactionTestCase, skipUnlessDBFeature\n+\n+from .models import (\n+    PrimaryKeyUUIDModel, RelatedToUUIDModel, UUIDChild, UUIDGrandchild,\n+)\n+\n+\n+class TestAsPrimaryKey(TestCase):\n+    def test_creation(self):\n+        PrimaryKeyUUIDModel.objects.create()\n+        loaded = PrimaryKeyUUIDModel.objects.get()\n+        self.assertIsInstance(loaded.pk, uuid.UUID)\n+\n+    def test_uuid_pk_on_save(self):\n+        saved = PrimaryKeyUUIDModel.objects.create(id=None)\n+        loaded = PrimaryKeyUUIDModel.objects.get()\n+        self.assertIsNotNone(loaded.id, None)\n+        self.assertEqual(loaded.id, saved.id)\n+\n+    def test_uuid_pk_on_bulk_create(self):\n+        u1 = PrimaryKeyUUIDModel()\n+        u2 = PrimaryKeyUUIDModel(id=None)\n+        PrimaryKeyUUIDModel.objects.bulk_create([u1, u2])\n+        # The two objects were correctly created.\n+        u1_found = PrimaryKeyUUIDModel.objects.filter(id=u1.id).exists()\n+        u2_found = PrimaryKeyUUIDModel.objects.exclude(id=u1.id).exists()\n+        self.assertTrue(u1_found)\n+        self.assertTrue(u2_found)\n+        self.assertEqual(PrimaryKeyUUIDModel.objects.count(), 2)\n+\n+    def test_underlying_field(self):\n+        pk_model = PrimaryKeyUUIDModel.objects.create()\n+        RelatedToUUIDModel.objects.create(uuid_fk=pk_model)\n+        related = RelatedToUUIDModel.objects.get()\n+        self.assertEqual(related.uuid_fk.pk, related.uuid_fk_id)\n+\n+    def test_update_with_related_model_instance(self):\n+        # regression for #24611\n+        u1 = PrimaryKeyUUIDModel.objects.create()\n+        u2 = PrimaryKeyUUIDModel.objects.create()\n+        r = RelatedToUUIDModel.objects.create(uuid_fk=u1)\n+        RelatedToUUIDModel.objects.update(uuid_fk=u2)\n+        r.refresh_from_db()\n+        self.assertEqual(r.uuid_fk, u2)\n+\n+    def test_update_with_related_model_id(self):\n+        u1 = PrimaryKeyUUIDModel.objects.create()\n+        u2 = PrimaryKeyUUIDModel.objects.create()\n+        r = RelatedToUUIDModel.objects.create(uuid_fk=u1)\n+        RelatedToUUIDModel.objects.update(uuid_fk=u2.pk)\n+        r.refresh_from_db()\n+        self.assertEqual(r.uuid_fk, u2)\n+\n+    def test_two_level_foreign_keys(self):\n+        gc = UUIDGrandchild()\n+        # exercises ForeignKey.get_db_prep_value()\n+        gc.save()\n+        self.assertIsInstance(gc.uuidchild_ptr_id, uuid.UUID)\n+        gc.refresh_from_db()\n+        self.assertIsInstance(gc.uuidchild_ptr_id, uuid.UUID)\n+\n+    def test_save_explicit_pk_with_default(self):\n+        \"\"\"\n+        Saving a model instance with an explicit PK value should result in an\n+        UPDATE if the PK already exists, even if the PK field has a default.\n+        \"\"\"\n+        obj = PrimaryKeyUUIDModel.objects.create()\n+        # This save() should be an UPDATE, not an INSERT. Before the fix, this\n+        # will raise an IntegrityError.\n+        PrimaryKeyUUIDModel(pk=obj.pk).save()\n+        self.assertEqual(PrimaryKeyUUIDModel.objects.count(), 1)\n+\n+\n+class TestAsPrimaryKeyTransactionTests(TransactionTestCase):\n+    # Need a TransactionTestCase to avoid deferring FK constraint checking.\n+    available_apps = ['model_fields']\n+\n+    @skipUnlessDBFeature('supports_foreign_keys')\n+    def test_unsaved_fk(self):\n+        u1 = PrimaryKeyUUIDModel()\n+        with self.assertRaises(IntegrityError):\n+            RelatedToUUIDModel.objects.create(uuid_fk=u1)\n"
    },
    "django__django-14752": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/admin_views/test_autocomplete_extensibility.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py admin_views.test_autocomplete_extensibility"
        ],
        "reproduced_bug_patch": "diff --git a/tests/admin_views/test_autocomplete_extensibility.py b/tests/admin_views/test_autocomplete_extensibility.py\nnew file mode 100644\nindex 0000000000..934fb2acbd\n--- /dev/null\n+++ b/tests/admin_views/test_autocomplete_extensibility.py\n@@ -0,0 +1,197 @@\n+import json\n+from contextlib import contextmanager\n+\n+from django.contrib import admin\n+from django.contrib.admin.tests import AdminSeleniumTestCase\n+from django.contrib.admin.views.autocomplete import AutocompleteJsonView\n+from django.contrib.auth.models import Permission, User\n+from django.contrib.contenttypes.models import ContentType\n+from django.core.exceptions import PermissionDenied\n+from django.http import Http404\n+from django.test import RequestFactory, override_settings\n+from django.urls import reverse, reverse_lazy\n+\n+from .admin import AnswerAdmin, QuestionAdmin\n+from .models import (\n+    Answer, Author, Authorship, Bonus, Book, Employee, Manager, Parent,\n+    PKChild, Question, Toy, WorkHour,\n+)\n+from .tests import AdminViewBasicTestCase\n+\n+PAGINATOR_SIZE = AutocompleteJsonView.paginate_by\n+\n+\n+class AuthorAdmin(admin.ModelAdmin):\n+    ordering = ['id']\n+    search_fields = ['id']\n+\n+\n+class AuthorshipInline(admin.TabularInline):\n+    model = Authorship\n+    autocomplete_fields = ['author']\n+\n+\n+class BookAdmin(admin.ModelAdmin):\n+    inlines = [AuthorshipInline]\n+\n+\n+site = admin.AdminSite(name='autocomplete_admin')\n+site.register(Question, QuestionAdmin)\n+site.register(Answer, AnswerAdmin)\n+site.register(Author, AuthorAdmin)\n+site.register(Book, BookAdmin)\n+site.register(Employee, search_fields=['name'])\n+site.register(WorkHour, autocomplete_fields=['employee'])\n+site.register(Manager, search_fields=['name'])\n+site.register(Bonus, autocomplete_fields=['recipient'])\n+site.register(PKChild, search_fields=['name'])\n+site.register(Toy, autocomplete_fields=['child'])\n+\n+\n+@contextmanager\n+def model_admin(model, model_admin, admin_site=site):\n+    org_admin = admin_site._registry.get(model)\n+    if org_admin:\n+        admin_site.unregister(model)\n+    admin_site.register(model, model_admin)\n+    try:\n+        yield\n+    finally:\n+        if org_admin:\n+            admin_site._registry[model] = org_admin\n+\n+\n+class AutocompleteJsonViewTests(AdminViewBasicTestCase):\n+    as_view_args = {'admin_site': site}\n+    opts = {\n+        'app_label': Answer._meta.app_label,\n+        'model_name': Answer._meta.model_name,\n+        'field_name': 'question'\n+    }\n+    factory = RequestFactory()\n+    url = reverse_lazy('autocomplete_admin:autocomplete')\n+\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.user = User.objects.create_user(\n+            username='user', password='secret',\n+            email='user@example.com', is_staff=True,\n+        )\n+        super().setUpTestData()\n+\n+    def test_success(self):\n+        q = Question.objects.create(question='Is this a question?')\n+        request = self.factory.get(self.url, {'term': 'is', **self.opts})\n+        request.user = self.superuser\n+        response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n+        self.assertEqual(response.status_code, 200)\n+        data = json.loads(response.content.decode('utf-8'))\n+        self.assertEqual(data, {\n+            'results': [{'id': str(q.pk), 'text': q.question}],\n+            'pagination': {'more': False},\n+        })\n+\n+    def test_custom_to_field(self):\n+        q = Question.objects.create(question='Is this a question?')\n+        request = self.factory.get(self.url, {'term': 'is', **self.opts, 'field_name': 'question_with_to_field'})\n+        request.user = self.superuser\n+        response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n+        self.assertEqual(response.status_code, 200)\n+        data = json.loads(response.content.decode('utf-8'))\n+        self.assertEqual(data, {\n+            'results': [{'id': str(q.uuid), 'text': q.question}],\n+            'pagination': {'more': False},\n+        })\n+\n+    def test_custom_to_field_permission_denied(self):\n+        Question.objects.create(question='Is this a question?')\n+        request = self.factory.get(self.url, {'term': 'is', **self.opts, 'field_name': 'question_with_to_field'})\n+        request.user = self.user\n+        with self.assertRaises(PermissionDenied):\n+            AutocompleteJsonView.as_view(**self.as_view_args)(request)\n+\n+    def test_custom_to_field_custom_pk(self):\n+        q = Question.objects.create(question='Is this a question?')\n+        opts = {\n+            'app_label': Question._meta.app_label,\n+            'model_name': Question._meta.model_name,\n+            'field_name': 'related_questions',\n+        }\n+        request = self.factory.get(self.url, {'term': 'is', **opts})\n+        request.user = self.superuser\n+        response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n+        self.assertEqual(response.status_code, 200)\n+        data = json.loads(response.content.decode('utf-8'))\n+        self.assertEqual(data, {\n+            'results': [{'id': str(q.big_id), 'text': q.question}],\n+            'pagination': {'more': False},\n+        })\n+\n+    def test_to_field_resolution_with_mti(self):\n+        \"\"\"\n+        to_field resolution should correctly resolve for target models using\n+        MTI. Tests for single and multi-level cases.\n+        \"\"\"\n+        tests = [\n+            (Employee, WorkHour, 'employee'),\n+            (Manager, Bonus, 'recipient'),\n+        ]\n+        for Target, Remote, related_name in tests:\n+            with self.subTest(target_model=Target, remote_model=Remote, related_name=related_name):\n+                o = Target.objects.create(name=\"Frida Kahlo\", gender=2, code=\"painter\", alive=False)\n+                opts = {\n+                    'app_label': Remote._meta.app_label,\n+                    'model_name': Remote._meta.model_name,\n+                    'field_name': related_name,\n+                }\n+                request = self.factory.get(self.url, {'term': 'frida', **opts})\n+                request.user = self.superuser\n+                response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n+                self.assertEqual(response.status_code, 200)\n+                data = json.loads(response.content.decode('utf-8'))\n+                self.assertEqual(data, {\n+                    'results': [{'id': str(o.pk), 'text': o.name}],\n+                    'pagination': {'more': False},\n+                })\n+\n+    def test_to_field_resolution_with_fk_pk(self):\n+        p = Parent.objects.create(name=\"Bertie\")\n+        c = PKChild.objects.create(parent=p, name=\"Anna\")\n+        opts = {\n+            'app_label': Toy._meta.app_label,\n+            'model_name': Toy._meta.model_name,\n+            'field_name': 'child',\n+        }\n+        request = self.factory.get(self.url, {'term': 'anna', **opts})\n+        request.user = self.superuser\n+        response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n+        self.assertEqual(response.status_code, 200)\n+        data = json.loads(response.content.decode('utf-8'))\n+        self.assertEqual(data, {\n+            'results': [{'id': str(c.pk), 'text': c.name}],\n+            'pagination': {'more': False},\n+        })\n+\n+    def test_serialize_result_hook(self):\n+        \"\"\"\n+        AutocompleteJsonView should have a `serialize_result` hook to allow\n+        easy customization of the result data, as proposed in the issue.\n+        \"\"\"\n+        class CustomAutocompleteJsonView(AutocompleteJsonView):\n+            def serialize_result(self, obj, to_field_name):\n+                return super().serialize_result(obj, to_field_name) | {'notes': str(obj.uuid)}\n+\n+        q = Question.objects.create(question='Is this a question?')\n+        request = self.factory.get(self.url, {'term': 'is', **self.opts})\n+        request.user = self.superuser\n+        response = CustomAutocompleteJsonView.as_view(**self.as_view_args)(request)\n+        self.assertEqual(response.status_code, 200)\n+        data = json.loads(response.content.decode('utf-8'))\n+        self.assertEqual(data, {\n+            'results': [{\n+                'id': str(q.pk),\n+                'text': q.question,\n+                'notes': str(q.uuid),\n+            }],\n+            'pagination': {'more': False},\n+        })\n"
    },
    "matplotlib__matplotlib-20676": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_span_selector.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_span_selector.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_span_selector.py b/lib/matplotlib/tests/test_span_selector.py\nnew file mode 100644\nindex 0000000000..253db2fea0\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_span_selector.py\n@@ -0,0 +1,22 @@\n+import pytest\n+import matplotlib.pyplot as plt\n+import matplotlib.widgets as widgets\n+from numpy.testing import assert_allclose\n+\n+\n+def test_span_selector_interactive_limits():\n+    \"\"\"\n+    Check that creating an interactive SpanSelector does not change the axes\n+    limits, specifically that it does not force them to include 0.\n+    \"\"\"\n+    fig, ax = plt.subplots()\n+    ax.plot([10, 20], [10, 20])\n+    initial_xlim = ax.get_xlim()\n+\n+    # The onselect function can be a no-op lambda.\n+    # The bug is triggered upon instantiation of the SpanSelector.\n+    widgets.SpanSelector(ax, lambda min, max: None, \"horizontal\",\n+                         interactive=True)\n+\n+    final_xlim = ax.get_xlim()\n+    assert_allclose(final_xlim, initial_xlim)\n"
    },
    "scikit-learn__scikit-learn-14053": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/tree/tests/test_export_text.py",
        "reproduced_bug_commands": [
            "pytest sklearn/tree/tests/test_export_text.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/tree/tests/test_export_text.py b/sklearn/tree/tests/test_export_text.py\nnew file mode 100644\nindex 0000000000..a7028e38b0\n--- /dev/null\n+++ b/sklearn/tree/tests/test_export_text.py\n@@ -0,0 +1,20 @@\n+from sklearn.tree import DecisionTreeClassifier\n+from sklearn.tree.export import export_text\n+from sklearn.datasets import load_iris\n+\n+\n+def test_export_text_single_feature():\n+    \"\"\"Test export_text with a single feature.\n+\n+    Non-regression test for #14444. It checks that export_text does not raise\n+    an IndexError when the tree is trained on a single feature.\n+    \"\"\"\n+    X, y = load_iris(return_X_y=True)\n+    X = X[:, 0].reshape(-1, 1)\n+\n+    tree = DecisionTreeClassifier(random_state=0)\n+    tree.fit(X, y)\n+    tree_text = export_text(tree, feature_names=['sepal_length'])\n+\n+    assert isinstance(tree_text, str)\n+    assert 'sepal_length' in tree_text\n"
    },
    "sympy__sympy-15875": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/sympy/core/tests/test_complex_arithmetic.py",
        "reproduced_bug_commands": [
            "pytest sympy/sympy/core/tests/test_complex_arithmetic.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/sympy/core/tests/test_complex_arithmetic.py b/sympy/sympy/core/tests/test_complex_arithmetic.py\nnew file mode 100644\nindex 0000000000..31e89f79b3\n--- /dev/null\n+++ b/sympy/sympy/core/tests/test_complex_arithmetic.py\n@@ -0,0 +1,13 @@\n+from sympy import I\n+\n+def test_issue_15872():\n+    \"\"\"\n+    Test for issue #15872.\n+\n+    is_zero was incorrectly returning False for a complex expression\n+    that is equal to zero.\n+    \"\"\"\n+    e = -2*I + (1 + I)**2\n+    # simplify(e) is 0, so e.is_zero should not be False.\n+    # It should be True, or None if it can't be determined.\n+    assert e.is_zero is not False\n"
    },
    "django__django-12262": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/template_tests/syntax_tests/test_simple_tag_keyword_only_arg.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py template_tests.syntax_tests.test_simple_tag_keyword_only_arg"
        ],
        "reproduced_bug_patch": "diff --git a/tests/template_tests/syntax_tests/test_simple_tag_keyword_only_arg.py b/tests/template_tests/syntax_tests/test_simple_tag_keyword_only_arg.py\nnew file mode 100644\nindex 0000000000..d7650c5e76\n--- /dev/null\n+++ b/tests/template_tests/syntax_tests/test_simple_tag_keyword_only_arg.py\n@@ -0,0 +1,21 @@\n+from django.template import Context, Engine, Library\n+from django.test import SimpleTestCase\n+\n+\n+class KeywordOnlySimpleTagTests(SimpleTestCase):\n+    def test_keyword_only_arg_with_default(self):\n+        \"\"\"\n+        A simple_tag with a keyword-only argument with a default value can be\n+        called by providing that keyword argument.\n+        \"\"\"\n+        lib = Library()\n+\n+        @lib.simple_tag\n+        def hello(*, greeting='hello'):\n+            return f'{greeting} world'\n+\n+        engine = Engine()\n+        engine.template_libraries['custom'] = lib\n+        template = engine.from_string(\"{% load custom %}{% hello greeting='hi' %}\")\n+        output = template.render(Context())\n+        self.assertEqual(output, 'hi world')\n"
    },
    "django__django-14765": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/migrations/test_state_clone.py",
        "reproduced_bug_commands": [
            "cd tests && python runtests.py migrations.test_state_clone"
        ],
        "reproduced_bug_patch": "diff --git a/tests/migrations/test_state_clone.py b/tests/migrations/test_state_clone.py\nnew file mode 100644\nindex 0000000000..d068ac31ce\n--- /dev/null\n+++ b/tests/migrations/test_state_clone.py\n@@ -0,0 +1,15 @@\n+from django.db.migrations.state import ProjectState\n+from django.test import SimpleTestCase\n+\n+\n+class StateTests(SimpleTestCase):\n+    def test_real_apps_list_is_copied_on_clone(self):\n+        \"\"\"\n+        ProjectState.clone() should create a copy of the real_apps set, not a\n+        reference.\n+        \"\"\"\n+        state = ProjectState(real_apps=['app1'])\n+        clone_state = state.clone()\n+        # Mutating the original state's real_apps shouldn't affect the clone.\n+        state.real_apps.add('app2')\n+        self.assertEqual(clone_state.real_apps, {'app1'})\n"
    },
    "matplotlib__matplotlib-20826": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_shared_axes_clear.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_shared_axes_clear.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_shared_axes_clear.py b/lib/matplotlib/tests/test_shared_axes_clear.py\nnew file mode 100644\nindex 0000000000..a530c8f2c9\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_shared_axes_clear.py\n@@ -0,0 +1,27 @@\n+import pytest\n+import numpy as np\n+import matplotlib.pyplot as plt\n+\n+\n+def test_clear_shared_axes_tick_labels():\n+    \"\"\"\n+    Test that ax.clear() does not show tick labels that should be hidden.\n+\n+    This is a regression test based on a bug report where calling `ax.clear()`\n+    on a shared-axis subplot would cause tick labels to reappear incorrectly.\n+    \"\"\"\n+    fig, axes = plt.subplots(2, 2, sharex=True, sharey=True)\n+\n+    x = np.arange(0.0, 2 * np.pi, 0.01)\n+    y = np.sin(x)\n+\n+    for ax in axes.flatten():\n+        ax.clear()\n+        ax.plot(x, y)\n+\n+    # For a 2x2 grid with sharex=True, the x-tick labels on the top row\n+    # of axes should not be visible. This assertion checks the top-left axis.\n+    # The bug causes these labels to become visible after ax.clear(),\n+    # so this assertion will fail.\n+    assert all(not label.get_visible() for label\n+               in axes[0, 0].get_xticklabels())\n"
    },
    "scikit-learn__scikit-learn-14087": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/linear_model/tests/test_logistic_regression_cv.py",
        "reproduced_bug_commands": [
            "pytest sklearn/linear_model/tests/test_logistic_regression_cv.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/linear_model/tests/test_logistic_regression_cv.py b/sklearn/linear_model/tests/test_logistic_regression_cv.py\nnew file mode 100644\nindex 0000000000..b9a5f8ff7e\n--- /dev/null\n+++ b/sklearn/linear_model/tests/test_logistic_regression_cv.py\n@@ -0,0 +1,32 @@\n+import numpy as np\n+import pytest\n+\n+from sklearn.linear_model import LogisticRegressionCV\n+from sklearn.utils.testing import assert_array_almost_equal\n+\n+\n+def test_logistic_cv_refit_false_binary():\n+    \"\"\"Test that LogisticRegressionCV(refit=False) does not fail on binary\n+    classification problems.\n+\n+    Non-regression test for #14244.\n+    \"\"\"\n+    np.random.seed(29)\n+    X = np.random.normal(size=(1000, 3))\n+    beta = np.random.normal(size=3)\n+    intercept = np.random.normal(size=None)\n+    y = np.sign(intercept + X @ beta)\n+\n+    clf = LogisticRegressionCV(\n+        cv=5,\n+        solver='saga',\n+        tol=1e-2,\n+        refit=False\n+    )\n+    # This should not raise an IndexError\n+    clf.fit(X, y)\n+\n+    # When refit=False, coef_ is the average of the coefficients across\n+    # the CV folds. For a binary classification problem, its shape should\n+    # be (1, n_features). This assertion will fail if fit() crashes.\n+    assert clf.coef_.shape == (1, X.shape[1])\n"
    },
    "sympy__sympy-15976": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/printing/tests/test_mathml2.py",
        "reproduced_bug_commands": [
            "bin/test sympy/printing/tests/test_mathml2.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/printing/tests/test_mathml2.py b/sympy/printing/tests/test_mathml2.py\nnew file mode 100644\nindex 0000000000..94890d1489\n--- /dev/null\n+++ b/sympy/printing/tests/test_mathml2.py\n@@ -0,0 +1,19 @@\n+from sympy import diff, Integral, Limit, sin, Symbol, Integer, Rational, cos, \\\n+    tan, asin, acos, atan, sinh, cosh, tanh, asinh, acosh, atanh, E, I, oo, \\\n+    pi, GoldenRatio, EulerGamma, Sum, Eq, Ne, Ge, Lt, Float, Matrix, Basic, S, \\\n+    MatrixSymbol\n+from sympy.stats.rv import RandomSymbol\n+from sympy.printing.mathml import mathml, MathMLContentPrinter, MathMLPresentationPrinter, \\\n+    MathMLPrinter\n+\n+from sympy.utilities.pytest import raises\n+\n+x = Symbol('x')\n+y = Symbol('y')\n+mp = MathMLContentPrinter()\n+mpp = MathMLPresentationPrinter()\n+\n+\n+def test_issue_15733():\n+    x2 = Symbol('x2')\n+    assert mathml(x2, printer='presentation') == '<mi>x2</mi>'\n"
    },
    "django__django-12273": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/model_inheritance_regress/test_reset_pk_on_child_save.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py model_inheritance_regress.test_reset_pk_on_child_save"
        ],
        "reproduced_bug_patch": "diff --git a/tests/model_inheritance_regress/test_reset_pk_on_child_save.py b/tests/model_inheritance_regress/test_reset_pk_on_child_save.py\nnew file mode 100644\nindex 0000000000..e01ce3eb60\n--- /dev/null\n+++ b/tests/model_inheritance_regress/test_reset_pk_on_child_save.py\n@@ -0,0 +1,28 @@\n+from django.test import TestCase\n+\n+from .models import Place, Restaurant\n+\n+\n+class ResetPrimaryKeyOnChildTest(TestCase):\n+    def test_reset_pk_on_child_save(self):\n+        \"\"\"\n+        Resetting a child model's primary key to None should cause a new\n+        instance to be created on save(), rather than updating the existing one.\n+        \"\"\"\n+        restaurant = Restaurant.objects.create(serves_hot_dogs=True)\n+        original_pk = restaurant.pk\n+\n+        # Get the child instance via the parent, as in the bug report.\n+        place = Place.objects.get(pk=original_pk)\n+        child_obj = place.restaurant\n+\n+        # Reset the pk and change a field. This should cause a new row to be\n+        # created on save().\n+        child_obj.pk = None\n+        child_obj.serves_hot_dogs = False\n+        child_obj.save()\n+\n+        # The bug is that the original object is updated, so its\n+        # 'serves_hot_dogs' flag becomes False. When fixed, the original\n+        # object will be untouched and this assertion will pass.\n+        self.assertTrue(Restaurant.objects.get(pk=original_pk).serves_hot_dogs)\n"
    },
    "django__django-14771": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/utils/test_autoreload.py",
        "reproduced_bug_commands": [
            "python -X utf8 tests/runtests.py --noinput --settings=test_sqlite tests.utils.test_autoreload"
        ],
        "reproduced_bug_patch": "diff --git a/tests/utils/test_autoreload.py b/tests/utils/test_autoreload.py\nnew file mode 100644\nindex 0000000000..f654235ed4\n--- /dev/null\n+++ b/tests/utils/test_autoreload.py\n@@ -0,0 +1,21 @@\n+import sys\n+from unittest import mock, skipIf\n+\n+from django.test import SimpleTestCase\n+from django.utils import autoreload\n+\n+\n+class TestChildArguments(SimpleTestCase):\n+    @skipIf(not hasattr(sys, \"_xoptions\"), \"sys._xoptions is not available.\")\n+    @mock.patch(\"__main__.__spec__\", None)\n+    @mock.patch(\"sys.argv\", [\"manage.py\", \"runserver\"])\n+    @mock.patch(\"sys.warnoptions\", [])\n+    def test_xoptions_are_passed_to_child(self):\n+        \"\"\"\n+        -X options are passed to the child process.\n+        \"\"\"\n+        with mock.patch.dict(sys._xoptions, {\"utf8\": True}):\n+            self.assertEqual(\n+                autoreload.get_child_arguments(),\n+                [sys.executable, \"-Xutf8\", \"manage.py\", \"runserver\"],\n+            )\n"
    },
    "matplotlib__matplotlib-20859": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_subfigure.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_subfigure.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_subfigure.py b/lib/matplotlib/tests/test_subfigure.py\nnew file mode 100644\nindex 0000000000..68ea82fc43\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_subfigure.py\n@@ -0,0 +1,17 @@\n+import matplotlib.pyplot as plt\n+import pytest\n+\n+\n+def test_subfigure_legend():\n+    \"\"\"\n+    Test that adding a legend to a SubFigure works.\n+\n+    This test reproduces the bug where calling legend() on a SubFigure instance\n+    raises a TypeError. The expected behavior is for a legend to be created\n+    on the subfigure. The test will pass when the bug is fixed.\n+    \"\"\"\n+    subfig = plt.figure().subfigures()\n+    ax = subfig.subplots()\n+    ax.plot([0, 1, 2], [0, 1, 2], label=\"test\")\n+    subfig.legend()\n+    assert len(subfig.legends) == 1\n"
    },
    "scikit-learn__scikit-learn-14141": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/utils/tests/test_show_versions_joblib.py",
        "reproduced_bug_commands": [
            "pytest sklearn/utils/tests/test__show_versions_joblib.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/utils/tests/test_show_versions_joblib.py b/sklearn/utils/tests/test_show_versions_joblib.py\nnew file mode 100644\nindex 0000000000..d17c72c78f\n--- /dev/null\n+++ b/sklearn/utils/tests/test_show_versions_joblib.py\n@@ -0,0 +1,7 @@\n+from sklearn.utils._show_versions import _get_deps_info\n+\n+\n+def test_get_deps_info_for_joblib():\n+    \"\"\"Test that _get_deps_info includes joblib.\"\"\"\n+    deps_info = _get_deps_info()\n+    assert 'joblib' in deps_info\n"
    },
    "sympy__sympy-16450": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/core/tests/test_posify.py",
        "reproduced_bug_commands": [
            "pytest sympy/core/tests/test_posify.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/core/tests/test_posify.py b/sympy/core/tests/test_posify.py\nnew file mode 100644\nindex 0000000000..d111afa19c\n--- /dev/null\n+++ b/sympy/core/tests/test_posify.py\n@@ -0,0 +1,13 @@\n+from sympy import (\n+    Symbol,\n+    posify,\n+)\n+\n+\n+def test_posify_finite():\n+    \"\"\"\n+    Tests that posify preserves the 'finite' assumption.\n+    \"\"\"\n+    x = Symbol('x', finite=True)\n+    xp, _ = posify(x)\n+    assert xp.is_finite is True\n"
    },
    "django__django-12276": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/forms_tests/widget_tests/test_fileinput_use_required_attribute.py",
        "reproduced_bug_commands": [
            "pytest tests/forms_tests/widget_tests/test_fileinput_use_required_attribute.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/forms_tests/widget_tests/test_fileinput_use_required_attribute.py b/tests/forms_tests/widget_tests/test_fileinput_use_required_attribute.py\nnew file mode 100644\nindex 0000000000..1056db4c9a\n--- /dev/null\n+++ b/tests/forms_tests/widget_tests/test_fileinput_use_required_attribute.py\n@@ -0,0 +1,43 @@\n+from django.forms import FileInput\n+from django.forms.renderers import DjangoTemplates, Jinja2\n+from django.test import SimpleTestCase\n+\n+try:\n+    import jinja2\n+except ImportError:\n+    jinja2 = None\n+\n+\n+class WidgetTest(SimpleTestCase):\n+    beatles = (('J', 'John'), ('P', 'Paul'), ('G', 'George'), ('R', 'Ringo'))\n+\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.django_renderer = DjangoTemplates()\n+        cls.jinja2_renderer = Jinja2() if jinja2 else None\n+        cls.renderers = [cls.django_renderer] + ([cls.jinja2_renderer] if cls.jinja2_renderer else [])\n+        super().setUpClass()\n+\n+    def check_html(self, widget, name, value, html='', attrs=None, strict=False, **kwargs):\n+        assertEqual = self.assertEqual if strict else self.assertHTMLEqual\n+        if self.jinja2_renderer:\n+            output = widget.render(name, value, attrs=attrs, renderer=self.jinja2_renderer, **kwargs)\n+            # Django escapes quotes with '&quot;' while Jinja2 uses '&#34;'.\n+            output = output.replace('&#34;', '&quot;')\n+            # Django escapes single quotes with '&#x27;' while Jinja2 uses '&#39;'.\n+            output = output.replace('&#39;', '&#x27;')\n+            assertEqual(output, html)\n+\n+        output = widget.render(name, value, attrs=attrs, renderer=self.django_renderer, **kwargs)\n+        assertEqual(output, html)\n+\n+\n+class FileInputTest(WidgetTest):\n+    widget = FileInput()\n+\n+    def test_use_required_attribute_with_initial(self):\n+        \"\"\"\n+        FileInput.use_required_attribute() should be False when initial data\n+        exists because the user may want to keep the existing file.\n+        \"\"\"\n+        self.assertIs(self.widget.use_required_attribute('resume.txt'), False)\n"
    },
    "django__django-14787": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/decorators/test_method_decorator.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py decorators.test_method_decorator"
        ],
        "reproduced_bug_patch": "diff --git a/tests/decorators/test_method_decorator.py b/tests/decorators/test_method_decorator.py\nnew file mode 100644\nindex 0000000000..c497e63952\n--- /dev/null\n+++ b/tests/decorators/test_method_decorator.py\n@@ -0,0 +1,29 @@\n+from functools import wraps\n+\n+from django.test import SimpleTestCase\n+from django.utils.decorators import method_decorator\n+\n+\n+class MethodDecoratorTests(SimpleTestCase):\n+    def test_decorator_can_access_attributes_of_wrapped_function(self):\n+        \"\"\"\n+        A decorator applied via method_decorator() can access the attributes\n+        of the function it wraps.\n+        \"\"\"\n+        def logger(func):\n+            @wraps(func)\n+            def inner(*args, **kwargs):\n+                # This will raise an AttributeError if `func` is a partial\n+                # object without the attributes of the wrapped function.\n+                name = func.__name__\n+                return func(*args, **kwargs)\n+            return inner\n+\n+        class Test:\n+            @method_decorator(logger)\n+            def hello_world(self):\n+                return \"hello\"\n+\n+        # This call fails with an AttributeError before the bug is fixed.\n+        # After the fix, it should run without error, and the assertion will pass.\n+        self.assertEqual(Test().hello_world(), \"hello\")\n"
    },
    "matplotlib__matplotlib-21568": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_datetime_usetex.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_datetime_usetex.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_datetime_usetex.py b/lib/matplotlib/tests/test_datetime_usetex.py\nnew file mode 100644\nindex 0000000000..bfa9d6689f\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_datetime_usetex.py\n@@ -0,0 +1,41 @@\n+import matplotlib as mpl\n+import matplotlib.pyplot as plt\n+import numpy as np\n+import pandas as pd\n+import pytest\n+\n+\n+@pytest.mark.skipif(not mpl.checkdep_usetex(True), reason=\"LaTeX is not installed\")\n+def test_datetime_axis_usetex_spacing():\n+    \"\"\"\n+    Test to reproduce unclear spacing on datetime axis with usetex=True.\n+\n+    This test asserts that the date formatter selects a compact format\n+    for the tick labels (e.g., HH:MM), as it did in older Matplotlib\n+    versions, instead of a long format (e.g., HH:MM:SS) that causes\n+    labels to overlap when using LaTeX.\n+    \"\"\"\n+    mpl.rcParams[\"text.usetex\"] = True\n+\n+    np.random.seed(1)\n+\n+    dates = pd.date_range(\n+        \"2020-01-01 00:00:00\", end=\"2020-01-01 00:10:00\", periods=100\n+    ).to_pydatetime()\n+    data = np.random.rand(100)\n+\n+    fig, ax = plt.subplots(constrained_layout=True)\n+    ax.plot(dates, data)\n+    fig.canvas.draw()\n+\n+    # The buggy formatter produces labels with seconds (e.g., \"00:02:30\"),\n+    # which have two colons. The correct, more compact format (e.g., \"00:02\")\n+    # has only one.\n+    actual_labels = [tick.get_text() for tick in ax.get_xticklabels()]\n+    has_seconds_in_label = any(label.count(':') == 2 for label in actual_labels)\n+\n+    # This assertion fails now because the buggy formatter includes seconds.\n+    # It will pass when the formatter is fixed to choose a more compact format.\n+    assert not has_seconds_in_label, \\\n+        \"Tick labels should use a compact format (e.g., HH:MM) to avoid overlap, \" \\\n+        \"but a format with seconds (HH:MM:SS) was found.\"\n"
    },
    "scikit-learn__scikit-learn-14496": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/cluster/tests/test_optics_min_samples.py",
        "reproduced_bug_commands": [
            "pytest sklearn/cluster/tests/test_optics_min_samples.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/cluster/tests/test_optics_min_samples.py b/sklearn/cluster/tests/test_optics_min_samples.py\nnew file mode 100644\nindex 0000000000..a1c667a700\n--- /dev/null\n+++ b/sklearn/cluster/tests/test_optics_min_samples.py\n@@ -0,0 +1,20 @@\n+import numpy as np\n+import pytest\n+\n+from sklearn.cluster.optics_ import OPTICS\n+from sklearn.datasets import make_blobs\n+\n+\n+def test_optics_min_samples_float():\n+    \"\"\"Test OPTICS with float min_samples.\n+\n+    When min_samples is a float, it is converted to an absolute number of\n+    samples. This test ensures that it is converted to an integer and not\n+    passed as a float to NearestNeighbors, which would raise a TypeError.\n+    Non-regression test for issue #15101.\n+    \"\"\"\n+    X, _ = make_blobs(n_samples=100, random_state=0)\n+    # The following call should not raise a TypeError.\n+    # The test passes if fit completes successfully.\n+    clust = OPTICS(min_samples=0.1, metric='minkowski')\n+    clust.fit(X)\n"
    },
    "sympy__sympy-16597": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/core/tests/test_even_implies_finite.py",
        "reproduced_bug_commands": [
            "pytest sympy/core/tests/test_even_implies_finite.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/core/tests/test_even_implies_finite.py b/sympy/core/tests/test_even_implies_finite.py\nnew file mode 100644\nindex 0000000000..8f8ddc1811\n--- /dev/null\n+++ b/sympy/core/tests/test_even_implies_finite.py\n@@ -0,0 +1,15 @@\n+from sympy import I, sqrt, log, exp, sin, asin, factorial, Mod, pi\n+from sympy.core import Symbol, S, Rational, Integer, Dummy, Wild, Pow\n+from sympy.core.facts import InconsistentAssumptions\n+from sympy import simplify\n+from sympy.core.compatibility import range\n+\n+from sympy.utilities.pytest import raises, XFAIL\n+\n+\n+def test_even_implies_finite():\n+    \"\"\"\n+    Test that a Symbol that is even is also finite.\n+    \"\"\"\n+    m = Symbol('m', even=True)\n+    assert m.is_finite is True\n"
    },
    "django__django-12304": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/template_tests/test_enums.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py template_tests.test_enums"
        ],
        "reproduced_bug_patch": "diff --git a/tests/template_tests/test_enums.py b/tests/template_tests/test_enums.py\nnew file mode 100644\nindex 0000000000..a4525873e9\n--- /dev/null\n+++ b/tests/template_tests/test_enums.py\n@@ -0,0 +1,33 @@\n+from django.db import models\n+from django.template import Context, Engine\n+from django.test import SimpleTestCase\n+from django.utils.translation import gettext_lazy as _\n+\n+\n+class EnumTemplateTests(SimpleTestCase):\n+    engine = Engine()\n+\n+    def test_enum_in_template_comparison(self):\n+        \"\"\"\n+        Enumeration types can be used in template comparisons without being\n+        inadvertently called.\n+        \"\"\"\n+        class YearInSchool(models.TextChoices):\n+            FRESHMAN = 'FR', _('Freshman')\n+            SOPHOMORE = 'SO', _('Sophomore')\n+            JUNIOR = 'JR', _('Junior')\n+            SENIOR = 'SR', _('Senior')\n+\n+        class Student:\n+            year_in_school = YearInSchool.FRESHMAN\n+\n+        template = self.engine.from_string(\n+            '{% if student.year_in_school == YearInSchool.FRESHMAN %}yes{% endif %}'\n+        )\n+        context = Context({\n+            'student': Student(),\n+            'YearInSchool': YearInSchool,\n+        })\n+        # This will raise a TypeError because the template engine calls the\n+        # YearInSchool enum (which is a class) without arguments.\n+        self.assertEqual(template.render(context), 'yes')\n"
    },
    "django__django-14792": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "matplotlib__matplotlib-22719": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_category_deprecation.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_category_deprecation.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_category_deprecation.py b/lib/matplotlib/tests/test_category_deprecation.py\nnew file mode 100644\nindex 0000000000..821d29e059\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_category_deprecation.py\n@@ -0,0 +1,21 @@\n+import warnings\n+import pytest\n+import matplotlib.pyplot as plt\n+from matplotlib import MatplotlibDeprecationWarning\n+\n+\n+def test_empty_plot_with_category_units_no_warning():\n+    \"\"\"\n+    Test that plotting empty data with category units does not raise a\n+    deprecation warning. This reproduces a bug where a non-actionable\n+    MatplotlibDeprecationWarning is raised.\n+    \"\"\"\n+    fig, ax = plt.subplots()\n+    ax.xaxis.update_units([\"a\", \"b\"])\n+\n+    with warnings.catch_warnings(record=True) as w:\n+        # Filter for the specific warning which we don't expect to see.\n+        warnings.simplefilter(\"always\", MatplotlibDeprecationWarning)\n+        ax.plot([], [])\n+        # This will fail if a MatplotlibDeprecationWarning is raised.\n+        assert len(w) == 0\n"
    },
    "scikit-learn__scikit-learn-14629": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/model_selection/tests/test_cross_val_predict_multioutput.py",
        "reproduced_bug_commands": [
            "pip install \"numpy==1.16.4\" \"scipy==1.2.1\" \"scikit-learn==0.21.2\" \"Cython==0.29.12\" \"pandas==0.24.2\" pytest",
            "pytest sklearn/model_selection/tests/test_cross_val_predict_multioutput.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/model_selection/tests/test_cross_val_predict_multioutput.py b/sklearn/model_selection/tests/test_cross_val_predict_multioutput.py\nnew file mode 100644\nindex 0000000000..940d76cab2\n--- /dev/null\n+++ b/sklearn/model_selection/tests/test_cross_val_predict_multioutput.py\n@@ -0,0 +1,31 @@\n+import pytest\n+import numpy as np\n+\n+from sklearn.datasets import make_multilabel_classification\n+from sklearn.multioutput import MultiOutputClassifier\n+from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n+from sklearn.model_selection import cross_val_predict\n+\n+\n+def test_cross_val_predict_multioutput_predict_proba():\n+    \"\"\"\n+    Test cross_val_predict with method='predict_proba' on MultiOutputClassifier.\n+\n+    This is a non-regression test for a bug that caused an AttributeError\n+    because cross_val_predict was trying to access `classes_` on the\n+    MultiOutputClassifier meta-estimator instead of the sub-estimators.\n+    See issue #14257.\n+    \"\"\"\n+    X, Y = make_multilabel_classification(n_samples=100, n_classes=5,\n+                                          random_state=0)\n+\n+    # The combination of MultiOutputClassifier and method='predict_proba'\n+    # caused an AttributeError.\n+    clf = MultiOutputClassifier(LinearDiscriminantAnalysis())\n+    pred_proba = cross_val_predict(clf, X, Y, cv=3, method='predict_proba')\n+\n+    # The result should be a list of arrays, one for each of the 5 outputs.\n+    # Each array should have shape (n_samples, n_classes_in_output), which is\n+    # (100, 2) for each binary output.\n+    assert len(pred_proba) == 5\n+    assert pred_proba[0].shape == (100, 2)\n"
    },
    "sympy__sympy-16766": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/printing/tests/test_pycode_bug.py",
        "reproduced_bug_commands": [
            "python setup.py test"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/printing/tests/test_pycode_bug.py b/sympy/printing/tests/test_pycode_bug.py\nnew file mode 100644\nindex 0000000000..d009078682\n--- /dev/null\n+++ b/sympy/printing/tests/test_pycode_bug.py\n@@ -0,0 +1,25 @@\n+# -*- coding: utf-8 -*-\n+from __future__ import absolute_import\n+\n+from sympy.codegen import Assignment\n+from sympy.codegen.ast import none\n+from sympy.core import Expr, Mod, symbols, Eq, Le, Gt, zoo, oo, Rational\n+from sympy.core.numbers import pi\n+from sympy.functions import acos, Piecewise, sign\n+from sympy.logic import And, Or\n+from sympy.matrices import SparseMatrix, MatrixSymbol\n+from sympy.printing.pycode import (\n+    MpmathPrinter, NumPyPrinter, PythonCodePrinter, pycode, SciPyPrinter\n+)\n+from sympy.utilities.pytest import raises\n+from sympy import IndexedBase\n+\n+x, y, z = symbols('x y z')\n+\n+\n+def test_pycode_indexed():\n+    \"\"\"\n+    Test for printing Indexed objects.\n+    \"\"\"\n+    p = IndexedBase(\"p\")\n+    assert pycode(p[0]) == 'p[0]'\n"
    },
    "django__django-12308": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/admin_utils/test_jsonfield_display.py",
        "reproduced_bug_commands": [
            "tests/runtests.py admin_utils.test_jsonfield_display"
        ],
        "reproduced_bug_patch": "diff --git a/tests/admin_utils/test_jsonfield_display.py b/tests/admin_utils/test_jsonfield_display.py\nnew file mode 100644\nindex 0000000000..f9223eed28\n--- /dev/null\n+++ b/tests/admin_utils/test_jsonfield_display.py\n@@ -0,0 +1,17 @@\n+import json\n+\n+from django.contrib.admin.utils import display_for_field\n+from django.db import models\n+from django.test import SimpleTestCase\n+\n+\n+class JSONFieldDisplayTests(SimpleTestCase):\n+    def test_display_for_json_field(self):\n+        \"\"\"\n+        display_for_field() should serialize a JSONField value to a JSON string\n+        for display.\n+        \"\"\"\n+        field = models.JSONField()\n+        value = {'foo': 'bar'}\n+        result = display_for_field(value, field, '---')\n+        self.assertEqual(result, json.dumps(value))\n"
    },
    "django__django-14855": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/admin_views/test_readonly_foreign_key.py",
        "reproduced_bug_commands": [
            "cd tests && python runtests.py admin_views.test_readonly_foreign_key"
        ],
        "reproduced_bug_patch": "diff --git a/tests/admin_views/test_readonly_foreign_key.py b/tests/admin_views/test_readonly_foreign_key.py\nnew file mode 100644\nindex 0000000000..ed7d7a2297\n--- /dev/null\n+++ b/tests/admin_views/test_readonly_foreign_key.py\n@@ -0,0 +1,63 @@\n+import admin_views.models\n+from django.contrib import admin\n+from django.contrib.auth.models import User\n+from django.test import TestCase, override_settings\n+from django.urls import path, reverse\n+\n+# Models are defined in admin_views.models, so we can import them.\n+from admin_views.models import Child, Parent\n+\n+\n+# 1. A custom ModelAdmin that makes the ForeignKey readonly.\n+class ChildAdmin(admin.ModelAdmin):\n+    readonly_fields = ('parent',)\n+\n+\n+# 2. A custom AdminSite instance.\n+custom_admin_site = admin.AdminSite(name='custom_admin')\n+custom_admin_site.register(Parent)\n+custom_admin_site.register(Child, ChildAdmin)\n+\n+\n+# 3. URL patterns for the test, including the custom and default admin sites.\n+# This module will be used as the ROOT_URLCONF.\n+urlpatterns = [\n+    path('custom_admin/', custom_admin_site.urls),\n+    path('admin/', admin.site.urls),\n+]\n+\n+\n+# 4. The test class, pointing ROOT_URLCONF to this module.\n+# The path is based on the file's location in the project structure.\n+@override_settings(ROOT_URLCONF='admin_views.test_readonly_foreign_key')\n+class ReadonlyForeignKeyInCustomAdminTest(TestCase):\n+    @classmethod\n+    def setUpTestData(cls):\n+        # Create a user and model instances needed for the test.\n+        cls.superuser = User.objects.create_superuser('super', 'super@example.com', 'password')\n+        cls.parent_obj = Parent.objects.create(name='Test Parent')\n+        cls.child_obj = Child.objects.create(parent=cls.parent_obj, name='Test Child')\n+\n+    def test_readonly_foreign_key_url_in_custom_admin(self):\n+        \"\"\"\n+        The link for a readonly ForeignKey field in a custom admin site should\n+        use the custom site's URL, not the default admin's URL.\n+        \"\"\"\n+        self.client.login(username='super', password='password')\n+\n+        # URL for the change view of the 'Child' object in our custom admin.\n+        child_change_url = reverse('custom_admin:admin_views_child_change', args=[self.child_obj.pk])\n+        response = self.client.get(child_change_url)\n+\n+        # The expected URL for the link to the related 'Parent' object.\n+        # It should be resolved within the 'custom_admin' namespace.\n+        expected_parent_url = reverse('custom_admin:admin_views_parent_change', args=[self.parent_obj.pk])\n+\n+        # This assertion will fail if the bug is present because the generated\n+        # href will point to '/admin/...' instead of '/custom_admin/...'.\n+        self.assertContains(\n+            response,\n+            f'<a href=\"{expected_parent_url}\">{self.parent_obj.name}</a>',\n+            html=True,\n+            msg_prefix=\"The readonly field link does not point to the custom admin URL.\",\n+        )\n"
    },
    "matplotlib__matplotlib-22865": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_colorbar_drawedges_extended.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_colorbar_drawedges_extended.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_colorbar_drawedges_extended.py b/lib/matplotlib/tests/test_colorbar_drawedges_extended.py\nnew file mode 100644\nindex 0000000000..bbb935892c\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_colorbar_drawedges_extended.py\n@@ -0,0 +1,28 @@\n+import matplotlib as mpl\n+import numpy as np\n+import matplotlib.pyplot as plt\n+from matplotlib.colors import from_levels_and_colors\n+\n+\n+def test_colorbar_drawedges_extended():\n+    \"\"\"\n+    Test that for a colorbar with drawedges=True and extend='both',\n+    the extension patches have a visible linewidth.\n+\n+    Based on https://github.com/matplotlib/matplotlib/issues/22849\n+    \"\"\"\n+    my_cmap = mpl.cm.viridis\n+    bounds = np.arange(10)\n+    nb_colors = len(bounds) + 1\n+    colors = my_cmap(np.linspace(100, 255, nb_colors).astype(int))\n+    my_cmap, my_norm = from_levels_and_colors(bounds, colors, extend='both')\n+\n+    fig, ax = plt.subplots()\n+    cbar = mpl.colorbar.ColorbarBase(ax, cmap=my_cmap, norm=my_norm,\n+                                     orientation='horizontal', drawedges=True)\n+\n+    # The bug is that the edges of the extension patches are not drawn.\n+    # This is likely because their linewidth is 0. This assertion will fail\n+    # if the bug is present and pass when it is fixed.\n+    for patch in cbar._extend_patches:\n+        assert patch.get_linewidth() > 0\n"
    },
    "scikit-learn__scikit-learn-14710": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/ensemble/_hist_gradient_boosting/tests/test_hist_gradient_boosting_regressions.py",
        "reproduced_bug_commands": [
            "pytest sklearn/ensemble/_hist_gradient_boosting/tests/test_hist_gradient_boosting_regressions.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/ensemble/_hist_gradient_boosting/tests/test_hist_gradient_boosting_regressions.py b/sklearn/ensemble/_hist_gradient_boosting/tests/test_hist_gradient_boosting_regressions.py\nnew file mode 100644\nindex 0000000000..a96f299c98\n--- /dev/null\n+++ b/sklearn/ensemble/_hist_gradient_boosting/tests/test_hist_gradient_boosting_regressions.py\n@@ -0,0 +1,20 @@\n+import numpy as np\n+import pytest\n+\n+# To use this experimental feature, we need to explicitly ask for it:\n+from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n+from sklearn.ensemble import HistGradientBoostingClassifier\n+\n+\n+def test_early_stopping_with_string_target():\n+    \"\"\"Check that early stopping works with string classes.\n+\n+    Non-regression test for #14981.\n+    \"\"\"\n+    X = np.random.randn(100, 10)\n+    y = np.array(['x'] * 50 + ['y'] * 50, dtype=object)\n+    gbrt = HistGradientBoostingClassifier(n_iter_no_change=10)\n+\n+    # This should not raise:\n+    # TypeError: '<' not supported between instances of 'str' and 'float'\n+    gbrt.fit(X, y)\n"
    },
    "sympy__sympy-16792": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/utilities/tests/test_autowrap_bug.py",
        "reproduced_bug_commands": [
            "pytest sympy/utilities/tests/test_autowrap_bug.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/utilities/tests/test_autowrap_bug.py b/sympy/utilities/tests/test_autowrap_bug.py\nnew file mode 100644\nindex 0000000000..c70f56fc26\n--- /dev/null\n+++ b/sympy/utilities/tests/test_autowrap_bug.py\n@@ -0,0 +1,63 @@\n+import sympy\n+import tempfile\n+import os\n+from sympy import symbols, Eq, Mod, MatrixSymbol\n+from sympy.external import import_module\n+from sympy.tensor import IndexedBase, Idx\n+from sympy.utilities.autowrap import autowrap, ufuncify, CodeWrapError\n+from sympy.utilities.pytest import skip\n+\n+numpy = import_module('numpy', min_module_version='1.6.1')\n+Cython = import_module('Cython', min_module_version='0.15.1')\n+f2py = import_module('numpy.f2py', __import__kwargs={'fromlist': ['f2py']})\n+\n+f2pyworks = False\n+if f2py:\n+    try:\n+        autowrap(symbols('x'), 'f95', 'f2py')\n+    except (CodeWrapError, ImportError, OSError):\n+        f2pyworks = False\n+    else:\n+        f2pyworks = True\n+\n+a, b, c = symbols('a b c')\n+n, m, d = symbols('n m d', integer=True)\n+A, B, C = symbols('A B C', cls=IndexedBase)\n+i = Idx('i', m)\n+j = Idx('j', n)\n+k = Idx('k', d)\n+\n+\n+def has_module(module):\n+    \"\"\"\n+    Return True if module exists, otherwise run skip().\n+\n+    module should be a string.\n+    \"\"\"\n+    # To give a string of the module name to skip(), this function takes a\n+    # string.  So we don't waste time running import_module() more than once,\n+    # just map the three modules tested here in this dict.\n+    modnames = {'numpy': numpy, 'Cython': Cython, 'f2py': f2py}\n+\n+    if modnames[module]:\n+        if module == 'f2py' and not f2pyworks:\n+            skip(\"Couldn't run f2py.\")\n+        return True\n+    skip(\"Couldn't import %s.\" % module)\n+\n+\n+def test_autowrap_unused_array_argument_cython():\n+    \"\"\"\n+    Test for bug where array arguments that do not appear in the\n+    expression are not handled correctly by the cython backend.\n+    \"\"\"\n+    has_module('numpy')\n+    has_module('Cython')\n+\n+    x = MatrixSymbol('x', 2, 1)\n+    expr = 1.0\n+    f = autowrap(expr, args=(x,), backend='cython')\n+\n+    # This call fails with a TypeError, but should return 1.0\n+    # The array shape must match the MatrixSymbol dimensions.\n+    assert f(numpy.array([[1.0], [2.0]])) == 1.0\n"
    },
    "django__django-12325": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/invalid_models_tests/test_model_inheritance.py",
        "reproduced_bug_commands": [
            "python -m django test invalid_models_tests.test_model_inheritance"
        ],
        "reproduced_bug_patch": "diff --git a/tests/invalid_models_tests/test_model_inheritance.py b/tests/invalid_models_tests/test_model_inheritance.py\nnew file mode 100644\nindex 0000000000..c6b85e4732\n--- /dev/null\n+++ b/tests/invalid_models_tests/test_model_inheritance.py\n@@ -0,0 +1,25 @@\n+from django.db import models\n+from django.test import SimpleTestCase\n+from django.test.utils import isolate_apps\n+\n+\n+@isolate_apps('invalid_models_tests')\n+class ModelInheritanceTests(SimpleTestCase):\n+\n+    def test_multiple_o2o_to_parent_field_definition_order(self):\n+        \"\"\"\n+        A OneToOneField with parent_link=True should be found correctly even\n+        if it's not the last OneToOneField defined in the model.\n+        \"\"\"\n+        class Document(models.Model):\n+            pass\n+\n+        class Picking(Document):\n+            document_ptr = models.OneToOneField(\n+                Document, on_delete=models.CASCADE, parent_link=True, related_name='+'\n+            )\n+            origin = models.OneToOneField(\n+                Document, related_name='picking', on_delete=models.PROTECT\n+            )\n+\n+        self.assertEqual(Picking._meta.pk, Picking._meta.get_field('document_ptr'))\n"
    },
    "django__django-14915": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/model_forms/test_select_widget_bugs.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py model_forms.test_select_widget_bugs"
        ],
        "reproduced_bug_patch": "diff --git a/tests/model_forms/test_select_widget_bugs.py b/tests/model_forms/test_select_widget_bugs.py\nnew file mode 100644\nindex 0000000000..4b85ebe004\n--- /dev/null\n+++ b/tests/model_forms/test_select_widget_bugs.py\n@@ -0,0 +1,39 @@\n+from django import forms\n+from django.test import TestCase\n+\n+from .models import Category\n+\n+\n+class SelectWidgetBugsTest(TestCase):\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.cat = Category.objects.create(name='Test Category', slug='test-category', url='test-category')\n+\n+    def test_modelchoiceiteratorvalue_unhashable(self):\n+        \"\"\"\n+        A ModelChoiceIteratorValue should be hashable to allow it to be used\n+        in collections.\n+        \"\"\"\n+        class CustomSelect(forms.Select):\n+            def __init__(self, *args, **kwargs):\n+                self.show_fields = kwargs.pop('show_fields', {})\n+                super().__init__(*args, **kwargs)\n+\n+            def create_option(self, name, value, label, selected, index, subindex=None, attrs=None):\n+                # This check fails with \"TypeError: unhashable type:\n+                # 'ModelChoiceIteratorValue'\" because `value` is an object,\n+                # not a simple PK.\n+                if value in self.show_fields:\n+                    pass\n+                return super().create_option(name, value, label, selected, index, subindex, attrs)\n+\n+        class CategoryForm(forms.Form):\n+            category = forms.ModelChoiceField(\n+                queryset=Category.objects.all(),\n+                widget=CustomSelect(show_fields={self.cat.pk: ['field']}),\n+            )\n+\n+        form = CategoryForm()\n+        # Rendering the form calls create_option() for each choice. This test\n+        # will fail with a TypeError before the fix and pass after.\n+        form.as_p()\n"
    },
    "matplotlib__matplotlib-22871": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_concise_date_formatter.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_concise_date_formatter.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_concise_date_formatter.py b/lib/matplotlib/tests/test_concise_date_formatter.py\nnew file mode 100644\nindex 0000000000..d94b510766\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_concise_date_formatter.py\n@@ -0,0 +1,29 @@\n+import matplotlib.pyplot as plt\n+import matplotlib.dates as mdates\n+from datetime import datetime, timedelta\n+import pytest\n+\n+def test_concise_formatter_no_january():\n+    \"\"\"\n+    Test that ConciseDateFormatter shows the year in the offset when the\n+    plotted range is less than a year and does not include January.\n+    \"\"\"\n+    # create time array\n+    initial = datetime(2021, 2, 14, 0, 0, 0)\n+    time_array = [initial + timedelta(days=x) for x in range(1, 200)]\n+\n+    # create data array\n+    data = [-x**2/20000 for x in range(1, 200)]\n+\n+    # plot data\n+    fig, ax = plt.subplots()\n+    ax.plot(time_array, data)\n+\n+    locator = mdates.AutoDateLocator()\n+    formatter = mdates.ConciseDateFormatter(locator)\n+\n+    ax.xaxis.set_major_locator(locator)\n+    ax.xaxis.set_major_formatter(formatter)\n+    fig.canvas.draw()\n+\n+    assert formatter.get_offset() == '2021'\n"
    },
    "scikit-learn__scikit-learn-14894": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/svm/tests/test_svr_sparse_empty_support_vectors.py",
        "reproduced_bug_commands": [
            "pytest sklearn/svm/tests/test_svr_sparse_empty_support_vectors.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/svm/tests/test_svr_sparse_empty_support_vectors.py b/sklearn/svm/tests/test_svr_sparse_empty_support_vectors.py\nnew file mode 100644\nindex 0000000000..7117e26cfa\n--- /dev/null\n+++ b/sklearn/svm/tests/test_svr_sparse_empty_support_vectors.py\n@@ -0,0 +1,31 @@\n+import numpy as np\n+import pytest\n+from scipy import sparse\n+from sklearn.svm import SVR\n+\n+\n+def test_svr_sparse_empty_support_vectors():\n+    \"\"\"Test for ZeroDivisionError in SVR._sparse_fit.\n+\n+    When fitting on sparse data and the resulting `support_vectors_`\n+    is empty, a ZeroDivisionError was raised.\n+\n+    Regression test for scikit-learn/scikit-learn#14892.\n+    \"\"\"\n+    x_train = np.array([[0, 1, 0, 0],\n+                        [0, 0, 0, 1],\n+                        [0, 0, 1, 0],\n+                        [0, 0, 0, 1]])\n+    y_train = np.array([0.04, 0.04, 0.10, 0.16])\n+    model = SVR(C=316.227766017, cache_size=200, coef0=0.0, degree=3,\n+                epsilon=0.1, gamma=1.0, kernel='linear', max_iter=15000,\n+                shrinking=True, tol=0.001, verbose=False)\n+\n+    # convert to sparse\n+    xtrain_sparse = sparse.csr_matrix(x_train)\n+\n+    # This should not raise a ZeroDivisionError\n+    model.fit(xtrain_sparse, y_train)\n+\n+    # The model should fit without error and result in zero support vectors.\n+    assert len(model.support_) == 0\n"
    },
    "sympy__sympy-16886": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/crypto/tests/test_morse_code.py",
        "reproduced_bug_commands": [
            "pytest sympy/crypto/tests/test_morse_code.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/crypto/tests/test_morse_code.py b/sympy/crypto/tests/test_morse_code.py\nnew file mode 100644\nindex 0000000000..4903f826a6\n--- /dev/null\n+++ b/sympy/crypto/tests/test_morse_code.py\n@@ -0,0 +1,11 @@\n+from sympy.crypto.crypto import encode_morse\n+\n+\n+def test_morse_code_for_1():\n+    \"\"\"\n+    Tests the morse encoding for the digit \"1\".\n+\n+    The correct encoding is \".----\", but a bug in the mapping\n+    caused it to be \"----\".\n+    \"\"\"\n+    assert encode_morse(\"1\") == \".----\"\n"
    },
    "django__django-12406": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/model_forms/test_base.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py model_forms.test_base"
        ],
        "reproduced_bug_patch": "diff --git a/tests/model_forms/test_base.py b/tests/model_forms/test_base.py\nnew file mode 100644\nindex 0000000000..7c2d6fb3e4\n--- /dev/null\n+++ b/tests/model_forms/test_base.py\n@@ -0,0 +1,526 @@\n+import datetime\n+import os\n+from decimal import Decimal\n+from unittest import mock, skipUnless\n+\n+from django import forms\n+from django.core.exceptions import (\n+    NON_FIELD_ERRORS, FieldError, ImproperlyConfigured,\n+)\n+from django.core.files.uploadedfile import SimpleUploadedFile\n+from django.core.validators import ValidationError\n+from django.db import connection, models\n+from django.db.models.query import EmptyQuerySet\n+from django.forms.models import (\n+    ModelFormMetaclass, construct_instance, fields_for_model, model_to_dict,\n+    modelform_factory,\n+)\n+from django.template import Context, Template\n+from django.test import SimpleTestCase, TestCase, skipUnlessDBFeature\n+\n+from .models import (\n+    Article, ArticleStatus, Author, Author1, Award, BetterWriter, BigInt, Book,\n+    Category, Character, Colour, ColourfulItem, CustomErrorMessage, CustomFF,\n+    CustomFieldForExclusionModel, DateTimePost, DerivedBook, DerivedPost,\n+    Document, ExplicitPK, FilePathModel, FlexibleDatePost, Homepage,\n+    ImprovedArticle, ImprovedArticleWithParentLink, Inventory,\n+    NullableUniqueCharFieldModel, Person, Photo, Post, Price, Product,\n+    Publication, PublicationDefaults, StrictAssignmentAll,\n+    StrictAssignmentFieldSpecific, Student, StumpJoke, TextFile, Triple,\n+    Writer, WriterProfile, test_images,\n+)\n+\n+if test_images:\n+    from .models import ImageFile, OptionalImageFile, NoExtensionImageFile\n+\n+    class ImageFileForm(forms.ModelForm):\n+        class Meta:\n+            model = ImageFile\n+            fields = '__all__'\n+\n+    class OptionalImageFileForm(forms.ModelForm):\n+        class Meta:\n+            model = OptionalImageFile\n+            fields = '__all__'\n+\n+    class NoExtensionImageFileForm(forms.ModelForm):\n+        class Meta:\n+            model = NoExtensionImageFile\n+            fields = '__all__'\n+\n+\n+class ProductForm(forms.ModelForm):\n+    class Meta:\n+        model = Product\n+        fields = '__all__'\n+\n+\n+class PriceForm(forms.ModelForm):\n+    class Meta:\n+        model = Price\n+        fields = '__all__'\n+\n+\n+class BookForm(forms.ModelForm):\n+    class Meta:\n+        model = Book\n+        fields = '__all__'\n+\n+\n+class DerivedBookForm(forms.ModelForm):\n+    class Meta:\n+        model = DerivedBook\n+        fields = '__all__'\n+\n+\n+class ExplicitPKForm(forms.ModelForm):\n+    class Meta:\n+        model = ExplicitPK\n+        fields = ('key', 'desc',)\n+\n+\n+class PostForm(forms.ModelForm):\n+    class Meta:\n+        model = Post\n+        fields = '__all__'\n+\n+\n+class DerivedPostForm(forms.ModelForm):\n+    class Meta:\n+        model = DerivedPost\n+        fields = '__all__'\n+\n+\n+class CustomWriterForm(forms.ModelForm):\n+    name = forms.CharField(required=False)\n+\n+    class Meta:\n+        model = Writer\n+        fields = '__all__'\n+\n+\n+class BaseCategoryForm(forms.ModelForm):\n+    class Meta:\n+        model = Category\n+        fields = '__all__'\n+\n+\n+class ArticleForm(forms.ModelForm):\n+    class Meta:\n+        model = Article\n+        fields = '__all__'\n+\n+\n+class RoykoForm(forms.ModelForm):\n+    class Meta:\n+        model = Writer\n+        fields = '__all__'\n+\n+\n+class ArticleStatusForm(forms.ModelForm):\n+    class Meta:\n+        model = ArticleStatus\n+        fields = '__all__'\n+\n+\n+class InventoryForm(forms.ModelForm):\n+    class Meta:\n+        model = Inventory\n+        fields = '__all__'\n+\n+\n+class SelectInventoryForm(forms.Form):\n+    items = forms.ModelMultipleChoiceField(Inventory.objects.all(), to_field_name='barcode')\n+\n+\n+class CustomFieldForExclusionForm(forms.ModelForm):\n+    class Meta:\n+        model = CustomFieldForExclusionModel\n+        fields = ['name', 'markup']\n+\n+\n+class TextFileForm(forms.ModelForm):\n+    class Meta:\n+        model = TextFile\n+        fields = '__all__'\n+\n+\n+class BigIntForm(forms.ModelForm):\n+    class Meta:\n+        model = BigInt\n+        fields = '__all__'\n+\n+\n+class ModelFormWithMedia(forms.ModelForm):\n+    class Media:\n+        js = ('/some/form/javascript',)\n+        css = {\n+            'all': ('/some/form/css',)\n+        }\n+\n+    class Meta:\n+        model = TextFile\n+        fields = '__all__'\n+\n+\n+class CustomErrorMessageForm(forms.ModelForm):\n+    name1 = forms.CharField(error_messages={'invalid': 'Form custom error message.'})\n+\n+    class Meta:\n+        fields = '__all__'\n+        model = CustomErrorMessage\n+\n+\n+class ModelFormBaseTest(TestCase):\n+    def test_base_form(self):\n+        self.assertEqual(list(BaseCategoryForm.base_fields), ['name', 'slug', 'url'])\n+\n+    def test_no_model_class(self):\n+        class NoModelModelForm(forms.ModelForm):\n+            pass\n+        with self.assertRaisesMessage(ValueError, 'ModelForm has no model class specified.'):\n+            NoModelModelForm()\n+\n+    def test_empty_fields_to_fields_for_model(self):\n+        \"\"\"\n+        An argument of fields=() to fields_for_model should return an empty dictionary\n+        \"\"\"\n+        field_dict = fields_for_model(Person, fields=())\n+        self.assertEqual(len(field_dict), 0)\n+\n+    def test_empty_fields_on_modelform(self):\n+        \"\"\"\n+        No fields on a ModelForm should actually result in no fields.\n+        \"\"\"\n+        class EmptyPersonForm(forms.ModelForm):\n+            class Meta:\n+                model = Person\n+                fields = ()\n+\n+        form = EmptyPersonForm()\n+        self.assertEqual(len(form.fields), 0)\n+\n+    def test_empty_fields_to_construct_instance(self):\n+        \"\"\"\n+        No fields should be set on a model instance if construct_instance receives fields=().\n+        \"\"\"\n+        form = modelform_factory(Person, fields=\"__all__\")({'name': 'John Doe'})\n+        self.assertTrue(form.is_valid())\n+        instance = construct_instance(form, Person(), fields=())\n+        self.assertEqual(instance.name, '')\n+\n+    def test_blank_with_null_foreign_key_field(self):\n+        \"\"\"\n+        #13776 -- ModelForm's with models having a FK set to null=False and\n+        required=False should be valid.\n+        \"\"\"\n+        class FormForTestingIsValid(forms.ModelForm):\n+            class Meta:\n+                model = Student\n+                fields = '__all__'\n+\n+            def __init__(self, *args, **kwargs):\n+                super().__init__(*args, **kwargs)\n+                self.fields['character'].required = False\n+\n+        char = Character.objects.create(username='user', last_action=datetime.datetime.today())\n+        data = {'study': 'Engineering'}\n+        data2 = {'study': 'Engineering', 'character': char.pk}\n+\n+        # form is valid because required=False for field 'character'\n+        f1 = FormForTestingIsValid(data)\n+        self.assertTrue(f1.is_valid())\n+\n+        f2 = FormForTestingIsValid(data2)\n+        self.assertTrue(f2.is_valid())\n+        obj = f2.save()\n+        self.assertEqual(obj.character, char)\n+\n+    def test_blank_false_with_null_true_foreign_key_field(self):\n+        \"\"\"\n+        A ModelForm with a model having ForeignKey(blank=False, null=True)\n+        and the form field set to required=False should allow the field to be\n+        unset.\n+        \"\"\"\n+        class AwardForm(forms.ModelForm):\n+            class Meta:\n+                model = Award\n+                fields = '__all__'\n+\n+            def __init__(self, *args, **kwargs):\n+                super().__init__(*args, **kwargs)\n+                self.fields['character'].required = False\n+\n+        character = Character.objects.create(username='user', last_action=datetime.datetime.today())\n+        award = Award.objects.create(name='Best sprinter', character=character)\n+        data = {'name': 'Best tester', 'character': ''}  # remove character\n+        form = AwardForm(data=data, instance=award)\n+        self.assertTrue(form.is_valid())\n+        award = form.save()\n+        self.assertIsNone(award.character)\n+\n+    def test_foreignkey_radioselect_required_no_initial_checked(self):\n+        \"\"\"\n+        A ModelForm with a required ForeignKey (blank=False) rendered as a\n+        RadioSelect should not have a checked option on a new form.\n+        \"\"\"\n+        # Create a character so the queryset for the foreign key is not empty.\n+        Character.objects.create(username='user', last_action=datetime.datetime.today())\n+\n+        # Define the form with the RadioSelect widget.\n+        class AwardForm(forms.ModelForm):\n+            class Meta:\n+                model = Award\n+                fields = ['character']\n+                widgets = {\n+                    'character': forms.RadioSelect,\n+                }\n+\n+        # This form represents a new Award, so no character is selected yet.\n+        form = AwardForm()\n+\n+        # The field is required in the form (blank=False), so there should\n+        # be no choice pre-selected. The bug is that the blank choice\n+        # \"---------\" is rendered and checked.\n+        self.assertNotIn('checked', str(form['character']))\n+\n+    def test_save_blank_false_with_required_false(self):\n+        \"\"\"\n+        A ModelForm with a model with a field set to blank=False and the form\n+        field set to required=False should allow the field to be unset.\n+        \"\"\"\n+        obj = Writer.objects.create(name='test')\n+        form = CustomWriterForm(data={'name': ''}, instance=obj)\n+        self.assertTrue(form.is_valid())\n+        obj = form.save()\n+        self.assertEqual(obj.name, '')\n+\n+    def test_save_blank_null_unique_charfield_saves_null(self):\n+        form_class = modelform_factory(model=NullableUniqueCharFieldModel, fields=['codename'])\n+        empty_value = '' if connection.features.interprets_empty_strings_as_nulls else None\n+\n+        form = form_class(data={'codename': ''})\n+        self.assertTrue(form.is_valid())\n+        form.save()\n+        self.assertEqual(form.instance.codename, empty_value)\n+\n+        # Save a second form to verify there isn't a unique constraint violation.\n+        form = form_class(data={'codename': ''})\n+        self.assertTrue(form.is_valid())\n+        form.save()\n+        self.assertEqual(form.instance.codename, empty_value)\n+\n+    def test_missing_fields_attribute(self):\n+        message = (\n+            \"Creating a ModelForm without either the 'fields' attribute \"\n+            \"or the 'exclude' attribute is prohibited; form \"\n+            \"MissingFieldsForm needs updating.\"\n+        )\n+        with self.assertRaisesMessage(ImproperlyConfigured, message):\n+            class MissingFieldsForm(forms.ModelForm):\n+                class Meta:\n+                    model = Category\n+\n+    def test_extra_fields(self):\n+        class ExtraFields(BaseCategoryForm):\n+            some_extra_field = forms.BooleanField()\n+\n+        self.assertEqual(list(ExtraFields.base_fields),\n+                         ['name', 'slug', 'url', 'some_extra_field'])\n+\n+    def test_extra_field_model_form(self):\n+        with self.assertRaisesMessage(FieldError, 'no-field'):\n+            class ExtraPersonForm(forms.ModelForm):\n+                \"\"\" ModelForm with an extra field \"\"\"\n+                age = forms.IntegerField()\n+\n+                class Meta:\n+                    model = Person\n+                    fields = ('name', 'no-field')\n+\n+    def test_extra_declared_field_model_form(self):\n+        class ExtraPersonForm(forms.ModelForm):\n+            \"\"\" ModelForm with an extra field \"\"\"\n+            age = forms.IntegerField()\n+\n+            class Meta:\n+                model = Person\n+                fields = ('name', 'age')\n+\n+    def test_extra_field_modelform_factory(self):\n+        with self.assertRaisesMessage(FieldError, 'Unknown field(s) (no-field) specified for Person'):\n+            modelform_factory(Person, fields=['no-field', 'name'])\n+\n+    def test_replace_field(self):\n+        class ReplaceField(forms.ModelForm):\n+            url = forms.BooleanField()\n+\n+            class Meta:\n+                model = Category\n+                fields = '__all__'\n+\n+        self.assertIsInstance(ReplaceField.base_fields['url'], forms.fields.BooleanField)\n+\n+    def test_replace_field_variant_2(self):\n+        # Should have the same result as before,\n+        # but 'fields' attribute specified differently\n+        class ReplaceField(forms.ModelForm):\n+            url = forms.BooleanField()\n+\n+            class Meta:\n+                model = Category\n+                fields = ['url']\n+\n+        self.assertIsInstance(ReplaceField.base_fields['url'], forms.fields.BooleanField)\n+\n+    def test_replace_field_variant_3(self):\n+        # Should have the same result as before,\n+        # but 'fields' attribute specified differently\n+        class ReplaceField(forms.ModelForm):\n+            url = forms.BooleanField()\n+\n+            class Meta:\n+                model = Category\n+                fields = []  # url will still appear, since it is explicit above\n+\n+        self.assertIsInstance(ReplaceField.base_fields['url'], forms.fields.BooleanField)\n+\n+    def test_override_field(self):\n+        class WriterForm(forms.ModelForm):\n+            book = forms.CharField(required=False)\n+\n+            class Meta:\n+                model = Writer\n+                fields = '__all__'\n+\n+        wf = WriterForm({'name': 'Richard Lockridge'})\n+        self.assertTrue(wf.is_valid())\n+\n+    def test_limit_nonexistent_field(self):\n+        expected_msg = 'Unknown field(s) (nonexistent) specified for Category'\n+        with self.assertRaisesMessage(FieldError, expected_msg):\n+            class InvalidCategoryForm(forms.ModelForm):\n+                class Meta:\n+                    model = Category\n+                    fields = ['nonexistent']\n+\n+    def test_limit_fields_with_string(self):\n+        expected_msg = \"CategoryForm.Meta.fields cannot be a string. Did you mean to type: ('url',)?\"\n+        with self.assertRaisesMessage(TypeError, expected_msg):\n+            class CategoryForm(forms.ModelForm):\n+                class Meta:\n+                    model = Category\n+                    fields = ('url')  # note the missing comma\n+\n+    def test_exclude_fields(self):\n+        class ExcludeFields(forms.ModelForm):\n+            class Meta:\n+                model = Category\n+                exclude = ['url']\n+\n+        self.assertEqual(list(ExcludeFields.base_fields), ['name', 'slug'])\n+\n+    def test_exclude_nonexistent_field(self):\n+        class ExcludeFields(forms.ModelForm):\n+            class Meta:\n+                model = Category\n+                exclude = ['nonexistent']\n+\n+        self.assertEqual(list(ExcludeFields.base_fields), ['name', 'slug', 'url'])\n+\n+    def test_exclude_fields_with_string(self):\n+        expected_msg = \"CategoryForm.Meta.exclude cannot be a string. Did you mean to type: ('url',)?\"\n+        with self.assertRaisesMessage(TypeError, expected_msg):\n+            class CategoryForm(forms.ModelForm):\n+                class Meta:\n+                    model = Category\n+                    exclude = ('url')  # note the missing comma\n+\n+    def test_exclude_and_validation(self):\n+        # This Price instance generated by this form is not valid because the quantity\n+        # field is required, but the form is valid because the field is excluded from\n+        # the form. This is for backwards compatibility.\n+        class PriceFormWithoutQuantity(forms.ModelForm):\n+            class Meta:\n+                model = Price\n+                exclude = ('quantity',)\n+\n+        form = PriceFormWithoutQuantity({'price': '6.00'})\n+        self.assertTrue(form.is_valid())\n+        price = form.save(commit=False)\n+        msg = \"{'quantity': ['This field cannot be null.']}\"\n+        with self.assertRaisesMessage(ValidationError, msg):\n+            price.full_clean()\n+\n+        # The form should not validate fields that it doesn't contain even if they are\n+        # specified using 'fields', not 'exclude'.\n+        class PriceFormWithoutQuantity(forms.ModelForm):\n+            class Meta:\n+                model = Price\n+                fields = ('price',)\n+        form = PriceFormWithoutQuantity({'price': '6.00'})\n+        self.assertTrue(form.is_valid())\n+\n+        # The form should still have an instance of a model that is not complete and\n+        # not saved into a DB yet.\n+        self.assertEqual(form.instance.price, Decimal('6.00'))\n+        self.assertIsNone(form.instance.quantity)\n+        self.assertIsNone(form.instance.pk)\n+\n+    def test_confused_form(self):\n+        class ConfusedForm(forms.ModelForm):\n+            \"\"\" Using 'fields' *and* 'exclude'. Not sure why you'd want to do\n+            this, but uh, \"be liberal in what you accept\" and all.\n+            \"\"\"\n+            class Meta:\n+                model = Category\n+                fields = ['name', 'url']\n+                exclude = ['url']\n+\n+        self.assertEqual(list(ConfusedForm.base_fields),\n+                         ['name'])\n+\n+    def test_mixmodel_form(self):\n+        class MixModelForm(BaseCategoryForm):\n+            \"\"\" Don't allow more than one 'model' definition in the\n+            inheritance hierarchy.  Technically, it would generate a valid\n+            form, but the fact that the resulting save method won't deal with\n+            multiple objects is likely to trip up people not familiar with the\n+            mechanics.\n+            \"\"\"\n+            class Meta:\n+                model = Article\n+                fields = '__all__'\n+            # MixModelForm is now an Article-related thing, because MixModelForm.Meta\n+            # overrides BaseCategoryForm.Meta.\n+\n+        self.assertEqual(\n+            list(MixModelForm.base_fields),\n+            ['headline', 'slug', 'pub_date', 'writer', 'article', 'categories', 'status']\n+        )\n+\n+    def test_article_form(self):\n+        self.assertEqual(\n+            list(ArticleForm.base_fields),\n+            ['headline', 'slug', 'pub_date', 'writer', 'article', 'categories', 'status']\n+        )\n+\n+    def test_bad_form(self):\n+        # First class with a Meta class wins...\n+        class BadForm(ArticleForm, BaseCategoryForm):\n+            pass\n+\n+        self.assertEqual(\n+            list(BadForm.base_fields),\n+            ['headline', 'slug', 'pub_date', 'writer', 'article', 'categories', 'status']\n+        )\n+\n+    def test_invalid_meta_model(self):\n+        class InvalidModelForm(forms.ModelForm):\n+            class Meta:\n+                pass  # no model\n+\n+        # Can't create new form\n+        msg = 'ModelForm has no model class specified.'\n+        with self.assertRaisesMessage(ValueError, msg):\n+            InvalidModelForm()\n"
    },
    "django__django-14999": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "matplotlib__matplotlib-23299": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "scikit-learn__scikit-learn-14983": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/model_selection/tests/test_repeated_cross_validator.py",
        "reproduced_bug_commands": [
            "pytest sklearn/model_selection/tests/test_repeated_cross_validator.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/model_selection/tests/test_repeated_cross_validator.py b/sklearn/model_selection/tests/test_repeated_cross_validator.py\nnew file mode 100644\nindex 0000000000..f29be72920\n--- /dev/null\n+++ b/sklearn/model_selection/tests/test_repeated_cross_validator.py\n@@ -0,0 +1,17 @@\n+import numpy as np\n+\n+from sklearn.model_selection import RepeatedKFold\n+from sklearn.model_selection import RepeatedStratifiedKFold\n+\n+\n+def test_repeated_cross_validator_repr():\n+    \"\"\"Check the __repr__ methods of RepeatedKFold and RepeatedStratifiedKFold.\"\"\"\n+    # Test for RepeatedKFold\n+    rkf = RepeatedKFold()\n+    expected_rkf_repr = \"RepeatedKFold(n_splits=5, n_repeats=10, random_state=None)\"\n+    assert repr(rkf) == expected_rkf_repr\n+\n+    # Test for RepeatedStratifiedKFold\n+    rskf = RepeatedStratifiedKFold()\n+    expected_rskf_repr = \"RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=None)\"\n+    assert repr(rskf) == expected_rskf_repr\n"
    },
    "sympy__sympy-17139": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/simplify/tests/test_simplify_complex.py",
        "reproduced_bug_commands": [
            "bin/test sympy/simplify/tests/test_simplify_complex.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/simplify/tests/test_simplify_complex.py b/sympy/simplify/tests/test_simplify_complex.py\nnew file mode 100644\nindex 0000000000..1ae18509ac\n--- /dev/null\n+++ b/sympy/simplify/tests/test_simplify_complex.py\n@@ -0,0 +1,16 @@\n+from sympy import (\n+    Add, Mul, S, Symbol, cos, cot, pi, I, sin, sqrt, tan, root, csc, sec,\n+    powsimp, symbols, sinh, cosh, tanh, coth, sech, csch, Dummy, simplify)\n+from sympy.simplify.fu import (\n+    L, TR1, TR10, TR10i, TR11, TR12, TR12i, TR13, TR14, TR15, TR16,\n+    TR111, TR2, TR2i, TR3, TR5, TR6, TR7, TR8, TR9, TRmorrie, _TR56 as T,\n+    TRpower, hyper_as_trig, fu, process_common_addends, trig_split,\n+    as_f_sign_1)\n+from sympy.utilities.randtest import verify_numerically\n+from sympy.core.compatibility import range\n+from sympy.abc import a, b, c, x, y, z\n+\n+\n+def test_simplify_complex_power():\n+    \"\"\"Test case for simplifying trig function with complex power.\"\"\"\n+    assert simplify(cos(x)**I) == cos(x)**I\n"
    },
    "matplotlib__matplotlib-23314": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/mpl_toolkits/tests/test_axes3d.py",
        "reproduced_bug_commands": [
            "pytest lib/mpl_toolkits/tests/test_axes3d_bug.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/mpl_toolkits/tests/test_axes3d.py b/lib/mpl_toolkits/tests/test_axes3d.py\nnew file mode 100644\nindex 0000000000..7063c643a3\n--- /dev/null\n+++ b/lib/mpl_toolkits/tests/test_axes3d.py\n@@ -0,0 +1,19 @@\n+import matplotlib.pyplot as plt\n+import pytest\n+from mpl_toolkits.mplot3d import Axes3D\n+\n+\n+def test_set_visible_3d():\n+    \"\"\"\n+    Tests that set_visible(False) makes a 3D axes invisible.\n+\n+    Regression test for a bug where ``ax.set_visible(False)`` was not\n+    respected for 3D axes.\n+    \"\"\"\n+    fig = plt.figure()\n+    ax = fig.add_subplot(projection='3d')\n+    ax.set_visible(False)\n+    fig.canvas.draw()\n+    # A point in the middle of the figure.\n+    x, y = fig.bbox.width / 2, fig.bbox.height / 2\n+    assert fig.canvas.inaxes((x, y)) is None\n"
    },
    "scikit-learn__scikit-learn-15100": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/feature_extraction/tests/test_text_nfkd.py",
        "reproduced_bug_commands": [
            "pytest sklearn/feature_extraction/tests/test_text_nfkd.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/feature_extraction/tests/test_text_nfkd.py b/sklearn/feature_extraction/tests/test_text_nfkd.py\nnew file mode 100644\nindex 0000000000..d1266cb32f\n--- /dev/null\n+++ b/sklearn/feature_extraction/tests/test_text_nfkd.py\n@@ -0,0 +1,21 @@\n+# -*- coding: utf-8 -*-\n+import pytest\n+from sklearn.feature_extraction.text import strip_accents_unicode\n+\n+\n+def test_strip_accents_unicode_nfkd():\n+    \"\"\"Check that strip_accents_unicode works on NFKD-normalized strings.\n+\n+    Non-regression test for:\n+    https://github.com/scikit-learn/scikit-learn/issues/15089\n+    \"\"\"\n+    # The following two strings are visually identical and should be stripped to\n+    # the same character.\n+    # s1 contains a single character, \"LATIN SMALL LETTER N WITH TILDE\"\n+    s1 = chr(241)\n+    # s2 contains two characters, \"LATIN SMALL LETTER N\" and \"COMBINING TILDE\"\n+    s2 = chr(110) + chr(771)\n+\n+    # Both should be stripped to \"n\"\n+    assert strip_accents_unicode(s1) == \"n\"\n+    assert strip_accents_unicode(s2) == \"n\"\n"
    },
    "django__django-15022": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/admin_changelist/test_search.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py admin_changelist.test_search"
        ],
        "reproduced_bug_patch": "diff --git a/tests/admin_changelist/test_search.py b/tests/admin_changelist/test_search.py\nnew file mode 100644\nindex 0000000000..c39b0837fe\n--- /dev/null\n+++ b/tests/admin_changelist/test_search.py\n@@ -0,0 +1,95 @@\n+import datetime\n+\n+from django.contrib import admin\n+from django.contrib.admin.models import LogEntry\n+from django.contrib.admin.options import IncorrectLookupParameters\n+from django.contrib.admin.templatetags.admin_list import pagination\n+from django.contrib.admin.tests import AdminSeleniumTestCase\n+from django.contrib.admin.views.main import (\n+    ALL_VAR, IS_POPUP_VAR, ORDER_VAR, PAGE_VAR, SEARCH_VAR, TO_FIELD_VAR,\n+)\n+from django.contrib.auth.models import User\n+from django.contrib.contenttypes.models import ContentType\n+from django.contrib.messages.storage.cookie import CookieStorage\n+from django.db import connection, models\n+from django.db.models import F, Field, IntegerField\n+from django.db.models.functions import Upper\n+from django.db.models.lookups import Contains, Exact\n+from django.template import Context, Template, TemplateSyntaxError\n+from django.test import TestCase, override_settings\n+from django.test.client import RequestFactory\n+from django.test.utils import (\n+    CaptureQueriesContext, isolate_apps, register_lookup,\n+)\n+from django.urls import reverse\n+from django.utils import formats\n+\n+from .admin import (\n+    BandAdmin, ChildAdmin, ChordsBandAdmin, ConcertAdmin,\n+    CustomPaginationAdmin, CustomPaginator, DynamicListDisplayChildAdmin,\n+    DynamicListDisplayLinksChildAdmin, DynamicListFilterChildAdmin,\n+    DynamicSearchFieldsChildAdmin, EmptyValueChildAdmin, EventAdmin,\n+    FilteredChildAdmin, GroupAdmin, InvitationAdmin,\n+    NoListDisplayLinksParentAdmin, ParentAdmin, QuartetAdmin, SwallowAdmin,\n+    site as custom_site,\n+)\n+from .models import (\n+    Band, CharPK, Child, ChordsBand, ChordsMusician, Concert, CustomIdUser,\n+    Event, Genre, Group, Invitation, Membership, Musician, OrderedObject,\n+    Parent, Quartet, Swallow, SwallowOneToOne, UnorderedObject,\n+)\n+\n+\n+# Models from the bug report, defined here for this test case.\n+# The test runner will automatically create tables for them.\n+class Client(models.Model):\n+    name = models.CharField('name', max_length=256)\n+    name2 = models.CharField('unofficial or obsolete name', max_length=256, blank=True, null=True)\n+    contact_person = models.CharField('contact person', max_length=256, blank=True, null=True)\n+\n+    class Meta:\n+        app_label = 'admin_changelist'\n+\n+\n+class ClientOffice(models.Model):\n+    name = models.CharField('name', max_length=256)\n+    name2 = models.CharField('unofficial or obsolete name', max_length=256, blank=True, null=True)\n+    client = models.ForeignKey(Client, on_delete=models.CASCADE, verbose_name='client')\n+\n+    class Meta:\n+        app_label = 'admin_changelist'\n+\n+\n+@isolate_apps('admin_changelist')\n+@override_settings(ROOT_URLCONF=\"admin_changelist.urls\")\n+class ChangeListSearchTests(TestCase):\n+    factory = RequestFactory()\n+\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.superuser = User.objects.create_superuser(username='super', email='a@b.com', password='xxx')\n+        client = Client.objects.create(name='Some Client')\n+        ClientOffice.objects.create(client=client, name='foo bar office')\n+\n+    def test_unnecessary_joins_in_changelist_search(self):\n+        \"\"\"\n+        Searching with multiple terms on a related field shouldn't create\n+        unnecessary joins.\n+        \"\"\"\n+        class ClientAdmin(admin.ModelAdmin):\n+            search_fields = ('clientoffice__name',)\n+\n+        m = ClientAdmin(Client, custom_site)\n+        request = self.factory.get('/', data={SEARCH_VAR: 'foo bar'})\n+        request.user = self.superuser\n+\n+        with CaptureQueriesContext(connection) as context:\n+            cl = m.get_changelist_instance(request)\n+            # Evaluating the queryset will run the query.\n+            # This also sanity-checks that the result is correct.\n+            self.assertEqual(len(cl.queryset), 1)\n+\n+        # The bug creates a JOIN for each search term (\"foo\", \"bar\").\n+        # With the fix, there should be only one JOIN to the clientoffice table.\n+        # Django uses LEFT OUTER JOIN for these lookups.\n+        self.assertEqual(context.captured_queries[0]['sql'].upper().count('LEFT OUTER JOIN'), 1)\n"
    },
    "django__django-12419": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/middleware/test_security_2.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py middleware.test_security_2"
        ],
        "reproduced_bug_patch": "diff --git a/tests/middleware/test_security_2.py b/tests/middleware/test_security_2.py\nnew file mode 100644\nindex 0000000000..a85edfc680\n--- /dev/null\n+++ b/tests/middleware/test_security_2.py\n@@ -0,0 +1,50 @@\n+from django.http import HttpResponse\n+from django.test import RequestFactory, SimpleTestCase\n+from django.test.utils import override_settings\n+\n+\n+class SecurityMiddlewareTest(SimpleTestCase):\n+    @property\n+    def middleware(self):\n+        from django.middleware.security import SecurityMiddleware\n+        return SecurityMiddleware()\n+\n+    @property\n+    def secure_request_kwargs(self):\n+        return {\"wsgi.url_scheme\": \"https\"}\n+\n+    def response(self, *args, headers=None, **kwargs):\n+        response = HttpResponse(*args, **kwargs)\n+        if headers:\n+            for k, v in headers.items():\n+                response[k] = v\n+        return response\n+\n+    def process_response(self, *args, secure=False, request=None, **kwargs):\n+        request_kwargs = {}\n+        if secure:\n+            request_kwargs.update(self.secure_request_kwargs)\n+        if request is None:\n+            request = self.request.get(\"/some/url\", **request_kwargs)\n+        ret = self.middleware.process_request(request)\n+        if ret:\n+            return ret\n+        return self.middleware.process_response(\n+            request, self.response(*args, **kwargs))\n+\n+    request = RequestFactory()\n+\n+    def process_request(self, method, *args, secure=False, **kwargs):\n+        if secure:\n+            kwargs.update(self.secure_request_kwargs)\n+        req = getattr(self.request, method.lower())(*args, **kwargs)\n+        return self.middleware.process_request(req)\n+\n+    def test_referrer_policy_default(self):\n+        \"\"\"\n+        The default Referrer-Policy header is \"same-origin\".\n+        \"\"\"\n+        # This test will fail if SECURE_REFERRER_POLICY defaults to None.\n+        # It will pass when the default is changed to 'same-origin'.\n+        response = self.process_response()\n+        self.assertEqual(response.get('Referrer-Policy'), 'same-origin')\n"
    },
    "sympy__sympy-17318": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "django__django-12663": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "django__django-15037": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "matplotlib__matplotlib-23412": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_patch_dash_offset.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_patch_dash_offset.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_patch_dash_offset.py b/lib/matplotlib/tests/test_patch_dash_offset.py\nnew file mode 100644\nindex 0000000000..4945dbb3a6\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_patch_dash_offset.py\n@@ -0,0 +1,44 @@\n+import pytest\n+import matplotlib.patches as mpatches\n+import matplotlib.lines as mlines\n+from matplotlib.testing.decorators import check_figures_equal\n+\n+\n+@check_figures_equal()\n+def test_patch_dash_offset(fig_test, fig_ref):\n+    \"\"\"\n+    Test that the dash offset for patches is honored.\n+\n+    A patch with a given dash style is compared to a line with the same\n+    style. The line is known to render correctly.\n+    \"\"\"\n+    # Use a zero-height rectangle to easily compare with a line.\n+    ls = (10, (10, 10))\n+    lw = 4\n+\n+    # Test figure with the patch (currently buggy)\n+    ax_test = fig_test.add_subplot()\n+    ax_test.add_patch(\n+        mpatches.Rectangle(\n+            (0.1, 0.5), 0.8, 0,\n+            linewidth=lw,\n+            linestyle=ls,\n+            edgecolor='b',\n+            facecolor='none'\n+        )\n+    )\n+    ax_test.set_xlim(0, 1)\n+    ax_test.set_ylim(0, 1)\n+\n+    # Reference figure with a line (correct rendering)\n+    ax_ref = fig_ref.add_subplot()\n+    ax_ref.add_line(\n+        mlines.Line2D(\n+            [0.1, 0.9], [0.5, 0.5],\n+            linewidth=lw,\n+            linestyle=ls,\n+            color='b'\n+        )\n+    )\n+    ax_ref.set_xlim(0, 1)\n+    ax_ref.set_ylim(0, 1)\n"
    },
    "scikit-learn__scikit-learn-25102": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/feature_selection/tests/test_univariate_selection.py",
        "reproduced_bug_commands": [
            "pytest sklearn/feature_selection\nn/tests/test_univariate_selection.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/feature_selection/tests/test_univariate_selection.py b/sklearn/feature_selection/tests/test_univariate_selection.py\nnew file mode 100644\nindex 0000000000..347b6efb1e\n--- /dev/null\n+++ b/sklearn/feature_selection/tests/test_univariate_selection.py\n@@ -0,0 +1,32 @@\n+import pytest\n+import numpy as np\n+import pandas as pd\n+\n+from sklearn.datasets import load_iris\n+from sklearn.feature_selection import SelectKBest, chi2\n+\n+\n+def test_select_k_best_preserves_dtype_pandas_output():\n+    \"\"\"Check that SelectKBest preserves dtypes when outputting pandas.\n+\n+    Non-regression test for gh-24908.\n+    \"\"\"\n+    pd = pytest.importorskip(\"pandas\")\n+\n+    X, y = load_iris(return_X_y=True, as_frame=True)\n+    X = X.astype(\n+        {\n+            \"petal width (cm)\": np.float16,\n+            \"petal length (cm)\": np.float16,\n+        }\n+    )\n+    X[\"cat\"] = y.astype(\"category\")\n+\n+    selector = SelectKBest(chi2, k=2)\n+    selector.set_output(transform=\"pandas\")\n+    X_out = selector.fit_transform(X, y)\n+\n+    # When the bug is fixed, the dtypes of the output DataFrame should match\n+    # the dtypes of the selected columns in the input DataFrame.\n+    expected_dtypes = X[selector.get_feature_names_out()].dtypes\n+    pd.testing.assert_series_equal(X_out.dtypes, expected_dtypes)\n"
    },
    "sympy__sympy-17630": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/matrices/expressions/tests/test_blockmatrix_issue_17949.py",
        "reproduced_bug_commands": [
            "bin/test sympy/matrices/expressions/tests/test_blockmatrix_issue_17949.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/matrices/expressions/tests/test_blockmatrix_issue_17949.py b/sympy/matrices/expressions/tests/test_blockmatrix_issue_17949.py\nnew file mode 100644\nindex 0000000000..5a87576481\n--- /dev/null\n+++ b/sympy/matrices/expressions/tests/test_blockmatrix_issue_17949.py\n@@ -0,0 +1,41 @@\n+from sympy.core.expr import Expr\n+from sympy.matrices.expressions.blockmatrix import BlockMatrix\n+from sympy.matrices.expressions import MatrixSymbol, ZeroMatrix\n+from sympy.matrices import ImmutableDenseMatrix\n+from sympy.core.numbers import Zero\n+\n+\n+def test_blockmatrix_mul_with_scalar_zero_reproduces_issue_17949():\n+    \"\"\"\n+    Test for issue reported in https://github.com/sympy/sympy/issues/17949.\n+\n+    This test reproduces the `AttributeError: 'Zero' object has no attribute 'cols'`.\n+    The original bug occurred when an intermediate multiplication created a\n+    BlockMatrix containing a scalar `Zero` instead of a `ZeroMatrix`. In modern\n+    SymPy, the constructor has stricter validation that prevents this.\n+\n+    To reproduce the exact failure condition, this test bypasses the\n+    `BlockMatrix` constructor's validation by using `Expr.__new__`. This allows\n+    the creation of the malformed `BlockMatrix` containing a scalar `Zero`.\n+\n+    Calling `_blockmul` on this object then triggers the `AttributeError`,\n+    causing this test to fail as expected on a buggy version.\n+    \"\"\"\n+    a = MatrixSymbol(\"a\", 2, 2)\n+    z = ZeroMatrix(2, 2)\n+    b = BlockMatrix([[a, z], [z, z]])\n+\n+    # The original bug was that `b._blockmul(b)` would result in a BlockMatrix\n+    # whose `blocks` contained scalar Zeros.\n+    # We manually construct this malformed block structure.\n+    malformed_blocks = ImmutableDenseMatrix([[a**2, Zero()], [Zero(), Zero()]])\n+\n+    # We bypass the BlockMatrix constructor's validation by using Expr.__new__\n+    # to create an instance with the malformed blocks.\n+    malformed_intermediate = Expr.__new__(BlockMatrix, malformed_blocks)\n+\n+    # The following line will raise `AttributeError: 'Zero' object has no attribute 'cols'`\n+    # on a buggy version of SymPy, causing the test to fail and thus demonstrating\n+    # the bug. On a fixed version, this operation would be corrected to not\n+    # produce scalar Zeros, and this test would pass.\n+    malformed_intermediate._blockmul(b)\n"
    },
    "django__django-12708": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/migrations/test_alter_index_together.py",
        "reproduced_bug_commands": [
            "cd /testbed/tests && python runtests.py --settings=my_test_postgres migrations.test_alter_index_together.MigrationOperationsBugsTest.test_remove_index_together_with_unique_together"
        ],
        "reproduced_bug_patch": "diff --git a/tests/migrations/test_alter_index_together.py b/tests/migrations/test_alter_index_together.py\nnew file mode 100644\nindex 0000000000..ff329c2f5c\n--- /dev/null\n+++ b/tests/migrations/test_alter_index_together.py\n@@ -0,0 +1,82 @@\n+from __future__ import unicode_literals\n+\n+from django.db import connection, migrations, models\n+from django.db.migrations.state import ProjectState\n+from django.test import TestCase, override_settings\n+\n+\n+@override_settings(MIGRATION_MODULES={'test_remove_index_together_bug': None})\n+class MigrationOperationsBugsTest(TestCase):\n+    \"\"\"\n+    Tests for a bug where migration crashes deleting an index_together if\n+    there is a unique_together on the same fields.\n+    \"\"\"\n+\n+    def test_remove_index_together_with_unique_together(self):\n+        \"\"\"\n+        Tests that removing an index_together when a unique_together for the\n+        same fields exists doesn't crash.\n+        \"\"\"\n+        app_label = 'test_remove_index_together_bug'\n+        table_name = 'test_remove_index_together_bug_pony'\n+\n+        # 1. Create a model with both unique_together and index_together on the same two fields.\n+        project_state = ProjectState()\n+        create_model_op = migrations.CreateModel(\n+            'Pony',\n+            [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('field1', models.IntegerField()),\n+                ('field2', models.IntegerField()),\n+            ],\n+            options={\n+                'unique_together': {('field1', 'field2')},\n+                'index_together': {('field1', 'field2')},\n+            },\n+        )\n+\n+        # Apply the CreateModel operation to a fresh state and to the database.\n+        state_after_create = project_state.clone()\n+        with connection.schema_editor() as editor:\n+            create_model_op.state_forwards(app_label, state_after_create)\n+            create_model_op.database_forwards(app_label, editor, project_state, state_after_create)\n+\n+        # 2. Create an operation to delete the index_together.\n+        remove_index_op = migrations.AlterIndexTogether(\n+            'Pony',\n+            set(),  # An empty set removes all index_together.\n+        )\n+\n+        state_before_remove = state_after_create\n+        state_after_remove = state_before_remove.clone()\n+        remove_index_op.state_forwards(app_label, state_after_remove)\n+\n+        # 3. Apply the AlterIndexTogether operation. This is the step that fails.\n+        # It raises a ValueError because _delete_composed_index finds two constraints.\n+        # When the bug is fixed, this will execute without error.\n+        with connection.schema_editor() as editor:\n+            remove_index_op.database_forwards(\n+                app_label,\n+                editor,\n+                state_before_remove,\n+                state_after_remove\n+            )\n+\n+        # 4. Assert that the final state is correct after the fix.\n+        # The test will fail before this point if the bug is present.\n+        with connection.cursor() as cursor:\n+            constraints = connection.introspection.get_constraints(cursor, table_name)\n+\n+        # The unique constraint should still exist.\n+        unique_constraints = {\n+            name: c for name, c in constraints.items()\n+            if c['unique'] and not c['primary_key'] and c['columns'] == ['field1', 'field2']\n+        }\n+        self.assertEqual(len(unique_constraints), 1)\n+\n+        # The separate non-unique index should be gone.\n+        indexes = {\n+            name: c for name, c in constraints.items()\n+            if c['index'] and not c['unique']\n+        }\n+        self.assertEqual(len(indexes), 0)\n"
    },
    "django__django-15098": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/i18n/patterns/test_bcp47_language_code.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py i18n.patterns.test_bcp47_language_code"
        ],
        "reproduced_bug_patch": "diff --git a/tests/i18n/patterns/test_bcp47_language_code.py b/tests/i18n/patterns/test_bcp47_language_code.py\nnew file mode 100644\nindex 0000000000..b85a3aa30b\n--- /dev/null\n+++ b/tests/i18n/patterns/test_bcp47_language_code.py\n@@ -0,0 +1,74 @@\n+import os\n+\n+from django.conf import settings\n+from django.core.exceptions import ImproperlyConfigured\n+from django.http import HttpResponse, HttpResponsePermanentRedirect\n+from django.middleware.locale import LocaleMiddleware\n+from django.template import Context, Template\n+from django.test import SimpleTestCase, override_settings\n+from django.test.client import RequestFactory\n+from django.test.utils import override_script_prefix\n+from django.urls import clear_url_caches, reverse, translate_url\n+from django.utils import translation\n+\n+\n+@override_settings(\n+    USE_I18N=True,\n+    LOCALE_PATHS=[\n+        os.path.join(os.path.dirname(__file__), 'locale'),\n+    ],\n+    LANGUAGE_CODE='en-us',\n+    LANGUAGES=[\n+        ('nl', 'Dutch'),\n+        ('en', 'English'),\n+        ('pt-br', 'Brazilian Portuguese'),\n+    ],\n+    MIDDLEWARE=[\n+        'django.middleware.locale.LocaleMiddleware',\n+        'django.middleware.common.CommonMiddleware',\n+    ],\n+    ROOT_URLCONF='i18n.patterns.urls.default',\n+    TEMPLATES=[{\n+        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n+        'DIRS': [os.path.join(os.path.dirname(__file__), 'templates')],\n+        'OPTIONS': {\n+            'context_processors': [\n+                'django.template.context_processors.i18n',\n+            ],\n+        },\n+    }],\n+)\n+class URLTestCaseBase(SimpleTestCase):\n+    \"\"\"\n+    TestCase base-class for the URL tests.\n+    \"\"\"\n+\n+    def setUp(self):\n+        # Make sure the cache is empty before we are doing our tests.\n+        clear_url_caches()\n+\n+    def tearDown(self):\n+        # Make sure we will leave an empty cache for other testcases.\n+        clear_url_caches()\n+\n+\n+@override_settings(\n+    LANGUAGES=[\n+        ('en-us', 'English'),\n+        ('en-latn-us', 'Latin English'),\n+        ('en-Latn-US', 'BCP 47 case format'),\n+    ],\n+    ROOT_URLCONF='i18n.patterns.urls.default',\n+)\n+class LanguageCodeWithScriptAndRegionTests(URLTestCaseBase):\n+    \"\"\"\n+    Tests that language codes with script and region are correctly handled.\n+    \"\"\"\n+    def test_language_code_with_script_and_region(self):\n+        \"\"\"\n+        A language code including a script and a region should be matched.\n+        \"\"\"\n+        response = self.client.get('/en-latn-us/prefixed/')\n+        self.assertEqual(response.status_code, 200)\n+        response = self.client.get('/en-Latn-US/prefixed/')\n+        self.assertEqual(response.status_code, 200)\n"
    },
    "matplotlib__matplotlib-23476": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "scikit-learn__scikit-learn-25232": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/impute/tests/test_iterative_imputer.py",
        "reproduced_bug_commands": [
            "pytest sklearn/impute/tests/test_iterative_imputer.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/impute/tests/test_iterative_imputer.py b/sklearn/impute/tests/test_iterative_imputer.py\nnew file mode 100644\nindex 0000000000..73daab14fe\n--- /dev/null\n+++ b/sklearn/impute/tests/test_iterative_imputer.py\n@@ -0,0 +1,34 @@\n+import pytest\n+import numpy as np\n+\n+# make IterativeImputer available\n+from sklearn.experimental import enable_iterative_imputer  # noqa\n+from sklearn.impute import IterativeImputer\n+from sklearn.utils._testing import assert_array_equal\n+\n+\n+def test_iterative_imputer_constant_initial_strategy_fill_value():\n+    \"\"\"Test IterativeImputer with initial_strategy='constant' and fill_value.\n+\n+    When `initial_strategy` is set to `'constant'`, `IterativeImputer` should\n+    be able to accept a `fill_value` parameter to specify the constant to\n+    use for the initial imputation.\n+\n+    This test fails with a TypeError because `fill_value` is not a valid\n+    parameter for `IterativeImputer`.\n+    \"\"\"\n+    X = np.array([\n+        [1, np.nan],\n+        [3, 4.0]\n+    ])\n+    X_expected = np.array([\n+        [1, 0],\n+        [3, 4.0]\n+    ])\n+    # Use max_iter=0 to ensure only the initial imputation is performed.\n+    # random_state is passed for reproducibility.\n+    imputer = IterativeImputer(\n+        initial_strategy=\"constant\", fill_value=0, max_iter=0, random_state=0\n+    )\n+    X_imputed = imputer.fit_transform(X)\n+    assert_array_equal(X_expected, X_imputed)\n"
    },
    "sympy__sympy-17655": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/geometry/tests/test_point_arithmetic.py",
        "reproduced_bug_commands": [
            "python -m pytest sympy/geometry/tests/test_point_arithmetic.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/geometry/tests/test_point_arithmetic.py b/sympy/geometry/tests/test_point_arithmetic.py\nnew file mode 100644\nindex 0000000000..8a41277a13\n--- /dev/null\n+++ b/sympy/geometry/tests/test_point_arithmetic.py\n@@ -0,0 +1,17 @@\n+from sympy import S\n+from sympy.geometry import Point\n+\n+\n+def test_point_multiplication_in_sum():\n+    \"\"\"Test for issue where Point + Number * Point fails.\"\"\"\n+    point1 = Point(0, 0)\n+    point2 = Point(1, 1)\n+    num = S(2.0)\n+\n+    # This works fine\n+    working_expr = point1 + point2 * num\n+\n+    # This raises an exception but should be equivalent\n+    failing_expr = point1 + num * point2\n+\n+    assert failing_expr == working_expr\n"
    },
    "django__django-12713": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "django__django-15103": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/template_tests/filter_tests/test_json_script_no_id.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py template_tests.filter_tests.test_json_script_no_id"
        ],
        "reproduced_bug_patch": "diff --git a/tests/template_tests/filter_tests/test_json_script_no_id.py b/tests/template_tests/filter_tests/test_json_script_no_id.py\nnew file mode 100644\nindex 0000000000..8b5058d2dd\n--- /dev/null\n+++ b/tests/template_tests/filter_tests/test_json_script_no_id.py\n@@ -0,0 +1,20 @@\n+from django.test import SimpleTestCase\n+\n+from ..utils import setup\n+\n+\n+class JsonScriptTests(SimpleTestCase):\n+\n+    @setup({'json-tag-no-id': '{{ value|json_script }}'})\n+    def test_no_id(self):\n+        \"\"\"\n+        json_script should work without an element_id.\n+        \"\"\"\n+        output = self.engine.render_to_string(\n+            'json-tag-no-id',\n+            {'value': {'a': 'b'}}\n+        )\n+        self.assertEqual(\n+            output,\n+            '<script type=\"application/json\">{\"a\": \"b\"}</script>'\n+        )\n"
    },
    "matplotlib__matplotlib-24026": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_stackplot.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_stackplot.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_stackplot.py b/lib/matplotlib/tests/test_stackplot.py\nnew file mode 100644\nindex 0000000000..1c24eaf8a8\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_stackplot.py\n@@ -0,0 +1,24 @@\n+import pytest\n+import numpy as np\n+import matplotlib.pyplot as plt\n+\n+def test_stackplot_cn_color():\n+    \"\"\"\n+    Test that stackplot can accept 'CN' color strings, which should be\n+    resolved against the Axes property cycler.\n+\n+    This test reproduces the bug reported in issue #14221, where passing\n+    'CN' strings to the `colors` argument of `stackplot` raises a ValueError\n+    instead of using the cycler's colors.\n+    \"\"\"\n+    fig, ax = plt.subplots()\n+    x = [1, 2, 3]\n+    y = np.array([[1, 1, 1], [1, 2, 3], [4, 3, 2]])\n+\n+    # This call raises a ValueError on the faulty code but should execute\n+    # without error when fixed.\n+    collections = ax.stackplot(x, y, colors=['C2', 'C3', 'C4'])\n+\n+    # A minimal assertion that will pass when the bug is fixed.\n+    # stackplot should return one PolyCollection for each data series.\n+    assert len(collections) == 3\n"
    },
    "scikit-learn__scikit-learn-25747": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/tests/test_feature_union_pandas_aggregation.py",
        "reproduced_bug_commands": [
            "python3.10 -m pytest sklearn/tests/test_feature_union_pandas_aggregation.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/tests/test_feature_union_pandas_aggregation.py b/sklearn/tests/test_feature_union_pandas_aggregation.py\nnew file mode 100644\nindex 0000000000..0bf16280b3\n--- /dev/null\n+++ b/sklearn/tests/test_feature_union_pandas_aggregation.py\n@@ -0,0 +1,48 @@\n+import pytest\n+import pandas as pd\n+import numpy as np\n+\n+from sklearn.base import BaseEstimator, TransformerMixin\n+from sklearn.pipeline import make_union\n+from sklearn import set_config\n+from sklearn.utils._testing import assert_array_equal\n+\n+\n+class MyTransformer(BaseEstimator, TransformerMixin):\n+    def fit(self, X: pd.DataFrame, y: pd.Series | None = None, **kwargs):\n+        return self\n+\n+    def transform(self, X: pd.DataFrame, y: pd.Series | None = None) -> pd.DataFrame:\n+        return X.groupby(X[\"date\"])[\"value\"].sum()\n+\n+\n+def test_feature_union_with_pandas_output_aggregation():\n+    \"\"\"\n+    Regression test for a bug in FeatureUnion when a transformer aggregates\n+    data and `transform_output` is set to \"pandas\".\n+\n+    The error occurs because scikit-learn tries to align the index of the\n+    aggregated (shorter) output with the index of the original (longer)\n+    input, leading to a ValueError. When fixed, the transform should\n+    succeed and return a DataFrame with the correct aggregated shape.\n+    \"\"\"\n+    pd = pytest.importorskip(\"pandas\")\n+\n+    # Recreate the data from the bug report\n+    index = pd.date_range(start=\"2020-01-01\", end=\"2020-01-05\", inclusive=\"left\", freq=\"H\")\n+    data = pd.DataFrame(index=index, data=[10] * len(index), columns=[\"value\"])\n+    data[\"date\"] = index.date\n+\n+    union = make_union(MyTransformer())\n+\n+    # Configure the output to pandas, which triggers the bug\n+    set_config(transform_output=\"pandas\")\n+\n+    # This call raises a ValueError because the aggregated output's length (4)\n+    # does not match the input's length (96).\n+    # When fixed, this should return a pandas DataFrame.\n+    transformed_data = union.fit_transform(data)\n+\n+    # This assertion will fail until the bug is fixed. Once fixed, it will\n+    # verify that the output has the correct shape after aggregation.\n+    assert transformed_data.shape == (4, 1)\n"
    },
    "sympy__sympy-18189": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/solvers/tests/test_diophantine_issue.py",
        "reproduced_bug_commands": [
            "pytest sympy/solvers/tests/test_diophantine_issue.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/solvers/tests/test_diophantine_issue.py b/sympy/solvers/tests/test_diophantine_issue.py\nnew file mode 100644\nindex 0000000000..846ab24cdd\n--- /dev/null\n+++ b/sympy/solvers/tests/test_diophantine_issue.py\n@@ -0,0 +1,14 @@\n+from sympy import symbols\n+from sympy.solvers.diophantine import diophantine\n+\n+\n+def test_diophantine_incomplete_results_syms_order():\n+    \"\"\"\n+    Tests that the result of diophantine is independent of symbol order\n+    when permute=True.\n+    \"\"\"\n+    m, n = symbols('m, n', integer=True)\n+    eq = n**4 + m**4 - 2**4 - 3**4\n+    sol_mn = diophantine(eq, syms=(m, n), permute=True)\n+    sol_nm = diophantine(eq, syms=(n, m), permute=True)\n+    assert sol_nm == sol_mn\n"
    },
    "django__django-12741": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/backends/test_sql_flush.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py backends.test_sql_flush.SqlFlushSignatureTest --settings=custom_settings"
        ],
        "reproduced_bug_patch": "diff --git a/tests/backends/test_sql_flush.py b/tests/backends/test_sql_flush.py\nnew file mode 100644\nindex 0000000000..9a93833323\n--- /dev/null\n+++ b/tests/backends/test_sql_flush.py\n@@ -0,0 +1,29 @@\n+from django.core.management.color import no_style\n+from django.db import connection\n+from django.test import TransactionTestCase\n+\n+from backends.models import Author, Book\n+\n+\n+class SqlFlushSignatureTest(TransactionTestCase):\n+    available_apps = ['backends']\n+\n+    def test_execute_sql_flush_signature_simplified(self):\n+        \"\"\"\n+        Test that execute_sql_flush() can be called without the `using`\n+        argument.\n+        \"\"\"\n+        author = Author.objects.create(name='George Orwell')\n+        Book.objects.create(author=author, title='1984')\n+\n+        sql_list = connection.ops.sql_flush(\n+            no_style(),\n+            [Author._meta.db_table, Book._meta.db_table],\n+            allow_cascade=True,\n+        )\n+        # This call will raise a TypeError before the signature is changed to\n+        # accept a single argument.\n+        connection.ops.execute_sql_flush(sql_list)\n+\n+        self.assertFalse(Author.objects.exists())\n+        self.assertFalse(Book.objects.exists())\n"
    },
    "django__django-15104": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/migrations/test_autodetector_keyerror.py",
        "reproduced_bug_commands": [
            "cd tests && python runtests.py migrations.test_autodetector_keyerror"
        ],
        "reproduced_bug_patch": "diff --git a/tests/migrations/test_autodetector_keyerror.py b/tests/migrations/test_autodetector_keyerror.py\nnew file mode 100644\nindex 0000000000..fd1510b6eb\n--- /dev/null\n+++ b/tests/migrations/test_autodetector_keyerror.py\n@@ -0,0 +1,2977 @@\n+import functools\n+import re\n+from unittest import mock\n+\n+from django.apps import apps\n+from django.conf import settings\n+from django.contrib.auth.models import AbstractBaseUser\n+from django.core.validators import RegexValidator, validate_slug\n+from django.db import connection, migrations, models\n+from django.db.migrations.autodetector import MigrationAutodetector\n+from django.db.migrations.graph import MigrationGraph\n+from django.db.migrations.loader import MigrationLoader\n+from django.db.migrations.questioner import MigrationQuestioner\n+from django.db.migrations.state import ModelState, ProjectState\n+from django.test import SimpleTestCase, TestCase, override_settings\n+from django.test.utils import isolate_lru_cache\n+\n+from .models import FoodManager, FoodQuerySet\n+\n+\n+class DeconstructibleObject:\n+    \"\"\"\n+    A custom deconstructible object.\n+    \"\"\"\n+\n+    def __init__(self, *args, **kwargs):\n+        self.args = args\n+        self.kwargs = kwargs\n+\n+    def deconstruct(self):\n+        return (\n+            self.__module__ + '.' + self.__class__.__name__,\n+            self.args,\n+            self.kwargs\n+        )\n+\n+\n+class AutodetectorTests(TestCase):\n+    \"\"\"\n+    Tests the migration autodetector.\n+    \"\"\"\n+\n+    author_empty = ModelState(\"testapp\", \"Author\", [(\"id\", models.AutoField(primary_key=True))])\n+    author_name = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200)),\n+    ])\n+    author_name_null = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, null=True)),\n+    ])\n+    author_name_longer = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=400)),\n+    ])\n+    author_name_renamed = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"names\", models.CharField(max_length=200)),\n+    ])\n+    author_name_default = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default='Ada Lovelace')),\n+    ])\n+    author_name_check_constraint = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200)),\n+    ],\n+        {'constraints': [models.CheckConstraint(check=models.Q(name__contains='Bob'), name='name_contains_bob')]},\n+    )\n+    author_dates_of_birth_auto_now = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"date_of_birth\", models.DateField(auto_now=True)),\n+        (\"date_time_of_birth\", models.DateTimeField(auto_now=True)),\n+        (\"time_of_birth\", models.TimeField(auto_now=True)),\n+    ])\n+    author_dates_of_birth_auto_now_add = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"date_of_birth\", models.DateField(auto_now_add=True)),\n+        (\"date_time_of_birth\", models.DateTimeField(auto_now_add=True)),\n+        (\"time_of_birth\", models.TimeField(auto_now_add=True)),\n+    ])\n+    author_name_deconstructible_1 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=DeconstructibleObject())),\n+    ])\n+    author_name_deconstructible_2 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=DeconstructibleObject())),\n+    ])\n+    author_name_deconstructible_3 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=models.IntegerField())),\n+    ])\n+    author_name_deconstructible_4 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=models.IntegerField())),\n+    ])\n+    author_name_deconstructible_list_1 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=[DeconstructibleObject(), 123])),\n+    ])\n+    author_name_deconstructible_list_2 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=[DeconstructibleObject(), 123])),\n+    ])\n+    author_name_deconstructible_list_3 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=[DeconstructibleObject(), 999])),\n+    ])\n+    author_name_deconstructible_tuple_1 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=(DeconstructibleObject(), 123))),\n+    ])\n+    author_name_deconstructible_tuple_2 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=(DeconstructibleObject(), 123))),\n+    ])\n+    author_name_deconstructible_tuple_3 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=(DeconstructibleObject(), 999))),\n+    ])\n+    author_name_deconstructible_dict_1 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default={\n+            'item': DeconstructibleObject(), 'otheritem': 123\n+        })),\n+    ])\n+    author_name_deconstructible_dict_2 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default={\n+            'item': DeconstructibleObject(), 'otheritem': 123\n+        })),\n+    ])\n+    author_name_deconstructible_dict_3 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default={\n+            'item': DeconstructibleObject(), 'otheritem': 999\n+        })),\n+    ])\n+    author_name_nested_deconstructible_1 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=DeconstructibleObject(\n+            DeconstructibleObject(1),\n+            (DeconstructibleObject('t1'), DeconstructibleObject('t2'),),\n+            a=DeconstructibleObject('A'),\n+            b=DeconstructibleObject(B=DeconstructibleObject('c')),\n+        ))),\n+    ])\n+    author_name_nested_deconstructible_2 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=DeconstructibleObject(\n+            DeconstructibleObject(1),\n+            (DeconstructibleObject('t1'), DeconstructibleObject('t2'),),\n+            a=DeconstructibleObject('A'),\n+            b=DeconstructibleObject(B=DeconstructibleObject('c')),\n+        ))),\n+    ])\n+    author_name_nested_deconstructible_changed_arg = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=DeconstructibleObject(\n+            DeconstructibleObject(1),\n+            (DeconstructibleObject('t1'), DeconstructibleObject('t2-changed'),),\n+            a=DeconstructibleObject('A'),\n+            b=DeconstructibleObject(B=DeconstructibleObject('c')),\n+        ))),\n+    ])\n+    author_name_nested_deconstructible_extra_arg = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=DeconstructibleObject(\n+            DeconstructibleObject(1),\n+            (DeconstructibleObject('t1'), DeconstructibleObject('t2'),),\n+            None,\n+            a=DeconstructibleObject('A'),\n+            b=DeconstructibleObject(B=DeconstructibleObject('c')),\n+        ))),\n+    ])\n+    author_name_nested_deconstructible_changed_kwarg = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=DeconstructibleObject(\n+            DeconstructibleObject(1),\n+            (DeconstructibleObject('t1'), DeconstructibleObject('t2'),),\n+            a=DeconstructibleObject('A'),\n+            b=DeconstructibleObject(B=DeconstructibleObject('c-changed')),\n+        ))),\n+    ])\n+    author_name_nested_deconstructible_extra_kwarg = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=DeconstructibleObject(\n+            DeconstructibleObject(1),\n+            (DeconstructibleObject('t1'), DeconstructibleObject('t2'),),\n+            a=DeconstructibleObject('A'),\n+            b=DeconstructibleObject(B=DeconstructibleObject('c')),\n+            c=None,\n+        ))),\n+    ])\n+    author_custom_pk = ModelState(\"testapp\", \"Author\", [(\"pk_field\", models.IntegerField(primary_key=True))])\n+    author_with_biography_non_blank = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField()),\n+        (\"biography\", models.TextField()),\n+    ])\n+    author_with_biography_blank = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(blank=True)),\n+        (\"biography\", models.TextField(blank=True)),\n+    ])\n+    author_with_book = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200)),\n+        (\"book\", models.ForeignKey(\"otherapp.Book\", models.CASCADE)),\n+    ])\n+    author_with_book_order_wrt = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200)),\n+        (\"book\", models.ForeignKey(\"otherapp.Book\", models.CASCADE)),\n+    ], options={\"order_with_respect_to\": \"book\"})\n+    author_renamed_with_book = ModelState(\"testapp\", \"Writer\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200)),\n+        (\"book\", models.ForeignKey(\"otherapp.Book\", models.CASCADE)),\n+    ])\n+    author_with_publisher_string = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200)),\n+        (\"publisher_name\", models.CharField(max_length=200)),\n+    ])\n+    author_with_publisher = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200)),\n+        (\"publisher\", models.ForeignKey(\"testapp.Publisher\", models.CASCADE)),\n+    ])\n+    author_with_user = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200)),\n+        (\"user\", models.ForeignKey(\"auth.User\", models.CASCADE)),\n+    ])\n+    author_with_custom_user = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200)),\n+        (\"user\", models.ForeignKey(\"thirdapp.CustomUser\", models.CASCADE)),\n+    ])\n+    author_proxy = ModelState(\"testapp\", \"AuthorProxy\", [], {\"proxy\": True}, (\"testapp.author\",))\n+    author_proxy_options = ModelState(\"testapp\", \"AuthorProxy\", [], {\n+        \"proxy\": True,\n+        \"verbose_name\": \"Super Author\",\n+    }, (\"testapp.author\",))\n+    author_proxy_notproxy = ModelState(\"testapp\", \"AuthorProxy\", [], {}, (\"testapp.author\",))\n+    author_proxy_third = ModelState(\"thirdapp\", \"AuthorProxy\", [], {\"proxy\": True}, (\"testapp.author\",))\n+    author_proxy_third_notproxy = ModelState(\"thirdapp\", \"AuthorProxy\", [], {}, (\"testapp.author\",))\n+    author_proxy_proxy = ModelState(\"testapp\", \"AAuthorProxyProxy\", [], {\"proxy\": True}, (\"testapp.authorproxy\",))\n+    author_unmanaged = ModelState(\"testapp\", \"AuthorUnmanaged\", [], {\"managed\": False}, (\"testapp.author\",))\n+    author_unmanaged_managed = ModelState(\"testapp\", \"AuthorUnmanaged\", [], {}, (\"testapp.author\",))\n+    author_unmanaged_default_pk = ModelState(\"testapp\", \"Author\", [(\"id\", models.AutoField(primary_key=True))])\n+    author_unmanaged_custom_pk = ModelState(\"testapp\", \"Author\", [\n+        (\"pk_field\", models.IntegerField(primary_key=True)),\n+    ])\n+    author_with_m2m = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"publishers\", models.ManyToManyField(\"testapp.Publisher\")),\n+    ])\n+    author_with_m2m_blank = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"publishers\", models.ManyToManyField(\"testapp.Publisher\", blank=True)),\n+    ])\n+    author_with_m2m_through = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"publishers\", models.ManyToManyField(\"testapp.Publisher\", through=\"testapp.Contract\")),\n+    ])\n+    author_with_renamed_m2m_through = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"publishers\", models.ManyToManyField(\"testapp.Publisher\", through=\"testapp.Deal\")),\n+    ])\n+    author_with_former_m2m = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"publishers\", models.CharField(max_length=100)),\n+    ])\n+    author_with_options = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+    ], {\n+        \"permissions\": [('can_hire', 'Can hire')],\n+        \"verbose_name\": \"Authi\",\n+    })\n+    author_with_db_table_options = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+    ], {\"db_table\": \"author_one\"})\n+    author_with_new_db_table_options = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+    ], {\"db_table\": \"author_two\"})\n+    author_renamed_with_db_table_options = ModelState(\"testapp\", \"NewAuthor\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+    ], {\"db_table\": \"author_one\"})\n+    author_renamed_with_new_db_table_options = ModelState(\"testapp\", \"NewAuthor\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+    ], {\"db_table\": \"author_three\"})\n+    contract = ModelState(\"testapp\", \"Contract\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"publisher\", models.ForeignKey(\"testapp.Publisher\", models.CASCADE)),\n+    ])\n+    contract_renamed = ModelState(\"testapp\", \"Deal\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"publisher\", models.ForeignKey(\"testapp.Publisher\", models.CASCADE)),\n+    ])\n+    publisher = ModelState(\"testapp\", \"Publisher\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=100)),\n+    ])\n+    publisher_with_author = ModelState(\"testapp\", \"Publisher\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"name\", models.CharField(max_length=100)),\n+    ])\n+    publisher_with_aardvark_author = ModelState(\"testapp\", \"Publisher\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Aardvark\", models.CASCADE)),\n+        (\"name\", models.CharField(max_length=100)),\n+    ])\n+    publisher_with_book = ModelState(\"testapp\", \"Publisher\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"otherapp.Book\", models.CASCADE)),\n+        (\"name\", models.CharField(max_length=100)),\n+    ])\n+    other_pony = ModelState(\"otherapp\", \"Pony\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+    ])\n+    other_pony_food = ModelState(\"otherapp\", \"Pony\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+    ], managers=[\n+        ('food_qs', FoodQuerySet.as_manager()),\n+        ('food_mgr', FoodManager('a', 'b')),\n+        ('food_mgr_kwargs', FoodManager('x', 'y', 3, 4)),\n+    ])\n+    other_stable = ModelState(\"otherapp\", \"Stable\", [(\"id\", models.AutoField(primary_key=True))])\n+    third_thing = ModelState(\"thirdapp\", \"Thing\", [(\"id\", models.AutoField(primary_key=True))])\n+    book = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ])\n+    book_proxy_fk = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"thirdapp.AuthorProxy\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ])\n+    book_proxy_proxy_fk = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.AAuthorProxyProxy\", models.CASCADE)),\n+    ])\n+    book_migrations_fk = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"migrations.UnmigratedModel\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ])\n+    book_with_no_author_fk = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.IntegerField()),\n+        (\"title\", models.CharField(max_length=200)),\n+    ])\n+    book_with_no_author = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ])\n+    book_with_author_renamed = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Writer\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ])\n+    book_with_field_and_author_renamed = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"writer\", models.ForeignKey(\"testapp.Writer\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ])\n+    book_with_multiple_authors = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"authors\", models.ManyToManyField(\"testapp.Author\")),\n+        (\"title\", models.CharField(max_length=200)),\n+    ])\n+    book_with_multiple_authors_through_attribution = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"authors\", models.ManyToManyField(\"testapp.Author\", through=\"otherapp.Attribution\")),\n+        (\"title\", models.CharField(max_length=200)),\n+    ])\n+    book_indexes = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ], {\n+        \"indexes\": [models.Index(fields=[\"author\", \"title\"], name=\"book_title_author_idx\")],\n+    })\n+    book_unordered_indexes = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ], {\n+        \"indexes\": [models.Index(fields=[\"title\", \"author\"], name=\"book_author_title_idx\")],\n+    })\n+    book_foo_together = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ], {\n+        \"index_together\": {(\"author\", \"title\")},\n+        \"unique_together\": {(\"author\", \"title\")},\n+    })\n+    book_foo_together_2 = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ], {\n+        \"index_together\": {(\"title\", \"author\")},\n+        \"unique_together\": {(\"title\", \"author\")},\n+    })\n+    book_foo_together_3 = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"newfield\", models.IntegerField()),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ], {\n+        \"index_together\": {(\"title\", \"newfield\")},\n+        \"unique_together\": {(\"title\", \"newfield\")},\n+    })\n+    book_foo_together_4 = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"newfield2\", models.IntegerField()),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ], {\n+        \"index_together\": {(\"title\", \"newfield2\")},\n+        \"unique_together\": {(\"title\", \"newfield2\")},\n+    })\n+    attribution = ModelState(\"otherapp\", \"Attribution\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"book\", models.ForeignKey(\"otherapp.Book\", models.CASCADE)),\n+    ])\n+    edition = ModelState(\"thirdapp\", \"Edition\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"book\", models.ForeignKey(\"otherapp.Book\", models.CASCADE)),\n+    ])\n+    custom_user = ModelState(\"thirdapp\", \"CustomUser\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"username\", models.CharField(max_length=255)),\n+    ], bases=(AbstractBaseUser,))\n+    custom_user_no_inherit = ModelState(\"thirdapp\", \"CustomUser\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"username\", models.CharField(max_length=255)),\n+    ])\n+    aardvark = ModelState(\"thirdapp\", \"Aardvark\", [(\"id\", models.AutoField(primary_key=True))])\n+    aardvark_testapp = ModelState(\"testapp\", \"Aardvark\", [(\"id\", models.AutoField(primary_key=True))])\n+    aardvark_based_on_author = ModelState(\"testapp\", \"Aardvark\", [], bases=(\"testapp.Author\",))\n+    aardvark_pk_fk_author = ModelState(\"testapp\", \"Aardvark\", [\n+        (\"id\", models.OneToOneField(\"testapp.Author\", models.CASCADE, primary_key=True)),\n+    ])\n+    knight = ModelState(\"eggs\", \"Knight\", [(\"id\", models.AutoField(primary_key=True))])\n+    rabbit = ModelState(\"eggs\", \"Rabbit\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"knight\", models.ForeignKey(\"eggs.Knight\", models.CASCADE)),\n+        (\"parent\", models.ForeignKey(\"eggs.Rabbit\", models.CASCADE)),\n+    ], {\n+        \"unique_together\": {(\"parent\", \"knight\")},\n+        \"indexes\": [models.Index(fields=[\"parent\", \"knight\"], name='rabbit_circular_fk_index')],\n+    })\n+\n+    def repr_changes(self, changes, include_dependencies=False):\n+        output = \"\"\n+        for app_label, migrations_ in sorted(changes.items()):\n+            output += \"  %s:\\n\" % app_label\n+            for migration in migrations_:\n+                output += \"    %s\\n\" % migration.name\n+                for operation in migration.operations:\n+                    output += \"      %s\\n\" % operation\n+                if include_dependencies:\n+                    output += \"      Dependencies:\\n\"\n+                    if migration.dependencies:\n+                        for dep in migration.dependencies:\n+                            output += \"        %s\\n\" % (dep,)\n+                    else:\n+                        output += \"        None\\n\"\n+        return output\n+\n+    def assertNumberMigrations(self, changes, app_label, number):\n+        if len(changes.get(app_label, [])) != number:\n+            self.fail(\"Incorrect number of migrations (%s) for %s (expected %s)\\n%s\" % (\n+                len(changes.get(app_label, [])),\n+                app_label,\n+                number,\n+                self.repr_changes(changes),\n+            ))\n+\n+    def assertMigrationDependencies(self, changes, app_label, position, dependencies):\n+        if not changes.get(app_label):\n+            self.fail(\"No migrations found for %s\\n%s\" % (app_label, self.repr_changes(changes)))\n+        if len(changes[app_label]) < position + 1:\n+            self.fail(\"No migration at index %s for %s\\n%s\" % (position, app_label, self.repr_changes(changes)))\n+        migration = changes[app_label][position]\n+        if set(migration.dependencies) != set(dependencies):\n+            self.fail(\"Migration dependencies mismatch for %s.%s (expected %s):\\n%s\" % (\n+                app_label,\n+                migration.name,\n+                dependencies,\n+                self.repr_changes(changes, include_dependencies=True),\n+            ))\n+\n+    def assertOperationTypes(self, changes, app_label, position, types):\n+        if not changes.get(app_label):\n+            self.fail(\"No migrations found for %s\\n%s\" % (app_label, self.repr_changes(changes)))\n+        if len(changes[app_label]) < position + 1:\n+            self.fail(\"No migration at index %s for %s\\n%s\" % (position, app_label, self.repr_changes(changes)))\n+        migration = changes[app_label][position]\n+        real_types = [operation.__class__.__name__ for operation in migration.operations]\n+        if types != real_types:\n+            self.fail(\"Operation type mismatch for %s.%s (expected %s):\\n%s\" % (\n+                app_label,\n+                migration.name,\n+                types,\n+                self.repr_changes(changes),\n+            ))\n+\n+    def assertOperationAttributes(self, changes, app_label, position, operation_position, **attrs):\n+        if not changes.get(app_label):\n+            self.fail(\"No migrations found for %s\\n%s\" % (app_label, self.repr_changes(changes)))\n+        if len(changes[app_label]) < position + 1:\n+            self.fail(\"No migration at index %s for %s\\n%s\" % (position, app_label, self.repr_changes(changes)))\n+        migration = changes[app_label][position]\n+        if len(changes[app_label]) < position + 1:\n+            self.fail(\"No operation at index %s for %s.%s\\n%s\" % (\n+                operation_position,\n+                app_label,\n+                migration.name,\n+                self.repr_changes(changes),\n+            ))\n+        operation = migration.operations[operation_position]\n+        for attr, value in attrs.items():\n+            if getattr(operation, attr, None) != value:\n+                self.fail(\"Attribute mismatch for %s.%s op #%s, %s (expected %r, got %r):\\n%s\" % (\n+                    app_label,\n+                    migration.name,\n+                    operation_position,\n+                    attr,\n+                    value,\n+                    getattr(operation, attr, None),\n+                    self.repr_changes(changes),\n+                ))\n+\n+    def assertOperationFieldAttributes(self, changes, app_label, position, operation_position, **attrs):\n+        if not changes.get(app_label):\n+            self.fail(\"No migrations found for %s\\n%s\" % (app_label, self.repr_changes(changes)))\n+        if len(changes[app_label]) < position + 1:\n+            self.fail(\"No migration at index %s for %s\\n%s\" % (position, app_label, self.repr_changes(changes)))\n+        migration = changes[app_label][position]\n+        if len(changes[app_label]) < position + 1:\n+            self.fail(\"No operation at index %s for %s.%s\\n%s\" % (\n+                operation_position,\n+                app_label,\n+                migration.name,\n+                self.repr_changes(changes),\n+            ))\n+        operation = migration.operations[operation_position]\n+        if not hasattr(operation, 'field'):\n+            self.fail(\"No field attribute for %s.%s op #%s.\" % (\n+                app_label,\n+                migration.name,\n+                operation_position,\n+            ))\n+        field = operation.field\n+        for attr, value in attrs.items():\n+            if getattr(field, attr, None) != value:\n+                self.fail(\"Field attribute mismatch for %s.%s op #%s, field.%s (expected %r, got %r):\\n%s\" % (\n+                    app_label,\n+                    migration.name,\n+                    operation_position,\n+                    attr,\n+                    value,\n+                    getattr(field, attr, None),\n+                    self.repr_changes(changes),\n+                ))\n+\n+    def make_project_state(self, model_states):\n+        \"Shortcut to make ProjectStates from lists of predefined models\"\n+        project_state = ProjectState()\n+        for model_state in model_states:\n+            project_state.add_model(model_state.clone())\n+        return project_state\n+\n+    def get_changes(self, before_states, after_states, questioner=None):\n+        if not isinstance(before_states, ProjectState):\n+            before_states = self.make_project_state(before_states)\n+        if not isinstance(after_states, ProjectState):\n+            after_states = self.make_project_state(after_states)\n+        return MigrationAutodetector(\n+            before_states,\n+            after_states,\n+            questioner,\n+        )._detect_changes()\n+\n+    def test_fk_with_hardcoded_reference(self):\n+        \"\"\"\n+        The autodetector shouldn't crash on a custom ForeignKey that\n+        hardcodes its `to` argument and removes it from deconstruction.\n+        \"\"\"\n+        class CustomFKField(models.ForeignKey):\n+            def __init__(self, *args, **kwargs):\n+                kwargs['to'] = 'testapp.HardcodedModel'\n+                super().__init__(*args, **kwargs)\n+\n+            def deconstruct(self):\n+                name, path, args, kwargs = super().deconstruct()\n+                del kwargs['to']\n+                return name, path, args, kwargs\n+\n+        before = ProjectState()\n+        before.add_model(ModelState('testapp', 'HardcodedModel', []))\n+        after = ProjectState()\n+        after.add_model(ModelState('testapp', 'HardcodedModel', []))\n+        after.add_model(ModelState(\n+            'testapp',\n+            'TestModel',\n+            [('custom', CustomFKField(on_delete=models.CASCADE))]\n+        ))\n+        changes = MigrationAutodetector(before, after)._detect_changes()\n+        self.assertEqual(len(changes['testapp']), 1)\n+\n+    def test_arrange_for_graph(self):\n+        \"\"\"Tests auto-naming of migrations for graph matching.\"\"\"\n+        # Make a fake graph\n+        graph = MigrationGraph()\n+        graph.add_node((\"testapp\", \"0001_initial\"), None)\n+        graph.add_node((\"testapp\", \"0002_foobar\"), None)\n+        graph.add_node((\"otherapp\", \"0001_initial\"), None)\n+        graph.add_dependency(\"testapp.0002_foobar\", (\"testapp\", \"0002_foobar\"), (\"testapp\", \"0001_initial\"))\n+        graph.add_dependency(\"testapp.0002_foobar\", (\"testapp\", \"0002_foobar\"), (\"otherapp\", \"0001_initial\"))\n+        # Use project state to make a new migration change set\n+        before = self.make_project_state([self.publisher, self.other_pony])\n+        after = self.make_project_state([\n+            self.author_empty, self.publisher, self.other_pony, self.other_stable,\n+        ])\n+        autodetector = MigrationAutodetector(before, after)\n+        changes = autodetector._detect_changes()\n+        # Run through arrange_for_graph\n+        changes = autodetector.arrange_for_graph(changes, graph)\n+        # Make sure there's a new name, deps match, etc.\n+        self.assertEqual(changes[\"testapp\"][0].name, \"0003_author\")\n+        self.assertEqual(changes[\"testapp\"][0].dependencies, [(\"testapp\", \"0002_foobar\")])\n+        self.assertEqual(changes[\"otherapp\"][0].name, '0002_stable')\n+        self.assertEqual(changes[\"otherapp\"][0].dependencies, [(\"otherapp\", \"0001_initial\")])\n+\n+    def test_arrange_for_graph_with_multiple_initial(self):\n+        # Make a fake graph.\n+        graph = MigrationGraph()\n+        # Use project state to make a new migration change set.\n+        before = self.make_project_state([])\n+        after = self.make_project_state([self.author_with_book, self.book, self.attribution])\n+        autodetector = MigrationAutodetector(before, after, MigrationQuestioner({'ask_initial': True}))\n+        changes = autodetector._detect_changes()\n+        changes = autodetector.arrange_for_graph(changes, graph)\n+\n+        self.assertEqual(changes['otherapp'][0].name, '0001_initial')\n+        self.assertEqual(changes['otherapp'][0].dependencies, [])\n+        self.assertEqual(changes['otherapp'][1].name, '0002_initial')\n+        self.assertCountEqual(\n+            changes['otherapp'][1].dependencies,\n+            [('testapp', '0001_initial'), ('otherapp', '0001_initial')],\n+        )\n+        self.assertEqual(changes['testapp'][0].name, '0001_initial')\n+        self.assertEqual(changes['testapp'][0].dependencies, [('otherapp', '0001_initial')])\n+\n+    def test_trim_apps(self):\n+        \"\"\"\n+        Trim does not remove dependencies but does remove unwanted apps.\n+        \"\"\"\n+        # Use project state to make a new migration change set\n+        before = self.make_project_state([])\n+        after = self.make_project_state([self.author_empty, self.other_pony, self.other_stable, self.third_thing])\n+        autodetector = MigrationAutodetector(before, after, MigrationQuestioner({\"ask_initial\": True}))\n+        changes = autodetector._detect_changes()\n+        # Run through arrange_for_graph\n+        graph = MigrationGraph()\n+        changes = autodetector.arrange_for_graph(changes, graph)\n+        changes[\"testapp\"][0].dependencies.append((\"otherapp\", \"0001_initial\"))\n+        changes = autodetector._trim_to_apps(changes, {\"testapp\"})\n+        # Make sure there's the right set of migrations\n+        self.assertEqual(changes[\"testapp\"][0].name, \"0001_initial\")\n+        self.assertEqual(changes[\"otherapp\"][0].name, \"0001_initial\")\n+        self.assertNotIn(\"thirdapp\", changes)\n+\n+    def test_custom_migration_name(self):\n+        \"\"\"Tests custom naming of migrations for graph matching.\"\"\"\n+        # Make a fake graph\n+        graph = MigrationGraph()\n+        graph.add_node((\"testapp\", \"0001_initial\"), None)\n+        graph.add_node((\"testapp\", \"0002_foobar\"), None)\n+        graph.add_node((\"otherapp\", \"0001_initial\"), None)\n+        graph.add_dependency(\"testapp.0002_foobar\", (\"testapp\", \"0002_foobar\"), (\"testapp\", \"0001_initial\"))\n+\n+        # Use project state to make a new migration change set\n+        before = self.make_project_state([])\n+        after = self.make_project_state([self.author_empty, self.other_pony, self.other_stable])\n+        autodetector = MigrationAutodetector(before, after)\n+        changes = autodetector._detect_changes()\n+\n+        # Run through arrange_for_graph\n+        migration_name = 'custom_name'\n+        changes = autodetector.arrange_for_graph(changes, graph, migration_name)\n+\n+        # Make sure there's a new name, deps match, etc.\n+        self.assertEqual(changes[\"testapp\"][0].name, \"0003_%s\" % migration_name)\n+        self.assertEqual(changes[\"testapp\"][0].dependencies, [(\"testapp\", \"0002_foobar\")])\n+        self.assertEqual(changes[\"otherapp\"][0].name, \"0002_%s\" % migration_name)\n+        self.assertEqual(changes[\"otherapp\"][0].dependencies, [(\"otherapp\", \"0001_initial\")])\n+\n+    def test_new_model(self):\n+        \"\"\"Tests autodetection of new models.\"\"\"\n+        changes = self.get_changes([], [self.other_pony_food])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 0, name=\"Pony\")\n+        self.assertEqual([name for name, mgr in changes['otherapp'][0].operations[0].managers],\n+                         ['food_qs', 'food_mgr', 'food_mgr_kwargs'])\n+\n+    def test_old_model(self):\n+        \"\"\"Tests deletion of old models.\"\"\"\n+        changes = self.get_changes([self.author_empty], [])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"DeleteModel\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"Author\")\n+\n+    def test_add_field(self):\n+        \"\"\"Tests autodetection of new fields.\"\"\"\n+        changes = self.get_changes([self.author_empty], [self.author_name])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n+\n+    @mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_not_null_addition',\n+                side_effect=AssertionError(\"Should not have prompted for not null addition\"))\n+    def test_add_date_fields_with_auto_now_not_asking_for_default(self, mocked_ask_method):\n+        changes = self.get_changes([self.author_empty], [self.author_dates_of_birth_auto_now])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\", \"AddField\", \"AddField\"])\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, auto_now=True)\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 1, auto_now=True)\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 2, auto_now=True)\n+\n+    @mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_not_null_addition',\n+                side_effect=AssertionError(\"Should not have prompted for not null addition\"))\n+    def test_add_date_fields_with_auto_now_add_not_asking_for_null_addition(self, mocked_ask_method):\n+        changes = self.get_changes([self.author_empty], [self.author_dates_of_birth_auto_now_add])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\", \"AddField\", \"AddField\"])\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, auto_now_add=True)\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 1, auto_now_add=True)\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 2, auto_now_add=True)\n+\n+    @mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_auto_now_add_addition')\n+    def test_add_date_fields_with_auto_now_add_asking_for_default(self, mocked_ask_method):\n+        changes = self.get_changes([self.author_empty], [self.author_dates_of_birth_auto_now_add])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\", \"AddField\", \"AddField\"])\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, auto_now_add=True)\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 1, auto_now_add=True)\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 2, auto_now_add=True)\n+        self.assertEqual(mocked_ask_method.call_count, 3)\n+\n+    def test_remove_field(self):\n+        \"\"\"Tests autodetection of removed fields.\"\"\"\n+        changes = self.get_changes([self.author_name], [self.author_empty])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"RemoveField\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n+\n+    def test_alter_field(self):\n+        \"\"\"Tests autodetection of new fields.\"\"\"\n+        changes = self.get_changes([self.author_name], [self.author_name_longer])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\", preserve_default=True)\n+\n+    def test_supports_functools_partial(self):\n+        def _content_file_name(instance, filename, key, **kwargs):\n+            return '{}/{}'.format(instance, filename)\n+\n+        def content_file_name(key, **kwargs):\n+            return functools.partial(_content_file_name, key, **kwargs)\n+\n+        # An unchanged partial reference.\n+        before = [ModelState(\"testapp\", \"Author\", [\n+            (\"id\", models.AutoField(primary_key=True)),\n+            (\"file\", models.FileField(max_length=200, upload_to=content_file_name('file'))),\n+        ])]\n+        after = [ModelState(\"testapp\", \"Author\", [\n+            (\"id\", models.AutoField(primary_key=True)),\n+            (\"file\", models.FileField(max_length=200, upload_to=content_file_name('file'))),\n+        ])]\n+        changes = self.get_changes(before, after)\n+        self.assertNumberMigrations(changes, 'testapp', 0)\n+\n+        # A changed partial reference.\n+        args_changed = [ModelState(\"testapp\", \"Author\", [\n+            (\"id\", models.AutoField(primary_key=True)),\n+            (\"file\", models.FileField(max_length=200, upload_to=content_file_name('other-file'))),\n+        ])]\n+        changes = self.get_changes(before, args_changed)\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, ['AlterField'])\n+        # Can't use assertOperationFieldAttributes because we need the\n+        # deconstructed version, i.e., the exploded func/args/keywords rather\n+        # than the partial: we don't care if it's not the same instance of the\n+        # partial, only if it's the same source function, args, and keywords.\n+        value = changes['testapp'][0].operations[0].field.upload_to\n+        self.assertEqual(\n+            (_content_file_name, ('other-file',), {}),\n+            (value.func, value.args, value.keywords)\n+        )\n+\n+        kwargs_changed = [ModelState(\"testapp\", \"Author\", [\n+            (\"id\", models.AutoField(primary_key=True)),\n+            (\"file\", models.FileField(max_length=200, upload_to=content_file_name('file', spam='eggs'))),\n+        ])]\n+        changes = self.get_changes(before, kwargs_changed)\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, ['AlterField'])\n+        value = changes['testapp'][0].operations[0].field.upload_to\n+        self.assertEqual(\n+            (_content_file_name, ('file',), {'spam': 'eggs'}),\n+            (value.func, value.args, value.keywords)\n+        )\n+\n+    @mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_not_null_alteration',\n+                side_effect=AssertionError(\"Should not have prompted for not null addition\"))\n+    def test_alter_field_to_not_null_with_default(self, mocked_ask_method):\n+        \"\"\"\n+        #23609 - Tests autodetection of nullable to non-nullable alterations.\n+        \"\"\"\n+        changes = self.get_changes([self.author_name_null], [self.author_name_default])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\", preserve_default=True)\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default='Ada Lovelace')\n+\n+    @mock.patch(\n+        'django.db.migrations.questioner.MigrationQuestioner.ask_not_null_alteration',\n+        return_value=models.NOT_PROVIDED,\n+    )\n+    def test_alter_field_to_not_null_without_default(self, mocked_ask_method):\n+        \"\"\"\n+        #23609 - Tests autodetection of nullable to non-nullable alterations.\n+        \"\"\"\n+        changes = self.get_changes([self.author_name_null], [self.author_name])\n+        self.assertEqual(mocked_ask_method.call_count, 1)\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\", preserve_default=True)\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default=models.NOT_PROVIDED)\n+\n+    @mock.patch(\n+        'django.db.migrations.questioner.MigrationQuestioner.ask_not_null_alteration',\n+        return_value='Some Name',\n+    )\n+    def test_alter_field_to_not_null_oneoff_default(self, mocked_ask_method):\n+        \"\"\"\n+        #23609 - Tests autodetection of nullable to non-nullable alterations.\n+        \"\"\"\n+        changes = self.get_changes([self.author_name_null], [self.author_name])\n+        self.assertEqual(mocked_ask_method.call_count, 1)\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\", preserve_default=False)\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default=\"Some Name\")\n+\n+    def test_rename_field(self):\n+        \"\"\"Tests autodetection of renamed fields.\"\"\"\n+        changes = self.get_changes(\n+            [self.author_name], [self.author_name_renamed], MigrationQuestioner({\"ask_rename\": True})\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"RenameField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name=\"name\", new_name=\"names\")\n+\n+    def test_rename_field_foreign_key_to_field(self):\n+        before = [\n+            ModelState('app', 'Foo', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('field', models.IntegerField(unique=True)),\n+            ]),\n+            ModelState('app', 'Bar', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('foo', models.ForeignKey('app.Foo', models.CASCADE, to_field='field')),\n+            ]),\n+        ]\n+        after = [\n+            ModelState('app', 'Foo', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('renamed_field', models.IntegerField(unique=True)),\n+            ]),\n+            ModelState('app', 'Bar', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('foo', models.ForeignKey('app.Foo', models.CASCADE, to_field='renamed_field')),\n+            ]),\n+        ]\n+        changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename': True}))\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'app', 1)\n+        self.assertOperationTypes(changes, 'app', 0, ['RenameField'])\n+        self.assertOperationAttributes(changes, 'app', 0, 0, old_name='field', new_name='renamed_field')\n+\n+    def test_rename_foreign_object_fields(self):\n+        fields = ('first', 'second')\n+        renamed_fields = ('first_renamed', 'second_renamed')\n+        before = [\n+            ModelState('app', 'Foo', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('first', models.IntegerField()),\n+                ('second', models.IntegerField()),\n+            ], options={'unique_together': {fields}}),\n+            ModelState('app', 'Bar', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('first', models.IntegerField()),\n+                ('second', models.IntegerField()),\n+                ('foo', models.ForeignObject(\n+                    'app.Foo', models.CASCADE, from_fields=fields, to_fields=fields,\n+                )),\n+            ]),\n+        ]\n+        # Case 1: to_fields renames.\n+        after = [\n+            ModelState('app', 'Foo', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('first_renamed', models.IntegerField()),\n+                ('second_renamed', models.IntegerField()),\n+            ], options={'unique_together': {renamed_fields}}),\n+            ModelState('app', 'Bar', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('first', models.IntegerField()),\n+                ('second', models.IntegerField()),\n+                ('foo', models.ForeignObject(\n+                    'app.Foo', models.CASCADE, from_fields=fields, to_fields=renamed_fields,\n+                )),\n+            ]),\n+        ]\n+        changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename': True}))\n+        self.assertNumberMigrations(changes, 'app', 1)\n+        self.assertOperationTypes(changes, 'app', 0, ['RenameField', 'RenameField', 'AlterUniqueTogether'])\n+        self.assertOperationAttributes(\n+            changes, 'app', 0, 0, model_name='foo', old_name='first', new_name='first_renamed',\n+        )\n+        self.assertOperationAttributes(\n+            changes, 'app', 0, 1, model_name='foo', old_name='second', new_name='second_renamed',\n+        )\n+        # Case 2: from_fields renames.\n+        after = [\n+            ModelState('app', 'Foo', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('first', models.IntegerField()),\n+                ('second', models.IntegerField()),\n+            ], options={'unique_together': {fields}}),\n+            ModelState('app', 'Bar', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('first_renamed', models.IntegerField()),\n+                ('second_renamed', models.IntegerField()),\n+                ('foo', models.ForeignObject(\n+                    'app.Foo', models.CASCADE, from_fields=renamed_fields, to_fields=fields,\n+                )),\n+            ]),\n+        ]\n+        changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename': True}))\n+        self.assertNumberMigrations(changes, 'app', 1)\n+        self.assertOperationTypes(changes, 'app', 0, ['RenameField', 'RenameField'])\n+        self.assertOperationAttributes(\n+            changes, 'app', 0, 0, model_name='bar', old_name='first', new_name='first_renamed',\n+        )\n+        self.assertOperationAttributes(\n+            changes, 'app', 0, 1, model_name='bar', old_name='second', new_name='second_renamed',\n+        )\n+\n+    def test_rename_referenced_primary_key(self):\n+        before = [\n+            ModelState('app', 'Foo', [\n+                ('id', models.CharField(primary_key=True, serialize=False)),\n+            ]),\n+            ModelState('app', 'Bar', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('foo', models.ForeignKey('app.Foo', models.CASCADE)),\n+            ]),\n+        ]\n+        after = [\n+            ModelState('app', 'Foo', [\n+                ('renamed_id', models.CharField(primary_key=True, serialize=False))\n+            ]),\n+            ModelState('app', 'Bar', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('foo', models.ForeignKey('app.Foo', models.CASCADE)),\n+            ]),\n+        ]\n+        changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename': True}))\n+        self.assertNumberMigrations(changes, 'app', 1)\n+        self.assertOperationTypes(changes, 'app', 0, ['RenameField'])\n+        self.assertOperationAttributes(changes, 'app', 0, 0, old_name='id', new_name='renamed_id')\n+\n+    def test_rename_field_preserved_db_column(self):\n+        \"\"\"\n+        RenameField is used if a field is renamed and db_column equal to the\n+        old field's column is added.\n+        \"\"\"\n+        before = [\n+            ModelState('app', 'Foo', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('field', models.IntegerField()),\n+            ]),\n+        ]\n+        after = [\n+            ModelState('app', 'Foo', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('renamed_field', models.IntegerField(db_column='field')),\n+            ]),\n+        ]\n+        changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename': True}))\n+        self.assertNumberMigrations(changes, 'app', 1)\n+        self.assertOperationTypes(changes, 'app', 0, ['AlterField', 'RenameField'])\n+        self.assertOperationAttributes(\n+            changes, 'app', 0, 0, model_name='foo', name='field',\n+        )\n+        self.assertEqual(changes['app'][0].operations[0].field.deconstruct(), (\n+            'field', 'django.db.models.IntegerField', [], {'db_column': 'field'},\n+        ))\n+        self.assertOperationAttributes(\n+            changes, 'app', 0, 1, model_name='foo', old_name='field',\n+            new_name='renamed_field',\n+        )\n+\n+    def test_rename_related_field_preserved_db_column(self):\n+        before = [\n+            ModelState('app', 'Foo', [\n+                ('id', models.AutoField(primary_key=True)),\n+            ]),\n+            ModelState('app', 'Bar', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('foo', models.ForeignKey('app.Foo', models.CASCADE)),\n+            ]),\n+        ]\n+        after = [\n+            ModelState('app', 'Foo', [\n+                ('id', models.AutoField(primary_key=True)),\n+            ]),\n+            ModelState('app', 'Bar', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('renamed_foo', models.ForeignKey('app.Foo', models.CASCADE, db_column='foo_id')),\n+            ]),\n+        ]\n+        changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename': True}))\n+        self.assertNumberMigrations(changes, 'app', 1)\n+        self.assertOperationTypes(changes, 'app', 0, ['AlterField', 'RenameField'])\n+        self.assertOperationAttributes(\n+            changes, 'app', 0, 0, model_name='bar', name='foo',\n+        )\n+        self.assertEqual(changes['app'][0].operations[0].field.deconstruct(), (\n+            'foo',\n+            'django.db.models.ForeignKey',\n+            [],\n+            {'to': 'app.foo', 'on_delete': models.CASCADE, 'db_column': 'foo_id'},\n+        ))\n+        self.assertOperationAttributes(\n+            changes, 'app', 0, 1, model_name='bar', old_name='foo',\n+            new_name='renamed_foo',\n+        )\n+\n+    def test_rename_model(self):\n+        \"\"\"Tests autodetection of renamed models.\"\"\"\n+        changes = self.get_changes(\n+            [self.author_with_book, self.book],\n+            [self.author_renamed_with_book, self.book_with_author_renamed],\n+            MigrationQuestioner({\"ask_rename_model\": True}),\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"RenameModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name=\"Author\", new_name=\"Writer\")\n+        # Now that RenameModel handles related fields too, there should be\n+        # no AlterField for the related field.\n+        self.assertNumberMigrations(changes, 'otherapp', 0)\n+\n+    def test_rename_model_case(self):\n+        \"\"\"\n+        Model name is case-insensitive. Changing case doesn't lead to any\n+        autodetected operations.\n+        \"\"\"\n+        author_renamed = ModelState('testapp', 'author', [\n+            ('id', models.AutoField(primary_key=True)),\n+        ])\n+        changes = self.get_changes(\n+            [self.author_empty, self.book],\n+            [author_renamed, self.book],\n+            questioner=MigrationQuestioner({'ask_rename_model': True}),\n+        )\n+        self.assertNumberMigrations(changes, 'testapp', 0)\n+        self.assertNumberMigrations(changes, 'otherapp', 0)\n+\n+    def test_renamed_referenced_m2m_model_case(self):\n+        publisher_renamed = ModelState('testapp', 'publisher', [\n+            ('id', models.AutoField(primary_key=True)),\n+            ('name', models.CharField(max_length=100)),\n+        ])\n+        changes = self.get_changes(\n+            [self.publisher, self.author_with_m2m],\n+            [publisher_renamed, self.author_with_m2m],\n+            questioner=MigrationQuestioner({'ask_rename_model': True}),\n+        )\n+        self.assertNumberMigrations(changes, 'testapp', 0)\n+        self.assertNumberMigrations(changes, 'otherapp', 0)\n+\n+    def test_rename_m2m_through_model(self):\n+        \"\"\"\n+        Tests autodetection of renamed models that are used in M2M relations as\n+        through models.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.author_with_m2m_through, self.publisher, self.contract],\n+            [self.author_with_renamed_m2m_through, self.publisher, self.contract_renamed],\n+            MigrationQuestioner({'ask_rename_model': True})\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, ['RenameModel'])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name='Contract', new_name='Deal')\n+\n+    def test_rename_model_with_renamed_rel_field(self):\n+        \"\"\"\n+        Tests autodetection of renamed models while simultaneously renaming one\n+        of the fields that relate to the renamed model.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.author_with_book, self.book],\n+            [self.author_renamed_with_book, self.book_with_field_and_author_renamed],\n+            MigrationQuestioner({\"ask_rename\": True, \"ask_rename_model\": True}),\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"RenameModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name=\"Author\", new_name=\"Writer\")\n+        # Right number/type of migrations for related field rename?\n+        # Alter is already taken care of.\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, [\"RenameField\"])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, old_name=\"author\", new_name=\"writer\")\n+\n+    def test_rename_model_with_fks_in_different_position(self):\n+        \"\"\"\n+        #24537 - The order of fields in a model does not influence\n+        the RenameModel detection.\n+        \"\"\"\n+        before = [\n+            ModelState(\"testapp\", \"EntityA\", [\n+                (\"id\", models.AutoField(primary_key=True)),\n+            ]),\n+            ModelState(\"testapp\", \"EntityB\", [\n+                (\"id\", models.AutoField(primary_key=True)),\n+                (\"some_label\", models.CharField(max_length=255)),\n+                (\"entity_a\", models.ForeignKey(\"testapp.EntityA\", models.CASCADE)),\n+            ]),\n+        ]\n+        after = [\n+            ModelState(\"testapp\", \"EntityA\", [\n+                (\"id\", models.AutoField(primary_key=True)),\n+            ]),\n+            ModelState(\"testapp\", \"RenamedEntityB\", [\n+                (\"id\", models.AutoField(primary_key=True)),\n+                (\"entity_a\", models.ForeignKey(\"testapp.EntityA\", models.CASCADE)),\n+                (\"some_label\", models.CharField(max_length=255)),\n+            ]),\n+        ]\n+        changes = self.get_changes(before, after, MigrationQuestioner({\"ask_rename_model\": True}))\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"RenameModel\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, old_name=\"EntityB\", new_name=\"RenamedEntityB\")\n+\n+    def test_rename_model_reverse_relation_dependencies(self):\n+        \"\"\"\n+        The migration to rename a model pointed to by a foreign key in another\n+        app must run after the other app's migration that adds the foreign key\n+        with model's original name. Therefore, the renaming migration has a\n+        dependency on that other migration.\n+        \"\"\"\n+        before = [\n+            ModelState('testapp', 'EntityA', [\n+                ('id', models.AutoField(primary_key=True)),\n+            ]),\n+            ModelState('otherapp', 'EntityB', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('entity_a', models.ForeignKey('testapp.EntityA', models.CASCADE)),\n+            ]),\n+        ]\n+        after = [\n+            ModelState('testapp', 'RenamedEntityA', [\n+                ('id', models.AutoField(primary_key=True)),\n+            ]),\n+            ModelState('otherapp', 'EntityB', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('entity_a', models.ForeignKey('testapp.RenamedEntityA', models.CASCADE)),\n+            ]),\n+        ]\n+        changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename_model': True}))\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertMigrationDependencies(changes, 'testapp', 0, [('otherapp', '__first__')])\n+        self.assertOperationTypes(changes, 'testapp', 0, ['RenameModel'])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name='EntityA', new_name='RenamedEntityA')\n+\n+    def test_fk_dependency(self):\n+        \"\"\"Having a ForeignKey automatically adds a dependency.\"\"\"\n+        # Note that testapp (author) has no dependencies,\n+        # otherapp (book) depends on testapp (author),\n+        # thirdapp (edition) depends on otherapp (book)\n+        changes = self.get_changes([], [self.author_name, self.book, self.edition])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"Author\")\n+        self.assertMigrationDependencies(changes, 'testapp', 0, [])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=\"Book\")\n+        self.assertMigrationDependencies(changes, 'otherapp', 0, [(\"testapp\", \"auto_1\")])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'thirdapp', 1)\n+        self.assertOperationTypes(changes, 'thirdapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'thirdapp', 0, 0, name=\"Edition\")\n+        self.assertMigrationDependencies(changes, 'thirdapp', 0, [(\"otherapp\", \"auto_1\")])\n+\n+    def test_proxy_fk_dependency(self):\n+        \"\"\"FK dependencies still work on proxy models.\"\"\"\n+        # Note that testapp (author) has no dependencies,\n+        # otherapp (book) depends on testapp (authorproxy)\n+        changes = self.get_changes([], [self.author_empty, self.author_proxy_third, self.book_proxy_fk])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"Author\")\n+        self.assertMigrationDependencies(changes, 'testapp', 0, [])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=\"Book\")\n+        self.assertMigrationDependencies(changes, 'otherapp', 0, [(\"thirdapp\", \"auto_1\")])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'thirdapp', 1)\n+        self.assertOperationTypes(changes, 'thirdapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'thirdapp', 0, 0, name=\"AuthorProxy\")\n+        self.assertMigrationDependencies(changes, 'thirdapp', 0, [(\"testapp\", \"auto_1\")])\n+\n+    def test_same_app_no_fk_dependency(self):\n+        \"\"\"\n+        A migration with a FK between two models of the same app\n+        does not have a dependency to itself.\n+        \"\"\"\n+        changes = self.get_changes([], [self.author_with_publisher, self.publisher])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\", \"CreateModel\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"Publisher\")\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"Author\")\n+        self.assertMigrationDependencies(changes, 'testapp', 0, [])\n+\n+    def test_circular_fk_dependency(self):\n+        \"\"\"\n+        Having a circular ForeignKey dependency automatically\n+        resolves the situation into 2 migrations on one side and 1 on the other.\n+        \"\"\"\n+        changes = self.get_changes([], [self.author_with_book, self.book, self.publisher_with_book])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\", \"CreateModel\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"Publisher\")\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"Author\")\n+        self.assertMigrationDependencies(changes, 'testapp', 0, [(\"otherapp\", \"auto_1\")])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'otherapp', 2)\n+        self.assertOperationTypes(changes, 'otherapp', 0, [\"CreateModel\"])\n+        self.assertOperationTypes(changes, 'otherapp', 1, [\"AddField\"])\n+        self.assertMigrationDependencies(changes, 'otherapp', 0, [])\n+        self.assertMigrationDependencies(changes, 'otherapp', 1, [(\"otherapp\", \"auto_1\"), (\"testapp\", \"auto_1\")])\n+        # both split migrations should be `initial`\n+        self.assertTrue(changes['otherapp'][0].initial)\n+        self.assertTrue(changes['otherapp'][1].initial)\n+\n+    def test_same_app_circular_fk_dependency(self):\n+        \"\"\"\n+        A migration with a FK between two models of the same app does\n+        not have a dependency to itself.\n+        \"\"\"\n+        changes = self.get_changes([], [self.author_with_publisher, self.publisher_with_author])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\", \"CreateModel\", \"AddField\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"Author\")\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"Publisher\")\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 2, name=\"publisher\")\n+        self.assertMigrationDependencies(changes, 'testapp', 0, [])\n+\n+    def test_same_app_circular_fk_dependency_with_unique_together_and_indexes(self):\n+        \"\"\"\n+        #22275 - A migration with circular FK dependency does not try\n+        to create unique together constraint and indexes before creating all\n+        required fields first.\n+        \"\"\"\n+        changes = self.get_changes([], [self.knight, self.rabbit])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'eggs', 1)\n+        self.assertOperationTypes(\n+            changes, 'eggs', 0, [\"CreateModel\", \"CreateModel\", \"AddIndex\", \"AlterUniqueTogether\"]\n+        )\n+        self.assertNotIn(\"unique_together\", changes['eggs'][0].operations[0].options)\n+        self.assertNotIn(\"unique_together\", changes['eggs'][0].operations[1].options)\n+        self.assertMigrationDependencies(changes, 'eggs', 0, [])\n+\n+    def test_alter_db_table_add(self):\n+        \"\"\"Tests detection for adding db_table in model's options.\"\"\"\n+        changes = self.get_changes([self.author_empty], [self.author_with_db_table_options])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterModelTable\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"author\", table=\"author_one\")\n+\n+    def test_alter_db_table_change(self):\n+        \"\"\"Tests detection for changing db_table in model's options'.\"\"\"\n+        changes = self.get_changes([self.author_with_db_table_options], [self.author_with_new_db_table_options])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterModelTable\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"author\", table=\"author_two\")\n+\n+    def test_alter_db_table_remove(self):\n+        \"\"\"Tests detection for removing db_table in model's options.\"\"\"\n+        changes = self.get_changes([self.author_with_db_table_options], [self.author_empty])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterModelTable\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"author\", table=None)\n+\n+    def test_alter_db_table_no_changes(self):\n+        \"\"\"\n+        Alter_db_table doesn't generate a migration if no changes have been made.\n+        \"\"\"\n+        changes = self.get_changes([self.author_with_db_table_options], [self.author_with_db_table_options])\n+        # Right number of migrations?\n+        self.assertEqual(len(changes), 0)\n+\n+    def test_keep_db_table_with_model_change(self):\n+        \"\"\"\n+        Tests when model changes but db_table stays as-is, autodetector must not\n+        create more than one operation.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.author_with_db_table_options],\n+            [self.author_renamed_with_db_table_options],\n+            MigrationQuestioner({\"ask_rename_model\": True}),\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"RenameModel\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, old_name=\"Author\", new_name=\"NewAuthor\")\n+\n+    def test_alter_db_table_with_model_change(self):\n+        \"\"\"\n+        Tests when model and db_table changes, autodetector must create two\n+        operations.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.author_with_db_table_options],\n+            [self.author_renamed_with_new_db_table_options],\n+            MigrationQuestioner({\"ask_rename_model\": True}),\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"RenameModel\", \"AlterModelTable\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, old_name=\"Author\", new_name=\"NewAuthor\")\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"newauthor\", table=\"author_three\")\n+\n+    def test_identical_regex_doesnt_alter(self):\n+        from_state = ModelState(\n+            \"testapp\", \"model\", [(\"id\", models.AutoField(primary_key=True, validators=[\n+                RegexValidator(\n+                    re.compile('^[-a-zA-Z0-9_]+\\Z'),\n+                    'Enter a valid “slug” consisting of letters, numbers, underscores or hyphens.',\n+                    'invalid'\n+                )\n+            ]))]\n+        )\n+        to_state = ModelState(\n+            \"testapp\", \"model\", [(\"id\", models.AutoField(primary_key=True, validators=[validate_slug]))]\n+        )\n+        changes = self.get_changes([from_state], [to_state])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 0)\n+\n+    def test_different_regex_does_alter(self):\n+        from_state = ModelState(\n+            \"testapp\", \"model\", [(\"id\", models.AutoField(primary_key=True, validators=[\n+                RegexValidator(\n+                    re.compile('^[a-z]+\\Z', 32),\n+                    'Enter a valid “slug” consisting of letters, numbers, underscores or hyphens.',\n+                    'invalid'\n+                )\n+            ]))]\n+        )\n+        to_state = ModelState(\n+            \"testapp\", \"model\", [(\"id\", models.AutoField(primary_key=True, validators=[validate_slug]))]\n+        )\n+        changes = self.get_changes([from_state], [to_state])\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n+\n+    def test_empty_foo_together(self):\n+        \"\"\"\n+        #23452 - Empty unique/index_together shouldn't generate a migration.\n+        \"\"\"\n+        # Explicitly testing for not specified, since this is the case after\n+        # a CreateModel operation w/o any definition on the original model\n+        model_state_not_specified = ModelState(\"a\", \"model\", [(\"id\", models.AutoField(primary_key=True))])\n+        # Explicitly testing for None, since this was the issue in #23452 after\n+        # an AlterFooTogether operation with e.g. () as value\n+        model_state_none = ModelState(\"a\", \"model\", [\n+            (\"id\", models.AutoField(primary_key=True))\n+        ], {\n+            \"index_together\": None,\n+            \"unique_together\": None,\n+        })\n+        # Explicitly testing for the empty set, since we now always have sets.\n+        # During removal (('col1', 'col2'),) --> () this becomes set([])\n+        model_state_empty = ModelState(\"a\", \"model\", [\n+            (\"id\", models.AutoField(primary_key=True))\n+        ], {\n+            \"index_together\": set(),\n+            \"unique_together\": set(),\n+        })\n+\n+        def test(from_state, to_state, msg):\n+            changes = self.get_changes([from_state], [to_state])\n+            if changes:\n+                ops = ', '.join(o.__class__.__name__ for o in changes['a'][0].operations)\n+                self.fail('Created operation(s) %s from %s' % (ops, msg))\n+\n+        tests = (\n+            (model_state_not_specified, model_state_not_specified, '\"not specified\" to \"not specified\"'),\n+            (model_state_not_specified, model_state_none, '\"not specified\" to \"None\"'),\n+            (model_state_not_specified, model_state_empty, '\"not specified\" to \"empty\"'),\n+            (model_state_none, model_state_not_specified, '\"None\" to \"not specified\"'),\n+            (model_state_none, model_state_none, '\"None\" to \"None\"'),\n+            (model_state_none, model_state_empty, '\"None\" to \"empty\"'),\n+            (model_state_empty, model_state_not_specified, '\"empty\" to \"not specified\"'),\n+            (model_state_empty, model_state_none, '\"empty\" to \"None\"'),\n+            (model_state_empty, model_state_empty, '\"empty\" to \"empty\"'),\n+        )\n+\n+        for t in tests:\n+            test(*t)\n+\n+    def test_create_model_with_indexes(self):\n+        \"\"\"Test creation of new model with indexes already defined.\"\"\"\n+        author = ModelState('otherapp', 'Author', [\n+            ('id', models.AutoField(primary_key=True)),\n+            ('name', models.CharField(max_length=200)),\n+        ], {'indexes': [models.Index(fields=['name'], name='create_model_with_indexes_idx')]})\n+        changes = self.get_changes([], [author])\n+        added_index = models.Index(fields=['name'], name='create_model_with_indexes_idx')\n+        # Right number of migrations?\n+        self.assertEqual(len(changes['otherapp']), 1)\n+        # Right number of actions?\n+        migration = changes['otherapp'][0]\n+        self.assertEqual(len(migration.operations), 2)\n+        # Right actions order?\n+        self.assertOperationTypes(changes, 'otherapp', 0, ['CreateModel', 'AddIndex'])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name='Author')\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 1, model_name='author', index=added_index)\n+\n+    def test_add_indexes(self):\n+        \"\"\"Test change detection of new indexes.\"\"\"\n+        changes = self.get_changes([self.author_empty, self.book], [self.author_empty, self.book_indexes])\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, ['AddIndex'])\n+        added_index = models.Index(fields=['author', 'title'], name='book_title_author_idx')\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, model_name='book', index=added_index)\n+\n+    def test_remove_indexes(self):\n+        \"\"\"Test change detection of removed indexes.\"\"\"\n+        changes = self.get_changes([self.author_empty, self.book_indexes], [self.author_empty, self.book])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, ['RemoveIndex'])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, model_name='book', name='book_title_author_idx')\n+\n+    def test_order_fields_indexes(self):\n+        \"\"\"Test change detection of reordering of fields in indexes.\"\"\"\n+        changes = self.get_changes(\n+            [self.author_empty, self.book_indexes], [self.author_empty, self.book_unordered_indexes]\n+        )\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, ['RemoveIndex', 'AddIndex'])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, model_name='book', name='book_title_author_idx')\n+        added_index = models.Index(fields=['title', 'author'], name='book_author_title_idx')\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 1, model_name='book', index=added_index)\n+\n+    def test_create_model_with_check_constraint(self):\n+        \"\"\"Test creation of new model with constraints already defined.\"\"\"\n+        author = ModelState('otherapp', 'Author', [\n+            ('id', models.AutoField(primary_key=True)),\n+            ('name', models.CharField(max_length=200)),\n+        ], {'constraints': [models.CheckConstraint(check=models.Q(name__contains='Bob'), name='name_contains_bob')]})\n+        changes = self.get_changes([], [author])\n+        added_constraint = models.CheckConstraint(check=models.Q(name__contains='Bob'), name='name_contains_bob')\n+        # Right number of migrations?\n+        self.assertEqual(len(changes['otherapp']), 1)\n+        # Right number of actions?\n+        migration = changes['otherapp'][0]\n+        self.assertEqual(len(migration.operations), 2)\n+        # Right actions order?\n+        self.assertOperationTypes(changes, 'otherapp', 0, ['CreateModel', 'AddConstraint'])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name='Author')\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 1, model_name='author', constraint=added_constraint)\n+\n+    def test_add_constraints(self):\n+        \"\"\"Test change detection of new constraints.\"\"\"\n+        changes = self.get_changes([self.author_name], [self.author_name_check_constraint])\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, ['AddConstraint'])\n+        added_constraint = models.CheckConstraint(check=models.Q(name__contains='Bob'), name='name_contains_bob')\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, model_name='author', constraint=added_constraint)\n+\n+    def test_remove_constraints(self):\n+        \"\"\"Test change detection of removed constraints.\"\"\"\n+        changes = self.get_changes([self.author_name_check_constraint], [self.author_name])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, ['RemoveConstraint'])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, model_name='author', name='name_contains_bob')\n+\n+    def test_add_foo_together(self):\n+        \"\"\"Tests index/unique_together detection.\"\"\"\n+        changes = self.get_changes([self.author_empty, self.book], [self.author_empty, self.book_foo_together])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"otherapp\", 1)\n+        self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterUniqueTogether\", \"AlterIndexTogether\"])\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 0, name=\"book\", unique_together={(\"author\", \"title\")})\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 1, name=\"book\", index_together={(\"author\", \"title\")})\n+\n+    def test_remove_foo_together(self):\n+        \"\"\"Tests index/unique_together detection.\"\"\"\n+        changes = self.get_changes([self.author_empty, self.book_foo_together], [self.author_empty, self.book])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"otherapp\", 1)\n+        self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterUniqueTogether\", \"AlterIndexTogether\"])\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 0, name=\"book\", unique_together=set())\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 1, name=\"book\", index_together=set())\n+\n+    def test_foo_together_remove_fk(self):\n+        \"\"\"Tests unique_together and field removal detection & ordering\"\"\"\n+        changes = self.get_changes(\n+            [self.author_empty, self.book_foo_together], [self.author_empty, self.book_with_no_author]\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"otherapp\", 1)\n+        self.assertOperationTypes(changes, \"otherapp\", 0, [\n+            \"AlterUniqueTogether\", \"AlterIndexTogether\", \"RemoveField\"\n+        ])\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 0, name=\"book\", unique_together=set())\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 1, name=\"book\", index_together=set())\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 2, model_name=\"book\", name=\"author\")\n+\n+    def test_foo_together_no_changes(self):\n+        \"\"\"\n+        index/unique_together doesn't generate a migration if no\n+        changes have been made.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.author_empty, self.book_foo_together], [self.author_empty, self.book_foo_together]\n+        )\n+        # Right number of migrations?\n+        self.assertEqual(len(changes), 0)\n+\n+    def test_foo_together_ordering(self):\n+        \"\"\"\n+        index/unique_together also triggers on ordering changes.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.author_empty, self.book_foo_together], [self.author_empty, self.book_foo_together_2]\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"otherapp\", 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, [\n+            'AlterUniqueTogether',\n+            'AlterIndexTogether',\n+            'AlterUniqueTogether',\n+            'AlterIndexTogether',\n+        ])\n+        self.assertOperationAttributes(\n+            changes, 'otherapp', 0, 0, name='book', unique_together=set(),\n+        )\n+        self.assertOperationAttributes(\n+            changes, 'otherapp', 0, 1, name='book', index_together=set(),\n+        )\n+        self.assertOperationAttributes(\n+            changes, 'otherapp', 0, 2, name='book',\n+            unique_together={('title', 'author')},\n+        )\n+        self.assertOperationAttributes(\n+            changes, 'otherapp', 0, 3, name='book',\n+            index_together={('title', 'author')},\n+        )\n+\n+    def test_add_field_and_foo_together(self):\n+        \"\"\"\n+        Added fields will be created before using them in index/unique_together.\n+        \"\"\"\n+        changes = self.get_changes([self.author_empty, self.book], [self.author_empty, self.book_foo_together_3])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"otherapp\", 1)\n+        self.assertOperationTypes(changes, \"otherapp\", 0, [\"AddField\", \"AlterUniqueTogether\", \"AlterIndexTogether\"])\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 1, name=\"book\", unique_together={(\"title\", \"newfield\")})\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 2, name=\"book\", index_together={(\"title\", \"newfield\")})\n+\n+    def test_create_model_and_unique_together(self):\n+        author = ModelState(\"otherapp\", \"Author\", [\n+            (\"id\", models.AutoField(primary_key=True)),\n+            (\"name\", models.CharField(max_length=200)),\n+        ])\n+        book_with_author = ModelState(\"otherapp\", \"Book\", [\n+            (\"id\", models.AutoField(primary_key=True)),\n+            (\"author\", models.ForeignKey(\"otherapp.Author\", models.CASCADE)),\n+            (\"title\", models.CharField(max_length=200)),\n+        ], {\n+            \"index_together\": {(\"title\", \"author\")},\n+            \"unique_together\": {(\"title\", \"author\")},\n+        })\n+        changes = self.get_changes([self.book_with_no_author], [author, book_with_author])\n+        # Right number of migrations?\n+        self.assertEqual(len(changes['otherapp']), 1)\n+        # Right number of actions?\n+        migration = changes['otherapp'][0]\n+        self.assertEqual(len(migration.operations), 4)\n+        # Right actions order?\n+        self.assertOperationTypes(\n+            changes, 'otherapp', 0,\n+            ['CreateModel', 'AddField', 'AlterUniqueTogether', 'AlterIndexTogether']\n+        )\n+\n+    def test_remove_field_and_foo_together(self):\n+        \"\"\"\n+        Removed fields will be removed after updating index/unique_together.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.author_empty, self.book_foo_together_3], [self.author_empty, self.book_foo_together]\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"otherapp\", 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, [\n+            'AlterUniqueTogether',\n+            'AlterIndexTogether',\n+            'AlterUniqueTogether',\n+            'AlterIndexTogether',\n+            'RemoveField',\n+        ])\n+        self.assertOperationAttributes(\n+            changes, 'otherapp', 0, 0, name='book', unique_together=set(),\n+        )\n+        self.assertOperationAttributes(\n+            changes, 'otherapp', 0, 1, name='book', index_together=set(),\n+        )\n+        self.assertOperationAttributes(\n+            changes, 'otherapp', 0, 2, name='book',\n+            unique_together={('author', 'title')},\n+        )\n+        self.assertOperationAttributes(\n+            changes, 'otherapp', 0, 3, name='book',\n+            index_together={('author', 'title')},\n+        )\n+        self.assertOperationAttributes(\n+            changes, 'otherapp', 0, 4, model_name='book', name='newfield',\n+        )\n+\n+    def test_alter_field_and_foo_together(self):\n+        \"\"\"Fields are altered after deleting some index/unique_together.\"\"\"\n+        initial_author = ModelState('testapp', 'Author', [\n+            ('id', models.AutoField(primary_key=True)),\n+            ('name', models.CharField(max_length=200)),\n+            ('age', models.IntegerField(db_index=True)),\n+        ], {\n+            'unique_together': {('name',)},\n+        })\n+        author_reversed_constraints = ModelState('testapp', 'Author', [\n+            ('id', models.AutoField(primary_key=True)),\n+            ('name', models.CharField(max_length=200, unique=True)),\n+            ('age', models.IntegerField()),\n+        ], {\n+            'index_together': {('age',)},\n+        })\n+        changes = self.get_changes([initial_author], [author_reversed_constraints])\n+\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\n+            'AlterUniqueTogether',\n+            'AlterField',\n+            'AlterField',\n+            'AlterIndexTogether',\n+        ])\n+        self.assertOperationAttributes(\n+            changes, 'testapp', 0, 0, name='author', unique_together=set(),\n+        )\n+        self.assertOperationAttributes(\n+            changes, 'testapp', 0, 1, model_name='author', name='age',\n+        )\n+        self.assertOperationAttributes(\n+            changes, 'testapp', 0, 2, model_name='author', name='name',\n+        )\n+        self.assertOperationAttributes(\n+            changes, 'testapp', 0, 3, name='author', index_together={('age',)},\n+        )\n+\n+    def test_partly_alter_foo_together(self):\n+        initial_author = ModelState('testapp', 'Author', [\n+            ('id', models.AutoField(primary_key=True)),\n+            ('name', models.CharField(max_length=200)),\n+            ('age', models.IntegerField()),\n+        ], {\n+            'unique_together': {('name',), ('age',)},\n+            'index_together': {('name',)},\n+        })\n+        author_reversed_constraints = ModelState('testapp', 'Author', [\n+            ('id', models.AutoField(primary_key=True)),\n+            ('name', models.CharField(max_length=200)),\n+            ('age', models.IntegerField()),\n+        ], {\n+            'unique_together': {('age',)},\n+            'index_together': {('name',), ('age',)},\n+        })\n+        changes = self.get_changes([initial_author], [author_reversed_constraints])\n+\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\n+            'AlterUniqueTogether',\n+            'AlterIndexTogether',\n+        ])\n+        self.assertOperationAttributes(\n+            changes, 'testapp', 0, 0, name='author', unique_together={('age',)},\n+        )\n+        self.assertOperationAttributes(\n+            changes, 'testapp', 0, 1, name='author',\n+            index_together={('name',), ('age',)},\n+        )\n+\n+    def test_rename_field_and_foo_together(self):\n+        \"\"\"Fields are renamed before updating index/unique_together.\"\"\"\n+        changes = self.get_changes(\n+            [self.author_empty, self.book_foo_together_3],\n+            [self.author_empty, self.book_foo_together_4],\n+            MigrationQuestioner({\"ask_rename\": True}),\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"otherapp\", 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, [\n+            'RenameField',\n+            'AlterUniqueTogether',\n+            'AlterIndexTogether',\n+            'AlterUniqueTogether',\n+            'AlterIndexTogether',\n+        ])\n+        self.assertOperationAttributes(\n+            changes, 'otherapp', 0, 1, name='book', unique_together=set(),\n+        )\n+        self.assertOperationAttributes(\n+            changes, 'otherapp', 0, 2, name='book', index_together=set(),\n+        )\n+        self.assertOperationAttributes(\n+            changes, 'otherapp', 0, 3, name='book',\n+            unique_together={('title', 'newfield2')},\n+        )\n+        self.assertOperationAttributes(\n+            changes, 'otherapp', 0, 4, name='book',\n+            index_together={('title', 'newfield2')},\n+        )\n+\n+    def test_proxy(self):\n+        \"\"\"The autodetector correctly deals with proxy models.\"\"\"\n+        # First, we test adding a proxy model\n+        changes = self.get_changes([self.author_empty], [self.author_empty, self.author_proxy])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(\n+            changes, \"testapp\", 0, 0, name=\"AuthorProxy\", options={\"proxy\": True, \"indexes\": [], \"constraints\": []}\n+        )\n+        # Now, we test turning a proxy model into a non-proxy model\n+        # It should delete the proxy then make the real one\n+        changes = self.get_changes(\n+            [self.author_empty, self.author_proxy], [self.author_empty, self.author_proxy_notproxy]\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"DeleteModel\", \"CreateModel\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"AuthorProxy\")\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"AuthorProxy\", options={})\n+\n+    def test_proxy_non_model_parent(self):\n+        class Mixin:\n+            pass\n+\n+        author_proxy_non_model_parent = ModelState(\n+            'testapp',\n+            'AuthorProxy',\n+            [],\n+            {'proxy': True},\n+            (Mixin, 'testapp.author'),\n+        )\n+        changes = self.get_changes(\n+            [self.author_empty],\n+            [self.author_empty, author_proxy_non_model_parent],\n+        )\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, ['CreateModel'])\n+        self.assertOperationAttributes(\n+            changes, 'testapp', 0, 0, name='AuthorProxy',\n+            options={'proxy': True, 'indexes': [], 'constraints': []},\n+            bases=(Mixin, 'testapp.author'),\n+        )\n+\n+    def test_proxy_custom_pk(self):\n+        \"\"\"\n+        #23415 - The autodetector must correctly deal with custom FK on proxy\n+        models.\n+        \"\"\"\n+        # First, we test the default pk field name\n+        changes = self.get_changes([], [self.author_empty, self.author_proxy_third, self.book_proxy_fk])\n+        # The model the FK is pointing from and to.\n+        self.assertEqual(\n+            changes['otherapp'][0].operations[0].fields[2][1].remote_field.model,\n+            'thirdapp.AuthorProxy',\n+        )\n+        # Now, we test the custom pk field name\n+        changes = self.get_changes([], [self.author_custom_pk, self.author_proxy_third, self.book_proxy_fk])\n+        # The model the FK is pointing from and to.\n+        self.assertEqual(\n+            changes['otherapp'][0].operations[0].fields[2][1].remote_field.model,\n+            'thirdapp.AuthorProxy',\n+        )\n+\n+    def test_proxy_to_mti_with_fk_to_proxy(self):\n+        # First, test the pk table and field name.\n+        to_state = self.make_project_state(\n+            [self.author_empty, self.author_proxy_third, self.book_proxy_fk],\n+        )\n+        changes = self.get_changes([], to_state)\n+        fk_field = changes['otherapp'][0].operations[0].fields[2][1]\n+        self.assertEqual(\n+            to_state.get_concrete_model_key(fk_field.remote_field.model),\n+            ('testapp', 'author'),\n+        )\n+        self.assertEqual(fk_field.remote_field.model, 'thirdapp.AuthorProxy')\n+\n+        # Change AuthorProxy to use MTI.\n+        from_state = to_state.clone()\n+        to_state = self.make_project_state(\n+            [self.author_empty, self.author_proxy_third_notproxy, self.book_proxy_fk],\n+        )\n+        changes = self.get_changes(from_state, to_state)\n+        # Right number/type of migrations for the AuthorProxy model?\n+        self.assertNumberMigrations(changes, 'thirdapp', 1)\n+        self.assertOperationTypes(changes, 'thirdapp', 0, ['DeleteModel', 'CreateModel'])\n+        # Right number/type of migrations for the Book model with a FK to\n+        # AuthorProxy?\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])\n+        # otherapp should depend on thirdapp.\n+        self.assertMigrationDependencies(changes, 'otherapp', 0, [('thirdapp', 'auto_1')])\n+        # Now, test the pk table and field name.\n+        fk_field = changes['otherapp'][0].operations[0].field\n+        self.assertEqual(\n+            to_state.get_concrete_model_key(fk_field.remote_field.model),\n+            ('thirdapp', 'authorproxy'),\n+        )\n+        self.assertEqual(fk_field.remote_field.model, 'thirdapp.AuthorProxy')\n+\n+    def test_proxy_to_mti_with_fk_to_proxy_proxy(self):\n+        # First, test the pk table and field name.\n+        to_state = self.make_project_state([\n+            self.author_empty,\n+            self.author_proxy,\n+            self.author_proxy_proxy,\n+            self.book_proxy_proxy_fk,\n+        ])\n+        changes = self.get_changes([], to_state)\n+        fk_field = changes['otherapp'][0].operations[0].fields[1][1]\n+        self.assertEqual(\n+            to_state.get_concrete_model_key(fk_field.remote_field.model),\n+            ('testapp', 'author'),\n+        )\n+        self.assertEqual(fk_field.remote_field.model, 'testapp.AAuthorProxyProxy')\n+\n+        # Change AuthorProxy to use MTI. FK still points to AAuthorProxyProxy,\n+        # a proxy of AuthorProxy.\n+        from_state = to_state.clone()\n+        to_state = self.make_project_state([\n+            self.author_empty,\n+            self.author_proxy_notproxy,\n+            self.author_proxy_proxy,\n+            self.book_proxy_proxy_fk,\n+        ])\n+        changes = self.get_changes(from_state, to_state)\n+        # Right number/type of migrations for the AuthorProxy model?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, ['DeleteModel', 'CreateModel'])\n+        # Right number/type of migrations for the Book model with a FK to\n+        # AAuthorProxyProxy?\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])\n+        # otherapp should depend on testapp.\n+        self.assertMigrationDependencies(changes, 'otherapp', 0, [('testapp', 'auto_1')])\n+        # Now, test the pk table and field name.\n+        fk_field = changes['otherapp'][0].operations[0].field\n+        self.assertEqual(\n+            to_state.get_concrete_model_key(fk_field.remote_field.model),\n+            ('testapp', 'authorproxy'),\n+        )\n+        self.assertEqual(fk_field.remote_field.model, 'testapp.AAuthorProxyProxy')\n+\n+    def test_unmanaged_create(self):\n+        \"\"\"The autodetector correctly deals with managed models.\"\"\"\n+        # First, we test adding an unmanaged model\n+        changes = self.get_changes([self.author_empty], [self.author_empty, self.author_unmanaged])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"AuthorUnmanaged\", options={\"managed\": False})\n+\n+    def test_unmanaged_delete(self):\n+        changes = self.get_changes([self.author_empty, self.author_unmanaged], [self.author_empty])\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, ['DeleteModel'])\n+\n+    def test_unmanaged_to_managed(self):\n+        # Now, we test turning an unmanaged model into a managed model\n+        changes = self.get_changes(\n+            [self.author_empty, self.author_unmanaged], [self.author_empty, self.author_unmanaged_managed]\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterModelOptions\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"authorunmanaged\", options={})\n+\n+    def test_managed_to_unmanaged(self):\n+        # Now, we turn managed to unmanaged.\n+        changes = self.get_changes(\n+            [self.author_empty, self.author_unmanaged_managed], [self.author_empty, self.author_unmanaged]\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelOptions\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"authorunmanaged\", options={\"managed\": False})\n+\n+    def test_unmanaged_custom_pk(self):\n+        \"\"\"\n+        #23415 - The autodetector must correctly deal with custom FK on\n+        unmanaged models.\n+        \"\"\"\n+        # First, we test the default pk field name\n+        changes = self.get_changes([], [self.author_unmanaged_default_pk, self.book])\n+        # The model the FK on the book model points to.\n+        fk_field = changes['otherapp'][0].operations[0].fields[2][1]\n+        self.assertEqual(fk_field.remote_field.model, 'testapp.Author')\n+        # Now, we test the custom pk field name\n+        changes = self.get_changes([], [self.author_unmanaged_custom_pk, self.book])\n+        # The model the FK on the book model points to.\n+        fk_field = changes['otherapp'][0].operations[0].fields[2][1]\n+        self.assertEqual(fk_field.remote_field.model, 'testapp.Author')\n+\n+    @override_settings(AUTH_USER_MODEL=\"thirdapp.CustomUser\")\n+    def test_swappable(self):\n+        with isolate_lru_cache(apps.get_swappable_settings_name):\n+            changes = self.get_changes([self.custom_user], [self.custom_user, self.author_with_custom_user])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"Author\")\n+        self.assertMigrationDependencies(changes, 'testapp', 0, [(\"__setting__\", \"AUTH_USER_MODEL\")])\n+\n+    def test_swappable_changed(self):\n+        with isolate_lru_cache(apps.get_swappable_settings_name):\n+            before = self.make_project_state([self.custom_user, self.author_with_user])\n+            with override_settings(AUTH_USER_MODEL=\"thirdapp.CustomUser\"):\n+                after = self.make_project_state([self.custom_user, self.author_with_custom_user])\n+            autodetector = MigrationAutodetector(before, after)\n+            changes = autodetector._detect_changes()\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, model_name=\"author\", name='user')\n+        fk_field = changes['testapp'][0].operations[0].field\n+        self.assertEqual(fk_field.remote_field.model, 'thirdapp.CustomUser')\n+\n+    def test_add_field_with_default(self):\n+        \"\"\"#22030 - Adding a field with a default should work.\"\"\"\n+        changes = self.get_changes([self.author_empty], [self.author_name_default])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"name\")\n+\n+    def test_custom_deconstructible(self):\n+        \"\"\"\n+        Two instances which deconstruct to the same value aren't considered a\n+        change.\n+        \"\"\"\n+        changes = self.get_changes([self.author_name_deconstructible_1], [self.author_name_deconstructible_2])\n+        # Right number of migrations?\n+        self.assertEqual(len(changes), 0)\n+\n+    def test_deconstruct_field_kwarg(self):\n+        \"\"\"Field instances are handled correctly by nested deconstruction.\"\"\"\n+        changes = self.get_changes([self.author_name_deconstructible_3], [self.author_name_deconstructible_4])\n+        self.assertEqual(changes, {})\n+\n+    def test_deconstructible_list(self):\n+        \"\"\"Nested deconstruction descends into lists.\"\"\"\n+        # When lists contain items that deconstruct to identical values, those lists\n+        # should be considered equal for the purpose of detecting state changes\n+        # (even if the original items are unequal).\n+        changes = self.get_changes(\n+            [self.author_name_deconstructible_list_1], [self.author_name_deconstructible_list_2]\n+        )\n+        self.assertEqual(changes, {})\n+        # Legitimate differences within the deconstructed lists should be reported\n+        # as a change\n+        changes = self.get_changes(\n+            [self.author_name_deconstructible_list_1], [self.author_name_deconstructible_list_3]\n+        )\n+        self.assertEqual(len(changes), 1)\n+\n+    def test_deconstructible_tuple(self):\n+        \"\"\"Nested deconstruction descends into tuples.\"\"\"\n+        # When tuples contain items that deconstruct to identical values, those tuples\n+        # should be considered equal for the purpose of detecting state changes\n+        # (even if the original items are unequal).\n+        changes = self.get_changes(\n+            [self.author_name_deconstructible_tuple_1], [self.author_name_deconstructible_tuple_2]\n+        )\n+        self.assertEqual(changes, {})\n+        # Legitimate differences within the deconstructed tuples should be reported\n+        # as a change\n+        changes = self.get_changes(\n+            [self.author_name_deconstructible_tuple_1], [self.author_name_deconstructible_tuple_3]\n+        )\n+        self.assertEqual(len(changes), 1)\n+\n+    def test_deconstructible_dict(self):\n+        \"\"\"Nested deconstruction descends into dict values.\"\"\"\n+        # When dicts contain items whose values deconstruct to identical values,\n+        # those dicts should be considered equal for the purpose of detecting\n+        # state changes (even if the original values are unequal).\n+        changes = self.get_changes(\n+            [self.author_name_deconstructible_dict_1], [self.author_name_deconstructible_dict_2]\n+        )\n+        self.assertEqual(changes, {})\n+        # Legitimate differences within the deconstructed dicts should be reported\n+        # as a change\n+        changes = self.get_changes(\n+            [self.author_name_deconstructible_dict_1], [self.author_name_deconstructible_dict_3]\n+        )\n+        self.assertEqual(len(changes), 1)\n+\n+    def test_nested_deconstructible_objects(self):\n+        \"\"\"\n+        Nested deconstruction is applied recursively to the args/kwargs of\n+        deconstructed objects.\n+        \"\"\"\n+        # If the items within a deconstructed object's args/kwargs have the same\n+        # deconstructed values - whether or not the items themselves are different\n+        # instances - then the object as a whole is regarded as unchanged.\n+        changes = self.get_changes(\n+            [self.author_name_nested_deconstructible_1], [self.author_name_nested_deconstructible_2]\n+        )\n+        self.assertEqual(changes, {})\n+        # Differences that exist solely within the args list of a deconstructed object\n+        # should be reported as changes\n+        changes = self.get_changes(\n+            [self.author_name_nested_deconstructible_1], [self.author_name_nested_deconstructible_changed_arg]\n+        )\n+        self.assertEqual(len(changes), 1)\n+        # Additional args should also be reported as a change\n+        changes = self.get_changes(\n+            [self.author_name_nested_deconstructible_1], [self.author_name_nested_deconstructible_extra_arg]\n+        )\n+        self.assertEqual(len(changes), 1)\n+        # Differences that exist solely within the kwargs dict of a deconstructed object\n+        # should be reported as changes\n+        changes = self.get_changes(\n+            [self.author_name_nested_deconstructible_1], [self.author_name_nested_deconstructible_changed_kwarg]\n+        )\n+        self.assertEqual(len(changes), 1)\n+        # Additional kwargs should also be reported as a change\n+        changes = self.get_changes(\n+            [self.author_name_nested_deconstructible_1], [self.author_name_nested_deconstructible_extra_kwarg]\n+        )\n+        self.assertEqual(len(changes), 1)\n+\n+    def test_deconstruct_type(self):\n+        \"\"\"\n+        #22951 -- Uninstantiated classes with deconstruct are correctly returned\n+        by deep_deconstruct during serialization.\n+        \"\"\"\n+        author = ModelState(\n+            \"testapp\",\n+            \"Author\",\n+            [\n+                (\"id\", models.AutoField(primary_key=True)),\n+                (\"name\", models.CharField(\n+                    max_length=200,\n+                    # IntegerField intentionally not instantiated.\n+                    default=models.IntegerField,\n+                ))\n+            ],\n+        )\n+        changes = self.get_changes([], [author])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\"])\n+\n+    def test_replace_string_with_foreignkey(self):\n+        \"\"\"\n+        #22300 - Adding an FK in the same \"spot\" as a deleted CharField should\n+        work.\n+        \"\"\"\n+        changes = self.get_changes([self.author_with_publisher_string], [self.author_with_publisher, self.publisher])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\", \"RemoveField\", \"AddField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"Publisher\")\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"publisher_name\")\n+        self.assertOperationAttributes(changes, 'testapp', 0, 2, name=\"publisher\")\n+\n+    def test_foreign_key_removed_before_target_model(self):\n+        \"\"\"\n+        Removing an FK and the model it targets in the same change must remove\n+        the FK field before the model to maintain consistency.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.author_with_publisher, self.publisher], [self.author_name]\n+        )  # removes both the model and FK\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"RemoveField\", \"DeleteModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"publisher\")\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"Publisher\")\n+\n+    @mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_not_null_addition',\n+                side_effect=AssertionError(\"Should not have prompted for not null addition\"))\n+    def test_add_many_to_many(self, mocked_ask_method):\n+        \"\"\"#22435 - Adding a ManyToManyField should not prompt for a default.\"\"\"\n+        changes = self.get_changes([self.author_empty, self.publisher], [self.author_with_m2m, self.publisher])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"publishers\")\n+\n+    def test_alter_many_to_many(self):\n+        changes = self.get_changes(\n+            [self.author_with_m2m, self.publisher], [self.author_with_m2m_blank, self.publisher]\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"publishers\")\n+\n+    def test_create_with_through_model(self):\n+        \"\"\"\n+        Adding a m2m with a through model and the models that use it should be\n+        ordered correctly.\n+        \"\"\"\n+        changes = self.get_changes([], [self.author_with_m2m_through, self.publisher, self.contract])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\n+            'CreateModel', 'CreateModel', 'CreateModel', 'AddField',\n+        ])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='Author')\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, name='Publisher')\n+        self.assertOperationAttributes(changes, 'testapp', 0, 2, name='Contract')\n+        self.assertOperationAttributes(changes, 'testapp', 0, 3, model_name='author', name='publishers')\n+\n+    def test_many_to_many_removed_before_through_model(self):\n+        \"\"\"\n+        Removing a ManyToManyField and the \"through\" model in the same change\n+        must remove the field before the model to maintain consistency.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.book_with_multiple_authors_through_attribution, self.author_name, self.attribution],\n+            [self.book_with_no_author, self.author_name],\n+        )\n+        # Remove both the through model and ManyToMany\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"otherapp\", 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, ['RemoveField', 'DeleteModel'])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name='authors', model_name='book')\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 1, name='Attribution')\n+\n+    def test_many_to_many_removed_before_through_model_2(self):\n+        \"\"\"\n+        Removing a model that contains a ManyToManyField and the \"through\" model\n+        in the same change must remove the field before the model to maintain\n+        consistency.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.book_with_multiple_authors_through_attribution, self.author_name, self.attribution],\n+            [self.author_name],\n+        )\n+        # Remove both the through model and ManyToMany\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"otherapp\", 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, ['RemoveField', 'DeleteModel', 'DeleteModel'])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name='authors', model_name='book')\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 1, name='Attribution')\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 2, name='Book')\n+\n+    def test_m2m_w_through_multistep_remove(self):\n+        \"\"\"\n+        A model with a m2m field that specifies a \"through\" model cannot be\n+        removed in the same migration as that through model as the schema will\n+        pass through an inconsistent state. The autodetector should produce two\n+        migrations to avoid this issue.\n+        \"\"\"\n+        changes = self.get_changes([self.author_with_m2m_through, self.publisher, self.contract], [self.publisher])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\n+            \"RemoveField\", \"RemoveField\", \"DeleteModel\", \"DeleteModel\"\n+        ])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"author\", model_name='contract')\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"publisher\", model_name='contract')\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 2, name=\"Author\")\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 3, name=\"Contract\")\n+\n+    def test_concrete_field_changed_to_many_to_many(self):\n+        \"\"\"\n+        #23938 - Changing a concrete field into a ManyToManyField\n+        first removes the concrete field and then adds the m2m field.\n+        \"\"\"\n+        changes = self.get_changes([self.author_with_former_m2m], [self.author_with_m2m, self.publisher])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"CreateModel\", \"RemoveField\", \"AddField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='Publisher')\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"publishers\", model_name='author')\n+        self.assertOperationAttributes(changes, 'testapp', 0, 2, name=\"publishers\", model_name='author')\n+\n+    def test_many_to_many_changed_to_concrete_field(self):\n+        \"\"\"\n+        #23938 - Changing a ManyToManyField into a concrete field\n+        first removes the m2m field and then adds the concrete field.\n+        \"\"\"\n+        changes = self.get_changes([self.author_with_m2m, self.publisher], [self.author_with_former_m2m])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"RemoveField\", \"AddField\", \"DeleteModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"publishers\", model_name='author')\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"publishers\", model_name='author')\n+        self.assertOperationAttributes(changes, 'testapp', 0, 2, name='Publisher')\n+        self.assertOperationFieldAttributes(changes, 'testapp', 0, 1, max_length=100)\n+\n+    def test_non_circular_foreignkey_dependency_removal(self):\n+        \"\"\"\n+        If two models with a ForeignKey from one to the other are removed at the\n+        same time, the autodetector should remove them in the correct order.\n+        \"\"\"\n+        changes = self.get_changes([self.author_with_publisher, self.publisher_with_author], [])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"RemoveField\", \"DeleteModel\", \"DeleteModel\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"author\", model_name='publisher')\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"Author\")\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 2, name=\"Publisher\")\n+\n+    def test_alter_model_options(self):\n+        \"\"\"Changing a model's options should make a change.\"\"\"\n+        changes = self.get_changes([self.author_empty], [self.author_with_options])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelOptions\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, options={\n+            \"permissions\": [('can_hire', 'Can hire')],\n+            \"verbose_name\": \"Authi\",\n+        })\n+\n+        # Changing them back to empty should also make a change\n+        changes = self.get_changes([self.author_with_options], [self.author_empty])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelOptions\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"author\", options={})\n+\n+    def test_alter_model_options_proxy(self):\n+        \"\"\"Changing a proxy model's options should also make a change.\"\"\"\n+        changes = self.get_changes(\n+            [self.author_proxy, self.author_empty], [self.author_proxy_options, self.author_empty]\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelOptions\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"authorproxy\", options={\n+            \"verbose_name\": \"Super Author\"\n+        })\n+\n+    def test_set_alter_order_with_respect_to(self):\n+        \"\"\"Setting order_with_respect_to adds a field.\"\"\"\n+        changes = self.get_changes([self.book, self.author_with_book], [self.book, self.author_with_book_order_wrt])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterOrderWithRespectTo\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"author\", order_with_respect_to=\"book\")\n+\n+    def test_add_alter_order_with_respect_to(self):\n+        \"\"\"\n+        Setting order_with_respect_to when adding the FK too does\n+        things in the right order.\n+        \"\"\"\n+        changes = self.get_changes([self.author_name], [self.book, self.author_with_book_order_wrt])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\", \"AlterOrderWithRespectTo\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, model_name=\"author\", name=\"book\")\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"author\", order_with_respect_to=\"book\")\n+\n+    def test_remove_alter_order_with_respect_to(self):\n+        \"\"\"\n+        Removing order_with_respect_to when removing the FK too does\n+        things in the right order.\n+        \"\"\"\n+        changes = self.get_changes([self.book, self.author_with_book_order_wrt], [self.author_name])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterOrderWithRespectTo\", \"RemoveField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"author\", order_with_respect_to=None)\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, model_name=\"author\", name=\"book\")\n+\n+    def test_add_model_order_with_respect_to(self):\n+        \"\"\"\n+        Setting order_with_respect_to when adding the whole model\n+        does things in the right order.\n+        \"\"\"\n+        changes = self.get_changes([], [self.book, self.author_with_book_order_wrt])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(\n+            changes, 'testapp', 0, 0, name=\"Author\", options={'order_with_respect_to': 'book'}\n+        )\n+        self.assertNotIn(\"_order\", [name for name, field in changes['testapp'][0].operations[0].fields])\n+\n+    def test_add_model_order_with_respect_to_index_foo_together(self):\n+        changes = self.get_changes([], [\n+            self.book,\n+            ModelState('testapp', 'Author', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('name', models.CharField(max_length=200)),\n+                ('book', models.ForeignKey('otherapp.Book', models.CASCADE)),\n+            ], options={\n+                'order_with_respect_to': 'book',\n+                'index_together': {('name', '_order')},\n+                'unique_together': {('id', '_order')},\n+            }),\n+        ])\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, ['CreateModel'])\n+        self.assertOperationAttributes(\n+            changes,\n+            'testapp',\n+            0,\n+            0,\n+            name='Author',\n+            options={\n+                'order_with_respect_to': 'book',\n+                'index_together': {('name', '_order')},\n+                'unique_together': {('id', '_order')},\n+            },\n+        )\n+\n+    def test_add_model_order_with_respect_to_index_constraint(self):\n+        tests = [\n+            (\n+                'AddIndex',\n+                {'indexes': [\n+                    models.Index(fields=['_order'], name='book_order_idx'),\n+                ]},\n+            ),\n+            (\n+                'AddConstraint',\n+                {'constraints': [\n+                    models.CheckConstraint(\n+                        check=models.Q(_order__gt=1),\n+                        name='book_order_gt_1',\n+                    ),\n+                ]},\n+            ),\n+        ]\n+        for operation, extra_option in tests:\n+            with self.subTest(operation=operation):\n+                after = ModelState('testapp', 'Author', [\n+                    ('id', models.AutoField(primary_key=True)),\n+                    ('name', models.CharField(max_length=200)),\n+                    ('book', models.ForeignKey('otherapp.Book', models.CASCADE)),\n+                ], options={\n+                    'order_with_respect_to': 'book',\n+                    **extra_option,\n+                })\n+                changes = self.get_changes([], [self.book, after])\n+                self.assertNumberMigrations(changes, 'testapp', 1)\n+                self.assertOperationTypes(changes, 'testapp', 0, [\n+                    'CreateModel', operation,\n+                ])\n+                self.assertOperationAttributes(\n+                    changes,\n+                    'testapp',\n+                    0,\n+                    0,\n+                    name='Author',\n+                    options={'order_with_respect_to': 'book'},\n+                )\n+\n+    def test_set_alter_order_with_respect_to_index_constraint_foo_together(self):\n+        tests = [\n+            (\n+                'AddIndex',\n+                {'indexes': [\n+                    models.Index(fields=['_order'], name='book_order_idx'),\n+                ]},\n+            ),\n+            (\n+                'AddConstraint',\n+                {'constraints': [\n+                    models.CheckConstraint(\n+                        check=models.Q(_order__gt=1),\n+                        name='book_order_gt_1',\n+                    ),\n+                ]},\n+            ),\n+            ('AlterIndexTogether', {'index_together': {('name', '_order')}}),\n+            ('AlterUniqueTogether', {'unique_together': {('id', '_order')}}),\n+        ]\n+        for operation, extra_option in tests:\n+            with self.subTest(operation=operation):\n+                after = ModelState('testapp', 'Author', [\n+                    ('id', models.AutoField(primary_key=True)),\n+                    ('name', models.CharField(max_length=200)),\n+                    ('book', models.ForeignKey('otherapp.Book', models.CASCADE)),\n+                ], options={\n+                    'order_with_respect_to': 'book',\n+                    **extra_option,\n+                })\n+                changes = self.get_changes(\n+                    [self.book, self.author_with_book],\n+                    [self.book, after],\n+                )\n+                self.assertNumberMigrations(changes, 'testapp', 1)\n+                self.assertOperationTypes(changes, 'testapp', 0, [\n+                    'AlterOrderWithRespectTo', operation,\n+                ])\n+\n+    def test_alter_model_managers(self):\n+        \"\"\"\n+        Changing the model managers adds a new operation.\n+        \"\"\"\n+        changes = self.get_changes([self.other_pony], [self.other_pony_food])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, [\"AlterModelManagers\"])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=\"pony\")\n+        self.assertEqual([name for name, mgr in changes['otherapp'][0].operations[0].managers],\n+                         ['food_qs', 'food_mgr', 'food_mgr_kwargs'])\n+        self.assertEqual(changes['otherapp'][0].operations[0].managers[1][1].args, ('a', 'b', 1, 2))\n+        self.assertEqual(changes['otherapp'][0].operations[0].managers[2][1].args, ('x', 'y', 3, 4))\n+\n+    def test_swappable_first_inheritance(self):\n+        \"\"\"Swappable models get their CreateModel first.\"\"\"\n+        changes = self.get_changes([], [self.custom_user, self.aardvark])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'thirdapp', 1)\n+        self.assertOperationTypes(changes, 'thirdapp', 0, [\"CreateModel\", \"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'thirdapp', 0, 0, name=\"CustomUser\")\n+        self.assertOperationAttributes(changes, 'thirdapp', 0, 1, name=\"Aardvark\")\n+\n+    def test_default_related_name_option(self):\n+        model_state = ModelState('app', 'model', [\n+            ('id', models.AutoField(primary_key=True)),\n+        ], options={'default_related_name': 'related_name'})\n+        changes = self.get_changes([], [model_state])\n+        self.assertNumberMigrations(changes, 'app', 1)\n+        self.assertOperationTypes(changes, 'app', 0, ['CreateModel'])\n+        self.assertOperationAttributes(\n+            changes, 'app', 0, 0, name='model',\n+            options={'default_related_name': 'related_name'},\n+        )\n+        altered_model_state = ModelState('app', 'Model', [\n+            ('id', models.AutoField(primary_key=True)),\n+        ])\n+        changes = self.get_changes([model_state], [altered_model_state])\n+        self.assertNumberMigrations(changes, 'app', 1)\n+        self.assertOperationTypes(changes, 'app', 0, ['AlterModelOptions'])\n+        self.assertOperationAttributes(changes, 'app', 0, 0, name='model', options={})\n+\n+    @override_settings(AUTH_USER_MODEL=\"thirdapp.CustomUser\")\n+    def test_swappable_first_setting(self):\n+        \"\"\"Swappable models get their CreateModel first.\"\"\"\n+        with isolate_lru_cache(apps.get_swappable_settings_name):\n+            changes = self.get_changes([], [self.custom_user_no_inherit, self.aardvark])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'thirdapp', 1)\n+        self.assertOperationTypes(changes, 'thirdapp', 0, [\"CreateModel\", \"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'thirdapp', 0, 0, name=\"CustomUser\")\n+        self.assertOperationAttributes(changes, 'thirdapp', 0, 1, name=\"Aardvark\")\n+\n+    def test_bases_first(self):\n+        \"\"\"Bases of other models come first.\"\"\"\n+        changes = self.get_changes([], [self.aardvark_based_on_author, self.author_name])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\", \"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"Author\")\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"Aardvark\")\n+\n+    def test_bases_first_mixed_case_app_label(self):\n+        app_label = 'MiXedCaseApp'\n+        changes = self.get_changes([], [\n+            ModelState(app_label, 'owner', [\n+                ('id', models.AutoField(primary_key=True)),\n+            ]),\n+            ModelState(app_label, 'place', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('owner', models.ForeignKey('MiXedCaseApp.owner', models.CASCADE)),\n+            ]),\n+            ModelState(app_label, 'restaurant', [], bases=('MiXedCaseApp.place',)),\n+        ])\n+        self.assertNumberMigrations(changes, app_label, 1)\n+        self.assertOperationTypes(changes, app_label, 0, [\n+            'CreateModel', 'CreateModel', 'CreateModel',\n+        ])\n+        self.assertOperationAttributes(changes, app_label, 0, 0, name='owner')\n+        self.assertOperationAttributes(changes, app_label, 0, 1, name='place')\n+        self.assertOperationAttributes(changes, app_label, 0, 2, name='restaurant')\n+\n+    def test_multiple_bases(self):\n+        \"\"\"#23956 - Inheriting models doesn't move *_ptr fields into AddField operations.\"\"\"\n+        A = ModelState(\"app\", \"A\", [(\"a_id\", models.AutoField(primary_key=True))])\n+        B = ModelState(\"app\", \"B\", [(\"b_id\", models.AutoField(primary_key=True))])\n+        C = ModelState(\"app\", \"C\", [], bases=(\"app.A\", \"app.B\"))\n+        D = ModelState(\"app\", \"D\", [], bases=(\"app.A\", \"app.B\"))\n+        E = ModelState(\"app\", \"E\", [], bases=(\"app.A\", \"app.B\"))\n+        changes = self.get_changes([], [A, B, C, D, E])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"app\", 1)\n+        self.assertOperationTypes(changes, \"app\", 0, [\n+            \"CreateModel\", \"CreateModel\", \"CreateModel\", \"CreateModel\", \"CreateModel\"\n+        ])\n+        self.assertOperationAttributes(changes, \"app\", 0, 0, name=\"A\")\n+        self.assertOperationAttributes(changes, \"app\", 0, 1, name=\"B\")\n+        self.assertOperationAttributes(changes, \"app\", 0, 2, name=\"C\")\n+        self.assertOperationAttributes(changes, \"app\", 0, 3, name=\"D\")\n+        self.assertOperationAttributes(changes, \"app\", 0, 4, name=\"E\")\n+\n+    def test_proxy_bases_first(self):\n+        \"\"\"Bases of proxies come first.\"\"\"\n+        changes = self.get_changes([], [self.author_empty, self.author_proxy, self.author_proxy_proxy])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\", \"CreateModel\", \"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"Author\")\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"AuthorProxy\")\n+        self.assertOperationAttributes(changes, 'testapp', 0, 2, name=\"AAuthorProxyProxy\")\n+\n+    def test_pk_fk_included(self):\n+        \"\"\"\n+        A relation used as the primary key is kept as part of CreateModel.\n+        \"\"\"\n+        changes = self.get_changes([], [self.aardvark_pk_fk_author, self.author_name])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\", \"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"Author\")\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"Aardvark\")\n+\n+    def test_first_dependency(self):\n+        \"\"\"\n+        A dependency to an app with no migrations uses __first__.\n+        \"\"\"\n+        # Load graph\n+        loader = MigrationLoader(connection)\n+        before = self.make_project_state([])\n+        after = self.make_project_state([self.book_migrations_fk])\n+        after.real_apps = {'migrations'}\n+        autodetector = MigrationAutodetector(before, after)\n+        changes = autodetector._detect_changes(graph=loader.graph)\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=\"Book\")\n+        self.assertMigrationDependencies(changes, 'otherapp', 0, [(\"migrations\", \"__first__\")])\n+\n+    @override_settings(MIGRATION_MODULES={\"migrations\": \"migrations.test_migrations\"})\n+    def test_last_dependency(self):\n+        \"\"\"\n+        A dependency to an app with existing migrations uses the\n+        last migration of that app.\n+        \"\"\"\n+        # Load graph\n+        loader = MigrationLoader(connection)\n+        before = self.make_project_state([])\n+        after = self.make_project_state([self.book_migrations_fk])\n+        after.real_apps = {'migrations'}\n+        autodetector = MigrationAutodetector(before, after)\n+        changes = autodetector._detect_changes(graph=loader.graph)\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=\"Book\")\n+        self.assertMigrationDependencies(changes, 'otherapp', 0, [(\"migrations\", \"0002_second\")])\n+\n+    def test_alter_fk_before_model_deletion(self):\n+        \"\"\"\n+        ForeignKeys are altered _before_ the model they used to\n+        refer to are deleted.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.author_name, self.publisher_with_author],\n+            [self.aardvark_testapp, self.publisher_with_aardvark_author]\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\", \"AlterField\", \"DeleteModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"Aardvark\")\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"author\")\n+        self.assertOperationAttributes(changes, 'testapp', 0, 2, name=\"Author\")\n+\n+    def test_fk_dependency_other_app(self):\n+        \"\"\"\n+        #23100 - ForeignKeys correctly depend on other apps' models.\n+        \"\"\"\n+        changes = self.get_changes([self.author_name, self.book], [self.author_with_book, self.book])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"book\")\n+        self.assertMigrationDependencies(changes, 'testapp', 0, [(\"otherapp\", \"__first__\")])\n+\n+    def test_alter_field_to_fk_dependency_other_app(self):\n+        changes = self.get_changes(\n+            [self.author_empty, self.book_with_no_author_fk],\n+            [self.author_empty, self.book],\n+        )\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])\n+        self.assertMigrationDependencies(changes, 'otherapp', 0, [('testapp', '__first__')])\n+\n+    def test_circular_dependency_mixed_addcreate(self):\n+        \"\"\"\n+        #23315 - The dependency resolver knows to put all CreateModel\n+        before AddField and not become unsolvable.\n+        \"\"\"\n+        address = ModelState(\"a\", \"Address\", [\n+            (\"id\", models.AutoField(primary_key=True)),\n+            (\"country\", models.ForeignKey(\"b.DeliveryCountry\", models.CASCADE)),\n+        ])\n+        person = ModelState(\"a\", \"Person\", [\n+            (\"id\", models.AutoField(primary_key=True)),\n+        ])\n+        apackage = ModelState(\"b\", \"APackage\", [\n+            (\"id\", models.AutoField(primary_key=True)),\n+            (\"person\", models.ForeignKey(\"a.Person\", models.CASCADE)),\n+        ])\n+        country = ModelState(\"b\", \"DeliveryCountry\", [\n+            (\"id\", models.AutoField(primary_key=True)),\n+        ])\n+        changes = self.get_changes([], [address, person, apackage, country])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'a', 2)\n+        self.assertNumberMigrations(changes, 'b', 1)\n+        self.assertOperationTypes(changes, 'a', 0, [\"CreateModel\", \"CreateModel\"])\n+        self.assertOperationTypes(changes, 'a', 1, [\"AddField\"])\n+        self.assertOperationTypes(changes, 'b', 0, [\"CreateModel\", \"CreateModel\"])\n+\n+    @override_settings(AUTH_USER_MODEL=\"a.Tenant\")\n+    def test_circular_dependency_swappable(self):\n+        \"\"\"\n+        #23322 - The dependency resolver knows to explicitly resolve\n+        swappable models.\n+        \"\"\"\n+        with isolate_lru_cache(apps.get_swappable_settings_name):\n+            tenant = ModelState(\"a\", \"Tenant\", [\n+                (\"id\", models.AutoField(primary_key=True)),\n+                (\"primary_address\", models.ForeignKey(\"b.Address\", models.CASCADE))],\n+                bases=(AbstractBaseUser,)\n+            )\n+            address = ModelState(\"b\", \"Address\", [\n+                (\"id\", models.AutoField(primary_key=True)),\n+                (\"tenant\", models.ForeignKey(settings.AUTH_USER_MODEL, models.CASCADE)),\n+            ])\n+            changes = self.get_changes([], [address, tenant])\n+\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'a', 2)\n+        self.assertOperationTypes(changes, 'a', 0, [\"CreateModel\"])\n+        self.assertOperationTypes(changes, 'a', 1, [\"AddField\"])\n+        self.assertMigrationDependencies(changes, 'a', 0, [])\n+        self.assertMigrationDependencies(changes, 'a', 1, [('a', 'auto_1'), ('b', 'auto_1')])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'b', 1)\n+        self.assertOperationTypes(changes, 'b', 0, [\"CreateModel\"])\n+        self.assertMigrationDependencies(changes, 'b', 0, [('__setting__', 'AUTH_USER_MODEL')])\n+\n+    @override_settings(AUTH_USER_MODEL=\"b.Tenant\")\n+    def test_circular_dependency_swappable2(self):\n+        \"\"\"\n+        #23322 - The dependency resolver knows to explicitly resolve\n+        swappable models but with the swappable not being the first migrated\n+        model.\n+        \"\"\"\n+        with isolate_lru_cache(apps.get_swappable_settings_name):\n+            address = ModelState(\"a\", \"Address\", [\n+                (\"id\", models.AutoField(primary_key=True)),\n+                (\"tenant\", models.ForeignKey(settings.AUTH_USER_MODEL, models.CASCADE)),\n+            ])\n+            tenant = ModelState(\"b\", \"Tenant\", [\n+                (\"id\", models.AutoField(primary_key=True)),\n+                (\"primary_address\", models.ForeignKey(\"a.Address\", models.CASCADE))],\n+                bases=(AbstractBaseUser,)\n+            )\n+            changes = self.get_changes([], [address, tenant])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'a', 2)\n+        self.assertOperationTypes(changes, 'a', 0, [\"CreateModel\"])\n+        self.assertOperationTypes(changes, 'a', 1, [\"AddField\"])\n+        self.assertMigrationDependencies(changes, 'a', 0, [])\n+        self.assertMigrationDependencies(changes, 'a', 1, [('__setting__', 'AUTH_USER_MODEL'), ('a', 'auto_1')])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'b', 1)\n+        self.assertOperationTypes(changes, 'b', 0, [\"CreateModel\"])\n+        self.assertMigrationDependencies(changes, 'b', 0, [('a', 'auto_1')])\n+\n+    @override_settings(AUTH_USER_MODEL=\"a.Person\")\n+    def test_circular_dependency_swappable_self(self):\n+        \"\"\"\n+        #23322 - The dependency resolver knows to explicitly resolve\n+        swappable models.\n+        \"\"\"\n+        with isolate_lru_cache(apps.get_swappable_settings_name):\n+            person = ModelState(\"a\", \"Person\", [\n+                (\"id\", models.AutoField(primary_key=True)),\n+                (\"parent1\", models.ForeignKey(settings.AUTH_USER_MODEL, models.CASCADE, related_name='children'))\n+            ])\n+            changes = self.get_changes([], [person])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'a', 1)\n+        self.assertOperationTypes(changes, 'a', 0, [\"CreateModel\"])\n+        self.assertMigrationDependencies(changes, 'a', 0, [])\n+\n+    @override_settings(AUTH_USER_MODEL='a.User')\n+    def test_swappable_circular_multi_mti(self):\n+        with isolate_lru_cache(apps.get_swappable_settings_name):\n+            parent = ModelState('a', 'Parent', [\n+                ('user', models.ForeignKey(settings.AUTH_USER_MODEL, models.CASCADE))\n+            ])\n+            child = ModelState('a', 'Child', [], bases=('a.Parent',))\n+            user = ModelState('a', 'User', [], bases=(AbstractBaseUser, 'a.Child'))\n+            changes = self.get_changes([], [parent, child, user])\n+        self.assertNumberMigrations(changes, 'a', 1)\n+        self.assertOperationTypes(changes, 'a', 0, ['CreateModel', 'CreateModel', 'CreateModel', 'AddField'])\n+\n+    @mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_not_null_addition',\n+                side_effect=AssertionError(\"Should not have prompted for not null addition\"))\n+    def test_add_blank_textfield_and_charfield(self, mocked_ask_method):\n+        \"\"\"\n+        #23405 - Adding a NOT NULL and blank `CharField` or `TextField`\n+        without default should not prompt for a default.\n+        \"\"\"\n+        changes = self.get_changes([self.author_empty], [self.author_with_biography_blank])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\", \"AddField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0)\n+\n+    @mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_not_null_addition')\n+    def test_add_non_blank_textfield_and_charfield(self, mocked_ask_method):\n+        \"\"\"\n+        #23405 - Adding a NOT NULL and non-blank `CharField` or `TextField`\n+        without default should prompt for a default.\n+        \"\"\"\n+        changes = self.get_changes([self.author_empty], [self.author_with_biography_non_blank])\n+        self.assertEqual(mocked_ask_method.call_count, 2)\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\", \"AddField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0)\n+\n+    def test_mti_inheritance_model_removal(self):\n+        Animal = ModelState('app', 'Animal', [\n+            (\"id\", models.AutoField(primary_key=True)),\n+        ])\n+        Dog = ModelState('app', 'Dog', [], bases=('app.Animal',))\n+        changes = self.get_changes([Animal, Dog], [Animal])\n+        self.assertNumberMigrations(changes, 'app', 1)\n+        self.assertOperationTypes(changes, 'app', 0, ['DeleteModel'])\n+        self.assertOperationAttributes(changes, 'app', 0, 0, name='Dog')\n+\n+    def test_add_model_with_field_removed_from_base_model(self):\n+        \"\"\"\n+        Removing a base field takes place before adding a new inherited model\n+        that has a field with the same name.\n+        \"\"\"\n+        before = [\n+            ModelState('app', 'readable', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('title', models.CharField(max_length=200)),\n+            ]),\n+        ]\n+        after = [\n+            ModelState('app', 'readable', [\n+                ('id', models.AutoField(primary_key=True)),\n+            ]),\n+            ModelState('app', 'book', [\n+                ('title', models.CharField(max_length=200)),\n+            ], bases=('app.readable',)),\n+        ]\n+        changes = self.get_changes(before, after)\n+        self.assertNumberMigrations(changes, 'app', 1)\n+        self.assertOperationTypes(changes, 'app', 0, ['RemoveField', 'CreateModel'])\n+        self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='readable')\n+        self.assertOperationAttributes(changes, 'app', 0, 1, name='book')\n+\n+    def test_parse_number(self):\n+        tests = [\n+            ('no_number', None),\n+            ('0001_initial', 1),\n+            ('0002_model3', 2),\n+            ('0002_auto_20380101_1112', 2),\n+            ('0002_squashed_0003', 3),\n+            ('0002_model2_squashed_0003_other4', 3),\n+            ('0002_squashed_0003_squashed_0004', 4),\n+            ('0002_model2_squashed_0003_other4_squashed_0005_other6', 5),\n+            ('0002_custom_name_20380101_1112_squashed_0003_model', 3),\n+            ('2_squashed_4', 4),\n+        ]\n+        for migration_name, expected_number in tests:\n+            with self.subTest(migration_name=migration_name):\n+                self.assertEqual(\n+                    MigrationAutodetector.parse_number(migration_name),\n+                    expected_number,\n+                )\n+\n+\n+class MigrationSuggestNameTests(SimpleTestCase):\n+    def test_no_operations(self):\n+        class Migration(migrations.Migration):\n+            operations = []\n+\n+        migration = Migration('some_migration', 'test_app')\n+        self.assertIs(migration.suggest_name().startswith('auto_'), True)\n+\n+    def test_no_operations_initial(self):\n+        class Migration(migrations.Migration):\n+            initial = True\n+            operations = []\n+\n+        migration = Migration('some_migration', 'test_app')\n+        self.assertEqual(migration.suggest_name(), 'initial')\n+\n+    def test_single_operation(self):\n+        class Migration(migrations.Migration):\n+            operations = [migrations.CreateModel('Person', fields=[])]\n+\n+        migration = Migration('0001_initial', 'test_app')\n+        self.assertEqual(migration.suggest_name(), 'person')\n+\n+        class Migration(migrations.Migration):\n+            operations = [migrations.DeleteModel('Person')]\n+\n+        migration = Migration('0002_initial', 'test_app')\n+        self.assertEqual(migration.suggest_name(), 'delete_person')\n+\n+    def test_single_operation_long_name(self):\n+        class Migration(migrations.Migration):\n+            operations = [migrations.CreateModel('A' * 53, fields=[])]\n+\n+        migration = Migration('some_migration', 'test_app')\n+        self.assertEqual(migration.suggest_name(), 'a' * 53)\n+\n+    def test_two_operations(self):\n+        class Migration(migrations.Migration):\n+            operations = [\n+                migrations.CreateModel('Person', fields=[]),\n+                migrations.DeleteModel('Animal'),\n+            ]\n+\n+        migration = Migration('some_migration', 'test_app')\n+        self.assertEqual(migration.suggest_name(), 'person_delete_animal')\n+\n+    def test_two_create_models(self):\n+        class Migration(migrations.Migration):\n+            operations = [\n+                migrations.CreateModel('Person', fields=[]),\n+                migrations.CreateModel('Animal', fields=[]),\n+            ]\n+\n+        migration = Migration('0001_initial', 'test_app')\n+        self.assertEqual(migration.suggest_name(), 'person_animal')\n+\n+    def test_two_create_models_with_initial_true(self):\n+        class Migration(migrations.Migration):\n+            initial = True\n+            operations = [\n+                migrations.CreateModel('Person', fields=[]),\n+                migrations.CreateModel('Animal', fields=[]),\n+            ]\n+\n+        migration = Migration('0001_initial', 'test_app')\n+        self.assertEqual(migration.suggest_name(), 'initial')\n+\n+    def test_many_operations_suffix(self):\n+        class Migration(migrations.Migration):\n+            operations = [\n+                migrations.CreateModel('Person1', fields=[]),\n+                migrations.CreateModel('Person2', fields=[]),\n+                migrations.CreateModel('Person3', fields=[]),\n+                migrations.DeleteModel('Person4'),\n+                migrations.DeleteModel('Person5'),\n+            ]\n+\n+        migration = Migration('some_migration', 'test_app')\n+        self.assertEqual(\n+            migration.suggest_name(),\n+            'person1_person2_person3_delete_person4_and_more',\n+        )\n+\n+    def test_operation_with_no_suggested_name(self):\n+        class Migration(migrations.Migration):\n+            operations = [\n+                migrations.CreateModel('Person', fields=[]),\n+                migrations.RunSQL('SELECT 1 FROM person;'),\n+            ]\n+\n+        migration = Migration('some_migration', 'test_app')\n+        self.assertIs(migration.suggest_name().startswith('auto_'), True)\n+\n+    def test_none_name(self):\n+        class Migration(migrations.Migration):\n+            operations = [migrations.RunSQL('SELECT 1 FROM person;')]\n+\n+        migration = Migration('0001_initial', 'test_app')\n+        suggest_name = migration.suggest_name()\n+        self.assertIs(suggest_name.startswith('auto_'), True)\n+\n+    def test_none_name_with_initial_true(self):\n+        class Migration(migrations.Migration):\n+            initial = True\n+            operations = [migrations.RunSQL('SELECT 1 FROM person;')]\n+\n+        migration = Migration('0001_initial', 'test_app')\n+        self.assertEqual(migration.suggest_name(), 'initial')\n+\n+    def test_auto(self):\n+        migration = migrations.Migration('0001_initial', 'test_app')\n+        suggest_name = migration.suggest_name()\n+        self.assertIs(suggest_name.startswith('auto_'), True)\n"
    },
    "matplotlib__matplotlib-24149": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_bar.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_bar.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_bar.py b/lib/matplotlib/tests/test_bar.py\nnew file mode 100644\nindex 0000000000..f03805c9af\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_bar.py\n@@ -0,0 +1,17 @@\n+import numpy as np\n+import matplotlib.pyplot as plt\n+\n+\n+def test_bar_all_nan():\n+    \"\"\"\n+    Test that drawing a bar with nan-only data does not raise an error.\n+\n+    This is a regression test for issue #24125, where ax.bar would raise\n+    a StopIteration error for all-NaN data on matplotlib 3.6.1.\n+    The expected behavior is to create a bar, even if it's not visible.\n+    \"\"\"\n+    fig, ax = plt.subplots()\n+    # This call should not raise an exception.\n+    container = ax.bar([np.nan], [np.nan])\n+    # A BarContainer should be returned with one patch.\n+    assert len(container.patches) == 1\n"
    },
    "scikit-learn__scikit-learn-25931": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sklearn/ensemble/tests/test_iforest_issue_25824.py",
        "reproduced_bug_commands": [
            "pytest sklearn/ensemble/tests/test_iforest_issue_25824.py"
        ],
        "reproduced_bug_patch": "diff --git a/sklearn/ensemble/tests/test_iforest_issue_25824.py b/sklearn/ensemble/tests/test_iforest_issue_25824.py\nnew file mode 100644\nindex 0000000000..ca0b3c17d9\n--- /dev/null\n+++ b/sklearn/ensemble/tests/test_iforest_issue_25824.py\n@@ -0,0 +1,24 @@\n+import warnings\n+import pandas as pd\n+import pytest\n+\n+from sklearn.ensemble import IsolationForest\n+\n+\n+def test_iforest_fit_dataframe_with_contamination_no_warning():\n+    \"\"\"Check that fitting with a dataframe and contamination does not raise a\n+    warning about feature names.\n+\n+    Non-regression test for #25824.\n+    \"\"\"\n+    X = pd.DataFrame({\"a\": [-1.1, 0.3, 0.5, 100]})\n+    clf = IsolationForest(random_state=0, contamination=0.05)\n+\n+    # This should not raise \"X does not have valid feature names...\"\n+    with warnings.catch_warnings():\n+        warnings.filterwarnings(\n+            \"error\",\n+            message=\"X does not have valid feature names\",\n+            category=UserWarning,\n+        )\n+        clf.fit(X)\n"
    },
    "sympy__sympy-18199": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "django__django-12754": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/migrations/test_autodetector_bug.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py migrations.test_autodetector_bug"
        ],
        "reproduced_bug_patch": "diff --git a/tests/migrations/test_autodetector_bug.py b/tests/migrations/test_autodetector_bug.py\nnew file mode 100644\nindex 0000000000..4498079d26\n--- /dev/null\n+++ b/tests/migrations/test_autodetector_bug.py\n@@ -0,0 +1,2490 @@\n+import functools\n+import re\n+from unittest import mock\n+\n+from django.apps import apps\n+from django.conf import settings\n+from django.contrib.auth.models import AbstractBaseUser\n+from django.core.validators import RegexValidator, validate_slug\n+from django.db import connection, models\n+from django.db.migrations.autodetector import MigrationAutodetector\n+from django.db.migrations.graph import MigrationGraph\n+from django.db.migrations.loader import MigrationLoader\n+from django.db.migrations.questioner import MigrationQuestioner\n+from django.db.migrations.state import ModelState, ProjectState\n+from django.test import TestCase, override_settings\n+from django.test.utils import isolate_lru_cache\n+\n+from .models import FoodManager, FoodQuerySet\n+\n+\n+class DeconstructibleObject:\n+    \"\"\"\n+    A custom deconstructible object.\n+    \"\"\"\n+\n+    def __init__(self, *args, **kwargs):\n+        self.args = args\n+        self.kwargs = kwargs\n+\n+    def deconstruct(self):\n+        return (\n+            self.__module__ + '.' + self.__class__.__name__,\n+            self.args,\n+            self.kwargs\n+        )\n+\n+\n+class AutodetectorTests(TestCase):\n+    \"\"\"\n+    Tests the migration autodetector.\n+    \"\"\"\n+\n+    author_empty = ModelState(\"testapp\", \"Author\", [(\"id\", models.AutoField(primary_key=True))])\n+    author_name = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200)),\n+    ])\n+    author_name_null = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, null=True)),\n+    ])\n+    author_name_longer = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=400)),\n+    ])\n+    author_name_renamed = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"names\", models.CharField(max_length=200)),\n+    ])\n+    author_name_default = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default='Ada Lovelace')),\n+    ])\n+    author_name_check_constraint = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200)),\n+    ],\n+        {'constraints': [models.CheckConstraint(check=models.Q(name__contains='Bob'), name='name_contains_bob')]},\n+    )\n+    author_dates_of_birth_auto_now = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"date_of_birth\", models.DateField(auto_now=True)),\n+        (\"date_time_of_birth\", models.DateTimeField(auto_now=True)),\n+        (\"time_of_birth\", models.TimeField(auto_now=True)),\n+    ])\n+    author_dates_of_birth_auto_now_add = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"date_of_birth\", models.DateField(auto_now_add=True)),\n+        (\"date_time_of_birth\", models.DateTimeField(auto_now_add=True)),\n+        (\"time_of_birth\", models.TimeField(auto_now_add=True)),\n+    ])\n+    author_name_deconstructible_1 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=DeconstructibleObject())),\n+    ])\n+    author_name_deconstructible_2 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=DeconstructibleObject())),\n+    ])\n+    author_name_deconstructible_3 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=models.IntegerField())),\n+    ])\n+    author_name_deconstructible_4 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=models.IntegerField())),\n+    ])\n+    author_name_deconstructible_list_1 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=[DeconstructibleObject(), 123])),\n+    ])\n+    author_name_deconstructible_list_2 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=[DeconstructibleObject(), 123])),\n+    ])\n+    author_name_deconstructible_list_3 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=[DeconstructibleObject(), 999])),\n+    ])\n+    author_name_deconstructible_tuple_1 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=(DeconstructibleObject(), 123))),\n+    ])\n+    author_name_deconstructible_tuple_2 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=(DeconstructibleObject(), 123))),\n+    ])\n+    author_name_deconstructible_tuple_3 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=(DeconstructibleObject(), 999))),\n+    ])\n+    author_name_deconstructible_dict_1 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default={\n+            'item': DeconstructibleObject(), 'otheritem': 123\n+        })),\n+    ])\n+    author_name_deconstructible_dict_2 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default={\n+            'item': DeconstructibleObject(), 'otheritem': 123\n+        })),\n+    ])\n+    author_name_deconstructible_dict_3 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default={\n+            'item': DeconstructibleObject(), 'otheritem': 999\n+        })),\n+    ])\n+    author_name_nested_deconstructible_1 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=DeconstructibleObject(\n+            DeconstructibleObject(1),\n+            (DeconstructibleObject('t1'), DeconstructibleObject('t2'),),\n+            a=DeconstructibleObject('A'),\n+            b=DeconstructibleObject(B=DeconstructibleObject('c')),\n+        ))),\n+    ])\n+    author_name_nested_deconstructible_2 = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=DeconstructibleObject(\n+            DeconstructibleObject(1),\n+            (DeconstructibleObject('t1'), DeconstructibleObject('t2'),),\n+            a=DeconstructibleObject('A'),\n+            b=DeconstructibleObject(B=DeconstructibleObject('c')),\n+        ))),\n+    ])\n+    author_name_nested_deconstructible_changed_arg = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=DeconstructibleObject(\n+            DeconstructibleObject(1),\n+            (DeconstructibleObject('t1'), DeconstructibleObject('t2-changed'),),\n+            a=DeconstructibleObject('A'),\n+            b=DeconstructibleObject(B=DeconstructibleObject('c')),\n+        ))),\n+    ])\n+    author_name_nested_deconstructible_extra_arg = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=DeconstructibleObject(\n+            DeconstructibleObject(1),\n+            (DeconstructibleObject('t1'), DeconstructibleObject('t2'),),\n+            None,\n+            a=DeconstructibleObject('A'),\n+            b=DeconstructibleObject(B=DeconstructibleObject('c')),\n+        ))),\n+    ])\n+    author_name_nested_deconstructible_changed_kwarg = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=DeconstructibleObject(\n+            DeconstructibleObject(1),\n+            (DeconstructibleObject('t1'), DeconstructibleObject('t2'),),\n+            a=DeconstructibleObject('A'),\n+            b=DeconstructibleObject(B=DeconstructibleObject('c-changed')),\n+        ))),\n+    ])\n+    author_name_nested_deconstructible_extra_kwarg = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200, default=DeconstructibleObject(\n+            DeconstructibleObject(1),\n+            (DeconstructibleObject('t1'), DeconstructibleObject('t2'),),\n+            a=DeconstructibleObject('A'),\n+            b=DeconstructibleObject(B=DeconstructibleObject('c')),\n+            c=None,\n+        ))),\n+    ])\n+    author_custom_pk = ModelState(\"testapp\", \"Author\", [(\"pk_field\", models.IntegerField(primary_key=True))])\n+    author_with_biography_non_blank = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField()),\n+        (\"biography\", models.TextField()),\n+    ])\n+    author_with_biography_blank = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(blank=True)),\n+        (\"biography\", models.TextField(blank=True)),\n+    ])\n+    author_with_book = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200)),\n+        (\"book\", models.ForeignKey(\"otherapp.Book\", models.CASCADE)),\n+    ])\n+    author_with_book_order_wrt = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200)),\n+        (\"book\", models.ForeignKey(\"otherapp.Book\", models.CASCADE)),\n+    ], options={\"order_with_respect_to\": \"book\"})\n+    author_renamed_with_book = ModelState(\"testapp\", \"Writer\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200)),\n+        (\"book\", models.ForeignKey(\"otherapp.Book\", models.CASCADE)),\n+    ])\n+    author_with_publisher_string = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200)),\n+        (\"publisher_name\", models.CharField(max_length=200)),\n+    ])\n+    author_with_publisher = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200)),\n+        (\"publisher\", models.ForeignKey(\"testapp.Publisher\", models.CASCADE)),\n+    ])\n+    author_with_user = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200)),\n+        (\"user\", models.ForeignKey(\"auth.User\", models.CASCADE)),\n+    ])\n+    author_with_custom_user = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=200)),\n+        (\"user\", models.ForeignKey(\"thirdapp.CustomUser\", models.CASCADE)),\n+    ])\n+    author_proxy = ModelState(\"testapp\", \"AuthorProxy\", [], {\"proxy\": True}, (\"testapp.author\",))\n+    author_proxy_options = ModelState(\"testapp\", \"AuthorProxy\", [], {\n+        \"proxy\": True,\n+        \"verbose_name\": \"Super Author\",\n+    }, (\"testapp.author\",))\n+    author_proxy_notproxy = ModelState(\"testapp\", \"AuthorProxy\", [], {}, (\"testapp.author\",))\n+    author_proxy_third = ModelState(\"thirdapp\", \"AuthorProxy\", [], {\"proxy\": True}, (\"testapp.author\",))\n+    author_proxy_third_notproxy = ModelState(\"thirdapp\", \"AuthorProxy\", [], {}, (\"testapp.author\",))\n+    author_proxy_proxy = ModelState(\"testapp\", \"AAuthorProxyProxy\", [], {\"proxy\": True}, (\"testapp.authorproxy\",))\n+    author_unmanaged = ModelState(\"testapp\", \"AuthorUnmanaged\", [], {\"managed\": False}, (\"testapp.author\",))\n+    author_unmanaged_managed = ModelState(\"testapp\", \"AuthorUnmanaged\", [], {}, (\"testapp.author\",))\n+    author_unmanaged_default_pk = ModelState(\"testapp\", \"Author\", [(\"id\", models.AutoField(primary_key=True))])\n+    author_unmanaged_custom_pk = ModelState(\"testapp\", \"Author\", [\n+        (\"pk_field\", models.IntegerField(primary_key=True)),\n+    ])\n+    author_with_m2m = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"publishers\", models.ManyToManyField(\"testapp.Publisher\")),\n+    ])\n+    author_with_m2m_blank = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"publishers\", models.ManyToManyField(\"testapp.Publisher\", blank=True)),\n+    ])\n+    author_with_m2m_through = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"publishers\", models.ManyToManyField(\"testapp.Publisher\", through=\"testapp.Contract\")),\n+    ])\n+    author_with_renamed_m2m_through = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"publishers\", models.ManyToManyField(\"testapp.Publisher\", through=\"testapp.Deal\")),\n+    ])\n+    author_with_former_m2m = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"publishers\", models.CharField(max_length=100)),\n+    ])\n+    author_with_options = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+    ], {\n+        \"permissions\": [('can_hire', 'Can hire')],\n+        \"verbose_name\": \"Authi\",\n+    })\n+    author_with_db_table_options = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+    ], {\"db_table\": \"author_one\"})\n+    author_with_new_db_table_options = ModelState(\"testapp\", \"Author\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+    ], {\"db_table\": \"author_two\"})\n+    author_renamed_with_db_table_options = ModelState(\"testapp\", \"NewAuthor\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+    ], {\"db_table\": \"author_one\"})\n+    author_renamed_with_new_db_table_options = ModelState(\"testapp\", \"NewAuthor\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+    ], {\"db_table\": \"author_three\"})\n+    contract = ModelState(\"testapp\", \"Contract\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"publisher\", models.ForeignKey(\"testapp.Publisher\", models.CASCADE)),\n+    ])\n+    contract_renamed = ModelState(\"testapp\", \"Deal\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"publisher\", models.ForeignKey(\"testapp.Publisher\", models.CASCADE)),\n+    ])\n+    publisher = ModelState(\"testapp\", \"Publisher\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"name\", models.CharField(max_length=100)),\n+    ])\n+    publisher_with_author = ModelState(\"testapp\", \"Publisher\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"name\", models.CharField(max_length=100)),\n+    ])\n+    publisher_with_aardvark_author = ModelState(\"testapp\", \"Publisher\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Aardvark\", models.CASCADE)),\n+        (\"name\", models.CharField(max_length=100)),\n+    ])\n+    publisher_with_book = ModelState(\"testapp\", \"Publisher\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"otherapp.Book\", models.CASCADE)),\n+        (\"name\", models.CharField(max_length=100)),\n+    ])\n+    other_pony = ModelState(\"otherapp\", \"Pony\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+    ])\n+    other_pony_food = ModelState(\"otherapp\", \"Pony\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+    ], managers=[\n+        ('food_qs', FoodQuerySet.as_manager()),\n+        ('food_mgr', FoodManager('a', 'b')),\n+        ('food_mgr_kwargs', FoodManager('x', 'y', 3, 4)),\n+    ])\n+    other_stable = ModelState(\"otherapp\", \"Stable\", [(\"id\", models.AutoField(primary_key=True))])\n+    third_thing = ModelState(\"thirdapp\", \"Thing\", [(\"id\", models.AutoField(primary_key=True))])\n+    book = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ])\n+    book_proxy_fk = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"thirdapp.AuthorProxy\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ])\n+    book_proxy_proxy_fk = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.AAuthorProxyProxy\", models.CASCADE)),\n+    ])\n+    book_migrations_fk = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"migrations.UnmigratedModel\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ])\n+    book_with_no_author_fk = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.IntegerField()),\n+        (\"title\", models.CharField(max_length=200)),\n+    ])\n+    book_with_no_author = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ])\n+    book_with_author_renamed = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Writer\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ])\n+    book_with_field_and_author_renamed = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"writer\", models.ForeignKey(\"testapp.Writer\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ])\n+    book_with_multiple_authors = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"authors\", models.ManyToManyField(\"testapp.Author\")),\n+        (\"title\", models.CharField(max_length=200)),\n+    ])\n+    book_with_multiple_authors_through_attribution = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"authors\", models.ManyToManyField(\"testapp.Author\", through=\"otherapp.Attribution\")),\n+        (\"title\", models.CharField(max_length=200)),\n+    ])\n+    book_indexes = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ], {\n+        \"indexes\": [models.Index(fields=[\"author\", \"title\"], name=\"book_title_author_idx\")],\n+    })\n+    book_unordered_indexes = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ], {\n+        \"indexes\": [models.Index(fields=[\"title\", \"author\"], name=\"book_author_title_idx\")],\n+    })\n+    book_foo_together = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ], {\n+        \"index_together\": {(\"author\", \"title\")},\n+        \"unique_together\": {(\"author\", \"title\")},\n+    })\n+    book_foo_together_2 = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ], {\n+        \"index_together\": {(\"title\", \"author\")},\n+        \"unique_together\": {(\"title\", \"author\")},\n+    })\n+    book_foo_together_3 = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"newfield\", models.IntegerField()),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ], {\n+        \"index_together\": {(\"title\", \"newfield\")},\n+        \"unique_together\": {(\"title\", \"newfield\")},\n+    })\n+    book_foo_together_4 = ModelState(\"otherapp\", \"Book\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"newfield2\", models.IntegerField()),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"title\", models.CharField(max_length=200)),\n+    ], {\n+        \"index_together\": {(\"title\", \"newfield2\")},\n+        \"unique_together\": {(\"title\", \"newfield2\")},\n+    })\n+    attribution = ModelState(\"otherapp\", \"Attribution\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n+        (\"book\", models.ForeignKey(\"otherapp.Book\", models.CASCADE)),\n+    ])\n+    edition = ModelState(\"thirdapp\", \"Edition\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"book\", models.ForeignKey(\"otherapp.Book\", models.CASCADE)),\n+    ])\n+    custom_user = ModelState(\"thirdapp\", \"CustomUser\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"username\", models.CharField(max_length=255)),\n+    ], bases=(AbstractBaseUser,))\n+    custom_user_no_inherit = ModelState(\"thirdapp\", \"CustomUser\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"username\", models.CharField(max_length=255)),\n+    ])\n+    aardvark = ModelState(\"thirdapp\", \"Aardvark\", [(\"id\", models.AutoField(primary_key=True))])\n+    aardvark_testapp = ModelState(\"testapp\", \"Aardvark\", [(\"id\", models.AutoField(primary_key=True))])\n+    aardvark_based_on_author = ModelState(\"testapp\", \"Aardvark\", [], bases=(\"testapp.Author\",))\n+    aardvark_pk_fk_author = ModelState(\"testapp\", \"Aardvark\", [\n+        (\"id\", models.OneToOneField(\"testapp.Author\", models.CASCADE, primary_key=True)),\n+    ])\n+    knight = ModelState(\"eggs\", \"Knight\", [(\"id\", models.AutoField(primary_key=True))])\n+    rabbit = ModelState(\"eggs\", \"Rabbit\", [\n+        (\"id\", models.AutoField(primary_key=True)),\n+        (\"knight\", models.ForeignKey(\"eggs.Knight\", models.CASCADE)),\n+        (\"parent\", models.ForeignKey(\"eggs.Rabbit\", models.CASCADE)),\n+    ], {\n+        \"unique_together\": {(\"parent\", \"knight\")},\n+        \"indexes\": [models.Index(fields=[\"parent\", \"knight\"], name='rabbit_circular_fk_index')],\n+    })\n+\n+    def repr_changes(self, changes, include_dependencies=False):\n+        output = \"\"\n+        for app_label, migrations in sorted(changes.items()):\n+            output += \"  %s:\\n\" % app_label\n+            for migration in migrations:\n+                output += \"    %s\\n\" % migration.name\n+                for operation in migration.operations:\n+                    output += \"      %s\\n\" % operation\n+                if include_dependencies:\n+                    output += \"      Dependencies:\\n\"\n+                    if migration.dependencies:\n+                        for dep in migration.dependencies:\n+                            output += \"        %s\\n\" % (dep,)\n+                    else:\n+                        output += \"        None\\n\"\n+        return output\n+\n+    def assertNumberMigrations(self, changes, app_label, number):\n+        if len(changes.get(app_label, [])) != number:\n+            self.fail(\"Incorrect number of migrations (%s) for %s (expected %s)\\n%s\" % (\n+                len(changes.get(app_label, [])),\n+                app_label,\n+                number,\n+                self.repr_changes(changes),\n+            ))\n+\n+    def assertMigrationDependencies(self, changes, app_label, position, dependencies):\n+        if not changes.get(app_label):\n+            self.fail(\"No migrations found for %s\\n%s\" % (app_label, self.repr_changes(changes)))\n+        if len(changes[app_label]) < position + 1:\n+            self.fail(\"No migration at index %s for %s\\n%s\" % (position, app_label, self.repr_changes(changes)))\n+        migration = changes[app_label][position]\n+        if set(migration.dependencies) != set(dependencies):\n+            self.fail(\"Migration dependencies mismatch for %s.%s (expected %s):\\n%s\" % (\n+                app_label,\n+                migration.name,\n+                dependencies,\n+                self.repr_changes(changes, include_dependencies=True),\n+            ))\n+\n+    def assertOperationTypes(self, changes, app_label, position, types):\n+        if not changes.get(app_label):\n+            self.fail(\"No migrations found for %s\\n%s\" % (app_label, self.repr_changes(changes)))\n+        if len(changes[app_label]) < position + 1:\n+            self.fail(\"No migration at index %s for %s\\n%s\" % (position, app_label, self.repr_changes(changes)))\n+        migration = changes[app_label][position]\n+        real_types = [operation.__class__.__name__ for operation in migration.operations]\n+        if types != real_types:\n+            self.fail(\"Operation type mismatch for %s.%s (expected %s):\\n%s\" % (\n+                app_label,\n+                migration.name,\n+                types,\n+                self.repr_changes(changes),\n+            ))\n+\n+    def assertOperationAttributes(self, changes, app_label, position, operation_position, **attrs):\n+        if not changes.get(app_label):\n+            self.fail(\"No migrations found for %s\\n%s\" % (app_label, self.repr_changes(changes)))\n+        if len(changes[app_label]) < position + 1:\n+            self.fail(\"No migration at index %s for %s\\n%s\" % (position, app_label, self.repr_changes(changes)))\n+        migration = changes[app_label][position]\n+        if len(changes[app_label]) < position + 1:\n+            self.fail(\"No operation at index %s for %s.%s\\n%s\" % (\n+                operation_position,\n+                app_label,\n+                migration.name,\n+                self.repr_changes(changes),\n+            ))\n+        operation = migration.operations[operation_position]\n+        for attr, value in attrs.items():\n+            if getattr(operation, attr, None) != value:\n+                self.fail(\"Attribute mismatch for %s.%s op #%s, %s (expected %r, got %r):\\n%s\" % (\n+                    app_label,\n+                    migration.name,\n+                    operation_position,\n+                    attr,\n+                    value,\n+                    getattr(operation, attr, None),\n+                    self.repr_changes(changes),\n+                ))\n+\n+    def assertOperationFieldAttributes(self, changes, app_label, position, operation_position, **attrs):\n+        if not changes.get(app_label):\n+            self.fail(\"No migrations found for %s\\n%s\" % (app_label, self.repr_changes(changes)))\n+        if len(changes[app_label]) < position + 1:\n+            self.fail(\"No migration at index %s for %s\\n%s\" % (position, app_label, self.repr_changes(changes)))\n+        migration = changes[app_label][position]\n+        if len(changes[app_label]) < position + 1:\n+            self.fail(\"No operation at index %s for %s.%s\\n%s\" % (\n+                operation_position,\n+                app_label,\n+                migration.name,\n+                self.repr_changes(changes),\n+            ))\n+        operation = migration.operations[operation_position]\n+        if not hasattr(operation, 'field'):\n+            self.fail(\"No field attribute for %s.%s op #%s.\" % (\n+                app_label,\n+                migration.name,\n+                operation_position,\n+            ))\n+        field = operation.field\n+        for attr, value in attrs.items():\n+            if getattr(field, attr, None) != value:\n+                self.fail(\"Field attribute mismatch for %s.%s op #%s, field.%s (expected %r, got %r):\\n%s\" % (\n+                    app_label,\n+                    migration.name,\n+                    operation_position,\n+                    attr,\n+                    value,\n+                    getattr(field, attr, None),\n+                    self.repr_changes(changes),\n+                ))\n+\n+    def make_project_state(self, model_states):\n+        \"Shortcut to make ProjectStates from lists of predefined models\"\n+        project_state = ProjectState()\n+        for model_state in model_states:\n+            project_state.add_model(model_state.clone())\n+        return project_state\n+\n+    def get_changes(self, before_states, after_states, questioner=None):\n+        return MigrationAutodetector(\n+            self.make_project_state(before_states),\n+            self.make_project_state(after_states),\n+            questioner,\n+        )._detect_changes()\n+\n+    def test_arrange_for_graph(self):\n+        \"\"\"Tests auto-naming of migrations for graph matching.\"\"\"\n+        # Make a fake graph\n+        graph = MigrationGraph()\n+        graph.add_node((\"testapp\", \"0001_initial\"), None)\n+        graph.add_node((\"testapp\", \"0002_foobar\"), None)\n+        graph.add_node((\"otherapp\", \"0001_initial\"), None)\n+        graph.add_dependency(\"testapp.0002_foobar\", (\"testapp\", \"0002_foobar\"), (\"testapp\", \"0001_initial\"))\n+        graph.add_dependency(\"testapp.0002_foobar\", (\"testapp\", \"0002_foobar\"), (\"otherapp\", \"0001_initial\"))\n+        # Use project state to make a new migration change set\n+        before = self.make_project_state([])\n+        after = self.make_project_state([self.author_empty, self.other_pony, self.other_stable])\n+        autodetector = MigrationAutodetector(before, after)\n+        changes = autodetector._detect_changes()\n+        # Run through arrange_for_graph\n+        changes = autodetector.arrange_for_graph(changes, graph)\n+        # Make sure there's a new name, deps match, etc.\n+        self.assertEqual(changes[\"testapp\"][0].name, \"0003_author\")\n+        self.assertEqual(changes[\"testapp\"][0].dependencies, [(\"testapp\", \"0002_foobar\")])\n+        self.assertEqual(changes[\"otherapp\"][0].name, \"0002_pony_stable\")\n+        self.assertEqual(changes[\"otherapp\"][0].dependencies, [(\"otherapp\", \"0001_initial\")])\n+\n+    def test_trim_apps(self):\n+        \"\"\"\n+        Trim does not remove dependencies but does remove unwanted apps.\n+        \"\"\"\n+        # Use project state to make a new migration change set\n+        before = self.make_project_state([])\n+        after = self.make_project_state([self.author_empty, self.other_pony, self.other_stable, self.third_thing])\n+        autodetector = MigrationAutodetector(before, after, MigrationQuestioner({\"ask_initial\": True}))\n+        changes = autodetector._detect_changes()\n+        # Run through arrange_for_graph\n+        graph = MigrationGraph()\n+        changes = autodetector.arrange_for_graph(changes, graph)\n+        changes[\"testapp\"][0].dependencies.append((\"otherapp\", \"0001_initial\"))\n+        changes = autodetector._trim_to_apps(changes, {\"testapp\"})\n+        # Make sure there's the right set of migrations\n+        self.assertEqual(changes[\"testapp\"][0].name, \"0001_initial\")\n+        self.assertEqual(changes[\"otherapp\"][0].name, \"0001_initial\")\n+        self.assertNotIn(\"thirdapp\", changes)\n+\n+    def test_custom_migration_name(self):\n+        \"\"\"Tests custom naming of migrations for graph matching.\"\"\"\n+        # Make a fake graph\n+        graph = MigrationGraph()\n+        graph.add_node((\"testapp\", \"0001_initial\"), None)\n+        graph.add_node((\"testapp\", \"0002_foobar\"), None)\n+        graph.add_node((\"otherapp\", \"0001_initial\"), None)\n+        graph.add_dependency(\"testapp.0002_foobar\", (\"testapp\", \"0002_foobar\"), (\"testapp\", \"0001_initial\"))\n+\n+        # Use project state to make a new migration change set\n+        before = self.make_project_state([])\n+        after = self.make_project_state([self.author_empty, self.other_pony, self.other_stable])\n+        autodetector = MigrationAutodetector(before, after)\n+        changes = autodetector._detect_changes()\n+\n+        # Run through arrange_for_graph\n+        migration_name = 'custom_name'\n+        changes = autodetector.arrange_for_graph(changes, graph, migration_name)\n+\n+        # Make sure there's a new name, deps match, etc.\n+        self.assertEqual(changes[\"testapp\"][0].name, \"0003_%s\" % migration_name)\n+        self.assertEqual(changes[\"testapp\"][0].dependencies, [(\"testapp\", \"0002_foobar\")])\n+        self.assertEqual(changes[\"otherapp\"][0].name, \"0002_%s\" % migration_name)\n+        self.assertEqual(changes[\"otherapp\"][0].dependencies, [(\"otherapp\", \"0001_initial\")])\n+\n+    def test_new_model(self):\n+        \"\"\"Tests autodetection of new models.\"\"\"\n+        changes = self.get_changes([], [self.other_pony_food])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 0, name=\"Pony\")\n+        self.assertEqual([name for name, mgr in changes['otherapp'][0].operations[0].managers],\n+                         ['food_qs', 'food_mgr', 'food_mgr_kwargs'])\n+\n+    def test_old_model(self):\n+        \"\"\"Tests deletion of old models.\"\"\"\n+        changes = self.get_changes([self.author_empty], [])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"DeleteModel\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"Author\")\n+\n+    def test_add_field(self):\n+        \"\"\"Tests autodetection of new fields.\"\"\"\n+        changes = self.get_changes([self.author_empty], [self.author_name])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n+\n+    @mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_not_null_addition',\n+                side_effect=AssertionError(\"Should not have prompted for not null addition\"))\n+    def test_add_date_fields_with_auto_now_not_asking_for_default(self, mocked_ask_method):\n+        changes = self.get_changes([self.author_empty], [self.author_dates_of_birth_auto_now])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\", \"AddField\", \"AddField\"])\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, auto_now=True)\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 1, auto_now=True)\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 2, auto_now=True)\n+\n+    @mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_not_null_addition',\n+                side_effect=AssertionError(\"Should not have prompted for not null addition\"))\n+    def test_add_date_fields_with_auto_now_add_not_asking_for_null_addition(self, mocked_ask_method):\n+        changes = self.get_changes([self.author_empty], [self.author_dates_of_birth_auto_now_add])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\", \"AddField\", \"AddField\"])\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, auto_now_add=True)\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 1, auto_now_add=True)\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 2, auto_now_add=True)\n+\n+    @mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_auto_now_add_addition')\n+    def test_add_date_fields_with_auto_now_add_asking_for_default(self, mocked_ask_method):\n+        changes = self.get_changes([self.author_empty], [self.author_dates_of_birth_auto_now_add])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\", \"AddField\", \"AddField\"])\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, auto_now_add=True)\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 1, auto_now_add=True)\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 2, auto_now_add=True)\n+        self.assertEqual(mocked_ask_method.call_count, 3)\n+\n+    def test_remove_field(self):\n+        \"\"\"Tests autodetection of removed fields.\"\"\"\n+        changes = self.get_changes([self.author_name], [self.author_empty])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"RemoveField\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n+\n+    def test_alter_field(self):\n+        \"\"\"Tests autodetection of new fields.\"\"\"\n+        changes = self.get_changes([self.author_name], [self.author_name_longer])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\", preserve_default=True)\n+\n+    def test_supports_functools_partial(self):\n+        def _content_file_name(instance, filename, key, **kwargs):\n+            return '{}/{}'.format(instance, filename)\n+\n+        def content_file_name(key, **kwargs):\n+            return functools.partial(_content_file_name, key, **kwargs)\n+\n+        # An unchanged partial reference.\n+        before = [ModelState(\"testapp\", \"Author\", [\n+            (\"id\", models.AutoField(primary_key=True)),\n+            (\"file\", models.FileField(max_length=200, upload_to=content_file_name('file'))),\n+        ])]\n+        after = [ModelState(\"testapp\", \"Author\", [\n+            (\"id\", models.AutoField(primary_key=True)),\n+            (\"file\", models.FileField(max_length=200, upload_to=content_file_name('file'))),\n+        ])]\n+        changes = self.get_changes(before, after)\n+        self.assertNumberMigrations(changes, 'testapp', 0)\n+\n+        # A changed partial reference.\n+        args_changed = [ModelState(\"testapp\", \"Author\", [\n+            (\"id\", models.AutoField(primary_key=True)),\n+            (\"file\", models.FileField(max_length=200, upload_to=content_file_name('other-file'))),\n+        ])]\n+        changes = self.get_changes(before, args_changed)\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, ['AlterField'])\n+        # Can't use assertOperationFieldAttributes because we need the\n+        # deconstructed version, i.e., the exploded func/args/keywords rather\n+        # than the partial: we don't care if it's not the same instance of the\n+        # partial, only if it's the same source function, args, and keywords.\n+        value = changes['testapp'][0].operations[0].field.upload_to\n+        self.assertEqual(\n+            (_content_file_name, ('other-file',), {}),\n+            (value.func, value.args, value.keywords)\n+        )\n+\n+        kwargs_changed = [ModelState(\"testapp\", \"Author\", [\n+            (\"id\", models.AutoField(primary_key=True)),\n+            (\"file\", models.FileField(max_length=200, upload_to=content_file_name('file', spam='eggs'))),\n+        ])]\n+        changes = self.get_changes(before, kwargs_changed)\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, ['AlterField'])\n+        value = changes['testapp'][0].operations[0].field.upload_to\n+        self.assertEqual(\n+            (_content_file_name, ('file',), {'spam': 'eggs'}),\n+            (value.func, value.args, value.keywords)\n+        )\n+\n+    @mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_not_null_alteration',\n+                side_effect=AssertionError(\"Should not have prompted for not null addition\"))\n+    def test_alter_field_to_not_null_with_default(self, mocked_ask_method):\n+        \"\"\"\n+        #23609 - Tests autodetection of nullable to non-nullable alterations.\n+        \"\"\"\n+        changes = self.get_changes([self.author_name_null], [self.author_name_default])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\", preserve_default=True)\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default='Ada Lovelace')\n+\n+    @mock.patch(\n+        'django.db.migrations.questioner.MigrationQuestioner.ask_not_null_alteration',\n+        return_value=models.NOT_PROVIDED,\n+    )\n+    def test_alter_field_to_not_null_without_default(self, mocked_ask_method):\n+        \"\"\"\n+        #23609 - Tests autodetection of nullable to non-nullable alterations.\n+        \"\"\"\n+        changes = self.get_changes([self.author_name_null], [self.author_name])\n+        self.assertEqual(mocked_ask_method.call_count, 1)\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\", preserve_default=True)\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default=models.NOT_PROVIDED)\n+\n+    @mock.patch(\n+        'django.db.migrations.questioner.MigrationQuestioner.ask_not_null_alteration',\n+        return_value='Some Name',\n+    )\n+    def test_alter_field_to_not_null_oneoff_default(self, mocked_ask_method):\n+        \"\"\"\n+        #23609 - Tests autodetection of nullable to non-nullable alterations.\n+        \"\"\"\n+        changes = self.get_changes([self.author_name_null], [self.author_name])\n+        self.assertEqual(mocked_ask_method.call_count, 1)\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\", preserve_default=False)\n+        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default=\"Some Name\")\n+\n+    def test_rename_field(self):\n+        \"\"\"Tests autodetection of renamed fields.\"\"\"\n+        changes = self.get_changes(\n+            [self.author_name], [self.author_name_renamed], MigrationQuestioner({\"ask_rename\": True})\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"RenameField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name=\"name\", new_name=\"names\")\n+\n+    def test_rename_field_foreign_key_to_field(self):\n+        before = [\n+            ModelState('app', 'Foo', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('field', models.IntegerField(unique=True)),\n+            ]),\n+            ModelState('app', 'Bar', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('foo', models.ForeignKey('app.Foo', models.CASCADE, to_field='field')),\n+            ]),\n+        ]\n+        after = [\n+            ModelState('app', 'Foo', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('renamed_field', models.IntegerField(unique=True)),\n+            ]),\n+            ModelState('app', 'Bar', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('foo', models.ForeignKey('app.Foo', models.CASCADE, to_field='renamed_field')),\n+            ]),\n+        ]\n+        changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename': True}))\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'app', 1)\n+        self.assertOperationTypes(changes, 'app', 0, ['RenameField'])\n+        self.assertOperationAttributes(changes, 'app', 0, 0, old_name='field', new_name='renamed_field')\n+\n+    def test_rename_foreign_object_fields(self):\n+        fields = ('first', 'second')\n+        renamed_fields = ('first_renamed', 'second_renamed')\n+        before = [\n+            ModelState('app', 'Foo', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('first', models.IntegerField()),\n+                ('second', models.IntegerField()),\n+            ], options={'unique_together': {fields}}),\n+            ModelState('app', 'Bar', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('first', models.IntegerField()),\n+                ('second', models.IntegerField()),\n+                ('foo', models.ForeignObject(\n+                    'app.Foo', models.CASCADE, from_fields=fields, to_fields=fields,\n+                )),\n+            ]),\n+        ]\n+        # Case 1: to_fields renames.\n+        after = [\n+            ModelState('app', 'Foo', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('first_renamed', models.IntegerField()),\n+                ('second_renamed', models.IntegerField()),\n+            ], options={'unique_together': {renamed_fields}}),\n+            ModelState('app', 'Bar', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('first', models.IntegerField()),\n+                ('second', models.IntegerField()),\n+                ('foo', models.ForeignObject(\n+                    'app.Foo', models.CASCADE, from_fields=fields, to_fields=renamed_fields,\n+                )),\n+            ]),\n+        ]\n+        changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename': True}))\n+        self.assertNumberMigrations(changes, 'app', 1)\n+        self.assertOperationTypes(changes, 'app', 0, ['RenameField', 'RenameField', 'AlterUniqueTogether'])\n+        self.assertOperationAttributes(\n+            changes, 'app', 0, 0, model_name='foo', old_name='first', new_name='first_renamed',\n+        )\n+        self.assertOperationAttributes(\n+            changes, 'app', 0, 1, model_name='foo', old_name='second', new_name='second_renamed',\n+        )\n+        # Case 2: from_fields renames.\n+        after = [\n+            ModelState('app', 'Foo', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('first', models.IntegerField()),\n+                ('second', models.IntegerField()),\n+            ], options={'unique_together': {fields}}),\n+            ModelState('app', 'Bar', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('first_renamed', models.IntegerField()),\n+                ('second_renamed', models.IntegerField()),\n+                ('foo', models.ForeignObject(\n+                    'app.Foo', models.CASCADE, from_fields=renamed_fields, to_fields=fields,\n+                )),\n+            ]),\n+        ]\n+        changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename': True}))\n+        self.assertNumberMigrations(changes, 'app', 1)\n+        self.assertOperationTypes(changes, 'app', 0, ['RenameField', 'RenameField'])\n+        self.assertOperationAttributes(\n+            changes, 'app', 0, 0, model_name='bar', old_name='first', new_name='first_renamed',\n+        )\n+        self.assertOperationAttributes(\n+            changes, 'app', 0, 1, model_name='bar', old_name='second', new_name='second_renamed',\n+        )\n+\n+    def test_rename_referenced_primary_key(self):\n+        before = [\n+            ModelState('app', 'Foo', [\n+                ('id', models.CharField(primary_key=True, serialize=False)),\n+            ]),\n+            ModelState('app', 'Bar', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('foo', models.ForeignKey('app.Foo', models.CASCADE)),\n+            ]),\n+        ]\n+        after = [\n+            ModelState('app', 'Foo', [\n+                ('renamed_id', models.CharField(primary_key=True, serialize=False))\n+            ]),\n+            ModelState('app', 'Bar', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('foo', models.ForeignKey('app.Foo', models.CASCADE)),\n+            ]),\n+        ]\n+        changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename': True}))\n+        self.assertNumberMigrations(changes, 'app', 1)\n+        self.assertOperationTypes(changes, 'app', 0, ['RenameField'])\n+        self.assertOperationAttributes(changes, 'app', 0, 0, old_name='id', new_name='renamed_id')\n+\n+    def test_rename_field_preserved_db_column(self):\n+        \"\"\"\n+        RenameField is used if a field is renamed and db_column equal to the\n+        old field's column is added.\n+        \"\"\"\n+        before = [\n+            ModelState('app', 'Foo', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('field', models.IntegerField()),\n+            ]),\n+        ]\n+        after = [\n+            ModelState('app', 'Foo', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('renamed_field', models.IntegerField(db_column='field')),\n+            ]),\n+        ]\n+        changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename': True}))\n+        self.assertNumberMigrations(changes, 'app', 1)\n+        self.assertOperationTypes(changes, 'app', 0, ['RenameField', 'AlterField'])\n+        self.assertOperationAttributes(\n+            changes, 'app', 0, 0, model_name='foo', old_name='field', new_name='renamed_field',\n+        )\n+        self.assertOperationAttributes(changes, 'app', 0, 1, model_name='foo', name='renamed_field')\n+        self.assertEqual(changes['app'][0].operations[-1].field.deconstruct(), (\n+            'renamed_field', 'django.db.models.IntegerField', [], {'db_column': 'field'},\n+        ))\n+\n+    def test_rename_related_field_preserved_db_column(self):\n+        before = [\n+            ModelState('app', 'Foo', [\n+                ('id', models.AutoField(primary_key=True)),\n+            ]),\n+            ModelState('app', 'Bar', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('foo', models.ForeignKey('app.Foo', models.CASCADE)),\n+            ]),\n+        ]\n+        after = [\n+            ModelState('app', 'Foo', [\n+                ('id', models.AutoField(primary_key=True)),\n+            ]),\n+            ModelState('app', 'Bar', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('renamed_foo', models.ForeignKey('app.Foo', models.CASCADE, db_column='foo_id')),\n+            ]),\n+        ]\n+        changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename': True}))\n+        self.assertNumberMigrations(changes, 'app', 1)\n+        self.assertOperationTypes(changes, 'app', 0, ['RenameField', 'AlterField'])\n+        self.assertOperationAttributes(\n+            changes, 'app', 0, 0, model_name='bar', old_name='foo', new_name='renamed_foo',\n+        )\n+        self.assertOperationAttributes(changes, 'app', 0, 1, model_name='bar', name='renamed_foo')\n+        self.assertEqual(changes['app'][0].operations[-1].field.deconstruct(), (\n+            'renamed_foo',\n+            'django.db.models.ForeignKey',\n+            [],\n+            {'to': 'app.foo', 'on_delete': models.CASCADE, 'db_column': 'foo_id'},\n+        ))\n+\n+    def test_rename_model(self):\n+        \"\"\"Tests autodetection of renamed models.\"\"\"\n+        changes = self.get_changes(\n+            [self.author_with_book, self.book],\n+            [self.author_renamed_with_book, self.book_with_author_renamed],\n+            MigrationQuestioner({\"ask_rename_model\": True}),\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"RenameModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name=\"Author\", new_name=\"Writer\")\n+        # Now that RenameModel handles related fields too, there should be\n+        # no AlterField for the related field.\n+        self.assertNumberMigrations(changes, 'otherapp', 0)\n+\n+    def test_rename_model_case(self):\n+        \"\"\"\n+        Model name is case-insensitive. Changing case doesn't lead to any\n+        autodetected operations.\n+        \"\"\"\n+        author_renamed = ModelState('testapp', 'author', [\n+            ('id', models.AutoField(primary_key=True)),\n+        ])\n+        changes = self.get_changes(\n+            [self.author_empty, self.book],\n+            [author_renamed, self.book],\n+            questioner=MigrationQuestioner({'ask_rename_model': True}),\n+        )\n+        self.assertNumberMigrations(changes, 'testapp', 0)\n+        self.assertNumberMigrations(changes, 'otherapp', 0)\n+\n+    def test_rename_m2m_through_model(self):\n+        \"\"\"\n+        Tests autodetection of renamed models that are used in M2M relations as\n+        through models.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.author_with_m2m_through, self.publisher, self.contract],\n+            [self.author_with_renamed_m2m_through, self.publisher, self.contract_renamed],\n+            MigrationQuestioner({'ask_rename_model': True})\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, ['RenameModel'])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name='Contract', new_name='Deal')\n+\n+    def test_rename_model_with_renamed_rel_field(self):\n+        \"\"\"\n+        Tests autodetection of renamed models while simultaneously renaming one\n+        of the fields that relate to the renamed model.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.author_with_book, self.book],\n+            [self.author_renamed_with_book, self.book_with_field_and_author_renamed],\n+            MigrationQuestioner({\"ask_rename\": True, \"ask_rename_model\": True}),\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"RenameModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name=\"Author\", new_name=\"Writer\")\n+        # Right number/type of migrations for related field rename?\n+        # Alter is already taken care of.\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, [\"RenameField\"])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, old_name=\"author\", new_name=\"writer\")\n+\n+    def test_rename_model_with_fks_in_different_position(self):\n+        \"\"\"\n+        #24537 - The order of fields in a model does not influence\n+        the RenameModel detection.\n+        \"\"\"\n+        before = [\n+            ModelState(\"testapp\", \"EntityA\", [\n+                (\"id\", models.AutoField(primary_key=True)),\n+            ]),\n+            ModelState(\"testapp\", \"EntityB\", [\n+                (\"id\", models.AutoField(primary_key=True)),\n+                (\"some_label\", models.CharField(max_length=255)),\n+                (\"entity_a\", models.ForeignKey(\"testapp.EntityA\", models.CASCADE)),\n+            ]),\n+        ]\n+        after = [\n+            ModelState(\"testapp\", \"EntityA\", [\n+                (\"id\", models.AutoField(primary_key=True)),\n+            ]),\n+            ModelState(\"testapp\", \"RenamedEntityB\", [\n+                (\"id\", models.AutoField(primary_key=True)),\n+                (\"entity_a\", models.ForeignKey(\"testapp.EntityA\", models.CASCADE)),\n+                (\"some_label\", models.CharField(max_length=255)),\n+            ]),\n+        ]\n+        changes = self.get_changes(before, after, MigrationQuestioner({\"ask_rename_model\": True}))\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"RenameModel\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, old_name=\"EntityB\", new_name=\"RenamedEntityB\")\n+\n+    def test_rename_model_reverse_relation_dependencies(self):\n+        \"\"\"\n+        The migration to rename a model pointed to by a foreign key in another\n+        app must run after the other app's migration that adds the foreign key\n+        with model's original name. Therefore, the renaming migration has a\n+        dependency on that other migration.\n+        \"\"\"\n+        before = [\n+            ModelState('testapp', 'EntityA', [\n+                ('id', models.AutoField(primary_key=True)),\n+            ]),\n+            ModelState('otherapp', 'EntityB', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('entity_a', models.ForeignKey('testapp.EntityA', models.CASCADE)),\n+            ]),\n+        ]\n+        after = [\n+            ModelState('testapp', 'RenamedEntityA', [\n+                ('id', models.AutoField(primary_key=True)),\n+            ]),\n+            ModelState('otherapp', 'EntityB', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('entity_a', models.ForeignKey('testapp.RenamedEntityA', models.CASCADE)),\n+            ]),\n+        ]\n+        changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename_model': True}))\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertMigrationDependencies(changes, 'testapp', 0, [('otherapp', '__first__')])\n+        self.assertOperationTypes(changes, 'testapp', 0, ['RenameModel'])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name='EntityA', new_name='RenamedEntityA')\n+\n+    def test_fk_dependency(self):\n+        \"\"\"Having a ForeignKey automatically adds a dependency.\"\"\"\n+        # Note that testapp (author) has no dependencies,\n+        # otherapp (book) depends on testapp (author),\n+        # thirdapp (edition) depends on otherapp (book)\n+        changes = self.get_changes([], [self.author_name, self.book, self.edition])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"Author\")\n+        self.assertMigrationDependencies(changes, 'testapp', 0, [])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=\"Book\")\n+        self.assertMigrationDependencies(changes, 'otherapp', 0, [(\"testapp\", \"auto_1\")])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'thirdapp', 1)\n+        self.assertOperationTypes(changes, 'thirdapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'thirdapp', 0, 0, name=\"Edition\")\n+        self.assertMigrationDependencies(changes, 'thirdapp', 0, [(\"otherapp\", \"auto_1\")])\n+\n+    def test_proxy_fk_dependency(self):\n+        \"\"\"FK dependencies still work on proxy models.\"\"\"\n+        # Note that testapp (author) has no dependencies,\n+        # otherapp (book) depends on testapp (authorproxy)\n+        changes = self.get_changes([], [self.author_empty, self.author_proxy_third, self.book_proxy_fk])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"Author\")\n+        self.assertMigrationDependencies(changes, 'testapp', 0, [])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=\"Book\")\n+        self.assertMigrationDependencies(changes, 'otherapp', 0, [(\"thirdapp\", \"auto_1\")])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'thirdapp', 1)\n+        self.assertOperationTypes(changes, 'thirdapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'thirdapp', 0, 0, name=\"AuthorProxy\")\n+        self.assertMigrationDependencies(changes, 'thirdapp', 0, [(\"testapp\", \"auto_1\")])\n+\n+    def test_same_app_no_fk_dependency(self):\n+        \"\"\"\n+        A migration with a FK between two models of the same app\n+        does not have a dependency to itself.\n+        \"\"\"\n+        changes = self.get_changes([], [self.author_with_publisher, self.publisher])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\", \"CreateModel\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"Publisher\")\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"Author\")\n+        self.assertMigrationDependencies(changes, 'testapp', 0, [])\n+\n+    def test_circular_fk_dependency(self):\n+        \"\"\"\n+        Having a circular ForeignKey dependency automatically\n+        resolves the situation into 2 migrations on one side and 1 on the other.\n+        \"\"\"\n+        changes = self.get_changes([], [self.author_with_book, self.book, self.publisher_with_book])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\", \"CreateModel\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"Publisher\")\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"Author\")\n+        self.assertMigrationDependencies(changes, 'testapp', 0, [(\"otherapp\", \"auto_1\")])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'otherapp', 2)\n+        self.assertOperationTypes(changes, 'otherapp', 0, [\"CreateModel\"])\n+        self.assertOperationTypes(changes, 'otherapp', 1, [\"AddField\"])\n+        self.assertMigrationDependencies(changes, 'otherapp', 0, [])\n+        self.assertMigrationDependencies(changes, 'otherapp', 1, [(\"otherapp\", \"auto_1\"), (\"testapp\", \"auto_1\")])\n+        # both split migrations should be `initial`\n+        self.assertTrue(changes['otherapp'][0].initial)\n+        self.assertTrue(changes['otherapp'][1].initial)\n+\n+    def test_same_app_circular_fk_dependency(self):\n+        \"\"\"\n+        A migration with a FK between two models of the same app does\n+        not have a dependency to itself.\n+        \"\"\"\n+        changes = self.get_changes([], [self.author_with_publisher, self.publisher_with_author])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\", \"CreateModel\", \"AddField\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"Author\")\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"Publisher\")\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 2, name=\"publisher\")\n+        self.assertMigrationDependencies(changes, 'testapp', 0, [])\n+\n+    def test_same_app_circular_fk_dependency_with_unique_together_and_indexes(self):\n+        \"\"\"\n+        #22275 - A migration with circular FK dependency does not try\n+        to create unique together constraint and indexes before creating all\n+        required fields first.\n+        \"\"\"\n+        changes = self.get_changes([], [self.knight, self.rabbit])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'eggs', 1)\n+        self.assertOperationTypes(\n+            changes, 'eggs', 0, [\"CreateModel\", \"CreateModel\", \"AddIndex\", \"AlterUniqueTogether\"]\n+        )\n+        self.assertNotIn(\"unique_together\", changes['eggs'][0].operations[0].options)\n+        self.assertNotIn(\"unique_together\", changes['eggs'][0].operations[1].options)\n+        self.assertMigrationDependencies(changes, 'eggs', 0, [])\n+\n+    def test_alter_db_table_add(self):\n+        \"\"\"Tests detection for adding db_table in model's options.\"\"\"\n+        changes = self.get_changes([self.author_empty], [self.author_with_db_table_options])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterModelTable\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"author\", table=\"author_one\")\n+\n+    def test_alter_db_table_change(self):\n+        \"\"\"Tests detection for changing db_table in model's options'.\"\"\"\n+        changes = self.get_changes([self.author_with_db_table_options], [self.author_with_new_db_table_options])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterModelTable\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"author\", table=\"author_two\")\n+\n+    def test_alter_db_table_remove(self):\n+        \"\"\"Tests detection for removing db_table in model's options.\"\"\"\n+        changes = self.get_changes([self.author_with_db_table_options], [self.author_empty])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterModelTable\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"author\", table=None)\n+\n+    def test_alter_db_table_no_changes(self):\n+        \"\"\"\n+        Alter_db_table doesn't generate a migration if no changes have been made.\n+        \"\"\"\n+        changes = self.get_changes([self.author_with_db_table_options], [self.author_with_db_table_options])\n+        # Right number of migrations?\n+        self.assertEqual(len(changes), 0)\n+\n+    def test_keep_db_table_with_model_change(self):\n+        \"\"\"\n+        Tests when model changes but db_table stays as-is, autodetector must not\n+        create more than one operation.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.author_with_db_table_options],\n+            [self.author_renamed_with_db_table_options],\n+            MigrationQuestioner({\"ask_rename_model\": True}),\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"RenameModel\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, old_name=\"Author\", new_name=\"NewAuthor\")\n+\n+    def test_alter_db_table_with_model_change(self):\n+        \"\"\"\n+        Tests when model and db_table changes, autodetector must create two\n+        operations.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.author_with_db_table_options],\n+            [self.author_renamed_with_new_db_table_options],\n+            MigrationQuestioner({\"ask_rename_model\": True}),\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"RenameModel\", \"AlterModelTable\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, old_name=\"Author\", new_name=\"NewAuthor\")\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"newauthor\", table=\"author_three\")\n+\n+    def test_identical_regex_doesnt_alter(self):\n+        from_state = ModelState(\n+            \"testapp\", \"model\", [(\"id\", models.AutoField(primary_key=True, validators=[\n+                RegexValidator(\n+                    re.compile('^[-a-zA-Z0-9_]+\\Z'),\n+                    'Enter a valid “slug” consisting of letters, numbers, underscores or hyphens.',\n+                    'invalid'\n+                )\n+            ]))]\n+        )\n+        to_state = ModelState(\n+            \"testapp\", \"model\", [(\"id\", models.AutoField(primary_key=True, validators=[validate_slug]))]\n+        )\n+        changes = self.get_changes([from_state], [to_state])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 0)\n+\n+    def test_different_regex_does_alter(self):\n+        from_state = ModelState(\n+            \"testapp\", \"model\", [(\"id\", models.AutoField(primary_key=True, validators=[\n+                RegexValidator(\n+                    re.compile('^[a-z]+\\Z', 32),\n+                    'Enter a valid “slug” consisting of letters, numbers, underscores or hyphens.',\n+                    'invalid'\n+                )\n+            ]))]\n+        )\n+        to_state = ModelState(\n+            \"testapp\", \"model\", [(\"id\", models.AutoField(primary_key=True, validators=[validate_slug]))]\n+        )\n+        changes = self.get_changes([from_state], [to_state])\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n+\n+    def test_empty_foo_together(self):\n+        \"\"\"\n+        #23452 - Empty unique/index_together shouldn't generate a migration.\n+        \"\"\"\n+        # Explicitly testing for not specified, since this is the case after\n+        # a CreateModel operation w/o any definition on the original model\n+        model_state_not_specified = ModelState(\"a\", \"model\", [(\"id\", models.AutoField(primary_key=True))])\n+        # Explicitly testing for None, since this was the issue in #23452 after\n+        # an AlterFooTogether operation with e.g. () as value\n+        model_state_none = ModelState(\"a\", \"model\", [\n+            (\"id\", models.AutoField(primary_key=True))\n+        ], {\n+            \"index_together\": None,\n+            \"unique_together\": None,\n+        })\n+        # Explicitly testing for the empty set, since we now always have sets.\n+        # During removal (('col1', 'col2'),) --> () this becomes set([])\n+        model_state_empty = ModelState(\"a\", \"model\", [\n+            (\"id\", models.AutoField(primary_key=True))\n+        ], {\n+            \"index_together\": set(),\n+            \"unique_together\": set(),\n+        })\n+\n+        def test(from_state, to_state, msg):\n+            changes = self.get_changes([from_state], [to_state])\n+            if changes:\n+                ops = ', '.join(o.__class__.__name__ for o in changes['a'][0].operations)\n+                self.fail('Created operation(s) %s from %s' % (ops, msg))\n+\n+        tests = (\n+            (model_state_not_specified, model_state_not_specified, '\"not specified\" to \"not specified\"'),\n+            (model_state_not_specified, model_state_none, '\"not specified\" to \"None\"'),\n+            (model_state_not_specified, model_state_empty, '\"not specified\" to \"empty\"'),\n+            (model_state_none, model_state_not_specified, '\"None\" to \"not specified\"'),\n+            (model_state_none, model_state_none, '\"None\" to \"None\"'),\n+            (model_state_none, model_state_empty, '\"None\" to \"empty\"'),\n+            (model_state_empty, model_state_not_specified, '\"empty\" to \"not specified\"'),\n+            (model_state_empty, model_state_none, '\"empty\" to \"None\"'),\n+            (model_state_empty, model_state_empty, '\"empty\" to \"empty\"'),\n+        )\n+\n+        for t in tests:\n+            test(*t)\n+\n+    def test_create_model_with_indexes(self):\n+        \"\"\"Test creation of new model with indexes already defined.\"\"\"\n+        author = ModelState('otherapp', 'Author', [\n+            ('id', models.AutoField(primary_key=True)),\n+            ('name', models.CharField(max_length=200)),\n+        ], {'indexes': [models.Index(fields=['name'], name='create_model_with_indexes_idx')]})\n+        changes = self.get_changes([], [author])\n+        added_index = models.Index(fields=['name'], name='create_model_with_indexes_idx')\n+        # Right number of migrations?\n+        self.assertEqual(len(changes['otherapp']), 1)\n+        # Right number of actions?\n+        migration = changes['otherapp'][0]\n+        self.assertEqual(len(migration.operations), 2)\n+        # Right actions order?\n+        self.assertOperationTypes(changes, 'otherapp', 0, ['CreateModel', 'AddIndex'])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name='Author')\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 1, model_name='author', index=added_index)\n+\n+    def test_add_indexes(self):\n+        \"\"\"Test change detection of new indexes.\"\"\"\n+        changes = self.get_changes([self.author_empty, self.book], [self.author_empty, self.book_indexes])\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, ['AddIndex'])\n+        added_index = models.Index(fields=['author', 'title'], name='book_title_author_idx')\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, model_name='book', index=added_index)\n+\n+    def test_remove_indexes(self):\n+        \"\"\"Test change detection of removed indexes.\"\"\"\n+        changes = self.get_changes([self.author_empty, self.book_indexes], [self.author_empty, self.book])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, ['RemoveIndex'])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, model_name='book', name='book_title_author_idx')\n+\n+    def test_order_fields_indexes(self):\n+        \"\"\"Test change detection of reordering of fields in indexes.\"\"\"\n+        changes = self.get_changes(\n+            [self.author_empty, self.book_indexes], [self.author_empty, self.book_unordered_indexes]\n+        )\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, ['RemoveIndex', 'AddIndex'])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, model_name='book', name='book_title_author_idx')\n+        added_index = models.Index(fields=['title', 'author'], name='book_author_title_idx')\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 1, model_name='book', index=added_index)\n+\n+    def test_create_model_with_check_constraint(self):\n+        \"\"\"Test creation of new model with constraints already defined.\"\"\"\n+        author = ModelState('otherapp', 'Author', [\n+            ('id', models.AutoField(primary_key=True)),\n+            ('name', models.CharField(max_length=200)),\n+        ], {'constraints': [models.CheckConstraint(check=models.Q(name__contains='Bob'), name='name_contains_bob')]})\n+        changes = self.get_changes([], [author])\n+        added_constraint = models.CheckConstraint(check=models.Q(name__contains='Bob'), name='name_contains_bob')\n+        # Right number of migrations?\n+        self.assertEqual(len(changes['otherapp']), 1)\n+        # Right number of actions?\n+        migration = changes['otherapp'][0]\n+        self.assertEqual(len(migration.operations), 2)\n+        # Right actions order?\n+        self.assertOperationTypes(changes, 'otherapp', 0, ['CreateModel', 'AddConstraint'])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name='Author')\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 1, model_name='author', constraint=added_constraint)\n+\n+    def test_add_constraints(self):\n+        \"\"\"Test change detection of new constraints.\"\"\"\n+        changes = self.get_changes([self.author_name], [self.author_name_check_constraint])\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, ['AddConstraint'])\n+        added_constraint = models.CheckConstraint(check=models.Q(name__contains='Bob'), name='name_contains_bob')\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, model_name='author', constraint=added_constraint)\n+\n+    def test_remove_constraints(self):\n+        \"\"\"Test change detection of removed constraints.\"\"\"\n+        changes = self.get_changes([self.author_name_check_constraint], [self.author_name])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, ['RemoveConstraint'])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, model_name='author', name='name_contains_bob')\n+\n+    def test_add_foo_together(self):\n+        \"\"\"Tests index/unique_together detection.\"\"\"\n+        changes = self.get_changes([self.author_empty, self.book], [self.author_empty, self.book_foo_together])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"otherapp\", 1)\n+        self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterUniqueTogether\", \"AlterIndexTogether\"])\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 0, name=\"book\", unique_together={(\"author\", \"title\")})\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 1, name=\"book\", index_together={(\"author\", \"title\")})\n+\n+    def test_remove_foo_together(self):\n+        \"\"\"Tests index/unique_together detection.\"\"\"\n+        changes = self.get_changes([self.author_empty, self.book_foo_together], [self.author_empty, self.book])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"otherapp\", 1)\n+        self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterUniqueTogether\", \"AlterIndexTogether\"])\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 0, name=\"book\", unique_together=set())\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 1, name=\"book\", index_together=set())\n+\n+    def test_foo_together_remove_fk(self):\n+        \"\"\"Tests unique_together and field removal detection & ordering\"\"\"\n+        changes = self.get_changes(\n+            [self.author_empty, self.book_foo_together], [self.author_empty, self.book_with_no_author]\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"otherapp\", 1)\n+        self.assertOperationTypes(changes, \"otherapp\", 0, [\n+            \"AlterUniqueTogether\", \"AlterIndexTogether\", \"RemoveField\"\n+        ])\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 0, name=\"book\", unique_together=set())\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 1, name=\"book\", index_together=set())\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 2, model_name=\"book\", name=\"author\")\n+\n+    def test_foo_together_no_changes(self):\n+        \"\"\"\n+        index/unique_together doesn't generate a migration if no\n+        changes have been made.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.author_empty, self.book_foo_together], [self.author_empty, self.book_foo_together]\n+        )\n+        # Right number of migrations?\n+        self.assertEqual(len(changes), 0)\n+\n+    def test_foo_together_ordering(self):\n+        \"\"\"\n+        index/unique_together also triggers on ordering changes.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.author_empty, self.book_foo_together], [self.author_empty, self.book_foo_together_2]\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"otherapp\", 1)\n+        self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterUniqueTogether\", \"AlterIndexTogether\"])\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 0, name=\"book\", unique_together={(\"title\", \"author\")})\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 1, name=\"book\", index_together={(\"title\", \"author\")})\n+\n+    def test_add_field_and_foo_together(self):\n+        \"\"\"\n+        Added fields will be created before using them in index/unique_together.\n+        \"\"\"\n+        changes = self.get_changes([self.author_empty, self.book], [self.author_empty, self.book_foo_together_3])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"otherapp\", 1)\n+        self.assertOperationTypes(changes, \"otherapp\", 0, [\"AddField\", \"AlterUniqueTogether\", \"AlterIndexTogether\"])\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 1, name=\"book\", unique_together={(\"title\", \"newfield\")})\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 2, name=\"book\", index_together={(\"title\", \"newfield\")})\n+\n+    def test_create_model_and_unique_together(self):\n+        author = ModelState(\"otherapp\", \"Author\", [\n+            (\"id\", models.AutoField(primary_key=True)),\n+            (\"name\", models.CharField(max_length=200)),\n+        ])\n+        book_with_author = ModelState(\"otherapp\", \"Book\", [\n+            (\"id\", models.AutoField(primary_key=True)),\n+            (\"author\", models.ForeignKey(\"otherapp.Author\", models.CASCADE)),\n+            (\"title\", models.CharField(max_length=200)),\n+        ], {\n+            \"index_together\": {(\"title\", \"author\")},\n+            \"unique_together\": {(\"title\", \"author\")},\n+        })\n+        changes = self.get_changes([self.book_with_no_author], [author, book_with_author])\n+        # Right number of migrations?\n+        self.assertEqual(len(changes['otherapp']), 1)\n+        # Right number of actions?\n+        migration = changes['otherapp'][0]\n+        self.assertEqual(len(migration.operations), 4)\n+        # Right actions order?\n+        self.assertOperationTypes(\n+            changes, 'otherapp', 0,\n+            ['CreateModel', 'AddField', 'AlterUniqueTogether', 'AlterIndexTogether']\n+        )\n+\n+    def test_remove_field_and_foo_together(self):\n+        \"\"\"\n+        Removed fields will be removed after updating index/unique_together.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.author_empty, self.book_foo_together_3], [self.author_empty, self.book_foo_together]\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"otherapp\", 1)\n+        self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterUniqueTogether\", \"AlterIndexTogether\", \"RemoveField\"])\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 0, name=\"book\", unique_together={(\"author\", \"title\")})\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 1, name=\"book\", index_together={(\"author\", \"title\")})\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 2, model_name=\"book\", name=\"newfield\")\n+\n+    def test_rename_field_and_foo_together(self):\n+        \"\"\"\n+        Removed fields will be removed after updating index/unique_together.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.author_empty, self.book_foo_together_3],\n+            [self.author_empty, self.book_foo_together_4],\n+            MigrationQuestioner({\"ask_rename\": True}),\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"otherapp\", 1)\n+        self.assertOperationTypes(changes, \"otherapp\", 0, [\"RenameField\", \"AlterUniqueTogether\", \"AlterIndexTogether\"])\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 1, name=\"book\", unique_together={\n+            (\"title\", \"newfield2\")\n+        })\n+        self.assertOperationAttributes(changes, \"otherapp\", 0, 2, name=\"book\", index_together={(\"title\", \"newfield2\")})\n+\n+    def test_proxy(self):\n+        \"\"\"The autodetector correctly deals with proxy models.\"\"\"\n+        # First, we test adding a proxy model\n+        changes = self.get_changes([self.author_empty], [self.author_empty, self.author_proxy])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(\n+            changes, \"testapp\", 0, 0, name=\"AuthorProxy\", options={\"proxy\": True, \"indexes\": [], \"constraints\": []}\n+        )\n+        # Now, we test turning a proxy model into a non-proxy model\n+        # It should delete the proxy then make the real one\n+        changes = self.get_changes(\n+            [self.author_empty, self.author_proxy], [self.author_empty, self.author_proxy_notproxy]\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"DeleteModel\", \"CreateModel\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"AuthorProxy\")\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"AuthorProxy\", options={})\n+\n+    def test_proxy_custom_pk(self):\n+        \"\"\"\n+        #23415 - The autodetector must correctly deal with custom FK on proxy\n+        models.\n+        \"\"\"\n+        # First, we test the default pk field name\n+        changes = self.get_changes([], [self.author_empty, self.author_proxy_third, self.book_proxy_fk])\n+        # The field name the FK on the book model points to\n+        self.assertEqual(changes['otherapp'][0].operations[0].fields[2][1].remote_field.field_name, 'id')\n+        # Now, we test the custom pk field name\n+        changes = self.get_changes([], [self.author_custom_pk, self.author_proxy_third, self.book_proxy_fk])\n+        # The field name the FK on the book model points to\n+        self.assertEqual(changes['otherapp'][0].operations[0].fields[2][1].remote_field.field_name, 'pk_field')\n+\n+    def test_proxy_to_mti_with_fk_to_proxy(self):\n+        # First, test the pk table and field name.\n+        changes = self.get_changes(\n+            [],\n+            [self.author_empty, self.author_proxy_third, self.book_proxy_fk],\n+        )\n+        self.assertEqual(\n+            changes['otherapp'][0].operations[0].fields[2][1].remote_field.model._meta.db_table,\n+            'testapp_author',\n+        )\n+        self.assertEqual(changes['otherapp'][0].operations[0].fields[2][1].remote_field.field_name, 'id')\n+\n+        # Change AuthorProxy to use MTI.\n+        changes = self.get_changes(\n+            [self.author_empty, self.author_proxy_third, self.book_proxy_fk],\n+            [self.author_empty, self.author_proxy_third_notproxy, self.book_proxy_fk],\n+        )\n+        # Right number/type of migrations for the AuthorProxy model?\n+        self.assertNumberMigrations(changes, 'thirdapp', 1)\n+        self.assertOperationTypes(changes, 'thirdapp', 0, ['DeleteModel', 'CreateModel'])\n+        # Right number/type of migrations for the Book model with a FK to\n+        # AuthorProxy?\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])\n+        # otherapp should depend on thirdapp.\n+        self.assertMigrationDependencies(changes, 'otherapp', 0, [('thirdapp', 'auto_1')])\n+        # Now, test the pk table and field name.\n+        self.assertEqual(\n+            changes['otherapp'][0].operations[0].field.remote_field.model._meta.db_table,\n+            'thirdapp_authorproxy',\n+        )\n+        self.assertEqual(changes['otherapp'][0].operations[0].field.remote_field.field_name, 'author_ptr')\n+\n+    def test_proxy_to_mti_with_fk_to_proxy_proxy(self):\n+        # First, test the pk table and field name.\n+        changes = self.get_changes(\n+            [],\n+            [self.author_empty, self.author_proxy, self.author_proxy_proxy, self.book_proxy_proxy_fk],\n+        )\n+        self.assertEqual(\n+            changes['otherapp'][0].operations[0].fields[1][1].remote_field.model._meta.db_table,\n+            'testapp_author',\n+        )\n+        self.assertEqual(changes['otherapp'][0].operations[0].fields[1][1].remote_field.field_name, 'id')\n+\n+        # Change AuthorProxy to use MTI. FK still points to AAuthorProxyProxy,\n+        # a proxy of AuthorProxy.\n+        changes = self.get_changes(\n+            [self.author_empty, self.author_proxy, self.author_proxy_proxy, self.book_proxy_proxy_fk],\n+            [self.author_empty, self.author_proxy_notproxy, self.author_proxy_proxy, self.book_proxy_proxy_fk],\n+        )\n+        # Right number/type of migrations for the AuthorProxy model?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, ['DeleteModel', 'CreateModel'])\n+        # Right number/type of migrations for the Book model with a FK to\n+        # AAuthorProxyProxy?\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])\n+        # otherapp should depend on testapp.\n+        self.assertMigrationDependencies(changes, 'otherapp', 0, [('testapp', 'auto_1')])\n+        # Now, test the pk table and field name.\n+        self.assertEqual(\n+            changes['otherapp'][0].operations[0].field.remote_field.model._meta.db_table,\n+            'testapp_authorproxy',\n+        )\n+        self.assertEqual(changes['otherapp'][0].operations[0].field.remote_field.field_name, 'author_ptr')\n+\n+    def test_unmanaged_create(self):\n+        \"\"\"The autodetector correctly deals with managed models.\"\"\"\n+        # First, we test adding an unmanaged model\n+        changes = self.get_changes([self.author_empty], [self.author_empty, self.author_unmanaged])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"AuthorUnmanaged\", options={\"managed\": False})\n+\n+    def test_unmanaged_delete(self):\n+        changes = self.get_changes([self.author_empty, self.author_unmanaged], [self.author_empty])\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, ['DeleteModel'])\n+\n+    def test_unmanaged_to_managed(self):\n+        # Now, we test turning an unmanaged model into a managed model\n+        changes = self.get_changes(\n+            [self.author_empty, self.author_unmanaged], [self.author_empty, self.author_unmanaged_managed]\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterModelOptions\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"authorunmanaged\", options={})\n+\n+    def test_managed_to_unmanaged(self):\n+        # Now, we turn managed to unmanaged.\n+        changes = self.get_changes(\n+            [self.author_empty, self.author_unmanaged_managed], [self.author_empty, self.author_unmanaged]\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelOptions\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"authorunmanaged\", options={\"managed\": False})\n+\n+    def test_unmanaged_custom_pk(self):\n+        \"\"\"\n+        #23415 - The autodetector must correctly deal with custom FK on\n+        unmanaged models.\n+        \"\"\"\n+        # First, we test the default pk field name\n+        changes = self.get_changes([], [self.author_unmanaged_default_pk, self.book])\n+        # The field name the FK on the book model points to\n+        self.assertEqual(changes['otherapp'][0].operations[0].fields[2][1].remote_field.field_name, 'id')\n+        # Now, we test the custom pk field name\n+        changes = self.get_changes([], [self.author_unmanaged_custom_pk, self.book])\n+        # The field name the FK on the book model points to\n+        self.assertEqual(changes['otherapp'][0].operations[0].fields[2][1].remote_field.field_name, 'pk_field')\n+\n+    @override_settings(AUTH_USER_MODEL=\"thirdapp.CustomUser\")\n+    def test_swappable(self):\n+        with isolate_lru_cache(apps.get_swappable_settings_name):\n+            changes = self.get_changes([self.custom_user], [self.custom_user, self.author_with_custom_user])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"Author\")\n+        self.assertMigrationDependencies(changes, 'testapp', 0, [(\"__setting__\", \"AUTH_USER_MODEL\")])\n+\n+    def test_swappable_changed(self):\n+        with isolate_lru_cache(apps.get_swappable_settings_name):\n+            before = self.make_project_state([self.custom_user, self.author_with_user])\n+            with override_settings(AUTH_USER_MODEL=\"thirdapp.CustomUser\"):\n+                after = self.make_project_state([self.custom_user, self.author_with_custom_user])\n+            autodetector = MigrationAutodetector(before, after)\n+            changes = autodetector._detect_changes()\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, model_name=\"author\", name='user')\n+        fk_field = changes['testapp'][0].operations[0].field\n+        to_model = '%s.%s' % (\n+            fk_field.remote_field.model._meta.app_label,\n+            fk_field.remote_field.model._meta.object_name,\n+        )\n+        self.assertEqual(to_model, 'thirdapp.CustomUser')\n+\n+    def test_add_field_with_default(self):\n+        \"\"\"#22030 - Adding a field with a default should work.\"\"\"\n+        changes = self.get_changes([self.author_empty], [self.author_name_default])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"name\")\n+\n+    def test_custom_deconstructible(self):\n+        \"\"\"\n+        Two instances which deconstruct to the same value aren't considered a\n+        change.\n+        \"\"\"\n+        changes = self.get_changes([self.author_name_deconstructible_1], [self.author_name_deconstructible_2])\n+        # Right number of migrations?\n+        self.assertEqual(len(changes), 0)\n+\n+    def test_deconstruct_field_kwarg(self):\n+        \"\"\"Field instances are handled correctly by nested deconstruction.\"\"\"\n+        changes = self.get_changes([self.author_name_deconstructible_3], [self.author_name_deconstructible_4])\n+        self.assertEqual(changes, {})\n+\n+    def test_deconstructible_list(self):\n+        \"\"\"Nested deconstruction descends into lists.\"\"\"\n+        # When lists contain items that deconstruct to identical values, those lists\n+        # should be considered equal for the purpose of detecting state changes\n+        # (even if the original items are unequal).\n+        changes = self.get_changes(\n+            [self.author_name_deconstructible_list_1], [self.author_name_deconstructible_list_2]\n+        )\n+        self.assertEqual(changes, {})\n+        # Legitimate differences within the deconstructed lists should be reported\n+        # as a change\n+        changes = self.get_changes(\n+            [self.author_name_deconstructible_list_1], [self.author_name_deconstructible_list_3]\n+        )\n+        self.assertEqual(len(changes), 1)\n+\n+    def test_deconstructible_tuple(self):\n+        \"\"\"Nested deconstruction descends into tuples.\"\"\"\n+        # When tuples contain items that deconstruct to identical values, those tuples\n+        # should be considered equal for the purpose of detecting state changes\n+        # (even if the original items are unequal).\n+        changes = self.get_changes(\n+            [self.author_name_deconstructible_tuple_1], [self.author_name_deconstructible_tuple_2]\n+        )\n+        self.assertEqual(changes, {})\n+        # Legitimate differences within the deconstructed tuples should be reported\n+        # as a change\n+        changes = self.get_changes(\n+            [self.author_name_deconstructible_tuple_1], [self.author_name_deconstructible_tuple_3]\n+        )\n+        self.assertEqual(len(changes), 1)\n+\n+    def test_deconstructible_dict(self):\n+        \"\"\"Nested deconstruction descends into dict values.\"\"\"\n+        # When dicts contain items whose values deconstruct to identical values,\n+        # those dicts should be considered equal for the purpose of detecting\n+        # state changes (even if the original values are unequal).\n+        changes = self.get_changes(\n+            [self.author_name_deconstructible_dict_1], [self.author_name_deconstructible_dict_2]\n+        )\n+        self.assertEqual(changes, {})\n+        # Legitimate differences within the deconstructed dicts should be reported\n+        # as a change\n+        changes = self.get_changes(\n+            [self.author_name_deconstructible_dict_1], [self.author_name_deconstructible_dict_3]\n+        )\n+        self.assertEqual(len(changes), 1)\n+\n+    def test_nested_deconstructible_objects(self):\n+        \"\"\"\n+        Nested deconstruction is applied recursively to the args/kwargs of\n+        deconstructed objects.\n+        \"\"\"\n+        # If the items within a deconstructed object's args/kwargs have the same\n+        # deconstructed values - whether or not the items themselves are different\n+        # instances - then the object as a whole is regarded as unchanged.\n+        changes = self.get_changes(\n+            [self.author_name_nested_deconstructible_1], [self.author_name_nested_deconstructible_2]\n+        )\n+        self.assertEqual(changes, {})\n+        # Differences that exist solely within the args list of a deconstructed object\n+        # should be reported as changes\n+        changes = self.get_changes(\n+            [self.author_name_nested_deconstructible_1], [self.author_name_nested_deconstructible_changed_arg]\n+        )\n+        self.assertEqual(len(changes), 1)\n+        # Additional args should also be reported as a change\n+        changes = self.get_changes(\n+            [self.author_name_nested_deconstructible_1], [self.author_name_nested_deconstructible_extra_arg]\n+        )\n+        self.assertEqual(len(changes), 1)\n+        # Differences that exist solely within the kwargs dict of a deconstructed object\n+        # should be reported as changes\n+        changes = self.get_changes(\n+            [self.author_name_nested_deconstructible_1], [self.author_name_nested_deconstructible_changed_kwarg]\n+        )\n+        self.assertEqual(len(changes), 1)\n+        # Additional kwargs should also be reported as a change\n+        changes = self.get_changes(\n+            [self.author_name_nested_deconstructible_1], [self.author_name_nested_deconstructible_extra_kwarg]\n+        )\n+        self.assertEqual(len(changes), 1)\n+\n+    def test_deconstruct_type(self):\n+        \"\"\"\n+        #22951 -- Uninstantiated classes with deconstruct are correctly returned\n+        by deep_deconstruct during serialization.\n+        \"\"\"\n+        author = ModelState(\n+            \"testapp\",\n+            \"Author\",\n+            [\n+                (\"id\", models.AutoField(primary_key=True)),\n+                (\"name\", models.CharField(\n+                    max_length=200,\n+                    # IntegerField intentionally not instantiated.\n+                    default=models.IntegerField,\n+                ))\n+            ],\n+        )\n+        changes = self.get_changes([], [author])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\"])\n+\n+    def test_replace_string_with_foreignkey(self):\n+        \"\"\"\n+        #22300 - Adding an FK in the same \"spot\" as a deleted CharField should\n+        work.\n+        \"\"\"\n+        changes = self.get_changes([self.author_with_publisher_string], [self.author_with_publisher, self.publisher])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\", \"RemoveField\", \"AddField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"Publisher\")\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"publisher_name\")\n+        self.assertOperationAttributes(changes, 'testapp', 0, 2, name=\"publisher\")\n+\n+    def test_foreign_key_removed_before_target_model(self):\n+        \"\"\"\n+        Removing an FK and the model it targets in the same change must remove\n+        the FK field before the model to maintain consistency.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.author_with_publisher, self.publisher], [self.author_name]\n+        )  # removes both the model and FK\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"RemoveField\", \"DeleteModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"publisher\")\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"Publisher\")\n+\n+    @mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_not_null_addition',\n+                side_effect=AssertionError(\"Should not have prompted for not null addition\"))\n+    def test_add_many_to_many(self, mocked_ask_method):\n+        \"\"\"#22435 - Adding a ManyToManyField should not prompt for a default.\"\"\"\n+        changes = self.get_changes([self.author_empty, self.publisher], [self.author_with_m2m, self.publisher])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"publishers\")\n+\n+    def test_alter_many_to_many(self):\n+        changes = self.get_changes(\n+            [self.author_with_m2m, self.publisher], [self.author_with_m2m_blank, self.publisher]\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"publishers\")\n+\n+    def test_create_with_through_model(self):\n+        \"\"\"\n+        Adding a m2m with a through model and the models that use it should be\n+        ordered correctly.\n+        \"\"\"\n+        changes = self.get_changes([], [self.author_with_m2m_through, self.publisher, self.contract])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\n+            'CreateModel', 'CreateModel', 'CreateModel', 'AddField',\n+        ])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='Author')\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, name='Publisher')\n+        self.assertOperationAttributes(changes, 'testapp', 0, 2, name='Contract')\n+        self.assertOperationAttributes(changes, 'testapp', 0, 3, model_name='author', name='publishers')\n+\n+    def test_many_to_many_removed_before_through_model(self):\n+        \"\"\"\n+        Removing a ManyToManyField and the \"through\" model in the same change\n+        must remove the field before the model to maintain consistency.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.book_with_multiple_authors_through_attribution, self.author_name, self.attribution],\n+            [self.book_with_no_author, self.author_name],\n+        )\n+        # Remove both the through model and ManyToMany\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"otherapp\", 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, ['RemoveField', 'DeleteModel'])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name='authors', model_name='book')\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 1, name='Attribution')\n+\n+    def test_many_to_many_removed_before_through_model_2(self):\n+        \"\"\"\n+        Removing a model that contains a ManyToManyField and the \"through\" model\n+        in the same change must remove the field before the model to maintain\n+        consistency.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.book_with_multiple_authors_through_attribution, self.author_name, self.attribution],\n+            [self.author_name],\n+        )\n+        # Remove both the through model and ManyToMany\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"otherapp\", 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, ['RemoveField', 'DeleteModel', 'DeleteModel'])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name='authors', model_name='book')\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 1, name='Attribution')\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 2, name='Book')\n+\n+    def test_m2m_w_through_multistep_remove(self):\n+        \"\"\"\n+        A model with a m2m field that specifies a \"through\" model cannot be\n+        removed in the same migration as that through model as the schema will\n+        pass through an inconsistent state. The autodetector should produce two\n+        migrations to avoid this issue.\n+        \"\"\"\n+        changes = self.get_changes([self.author_with_m2m_through, self.publisher, self.contract], [self.publisher])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\n+            \"RemoveField\", \"RemoveField\", \"DeleteModel\", \"DeleteModel\"\n+        ])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"author\", model_name='contract')\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"publisher\", model_name='contract')\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 2, name=\"Author\")\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 3, name=\"Contract\")\n+\n+    def test_concrete_field_changed_to_many_to_many(self):\n+        \"\"\"\n+        #23938 - Changing a concrete field into a ManyToManyField\n+        first removes the concrete field and then adds the m2m field.\n+        \"\"\"\n+        changes = self.get_changes([self.author_with_former_m2m], [self.author_with_m2m, self.publisher])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"CreateModel\", \"RemoveField\", \"AddField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='Publisher')\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"publishers\", model_name='author')\n+        self.assertOperationAttributes(changes, 'testapp', 0, 2, name=\"publishers\", model_name='author')\n+\n+    def test_many_to_many_changed_to_concrete_field(self):\n+        \"\"\"\n+        #23938 - Changing a ManyToManyField into a concrete field\n+        first removes the m2m field and then adds the concrete field.\n+        \"\"\"\n+        changes = self.get_changes([self.author_with_m2m, self.publisher], [self.author_with_former_m2m])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"RemoveField\", \"AddField\", \"DeleteModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"publishers\", model_name='author')\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"publishers\", model_name='author')\n+        self.assertOperationAttributes(changes, 'testapp', 0, 2, name='Publisher')\n+        self.assertOperationFieldAttributes(changes, 'testapp', 0, 1, max_length=100)\n+\n+    def test_non_circular_foreignkey_dependency_removal(self):\n+        \"\"\"\n+        If two models with a ForeignKey from one to the other are removed at the\n+        same time, the autodetector should remove them in the correct order.\n+        \"\"\"\n+        changes = self.get_changes([self.author_with_publisher, self.publisher_with_author], [])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"RemoveField\", \"DeleteModel\", \"DeleteModel\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"author\", model_name='publisher')\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"Author\")\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 2, name=\"Publisher\")\n+\n+    def test_alter_model_options(self):\n+        \"\"\"Changing a model's options should make a change.\"\"\"\n+        changes = self.get_changes([self.author_empty], [self.author_with_options])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelOptions\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, options={\n+            \"permissions\": [('can_hire', 'Can hire')],\n+            \"verbose_name\": \"Authi\",\n+        })\n+\n+        # Changing them back to empty should also make a change\n+        changes = self.get_changes([self.author_with_options], [self.author_empty])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelOptions\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"author\", options={})\n+\n+    def test_alter_model_options_proxy(self):\n+        \"\"\"Changing a proxy model's options should also make a change.\"\"\"\n+        changes = self.get_changes(\n+            [self.author_proxy, self.author_empty], [self.author_proxy_options, self.author_empty]\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelOptions\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"authorproxy\", options={\n+            \"verbose_name\": \"Super Author\"\n+        })\n+\n+    def test_set_alter_order_with_respect_to(self):\n+        \"\"\"Setting order_with_respect_to adds a field.\"\"\"\n+        changes = self.get_changes([self.book, self.author_with_book], [self.book, self.author_with_book_order_wrt])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterOrderWithRespectTo\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"author\", order_with_respect_to=\"book\")\n+\n+    def test_add_alter_order_with_respect_to(self):\n+        \"\"\"\n+        Setting order_with_respect_to when adding the FK too does\n+        things in the right order.\n+        \"\"\"\n+        changes = self.get_changes([self.author_name], [self.book, self.author_with_book_order_wrt])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\", \"AlterOrderWithRespectTo\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, model_name=\"author\", name=\"book\")\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"author\", order_with_respect_to=\"book\")\n+\n+    def test_remove_alter_order_with_respect_to(self):\n+        \"\"\"\n+        Removing order_with_respect_to when removing the FK too does\n+        things in the right order.\n+        \"\"\"\n+        changes = self.get_changes([self.book, self.author_with_book_order_wrt], [self.author_name])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterOrderWithRespectTo\", \"RemoveField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"author\", order_with_respect_to=None)\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, model_name=\"author\", name=\"book\")\n+\n+    def test_add_model_order_with_respect_to(self):\n+        \"\"\"\n+        Setting order_with_respect_to when adding the whole model\n+        does things in the right order.\n+        \"\"\"\n+        changes = self.get_changes([], [self.book, self.author_with_book_order_wrt])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(\n+            changes, 'testapp', 0, 0, name=\"Author\", options={'order_with_respect_to': 'book'}\n+        )\n+        self.assertNotIn(\"_order\", [name for name, field in changes['testapp'][0].operations[0].fields])\n+\n+    def test_alter_model_managers(self):\n+        \"\"\"\n+        Changing the model managers adds a new operation.\n+        \"\"\"\n+        changes = self.get_changes([self.other_pony], [self.other_pony_food])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, [\"AlterModelManagers\"])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=\"pony\")\n+        self.assertEqual([name for name, mgr in changes['otherapp'][0].operations[0].managers],\n+                         ['food_qs', 'food_mgr', 'food_mgr_kwargs'])\n+        self.assertEqual(changes['otherapp'][0].operations[0].managers[1][1].args, ('a', 'b', 1, 2))\n+        self.assertEqual(changes['otherapp'][0].operations[0].managers[2][1].args, ('x', 'y', 3, 4))\n+\n+    def test_swappable_first_inheritance(self):\n+        \"\"\"Swappable models get their CreateModel first.\"\"\"\n+        changes = self.get_changes([], [self.custom_user, self.aardvark])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'thirdapp', 1)\n+        self.assertOperationTypes(changes, 'thirdapp', 0, [\"CreateModel\", \"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'thirdapp', 0, 0, name=\"CustomUser\")\n+        self.assertOperationAttributes(changes, 'thirdapp', 0, 1, name=\"Aardvark\")\n+\n+    def test_default_related_name_option(self):\n+        model_state = ModelState('app', 'model', [\n+            ('id', models.AutoField(primary_key=True)),\n+        ], options={'default_related_name': 'related_name'})\n+        changes = self.get_changes([], [model_state])\n+        self.assertNumberMigrations(changes, 'app', 1)\n+        self.assertOperationTypes(changes, 'app', 0, ['CreateModel'])\n+        self.assertOperationAttributes(\n+            changes, 'app', 0, 0, name='model',\n+            options={'default_related_name': 'related_name'},\n+        )\n+        altered_model_state = ModelState('app', 'Model', [\n+            ('id', models.AutoField(primary_key=True)),\n+        ])\n+        changes = self.get_changes([model_state], [altered_model_state])\n+        self.assertNumberMigrations(changes, 'app', 1)\n+        self.assertOperationTypes(changes, 'app', 0, ['AlterModelOptions'])\n+        self.assertOperationAttributes(changes, 'app', 0, 0, name='model', options={})\n+\n+    @override_settings(AUTH_USER_MODEL=\"thirdapp.CustomUser\")\n+    def test_swappable_first_setting(self):\n+        \"\"\"Swappable models get their CreateModel first.\"\"\"\n+        with isolate_lru_cache(apps.get_swappable_settings_name):\n+            changes = self.get_changes([], [self.custom_user_no_inherit, self.aardvark])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'thirdapp', 1)\n+        self.assertOperationTypes(changes, 'thirdapp', 0, [\"CreateModel\", \"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'thirdapp', 0, 0, name=\"CustomUser\")\n+        self.assertOperationAttributes(changes, 'thirdapp', 0, 1, name=\"Aardvark\")\n+\n+    def test_bases_first(self):\n+        \"\"\"Bases of other models come first.\"\"\"\n+        changes = self.get_changes([], [self.aardvark_based_on_author, self.author_name])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\", \"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"Author\")\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"Aardvark\")\n+\n+    def test_multiple_bases(self):\n+        \"\"\"#23956 - Inheriting models doesn't move *_ptr fields into AddField operations.\"\"\"\n+        A = ModelState(\"app\", \"A\", [(\"a_id\", models.AutoField(primary_key=True))])\n+        B = ModelState(\"app\", \"B\", [(\"b_id\", models.AutoField(primary_key=True))])\n+        C = ModelState(\"app\", \"C\", [], bases=(\"app.A\", \"app.B\"))\n+        D = ModelState(\"app\", \"D\", [], bases=(\"app.A\", \"app.B\"))\n+        E = ModelState(\"app\", \"E\", [], bases=(\"app.A\", \"app.B\"))\n+        changes = self.get_changes([], [A, B, C, D, E])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, \"app\", 1)\n+        self.assertOperationTypes(changes, \"app\", 0, [\n+            \"CreateModel\", \"CreateModel\", \"CreateModel\", \"CreateModel\", \"CreateModel\"\n+        ])\n+        self.assertOperationAttributes(changes, \"app\", 0, 0, name=\"A\")\n+        self.assertOperationAttributes(changes, \"app\", 0, 1, name=\"B\")\n+        self.assertOperationAttributes(changes, \"app\", 0, 2, name=\"C\")\n+        self.assertOperationAttributes(changes, \"app\", 0, 3, name=\"D\")\n+        self.assertOperationAttributes(changes, \"app\", 0, 4, name=\"E\")\n+\n+    def test_proxy_bases_first(self):\n+        \"\"\"Bases of proxies come first.\"\"\"\n+        changes = self.get_changes([], [self.author_empty, self.author_proxy, self.author_proxy_proxy])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\", \"CreateModel\", \"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"Author\")\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"AuthorProxy\")\n+        self.assertOperationAttributes(changes, 'testapp', 0, 2, name=\"AAuthorProxyProxy\")\n+\n+    def test_pk_fk_included(self):\n+        \"\"\"\n+        A relation used as the primary key is kept as part of CreateModel.\n+        \"\"\"\n+        changes = self.get_changes([], [self.aardvark_pk_fk_author, self.author_name])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\", \"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"Author\")\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"Aardvark\")\n+\n+    def test_first_dependency(self):\n+        \"\"\"\n+        A dependency to an app with no migrations uses __first__.\n+        \"\"\"\n+        # Load graph\n+        loader = MigrationLoader(connection)\n+        before = self.make_project_state([])\n+        after = self.make_project_state([self.book_migrations_fk])\n+        after.real_apps = [\"migrations\"]\n+        autodetector = MigrationAutodetector(before, after)\n+        changes = autodetector._detect_changes(graph=loader.graph)\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=\"Book\")\n+        self.assertMigrationDependencies(changes, 'otherapp', 0, [(\"migrations\", \"__first__\")])\n+\n+    @override_settings(MIGRATION_MODULES={\"migrations\": \"migrations.test_migrations\"})\n+    def test_last_dependency(self):\n+        \"\"\"\n+        A dependency to an app with existing migrations uses the\n+        last migration of that app.\n+        \"\"\"\n+        # Load graph\n+        loader = MigrationLoader(connection)\n+        before = self.make_project_state([])\n+        after = self.make_project_state([self.book_migrations_fk])\n+        after.real_apps = [\"migrations\"]\n+        autodetector = MigrationAutodetector(before, after)\n+        changes = autodetector._detect_changes(graph=loader.graph)\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, [\"CreateModel\"])\n+        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=\"Book\")\n+        self.assertMigrationDependencies(changes, 'otherapp', 0, [(\"migrations\", \"0002_second\")])\n+\n+    def test_alter_fk_before_model_deletion(self):\n+        \"\"\"\n+        ForeignKeys are altered _before_ the model they used to\n+        refer to are deleted.\n+        \"\"\"\n+        changes = self.get_changes(\n+            [self.author_name, self.publisher_with_author],\n+            [self.aardvark_testapp, self.publisher_with_aardvark_author]\n+        )\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\", \"AlterField\", \"DeleteModel\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"Aardvark\")\n+        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"author\")\n+        self.assertOperationAttributes(changes, 'testapp', 0, 2, name=\"Author\")\n+\n+    def test_fk_dependency_other_app(self):\n+        \"\"\"\n+        #23100 - ForeignKeys correctly depend on other apps' models.\n+        \"\"\"\n+        changes = self.get_changes([self.author_name, self.book], [self.author_with_book, self.book])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"book\")\n+        self.assertMigrationDependencies(changes, 'testapp', 0, [(\"otherapp\", \"__first__\")])\n+\n+    def test_alter_field_to_fk_dependency_other_app(self):\n+        changes = self.get_changes(\n+            [self.author_empty, self.book_with_no_author_fk],\n+            [self.author_empty, self.book],\n+        )\n+        self.assertNumberMigrations(changes, 'otherapp', 1)\n+        self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])\n+        self.assertMigrationDependencies(changes, 'otherapp', 0, [('testapp', '__first__')])\n+\n+    def test_circular_dependency_mixed_addcreate(self):\n+        \"\"\"\n+        #23315 - The dependency resolver knows to put all CreateModel\n+        before AddField and not become unsolvable.\n+        \"\"\"\n+        address = ModelState(\"a\", \"Address\", [\n+            (\"id\", models.AutoField(primary_key=True)),\n+            (\"country\", models.ForeignKey(\"b.DeliveryCountry\", models.CASCADE)),\n+        ])\n+        person = ModelState(\"a\", \"Person\", [\n+            (\"id\", models.AutoField(primary_key=True)),\n+        ])\n+        apackage = ModelState(\"b\", \"APackage\", [\n+            (\"id\", models.AutoField(primary_key=True)),\n+            (\"person\", models.ForeignKey(\"a.Person\", models.CASCADE)),\n+        ])\n+        country = ModelState(\"b\", \"DeliveryCountry\", [\n+            (\"id\", models.AutoField(primary_key=True)),\n+        ])\n+        changes = self.get_changes([], [address, person, apackage, country])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'a', 2)\n+        self.assertNumberMigrations(changes, 'b', 1)\n+        self.assertOperationTypes(changes, 'a', 0, [\"CreateModel\", \"CreateModel\"])\n+        self.assertOperationTypes(changes, 'a', 1, [\"AddField\"])\n+        self.assertOperationTypes(changes, 'b', 0, [\"CreateModel\", \"CreateModel\"])\n+\n+    @override_settings(AUTH_USER_MODEL=\"a.Tenant\")\n+    def test_circular_dependency_swappable(self):\n+        \"\"\"\n+        #23322 - The dependency resolver knows to explicitly resolve\n+        swappable models.\n+        \"\"\"\n+        with isolate_lru_cache(apps.get_swappable_settings_name):\n+            tenant = ModelState(\"a\", \"Tenant\", [\n+                (\"id\", models.AutoField(primary_key=True)),\n+                (\"primary_address\", models.ForeignKey(\"b.Address\", models.CASCADE))],\n+                bases=(AbstractBaseUser,)\n+            )\n+            address = ModelState(\"b\", \"Address\", [\n+                (\"id\", models.AutoField(primary_key=True)),\n+                (\"tenant\", models.ForeignKey(settings.AUTH_USER_MODEL, models.CASCADE)),\n+            ])\n+            changes = self.get_changes([], [address, tenant])\n+\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'a', 2)\n+        self.assertOperationTypes(changes, 'a', 0, [\"CreateModel\"])\n+        self.assertOperationTypes(changes, 'a', 1, [\"AddField\"])\n+        self.assertMigrationDependencies(changes, 'a', 0, [])\n+        self.assertMigrationDependencies(changes, 'a', 1, [('a', 'auto_1'), ('b', 'auto_1')])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'b', 1)\n+        self.assertOperationTypes(changes, 'b', 0, [\"CreateModel\"])\n+        self.assertMigrationDependencies(changes, 'b', 0, [('__setting__', 'AUTH_USER_MODEL')])\n+\n+    @override_settings(AUTH_USER_MODEL=\"b.Tenant\")\n+    def test_circular_dependency_swappable2(self):\n+        \"\"\"\n+        #23322 - The dependency resolver knows to explicitly resolve\n+        swappable models but with the swappable not being the first migrated\n+        model.\n+        \"\"\"\n+        with isolate_lru_cache(apps.get_swappable_settings_name):\n+            address = ModelState(\"a\", \"Address\", [\n+                (\"id\", models.AutoField(primary_key=True)),\n+                (\"tenant\", models.ForeignKey(settings.AUTH_USER_MODEL, models.CASCADE)),\n+            ])\n+            tenant = ModelState(\"b\", \"Tenant\", [\n+                (\"id\", models.AutoField(primary_key=True)),\n+                (\"primary_address\", models.ForeignKey(\"a.Address\", models.CASCADE))],\n+                bases=(AbstractBaseUser,)\n+            )\n+            changes = self.get_changes([], [address, tenant])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'a', 2)\n+        self.assertOperationTypes(changes, 'a', 0, [\"CreateModel\"])\n+        self.assertOperationTypes(changes, 'a', 1, [\"AddField\"])\n+        self.assertMigrationDependencies(changes, 'a', 0, [])\n+        self.assertMigrationDependencies(changes, 'a', 1, [('__setting__', 'AUTH_USER_MODEL'), ('a', 'auto_1')])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'b', 1)\n+        self.assertOperationTypes(changes, 'b', 0, [\"CreateModel\"])\n+        self.assertMigrationDependencies(changes, 'b', 0, [('a', 'auto_1')])\n+\n+    @override_settings(AUTH_USER_MODEL=\"a.Person\")\n+    def test_circular_dependency_swappable_self(self):\n+        \"\"\"\n+        #23322 - The dependency resolver knows to explicitly resolve\n+        swappable models.\n+        \"\"\"\n+        with isolate_lru_cache(apps.get_swappable_settings_name):\n+            person = ModelState(\"a\", \"Person\", [\n+                (\"id\", models.AutoField(primary_key=True)),\n+                (\"parent1\", models.ForeignKey(settings.AUTH_USER_MODEL, models.CASCADE, related_name='children'))\n+            ])\n+            changes = self.get_changes([], [person])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'a', 1)\n+        self.assertOperationTypes(changes, 'a', 0, [\"CreateModel\"])\n+        self.assertMigrationDependencies(changes, 'a', 0, [])\n+\n+    @override_settings(AUTH_USER_MODEL='a.User')\n+    def test_swappable_circular_multi_mti(self):\n+        with isolate_lru_cache(apps.get_swappable_settings_name):\n+            parent = ModelState('a', 'Parent', [\n+                ('user', models.ForeignKey(settings.AUTH_USER_MODEL, models.CASCADE))\n+            ])\n+            child = ModelState('a', 'Child', [], bases=('a.Parent',))\n+            user = ModelState('a', 'User', [], bases=(AbstractBaseUser, 'a.Child'))\n+            changes = self.get_changes([], [parent, child, user])\n+        self.assertNumberMigrations(changes, 'a', 1)\n+        self.assertOperationTypes(changes, 'a', 0, ['CreateModel', 'CreateModel', 'CreateModel', 'AddField'])\n+\n+    @mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_not_null_addition',\n+                side_effect=AssertionError(\"Should not have prompted for not null addition\"))\n+    def test_add_blank_textfield_and_charfield(self, mocked_ask_method):\n+        \"\"\"\n+        #23405 - Adding a NOT NULL and blank `CharField` or `TextField`\n+        without default should not prompt for a default.\n+        \"\"\"\n+        changes = self.get_changes([self.author_empty], [self.author_with_biography_blank])\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\", \"AddField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0)\n+\n+    @mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_not_null_addition')\n+    def test_add_non_blank_textfield_and_charfield(self, mocked_ask_method):\n+        \"\"\"\n+        #23405 - Adding a NOT NULL and non-blank `CharField` or `TextField`\n+        without default should prompt for a default.\n+        \"\"\"\n+        changes = self.get_changes([self.author_empty], [self.author_with_biography_non_blank])\n+        self.assertEqual(mocked_ask_method.call_count, 2)\n+        # Right number/type of migrations?\n+        self.assertNumberMigrations(changes, 'testapp', 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\", \"AddField\"])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0)\n+\n+    def test_mti_inheritance_model_removal(self):\n+        Animal = ModelState('app', 'Animal', [\n+            (\"id\", models.AutoField(primary_key=True)),\n+        ])\n+        Dog = ModelState('app', 'Dog', [], bases=('app.Animal',))\n+        changes = self.get_changes([Animal, Dog], [Animal])\n+        self.assertNumberMigrations(changes, 'app', 1)\n+        self.assertOperationTypes(changes, 'app', 0, ['DeleteModel'])\n+        self.assertOperationAttributes(changes, 'app', 0, 0, name='Dog')\n+\n+    def test_move_field_to_subclass(self):\n+        \"\"\"\n+        Tests that moving a field from a parent model to a new child model\n+        generates operations in the correct order (RemoveField, then\n+        CreateModel).\n+        \"\"\"\n+        readable_before = ModelState(\n+            \"testapp\",\n+            \"Readable\",\n+            [\n+                (\"id\", models.AutoField(primary_key=True)),\n+                (\"title\", models.CharField(max_length=200)),\n+            ],\n+        )\n+        readable_after = ModelState(\n+            \"testapp\",\n+            \"Readable\",\n+            [(\"id\", models.AutoField(primary_key=True))],\n+        )\n+        book_after = ModelState(\n+            \"testapp\",\n+            \"Book\",\n+            [(\"title\", models.CharField(max_length=200))],\n+            bases=(\"testapp.Readable\",)\n+        )\n+        changes = self.get_changes(\n+            [readable_before],\n+            [readable_after, book_after],\n+        )\n+        self.assertNumberMigrations(changes, \"testapp\", 1)\n+        self.assertOperationTypes(changes, \"testapp\", 0, [\"RemoveField\", \"CreateModel\"])\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 0, model_name=\"Readable\", name=\"title\")\n+        self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"Book\")\n"
    },
    "django__django-15127": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/messages_tests/test_tags.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py messages_tests.test_tags"
        ],
        "reproduced_bug_patch": "diff --git a/tests/messages_tests/test_tags.py b/tests/messages_tests/test_tags.py\nnew file mode 100644\nindex 0000000000..0e8b970c91\n--- /dev/null\n+++ b/tests/messages_tests/test_tags.py\n@@ -0,0 +1,17 @@\n+from django.contrib.messages import constants\n+from django.contrib.messages.storage.base import Message\n+from django.test import SimpleTestCase, override_settings\n+\n+\n+class MessageTagTests(SimpleTestCase):\n+    @override_settings(MESSAGE_TAGS={\n+        constants.INFO: 'info',\n+        49: 'custom',\n+    })\n+    def test_custom_level_tag(self):\n+        \"\"\"\n+        A message's level_tag is derived from MESSAGE_TAGS in settings. This\n+        should be updated when using override_settings.\n+        \"\"\"\n+        message = Message(49, 'A custom message.')\n+        self.assertEqual(message.level_tag, 'custom')\n"
    },
    "matplotlib__matplotlib-24177": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_hist.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_hist.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_hist.py b/lib/matplotlib/tests/test_hist.py\nnew file mode 100644\nindex 0000000000..1b1bcf4850\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_hist.py\n@@ -0,0 +1,26 @@\n+import numpy as np\n+import matplotlib.pyplot as plt\n+\n+\n+def test_hist_step_density_autoscale():\n+    \"\"\"\n+    Test that ax.hist with density=True and histtype='step' autoscales the\n+    y-axis correctly.\n+\n+    The bug is that the y-axis is not scaled to the data, resulting in a\n+    plot where the histogram is clipped or not visible. This test checks\n+    that the upper y-limit is greater than or equal to the maximum value of\n+    the histogram. This is a regression test for #24113.\n+    \"\"\"\n+    np.random.seed(19680801)\n+    scale = 1.2\n+    data = np.random.randn(100000) * scale\n+    bins = 100\n+\n+    fig, ax = plt.subplots()\n+    # n is the array of values for the histogram bins.\n+    n, _, _ = ax.hist(data, bins=bins, density=True, histtype='step')\n+\n+    # The y-axis limit must be large enough to show the histogram.\n+    # Due to the bug, the ylim is not set correctly for histtype='step'.\n+    assert ax.get_ylim()[1] >= np.max(n)\n"
    },
    "sphinx-doc__sphinx-7748": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_ext_autodoc_docstring_signature.py",
        "reproduced_bug_commands": [
            "pytest tests/test_ext_autodoc_docstring_signature.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_ext_autodoc_docstring_signature.py b/tests/test_ext_autodoc_docstring_signature.py\nnew file mode 100644\nindex 000000000..2f99fc7a1\n--- /dev/null\n+++ b/tests/test_ext_autodoc_docstring_signature.py\n@@ -0,0 +1,58 @@\n+import sys\n+from unittest.mock import Mock\n+\n+import pytest\n+from docutils.statemachine import ViewList\n+\n+from sphinx.ext.autodoc.directive import DocumenterBridge, process_documenter_options\n+from sphinx.ext.autodoc import Options\n+from sphinx.util.docutils import LoggingReporter\n+\n+\n+def do_autodoc(app, objtype, name, options=None):\n+    if options is None:\n+        options = {}\n+    app.env.temp_data.setdefault('docname', 'index')  # set dummy docname\n+    doccls = app.registry.documenters[objtype]\n+    docoptions = process_documenter_options(doccls, app.config, options)\n+    state = Mock()\n+    state.document.settings.tab_width = 8\n+    bridge = DocumenterBridge(app.env, LoggingReporter(''), docoptions, 1, state)\n+    documenter = doccls(bridge, name)\n+    documenter.generate()\n+\n+    return bridge.result\n+\n+\n+@pytest.mark.sphinx('html', testroot='ext-autodoc')\n+def test_autodoc_docstring_signature_with_overloaded_methods(app):\n+    \"\"\"Tests that autodoc picks up all overloaded signatures from a docstring.\"\"\"\n+    mod_name = 'test_autodoc_overloaded'\n+    mod = type(sys)(mod_name)\n+    sys.modules[mod_name] = mod\n+\n+    class Overloaded:\n+        def meth(self):\n+            \"\"\"meth(a, b)\n+meth(c)\n+\n+Docstring for the method.\n+\"\"\"\n+            pass\n+    mod.Overloaded = Overloaded\n+    app.config.autodoc_docstring_signature = True\n+\n+    try:\n+        actual = do_autodoc(app, 'method', f'{mod_name}.Overloaded.meth')\n+        expected = [\n+            '',\n+            '.. py:method:: Overloaded.meth(a, b)',\n+            '               Overloaded.meth(c)',\n+            f'   :module: {mod_name}',\n+            '',\n+            '   Docstring for the method.',\n+            '',\n+        ]\n+        assert list(actual) == expected\n+    finally:\n+        del sys.modules[mod_name]\n"
    },
    "sympy__sympy-18211": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/solvers/tests/test_solveset_transcendental.py",
        "reproduced_bug_commands": [
            "pytest sympy/solvers/tests/test_solveset_transcendental.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/solvers/tests/test_solveset_transcendental.py b/sympy/solvers/tests/test_solveset_transcendental.py\nnew file mode 100644\nindex 0000000000..4ee63d57d7\n--- /dev/null\n+++ b/sympy/solvers/tests/test_solveset_transcendental.py\n@@ -0,0 +1,25 @@\n+from sympy.core.relational import Eq\n+from sympy.core.singleton import S\n+from sympy.core.symbol import Symbol\n+from sympy.functions.elementary.trigonometric import cos, sin\n+from sympy.sets.conditionset import ConditionSet\n+\n+\n+def test_as_set_on_transcendental_eq_raises_notimplementederror():\n+    \"\"\"\n+    This test reproduces a bug where as_set() on a transcendental equation\n+    raises NotImplementedError instead of returning a ConditionSet.\n+\n+    The test asserts the fixed behavior. On a version with the bug, the\n+    test will fail with an unhandled NotImplementedError before the\n+    assertion is reached.\n+    \"\"\"\n+    # From the provided context file, `n` is defined as a real symbol.\n+    n = Symbol('n', real=True)\n+    eq = Eq(n*cos(n) - 3*sin(n), 0)\n+\n+    # The original bug report states that eq.as_set() raises NotImplementedError.\n+    # eq.as_set() on a single-variable equation calls solveset.\n+    # Since n is a real symbol, the domain for solveset should be S.Reals.\n+    # The desired behavior is for this call to return a ConditionSet.\n+    assert eq.as_set() == ConditionSet(n, eq, S.Reals)\n"
    },
    "django__django-12774": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/lookup/test_in_bulk_unique_constraint.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py lookup.test_in_bulk_unique_constraint"
        ],
        "reproduced_bug_patch": "diff --git a/tests/lookup/test_in_bulk_unique_constraint.py b/tests/lookup/test_in_bulk_unique_constraint.py\nnew file mode 100644\nindex 0000000000..b5c341695a\n--- /dev/null\n+++ b/tests/lookup/test_in_bulk_unique_constraint.py\n@@ -0,0 +1,30 @@\n+from django.db import models\n+from django.test import TestCase\n+\n+\n+class ArticleWithSlugConstraint(models.Model):\n+    headline = models.CharField(max_length=100)\n+    slug = models.CharField(max_length=255)\n+\n+    class Meta:\n+        app_label = 'lookup'\n+        constraints = [\n+            models.UniqueConstraint(fields=['slug'], name='%(app_label)s_%(class)s_slug_unq')\n+        ]\n+\n+    def __str__(self):\n+        return self.headline\n+\n+\n+class InBulkUniqueConstraintTest(TestCase):\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.a1 = ArticleWithSlugConstraint.objects.create(headline='Article 1', slug='a1')\n+        cls.a2 = ArticleWithSlugConstraint.objects.create(headline='Article 2', slug='a2')\n+\n+    def test_in_bulk_on_field_with_unique_constraint(self):\n+        \"\"\"\n+        in_bulk() should work on a field with a UniqueConstraint.\n+        \"\"\"\n+        articles = ArticleWithSlugConstraint.objects.in_bulk(field_name='slug')\n+        self.assertEqual(articles, {'a1': self.a1, 'a2': self.a2})\n"
    },
    "django__django-15128": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/queries/test_qs_or_operator_alias_collision.py",
        "reproduced_bug_commands": [
            "python",
            "runtests.py",
            "queries.test_qs_or_operator_alias_collision"
        ],
        "reproduced_bug_patch": "diff --git a/tests/queries/test_qs_or_operator_alias_collision.py b/tests/queries/test_qs_or_operator_alias_collision.py\nnew file mode 100644\nindex 0000000000..88f7c14bd6\n--- /dev/null\n+++ b/tests/queries/test_qs_or_operator_alias_collision.py\n@@ -0,0 +1,74 @@\n+from django.db import models\n+from django.db.models import Q\n+from django.test import TestCase\n+\n+\n+# Models inspired by the bug report to create a self-contained regression test.\n+# These models are intentionally named to be unique for this test case and are\n+# assigned to an existing app to ensure they are created by the test runner.\n+class ChangeAliasFoo(models.Model):\n+    qux = models.ForeignKey(\n+        \"ChangeAliasQux\", on_delete=models.CASCADE, related_name=\"foos\"\n+    )\n+\n+    class Meta:\n+        app_label = \"queries\"\n+\n+\n+class ChangeAliasBar(models.Model):\n+    foo = models.ForeignKey(\n+        \"ChangeAliasFoo\", on_delete=models.CASCADE, related_name=\"bars\"\n+    )\n+    another_foo = models.ForeignKey(\n+        \"ChangeAliasFoo\", on_delete=models.CASCADE, related_name=\"other_bars\"\n+    )\n+    baz = models.ForeignKey(\n+        \"ChangeAliasBaz\", on_delete=models.CASCADE, related_name=\"bars\"\n+    )\n+\n+    class Meta:\n+        app_label = \"queries\"\n+\n+\n+class ChangeAliasBaz(models.Model):\n+    class Meta:\n+        app_label = \"queries\"\n+\n+\n+class ChangeAliasQux(models.Model):\n+    bazes = models.ManyToManyField(\"ChangeAliasBaz\", related_name=\"quxes\")\n+\n+    class Meta:\n+        app_label = \"queries\"\n+\n+\n+class QueryCompilerTests(TestCase):\n+    \"\"\"\n+    Tests for the SQL query compiler, focusing on regressions and edge cases.\n+    \"\"\"\n+\n+    def test_qs_or_operator_alias_collision(self):\n+        \"\"\"\n+        Regression test for a bug where combining querysets with the OR\n+        operator (|) could lead to an AssertionError in Query.change_aliases.\n+\n+        This occurs when the right-hand-side queryset has sequential aliases\n+        that conflict with aliases being created during the join promotion\n+        process of the combination.\n+        \"\"\"\n+        qux = ChangeAliasQux.objects.create()\n+        # This queryset is a simple reverse foreign key lookup.\n+        qs1 = qux.foos.all()\n+        # This queryset involves multiple joins, leading to more complex aliasing.\n+        # The two filters on `bars` and `other_bars` create a situation\n+        # where sequential aliases are generated that can cause conflicts.\n+        qs2 = ChangeAliasFoo.objects.filter(\n+            Q(bars__baz__in=qux.bazes.all())\n+            | Q(other_bars__baz__in=qux.bazes.all())\n+        )\n+\n+        # The combination `qs1 | qs2` fails due to the alias collision bug,\n+        # raising an AssertionError. When fixed, it should execute without error.\n+        # The assertion checks for an empty result, which is correct as no\n+        # ChangeAliasFoo objects have been created. This forces query evaluation.\n+        self.assertQuerysetEqual(qs1 | qs2, [])\n"
    },
    "matplotlib__matplotlib-24570": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_hpacker_alignment.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_hpacker_alignment.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_hpacker_alignment.py b/lib/matplotlib/tests/test_hpacker_alignment.py\nnew file mode 100644\nindex 0000000000..6a99f7c6e4\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_hpacker_alignment.py\n@@ -0,0 +1,33 @@\n+import pytest\n+import matplotlib.pyplot as plt\n+from matplotlib.offsetbox import DrawingArea, HPacker\n+\n+\n+def test_hpacker_align_reversed():\n+    \"\"\"\n+    Test that HPacker alignment for 'top' and 'bottom' is correct.\n+\n+    The bug described in the issue shows that the behavior of 'top' and\n+    'bottom' alignment in HPacker is reversed. This test asserts the\n+    expected, correct behavior. It will fail with the buggy implementation\n+    and pass once the logic is corrected.\n+    \"\"\"\n+    # A renderer is needed to calculate the layout.\n+    fig, ax = plt.subplots()\n+    renderer = fig.canvas.get_renderer()\n+\n+    # Create two children of different heights to test alignment.\n+    da1 = DrawingArea(10, 20)  # height=20\n+    da2 = DrawingArea(10, 30)  # height=30\n+\n+    # Pack the children using HPacker with 'bottom' alignment.\n+    packer = HPacker(children=[da1, da2], align=\"bottom\", pad=0, sep=0)\n+\n+    # get_extent_offsets calculates the final positions of the children.\n+    *_, offsets = packer.get_extent_offsets(renderer)\n+    y_offsets = [y for x, y in offsets]\n+\n+    # For correct 'bottom' alignment, the y-offsets should be the same\n+    # (0, as they share a baseline). The buggy code implements 'top'\n+    # alignment instead, giving y-offsets of [10., 0.].\n+    assert y_offsets == [0., 0.]\n"
    },
    "sphinx-doc__sphinx-7757": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_domain_py_signature.py",
        "reproduced_bug_commands": [
            "pytest tests/test_domain_py_signature.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_domain_py_signature.py b/tests/test_domain_py_signature.py\nnew file mode 100644\nindex 000000000..cfd044fab\n--- /dev/null\n+++ b/tests/test_domain_py_signature.py\n@@ -0,0 +1,33 @@\n+import sys\n+from unittest.mock import Mock\n+\n+import pytest\n+from docutils import nodes\n+\n+from sphinx import addnodes\n+from sphinx.addnodes import (\n+    desc, desc_addname, desc_annotation, desc_content, desc_name, desc_optional,\n+    desc_parameter, desc_parameterlist, desc_returns, desc_signature,\n+    desc_sig_name, desc_sig_operator, desc_sig_punctuation, pending_xref,\n+)\n+from sphinx.domains.python import (\n+    py_sig_re, _parse_annotation, _pseudo_parse_arglist, PythonDomain,\n+)\n+from sphinx.testing import restructuredtext\n+from sphinx.testing.util import assert_node\n+\n+\n+@pytest.mark.skipif(sys.version_info < (3, 8), reason='python 3.8+ is required.')\n+def test_pyfunction_signature_positional_only_argument_with_default(app):\n+    \"\"\"Test parsing of positional only argument with a default value.\"\"\"\n+    text = \".. py:function:: foo(a, b=0, /, c=1)\"\n+    doctree = restructuredtext.parse(app, text)\n+    assert_node(doctree[1][0][1],\n+                [desc_parameterlist, ([desc_parameter, desc_sig_name, \"a\"],\n+                                      [desc_parameter, ([desc_sig_name, \"b\"],\n+                                                        [desc_sig_operator, \"=\"],\n+                                                        [nodes.inline, \"0\"])],\n+                                      [desc_parameter, desc_sig_operator, \"/\"],\n+                                      [desc_parameter, ([desc_sig_name, \"c\"],\n+                                                        [desc_sig_operator, \"=\"],\n+                                                        [nodes.inline, \"1\"])])])\n"
    },
    "sympy__sympy-18698": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/polys/tests/test_sqf_list.py",
        "reproduced_bug_commands": [
            "pytest sympy/polys/tests/test_sqf_list.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/polys/tests/test_sqf_list.py b/sympy/polys/tests/test_sqf_list.py\nnew file mode 100644\nindex 0000000000..6dea8922e8\n--- /dev/null\n+++ b/sympy/polys/tests/test_sqf_list.py\n@@ -0,0 +1,25 @@\n+from sympy import Symbol\n+from sympy.polys.polytools import sqf_list\n+\n+def test_sqf_list_groups_factors_with_same_multiplicity():\n+    \"\"\"\n+    Test that sqf_list combines factors of the same multiplicity.\n+\n+    This is a regression test for a bug where factors with the same\n+    multiplicity were returned as separate factors, instead of being\n+    multiplied together.\n+    \"\"\"\n+    x = Symbol('x')\n+    poly = (x**2 + 1) * (x - 1)**2 * (x - 2)**3 * (x - 3)**3\n+\n+    _coeff, factors = sqf_list(poly)\n+\n+    # The bug is that factors with multiplicity 3 are not grouped.\n+    # This isolates the factors that should be grouped.\n+    factors_with_mult_3 = {p for p, k in factors if k == 3}\n+\n+    # When fixed, there should be one factor, the product of the two.\n+    # With the bug, there will be two factors: {x - 2, x - 3}.\n+    expected_factor = (x - 2)*(x - 3)\n+\n+    assert factors_with_mult_3 == {expected_factor}\n"
    },
    "sphinx-doc__sphinx-7889": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_ext_autodoc_mock_generic_subclass.py",
        "reproduced_bug_commands": [
            "pytest tests/test_ext_autodoc_mock_generic_subclass.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_ext_autodoc_mock_generic_subclass.py b/tests/test_ext_autodoc_mock_generic_subclass.py\nnew file mode 100644\nindex 000000000..ea9275b12\n--- /dev/null\n+++ b/tests/test_ext_autodoc_mock_generic_subclass.py\n@@ -0,0 +1,27 @@\n+import pytest\n+from typing import TypeVar\n+\n+from sphinx.ext.autodoc.mock import _MockObject\n+\n+\n+def test_mock_subclassing_generic_class():\n+    \"\"\"\n+    Tests that creating a subclass of a mocked generic type does not raise a\n+    TypeError.\n+\n+    This test reproduces the bug where ``_make_subclass`` attempts to\n+    concatenate a string with a ``TypeVar``, which previously caused documentation\n+    generation to fail for projects using generic-typed classes.\n+    \"\"\"\n+    T = TypeVar('T')\n+    mock_generic_class = _MockObject()\n+    mock_generic_class.__display_name__ = 'mocked.Generic'\n+\n+    # This line triggers the TypeError in the buggy version, as it calls\n+    # _make_subclass with a TypeVar, leading to an invalid concatenation.\n+    generic_alias = mock_generic_class[T]\n+\n+    # This assertion will fail with a TypeError before the fix, and pass after.\n+    # It checks that the returned object is a _MockObject with the correct\n+    # name, which is expected behavior for a mocked generic alias.\n+    assert repr(generic_alias) == 'mocked.Generic.~T'\n"
    },
    "django__django-12858": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/check_framework/test_ordering_check.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py check_framework.test_ordering_check"
        ],
        "reproduced_bug_patch": "diff --git a/tests/check_framework/test_ordering_check.py b/tests/check_framework/test_ordering_check.py\nnew file mode 100644\nindex 0000000000..bef597a3ec\n--- /dev/null\n+++ b/tests/check_framework/test_ordering_check.py\n@@ -0,0 +1,36 @@\n+from django.core import checks\n+from django.db import models\n+from django.test import SimpleTestCase\n+from django.test.utils import isolate_apps, override_system_checks\n+\n+\n+@isolate_apps('check_framework', attr_name='apps')\n+@override_system_checks([checks.model_checks.check_all_models])\n+class OrderingCheckTests(SimpleTestCase):\n+    def test_ordering_by_lookup_that_is_not_a_transform(self):\n+        \"\"\"\n+        ordering shouldn't raise E015 for lookups that are not transforms.\n+        \"\"\"\n+        class Product(models.Model):\n+            parent = models.ForeignKey(\n+                'self', on_delete=models.CASCADE, null=True,\n+            )\n+\n+            class Meta:\n+                app_label = 'check_framework'\n+\n+        class Supply(models.Model):\n+            product = models.ForeignKey(Product, on_delete=models.CASCADE)\n+\n+            class Meta:\n+                app_label = 'check_framework'\n+\n+        class Stock(models.Model):\n+            supply = models.ForeignKey(Supply, on_delete=models.CASCADE)\n+\n+            class Meta:\n+                app_label = 'check_framework'\n+                ordering = ('supply__product__parent__isnull',)\n+\n+        errors = checks.run_checks(app_configs=self.apps.get_app_configs())\n+        self.assertEqual(errors, [])\n"
    },
    "django__django-15161": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/migrations/test_writer_bug.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py migrations.test_writer_bug"
        ],
        "reproduced_bug_patch": "diff --git a/tests/migrations/test_writer_bug.py b/tests/migrations/test_writer_bug.py\nnew file mode 100644\nindex 0000000000..5ba7b0a9b2\n--- /dev/null\n+++ b/tests/migrations/test_writer_bug.py\n@@ -0,0 +1,57 @@\n+import datetime\n+import decimal\n+import enum\n+import functools\n+import math\n+import os\n+import pathlib\n+import re\n+import sys\n+import uuid\n+from unittest import mock\n+\n+from django.db import models\n+from django.db.migrations.writer import MigrationWriter\n+from django.test import SimpleTestCase\n+from django.utils.functional import SimpleLazyObject\n+\n+\n+class WriterTests(SimpleTestCase):\n+    \"\"\"\n+    Tests the migration writer (makes migration files from Migration instances)\n+    \"\"\"\n+\n+    def safe_exec(self, string, value=None):\n+        d = {}\n+        try:\n+            exec(string, globals(), d)\n+        except Exception as e:\n+            if value:\n+                self.fail(\"Could not exec %r (from value %r): %s\" % (string.strip(), value, e))\n+            else:\n+                self.fail(\"Could not exec %r: %s\" % (string.strip(), e))\n+        return d\n+\n+    def serialize_round_trip(self, value):\n+        string, imports = MigrationWriter.serialize(value)\n+        return self.safe_exec(\"%s\\ntest_value_result = %s\" % (\"\\n\".join(imports), string), value)['test_value_result']\n+\n+    def assertSerializedEqual(self, value):\n+        self.assertEqual(self.serialize_round_trip(value), value)\n+\n+    def assertSerializedResultEqual(self, value, target):\n+        self.assertEqual(MigrationWriter.serialize(value), target)\n+\n+    def test_serialize_expression_simplified_path(self):\n+        expression = models.ExpressionWrapper(\n+            models.F('some_field'),\n+            output_field=models.BooleanField(),\n+        )\n+        self.assertSerializedResultEqual(\n+            expression,\n+            (\n+                \"models.ExpressionWrapper(models.F('some_field'), \"\n+                \"output_field=models.BooleanField())\",\n+                {'from django.db import models'},\n+            ),\n+        )\n"
    },
    "matplotlib__matplotlib-24627": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_artist_lifecycle.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_artist_lifecycle.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_artist_lifecycle.py b/lib/matplotlib/tests/test_artist_lifecycle.py\nnew file mode 100644\nindex 0000000000..82c641fcb8\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_artist_lifecycle.py\n@@ -0,0 +1,26 @@\n+import matplotlib.pyplot as plt\n+from matplotlib.figure import Figure\n+\n+\n+def test_cla_unsets_artist_parents():\n+    \"\"\"\n+    Check that clearing an axes unsets the .axes and .figure attributes on the\n+    artists that are removed, matching the behavior of artist.remove().\n+    \"\"\"\n+    fig, ax = plt.subplots()\n+    line, = ax.plot([1, 2])\n+    ax.cla()\n+    assert line.axes is None\n+    assert line.figure is None\n+\n+\n+def test_clf_unsets_artist_parents():\n+    \"\"\"\n+    Check that clearing a figure unsets the .axes and .figure attributes on\n+    the artists that are removed, matching the behavior of artist.remove().\n+    \"\"\"\n+    fig, ax = plt.subplots()\n+    line, = ax.plot([1, 2])\n+    fig.clf()\n+    assert line.axes is None\n+    assert line.figure is None\n"
    },
    "sympy__sympy-18763": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/printing/tests/test_latex_subs.py",
        "reproduced_bug_commands": [
            "pytest sympy/printing/tests/test_latex_subs.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/printing/tests/test_latex_subs.py b/sympy/printing/tests/test_latex_subs.py\nnew file mode 100644\nindex 0000000000..3f091a53f7\n--- /dev/null\n+++ b/sympy/printing/tests/test_latex_subs.py\n@@ -0,0 +1,11 @@\n+from sympy import Subs\n+from sympy.abc import x, y\n+from sympy.printing.latex import latex\n+\n+\n+def test_latex_subs_parenthesizing():\n+    \"\"\"\n+    Test for incorrect parenthesizing of Subs.\n+    \"\"\"\n+    expr = 3*Subs(-x + y, (x,), (1,))\n+    assert latex(expr) == r'3 \\left. \\left(- x + y\\right) \\right|_{\\substack{ x=1 }}'\n"
    },
    "django__django-12965": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/delete/test_fast_delete.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py delete.test_fast_delete"
        ],
        "reproduced_bug_patch": "diff --git a/tests/delete/test_fast_delete.py b/tests/delete/test_fast_delete.py\nnew file mode 100644\nindex 0000000000..1c7c765d6e\n--- /dev/null\n+++ b/tests/delete/test_fast_delete.py\n@@ -0,0 +1,19 @@\n+from django.db import connection\n+from django.test import TestCase\n+\n+from .models import Avatar\n+\n+\n+class FastDeleteTests(TestCase):\n+    def test_delete_all_no_subquery(self):\n+        \"\"\"\n+        Model.objects.all().delete() should be a fast delete and not use a\n+        subquery.\n+        \"\"\"\n+        Avatar.objects.create()\n+        # This delete should produce a single \"DELETE FROM ...\".\n+        with self.assertNumQueries(1):\n+            Avatar.objects.all().delete()\n+        # The query shouldn't have a WHERE clause, which would indicate a\n+        # subquery.\n+        self.assertNotIn('WHERE', connection.queries[-1]['sql'].upper())\n"
    },
    "django__django-15252": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/migrations/test_multidb_operations.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py migrations.test_multidb_operations"
        ],
        "reproduced_bug_patch": "diff --git a/tests/migrations/test_multidb_operations.py b/tests/migrations/test_multidb_operations.py\nnew file mode 100644\nindex 0000000000..173e89f53b\n--- /dev/null\n+++ b/tests/migrations/test_multidb_operations.py\n@@ -0,0 +1,189 @@\n+from django.db import connection, connections, migrations, models\n+from django.db.migrations.recorder import MigrationRecorder\n+from django.db.migrations.state import ProjectState\n+from django.test import override_settings\n+\n+from .test_base import OperationTestBase\n+\n+\n+class AgnosticRouter:\n+    \"\"\"\n+    A router that doesn't have an opinion regarding migrating.\n+    \"\"\"\n+    def allow_migrate(self, db, app_label, **hints):\n+        return None\n+\n+\n+class MigrateNothingRouter:\n+    \"\"\"\n+    A router that doesn't allow migrating.\n+    \"\"\"\n+    def allow_migrate(self, db, app_label, **hints):\n+        return False\n+\n+\n+class MigrateEverythingRouter:\n+    \"\"\"\n+    A router that always allows migrating.\n+    \"\"\"\n+    def allow_migrate(self, db, app_label, **hints):\n+        return True\n+\n+\n+class MigrateWhenFooRouter:\n+    \"\"\"\n+    A router that allows migrating depending on a hint.\n+    \"\"\"\n+    def allow_migrate(self, db, app_label, **hints):\n+        return hints.get('foo', False)\n+\n+\n+class AllowDefaultRouter:\n+    \"\"\"\n+    A router that only allows migrating on the 'default' database.\n+    \"\"\"\n+    def allow_migrate(self, db, app_label, **hints):\n+        return db == 'default'\n+\n+\n+class MultiDBOperationTests(OperationTestBase):\n+    databases = {'default', 'other'}\n+\n+    @override_settings(DATABASE_ROUTERS=[AllowDefaultRouter()])\n+    def test_recorder_honors_router(self):\n+        \"\"\"\n+        MigrationRecorder.ensure_schema() should honor database routers.\n+        \"\"\"\n+        recorder = MigrationRecorder(connections['other'])\n+        recorder.ensure_schema()\n+        self.assertTableNotExists(recorder.Migration._meta.db_table, using='other')\n+\n+    def _test_create_model(self, app_label, should_run):\n+        \"\"\"\n+        CreateModel honors multi-db settings.\n+        \"\"\"\n+        operation = migrations.CreateModel(\n+            \"Pony\",\n+            [(\"id\", models.AutoField(primary_key=True))],\n+        )\n+        # Test the state alteration\n+        project_state = ProjectState()\n+        new_state = project_state.clone()\n+        operation.state_forwards(app_label, new_state)\n+        # Test the database alteration\n+        self.assertTableNotExists(\"%s_pony\" % app_label)\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n+        if should_run:\n+            self.assertTableExists(\"%s_pony\" % app_label)\n+        else:\n+            self.assertTableNotExists(\"%s_pony\" % app_label)\n+        # And test reversal\n+        with connection.schema_editor() as editor:\n+            operation.database_backwards(app_label, editor, new_state, project_state)\n+        self.assertTableNotExists(\"%s_pony\" % app_label)\n+\n+    @override_settings(DATABASE_ROUTERS=[AgnosticRouter()])\n+    def test_create_model(self):\n+        \"\"\"\n+        Test when router doesn't have an opinion (i.e. CreateModel should run).\n+        \"\"\"\n+        self._test_create_model(\"test_mltdb_crmo\", should_run=True)\n+\n+    @override_settings(DATABASE_ROUTERS=[MigrateNothingRouter()])\n+    def test_create_model2(self):\n+        \"\"\"\n+        Test when router returns False (i.e. CreateModel shouldn't run).\n+        \"\"\"\n+        self._test_create_model(\"test_mltdb_crmo2\", should_run=False)\n+\n+    @override_settings(DATABASE_ROUTERS=[MigrateEverythingRouter()])\n+    def test_create_model3(self):\n+        \"\"\"\n+        Test when router returns True (i.e. CreateModel should run).\n+        \"\"\"\n+        self._test_create_model(\"test_mltdb_crmo3\", should_run=True)\n+\n+    def test_create_model4(self):\n+        \"\"\"\n+        Test multiple routers.\n+        \"\"\"\n+        with override_settings(DATABASE_ROUTERS=[AgnosticRouter(), AgnosticRouter()]):\n+            self._test_create_model(\"test_mltdb_crmo4\", should_run=True)\n+        with override_settings(DATABASE_ROUTERS=[MigrateNothingRouter(), MigrateEverythingRouter()]):\n+            self._test_create_model(\"test_mltdb_crmo4\", should_run=False)\n+        with override_settings(DATABASE_ROUTERS=[MigrateEverythingRouter(), MigrateNothingRouter()]):\n+            self._test_create_model(\"test_mltdb_crmo4\", should_run=True)\n+\n+    def _test_run_sql(self, app_label, should_run, hints=None):\n+        with override_settings(DATABASE_ROUTERS=[MigrateEverythingRouter()]):\n+            project_state = self.set_up_test_model(app_label)\n+\n+        sql = \"\"\"\n+        INSERT INTO {0}_pony (pink, weight) VALUES (1, 3.55);\n+        INSERT INTO {0}_pony (pink, weight) VALUES (3, 5.0);\n+        \"\"\".format(app_label)\n+\n+        operation = migrations.RunSQL(sql, hints=hints or {})\n+        # Test the state alteration does nothing\n+        new_state = project_state.clone()\n+        operation.state_forwards(app_label, new_state)\n+        self.assertEqual(new_state, project_state)\n+        # Test the database alteration\n+        self.assertEqual(project_state.apps.get_model(app_label, \"Pony\").objects.count(), 0)\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n+        Pony = project_state.apps.get_model(app_label, \"Pony\")\n+        if should_run:\n+            self.assertEqual(Pony.objects.count(), 2)\n+        else:\n+            self.assertEqual(Pony.objects.count(), 0)\n+\n+    @override_settings(DATABASE_ROUTERS=[MigrateNothingRouter()])\n+    def test_run_sql_migrate_nothing_router(self):\n+        self._test_run_sql(\"test_mltdb_runsql\", should_run=False)\n+\n+    @override_settings(DATABASE_ROUTERS=[MigrateWhenFooRouter()])\n+    def test_run_sql_migrate_foo_router_without_hints(self):\n+        self._test_run_sql(\"test_mltdb_runsql2\", should_run=False)\n+\n+    @override_settings(DATABASE_ROUTERS=[MigrateWhenFooRouter()])\n+    def test_run_sql_migrate_foo_router_with_hints(self):\n+        self._test_run_sql('test_mltdb_runsql3', should_run=True, hints={'foo': True})\n+\n+    def _test_run_python(self, app_label, should_run, hints=None):\n+        with override_settings(DATABASE_ROUTERS=[MigrateEverythingRouter()]):\n+            project_state = self.set_up_test_model(app_label)\n+\n+        # Create the operation\n+        def inner_method(models, schema_editor):\n+            Pony = models.get_model(app_label, \"Pony\")\n+            Pony.objects.create(pink=1, weight=3.55)\n+            Pony.objects.create(weight=5)\n+\n+        operation = migrations.RunPython(inner_method, hints=hints or {})\n+        # Test the state alteration does nothing\n+        new_state = project_state.clone()\n+        operation.state_forwards(app_label, new_state)\n+        self.assertEqual(new_state, project_state)\n+        # Test the database alteration\n+        self.assertEqual(project_state.apps.get_model(app_label, \"Pony\").objects.count(), 0)\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n+        Pony = project_state.apps.get_model(app_label, \"Pony\")\n+        if should_run:\n+            self.assertEqual(Pony.objects.count(), 2)\n+        else:\n+            self.assertEqual(Pony.objects.count(), 0)\n+\n+    @override_settings(DATABASE_ROUTERS=[MigrateNothingRouter()])\n+    def test_run_python_migrate_nothing_router(self):\n+        self._test_run_python(\"test_mltdb_runpython\", should_run=False)\n+\n+    @override_settings(DATABASE_ROUTERS=[MigrateWhenFooRouter()])\n+    def test_run_python_migrate_foo_router_without_hints(self):\n+        self._test_run_python(\"test_mltdb_runpython2\", should_run=False)\n+\n+    @override_settings(DATABASE_ROUTERS=[MigrateWhenFooRouter()])\n+    def test_run_python_migrate_foo_router_with_hints(self):\n+        self._test_run_python('test_mltdb_runpython3', should_run=True, hints={'foo': True})\n"
    },
    "matplotlib__matplotlib-24637": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_annotation_bbox.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_annotation_bbox.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_annotation_bbox.py b/lib/matplotlib/tests/test_annotation_bbox.py\nnew file mode 100644\nindex 0000000000..fbe7bfdcfb\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_annotation_bbox.py\n@@ -0,0 +1,34 @@\n+# E501 is a too-long line, which is okay in test data.\n+# ruff: noqa: E501\n+\n+import pytest\n+from io import BytesIO\n+\n+import numpy as np\n+\n+import matplotlib.pyplot as plt\n+from matplotlib.offsetbox import (OffsetImage, AnnotationBbox)\n+\n+\n+def test_annotation_bbox_gid():\n+    \"\"\"Test that AnnotationBbox gid is passed to the renderer.\"\"\"\n+    fig, ax = plt.subplots()\n+\n+    # Create a dummy image\n+    arr_img = np.zeros((10, 10))\n+\n+    # Create the AnnotationBbox\n+    imagebox = OffsetImage(arr_img, zoom=0.1)\n+    ab = AnnotationBbox(imagebox, (0.5, 0.5),\n+                        xycoords='data',\n+                        pad=0)\n+    ab.set_gid('my_annotation_gid')\n+    ax.add_artist(ab)\n+\n+    # Save to SVG\n+    with BytesIO() as buf:\n+        fig.savefig(buf, format=\"svg\")\n+        svg = buf.getvalue().decode('utf-8')\n+\n+    # Check that the gid is present in the SVG output\n+    assert 'id=\"my_annotation_gid\"' in svg\n\\ No newline at end of file\n"
    },
    "sphinx-doc__sphinx-7910": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "sympy__sympy-19040": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/polys/tests/test_issue_18895.py",
        "reproduced_bug_commands": [
            "pytest sympy/polys/tests/test_issue_18895.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/polys/tests/test_issue_18895.py b/sympy/polys/tests/test_issue_18895.py\nnew file mode 100644\nindex 0000000000..a32e63ef37\n--- /dev/null\n+++ b/sympy/polys/tests/test_issue_18895.py\n@@ -0,0 +1,17 @@\n+from sympy.polys.polytools import (\n+    factor)\n+\n+from sympy import (\n+    expand, I)\n+\n+from sympy.abc import x, y\n+\n+\n+def test_issue_18895():\n+    \"\"\"\n+    Test for issue 18895.\n+    \n+    Factor with extension=True drops a factor of y-1\n+    \"\"\"\n+    z = expand((x - 1)*(y - 1))\n+    assert factor(z, extension=[I]) == (x - 1)*(y - 1)\n"
    },
    "django__django-13012": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/aggregation_regress/test_grouping.py",
        "reproduced_bug_commands": [
            "python runtests.py aggregation_regress.test_grouping"
        ],
        "reproduced_bug_patch": "diff --git a/tests/aggregation_regress/test_grouping.py b/tests/aggregation_regress/test_grouping.py\nnew file mode 100644\nindex 0000000000..7088e303ef\n--- /dev/null\n+++ b/tests/aggregation_regress/test_grouping.py\n@@ -0,0 +1,68 @@\n+import datetime\n+from decimal import Decimal\n+\n+from django.db.models import (\n+    ExpressionWrapper, IntegerField, Sum, Value\n+)\n+from django.test import TestCase\n+\n+from .models import Author, Book, Publisher\n+\n+\n+class AggregateTestCase(TestCase):\n+\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.a1 = Author.objects.create(name='Adrian Holovaty', age=34)\n+        cls.a3 = Author.objects.create(name='Brad Dayley', age=45)\n+        cls.a4 = Author.objects.create(name='James Bennett', age=29)\n+        cls.a5 = Author.objects.create(name='Jeffrey Forcier', age=37)\n+        cls.a8 = Author.objects.create(name='Peter Norvig', age=57)\n+\n+        cls.p1 = Publisher.objects.create(name='Apress', num_awards=3)\n+        cls.p2 = Publisher.objects.create(name='Sams', num_awards=1)\n+        cls.p3 = Publisher.objects.create(name='Prentice Hall', num_awards=7)\n+        cls.p4 = Publisher.objects.create(name='Morgan Kaufmann', num_awards=9)\n+\n+        Book.objects.create(\n+            pages=447, rating=4.5, contact=cls.a1, publisher=cls.p1,\n+            name='The Definitive Guide to Django: Web Development Done Right',\n+        )\n+        Book.objects.create(\n+            pages=528, rating=3.0, contact=cls.a3, publisher=cls.p2,\n+            name='Sams Teach Yourself Django in 24 Hours',\n+        )\n+        Book.objects.create(\n+            pages=300, rating=4.0, contact=cls.a4, publisher=cls.p1,\n+            name='Practical Django Projects',\n+        )\n+        Book.objects.create(\n+            pages=350, rating=4.0, contact=cls.a5, publisher=cls.p3,\n+            name='Python Web Development with Django',\n+        )\n+        Book.objects.create(\n+            pages=1132, rating=4.0, contact=cls.a8, publisher=cls.p3,\n+            name='Artificial Intelligence: A Modern Approach',\n+        )\n+        Book.objects.create(\n+            pages=946, rating=5.0, contact=cls.a8, publisher=cls.p4,\n+            name='Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp',\n+        )\n+\n+    def test_constant_expression_wrapper_not_in_group_by(self):\n+        \"\"\"\n+        A constant wrapped in ExpressionWrapper shouldn't be added to the\n+        GROUP BY clause.\n+        \"\"\"\n+        qs = Book.objects.annotate(\n+            expr=ExpressionWrapper(Value(3), output_field=IntegerField())\n+        ).values('expr', 'rating').annotate(sum_pages=Sum('pages'))\n+\n+        compiler = qs.query.get_compiler(using='default')\n+        # pre_sql_setup() returns select, where, group_by, having, order_by,\n+        # and select_mask.\n+        _, _, group_by, _, _, _ = compiler.pre_sql_setup()\n+\n+        # The GROUP BY clause should only contain 'rating', not the constant\n+        # 'expr'. With the bug, len(group_by) is 2. After the fix, it will be 1.\n+        self.assertEqual(len(group_by), 1)\n"
    },
    "django__django-15268": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/migrations/test_optimizer_alter_together.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py migrations.test_optimizer_alter_together"
        ],
        "reproduced_bug_patch": "diff --git a/tests/migrations/test_optimizer_alter_together.py b/tests/migrations/test_optimizer_alter_together.py\nnew file mode 100644\nindex 0000000000..92d8b4eea1\n--- /dev/null\n+++ b/tests/migrations/test_optimizer_alter_together.py\n@@ -0,0 +1,69 @@\n+from django.db import migrations\n+from django.db.migrations.optimizer import MigrationOptimizer\n+from django.db.migrations.serializer import serializer_factory\n+from django.test import SimpleTestCase\n+\n+\n+class OptimizerTests(SimpleTestCase):\n+    \"\"\"\n+    Tests the migration optimizer.\n+    \"\"\"\n+\n+    def optimize(self, operations, app_label):\n+        \"\"\"\n+        Handy shortcut for getting results + number of loops\n+        \"\"\"\n+        optimizer = MigrationOptimizer()\n+        return optimizer.optimize(operations, app_label), optimizer._iterations\n+\n+    def serialize(self, value):\n+        return serializer_factory(value).serialize()[0]\n+\n+    def assertOptimizesTo(self, operations, expected, exact=None, less_than=None, app_label=None):\n+        result, iterations = self.optimize(operations, app_label or 'migrations')\n+        result = [self.serialize(f) for f in result]\n+        expected = [self.serialize(f) for f in expected]\n+        self.assertEqual(expected, result)\n+        if exact is not None and iterations != exact:\n+            raise self.failureException(\n+                \"Optimization did not take exactly %s iterations (it took %s)\" % (exact, iterations)\n+            )\n+        if less_than is not None and iterations >= less_than:\n+            raise self.failureException(\n+                \"Optimization did not take less than %s iterations (it took %s)\" % (less_than, iterations)\n+            )\n+\n+    def test_optimize_multiple_alter_foo_together(self):\n+        \"\"\"\n+        A sequence of AlterUniqueTogether/AlterIndexTogether that removes and\n+        then adds a constraint should be optimized into a single operation.\n+        \"\"\"\n+        operations = [\n+            migrations.AlterUniqueTogether(\n+                name='mymodel',\n+                unique_together=set(),\n+            ),\n+            migrations.AlterIndexTogether(\n+                name='mymodel',\n+                index_together=set(),\n+            ),\n+            migrations.AlterUniqueTogether(\n+                name='mymodel',\n+                unique_together={('col',)},\n+            ),\n+            migrations.AlterIndexTogether(\n+                name='mymodel',\n+                index_together={('col',)},\n+            ),\n+        ]\n+        expected = [\n+            migrations.AlterUniqueTogether(\n+                name='mymodel',\n+                unique_together={('col',)},\n+            ),\n+            migrations.AlterIndexTogether(\n+                name='mymodel',\n+                index_together={('col',)},\n+            ),\n+        ]\n+        self.assertOptimizesTo(operations, expected)\n"
    },
    "matplotlib__matplotlib-24870": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_contour_boolean.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_contour_boolean.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_contour_boolean.py b/lib/matplotlib/tests/test_contour_boolean.py\nnew file mode 100644\nindex 0000000000..89b6ae34f6\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_contour_boolean.py\n@@ -0,0 +1,14 @@\n+import numpy as np\n+from numpy.testing import assert_array_almost_equal\n+from matplotlib import pyplot as plt\n+\n+\n+def test_contour_boolean_autolevels():\n+    \"\"\"\n+    Test that contour() with a boolean array defaults levels to [0.5].\n+    \"\"\"\n+    ii, jj = np.ogrid[:100, :100]\n+    im = (ii + jj) % 20 < 10\n+    fig, ax = plt.subplots()\n+    cs = ax.contour(im)\n+    assert_array_almost_equal(cs.levels, [0.5])\n"
    },
    "sphinx-doc__sphinx-7985": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "sympy__sympy-19346": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/printing/tests/test_srepr_containers.py",
        "reproduced_bug_commands": [
            "pytest sympy/printing/tests/test_srepr_containers.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/printing/tests/test_srepr_containers.py b/sympy/printing/tests/test_srepr_containers.py\nnew file mode 100644\nindex 0000000000..b28a0c6036\n--- /dev/null\n+++ b/sympy/printing/tests/test_srepr_containers.py\n@@ -0,0 +1,36 @@\n+from sympy import symbols, Symbol\n+from sympy.core.compatibility import exec_\n+from sympy.printing import srepr\n+from typing import Any, Dict\n+\n+# Setup based on the context from sympy/printing/tests/test_repr.py\n+x, y = symbols('x,y')\n+\n+ENV: Dict[str, Any] = {}\n+exec_(\"from sympy import *\", ENV)\n+\n+\n+def sT(expr, string, import_stmt=None):\n+    \"\"\"\n+    sT := sreprTest\n+\n+    Tests that srepr delivers the expected string and that\n+    the condition eval(srepr(expr))==expr holds.\n+    \"\"\"\n+    if import_stmt is None:\n+        ENV2 = ENV\n+    else:\n+        ENV2 = ENV.copy()\n+        exec_(import_stmt, ENV2)\n+\n+    assert srepr(expr) == string\n+    assert eval(string, ENV2) == expr\n+\n+\n+def test_srepr_set_dict():\n+    \"\"\"\n+    Tests that srepr prints set and dict containers correctly.\n+    \"\"\"\n+    # srepr for sets should be canonical, we assume elements are sorted.\n+    sT({x, y}, \"{Symbol('x'), Symbol('y')}\")\n+    sT({x: y}, \"{Symbol('x'): Symbol('y')}\")\n"
    },
    "django__django-13023": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/model_fields/test_decimalfield_validation.py",
        "reproduced_bug_commands": [
            "python -m django test tests.model_fields.test_decimalfield_validation"
        ],
        "reproduced_bug_patch": "diff --git a/tests/model_fields/test_decimalfield_validation.py b/tests/model_fields/test_decimalfield_validation.py\nnew file mode 100644\nindex 0000000000..6cd7de7732\n--- /dev/null\n+++ b/tests/model_fields/test_decimalfield_validation.py\n@@ -0,0 +1,16 @@\n+import unittest\n+from decimal import Decimal\n+\n+from django.core.exceptions import ValidationError\n+from django.db import models\n+from django.test import TestCase\n+\n+\n+class DecimalFieldTests(TestCase):\n+    def test_to_python_dict_raises_validation_error(self):\n+        \"\"\"\n+        to_python() should raise ValidationError on dict input, not TypeError.\n+        \"\"\"\n+        f = models.DecimalField(max_digits=4, decimal_places=2)\n+        with self.assertRaises(ValidationError):\n+            f.to_python({})\n"
    },
    "django__django-15277": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/expressions/test_value.py",
        "reproduced_bug_commands": [
            "python",
            "tests/runtests.py",
            "tests.expressions.test_value"
        ],
        "reproduced_bug_patch": "diff --git a/tests/expressions/test_value.py b/tests/expressions/test_value.py\nnew file mode 100644\nindex 0000000000..90a3015722\n--- /dev/null\n+++ b/tests/expressions/test_value.py\n@@ -0,0 +1,14 @@\n+from django.db.models import Value\n+from django.test import SimpleTestCase\n+\n+\n+class ValueExpressionTests(SimpleTestCase):\n+\n+    def test_resolve_output_field_char_validator(self):\n+        \"\"\"\n+        Value._resolve_output_field() shouldn't add a MaxLengthValidator to a\n+        CharField.\n+        \"\"\"\n+        value = Value('test')\n+        output_field = value.resolve_expression(None).output_field\n+        self.assertEqual(output_field.validators, [])\n"
    },
    "matplotlib__matplotlib-24970": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_numpy_deprecation.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_numpy_deprecation.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_numpy_deprecation.py b/lib/matplotlib/tests/test_numpy_deprecation.py\nnew file mode 100644\nindex 0000000000..ee3605b2a2\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_numpy_deprecation.py\n@@ -0,0 +1,24 @@\n+import pytest\n+import matplotlib.pyplot as plt\n+import numpy as np\n+\n+\n+def test_no_numpy_deprecation_with_empty_array(recwarn):\n+    \"\"\"\n+    Test for NumPy 1.24 deprecation warnings when applying a colormap to an\n+    empty array.\n+\n+    The test fails if the specific DeprecationWarning from NumPy is raised,\n+    which is the bug's behavior. When the bug is fixed, no warning will be\n+    raised, and the test will pass.\n+    \"\"\"\n+    # This line causes DeprecationWarnings with NumPy 1.24+\n+    plt.get_cmap()(np.empty((0,), dtype=np.uint8))\n+\n+    # Filter for the specific deprecation warnings mentioned in the bug report.\n+    numpy_warnings = [\n+        w for w in recwarn\n+        if (issubclass(w.category, DeprecationWarning) and\n+            \"NumPy will stop allowing conversion\" in str(w.message))\n+    ]\n+    assert not numpy_warnings\n"
    },
    "sphinx-doc__sphinx-8035": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_ext_autodoc_private_members_specific.py",
        "reproduced_bug_commands": [
            "pytest tests/test_ext_autodoc_private_members_specific.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_ext_autodoc_private_members_specific.py b/tests/test_ext_autodoc_private_members_specific.py\nnew file mode 100644\nindex 000000000..f68483ac5\n--- /dev/null\n+++ b/tests/test_ext_autodoc_private_members_specific.py\n@@ -0,0 +1,26 @@\n+import pytest\n+\n+from test_ext_autodoc import do_autodoc\n+\n+\n+@pytest.mark.sphinx('html', testroot='ext-autodoc')\n+def test_private_members_specific_members(app):\n+    \"\"\"Test \"private-members\" option with specific members.\"\"\"\n+    app.config.autoclass_content = 'class'\n+    options = {\n+        'private-members': 'private_function',\n+    }\n+    actual = do_autodoc(app, 'module', 'target.private', options)\n+    assert list(actual) == [\n+        '',\n+        '.. py:module:: target.private',\n+        '',\n+        '',\n+        '.. py:function:: private_function(name)',\n+        '   :module: target.private',\n+        '',\n+        '   private_function is a docstring().',\n+        '',\n+        '   :meta private:',\n+        '',\n+    ]\n"
    },
    "sympy__sympy-19495": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/sets/tests/test_conditionset_subs.py",
        "reproduced_bug_commands": [
            "sed 's/from sympy.sets.fancysets import imageset/from sympy.sets.sets import imageset/' sympy/sets/tests/test_conditionset_subs.py > /tmp/test_conditionset_subs_fixed.py",
            "pytest /tmp/test_conditionset_subs_fixed.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/sets/tests/test_conditionset_subs.py b/sympy/sets/tests/test_conditionset_subs.py\nnew file mode 100644\nindex 0000000000..f8e3a67afe\n--- /dev/null\n+++ b/sympy/sets/tests/test_conditionset_subs.py\n@@ -0,0 +1,29 @@\n+import pytest\n+from sympy.core.numbers import Rational\n+from sympy.core.symbol import Symbol\n+from sympy.functions.elementary.trigonometric import asin\n+from sympy.sets.conditionset import ConditionSet\n+from sympy.sets.fancysets import imageset\n+from sympy.sets.sets import Interval\n+from sympy import S, Lambda, pi, Contains\n+from sympy.abc import x, y\n+\n+\n+def test_subs_on_conditionset_with_imageset_base():\n+    \"\"\"\n+    Test for issue where subs on a ConditionSet with an ImageSet base\n+    incorrectly substitutes the bound variable.\n+    \"\"\"\n+    n = Symbol('n')\n+    base_set = imageset(Lambda(n, 2*n*pi + asin(y)), S.Integers)\n+    c_set = ConditionSet(x, Contains(y, Interval(-1, 1)), base_set)\n+\n+    # This substitution is buggy. It seems to confuse the bound variable `x`\n+    # with the variable `y` being substituted.\n+    substituted = c_set.subs(y, Rational(1, 3))\n+\n+    # The condition Contains(1/3, Interval(-1, 1)) becomes True,\n+    # so the ConditionSet should simplify to its base_set with `y` substituted.\n+    expected = imageset(Lambda(n, 2*n*pi + asin(Rational(1, 3))), S.Integers)\n+\n+    assert substituted == expected\n"
    },
    "django__django-13028": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/queries/test_filterable_attribute.py",
        "reproduced_bug_commands": [
            "./tests/i18n/sampleproject/manage.py",
            "test",
            "queries.test_filterable_attribute"
        ],
        "reproduced_bug_patch": "diff --git a/tests/queries/test_filterable_attribute.py b/tests/queries/test_filterable_attribute.py\nnew file mode 100644\nindex 0000000000..0803559170\n--- /dev/null\n+++ b/tests/queries/test_filterable_attribute.py\n@@ -0,0 +1,37 @@\n+from django.db import models\n+from django.test import TestCase\n+\n+# These models are defined for the test and will be managed by Django's\n+# test runner. The app_label is set to make them part of a virtual app.\n+class ProductMetaDataType(models.Model):\n+    label = models.CharField(max_length=255)\n+    filterable = models.BooleanField(default=False)\n+\n+    class Meta:\n+        app_label = 'queries'\n+\n+class ProductMetaData(models.Model):\n+    value = models.TextField()\n+    metadata_type = models.ForeignKey(ProductMetaDataType, on_delete=models.CASCADE)\n+\n+    class Meta:\n+        app_label = 'queries'\n+\n+\n+class FilterableAttributeTests(TestCase):\n+    @classmethod\n+    def setUpTestData(cls):\n+        \"\"\"Set up data for the whole test case.\"\"\"\n+        cls.brand_metadata = ProductMetaDataType.objects.create(label='Brand', filterable=False)\n+        cls.product_metadata = ProductMetaData.objects.create(value='Dark Vador', metadata_type=cls.brand_metadata)\n+\n+    def test_filter_by_model_with_filterable_false_attribute(self):\n+        \"\"\"\n+        Filtering by a model instance with a `filterable=False` attribute should\n+        succeed without raising an error.\n+        \"\"\"\n+        # This query will raise an unhandled NotSupportedError with the current\n+        # buggy code, causing the test to fail as intended. Once the bug is\n+        # fixed, this query will succeed, and the assertion will pass.\n+        queryset = ProductMetaData.objects.filter(metadata_type=self.brand_metadata)\n+        self.assertIn(self.product_metadata, queryset)\n"
    },
    "django__django-15278": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/migrations/test_add_nullable_one_to_one_field.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py migrations.test_add_nullable_one_to_one_field"
        ],
        "reproduced_bug_patch": "diff --git a/tests/migrations/test_add_nullable_one_to_one_field.py b/tests/migrations/test_add_nullable_one_to_one_field.py\nnew file mode 100644\nindex 0000000000..38f6d8301f\n--- /dev/null\n+++ b/tests/migrations/test_add_nullable_one_to_one_field.py\n@@ -0,0 +1,54 @@\n+import unittest\n+\n+from django.db import connection, migrations, models\n+from django.db.migrations.state import ProjectState\n+from django.test import skipUnlessDBFeature\n+\n+from .test_base import OperationTestBase\n+\n+\n+class OperationsTests(OperationTestBase):\n+    @unittest.skipUnless(connection.vendor == 'sqlite', 'SQLite-specific bug')\n+    def test_add_nullable_one_to_one_field(self):\n+        \"\"\"\n+        Test AddField operation for a nullable OneToOneField on SQLite.\n+        \"\"\"\n+        app_label = 'test_add_nullable_o2o'\n+        # Initial state: two models, Author and Book.\n+        project_state = self.apply_operations(\n+            app_label,\n+            ProjectState(),\n+            operations=[\n+                migrations.CreateModel(\n+                    'Author',\n+                    [('id', models.AutoField(primary_key=True))],\n+                ),\n+                migrations.CreateModel(\n+                    'Book',\n+                    [('id', models.AutoField(primary_key=True))],\n+                ),\n+            ],\n+        )\n+\n+        # The operation that causes the crash on SQLite.\n+        operation = migrations.AddField(\n+            model_name='Book',\n+            name='author',\n+            field=models.OneToOneField(\n+                'Author',\n+                on_delete=models.SET_NULL,\n+                blank=True,\n+                null=True,\n+            ),\n+        )\n+\n+        # This should raise OperationalError: Cannot add a UNIQUE column on SQLite.\n+        # When the bug is fixed, this will pass.\n+        new_state = project_state.clone()\n+        operation.state_forwards(app_label, new_state)\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n+\n+        # The minimal assertion is to check that the column was created. This\n+        # will only be reached if the operation doesn't crash.\n+        self.assertColumnExists('%s_book' % app_label, 'author_id')\n"
    },
    "matplotlib__matplotlib-25122": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_mlab_psd.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_mlab_psd.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_mlab_psd.py b/lib/matplotlib/tests/test_mlab_psd.py\nnew file mode 100644\nindex 0000000000..4e5c3673b2\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_mlab_psd.py\n@@ -0,0 +1,45 @@\n+from numpy.testing import assert_allclose\n+import numpy as np\n+\n+from matplotlib import mlab\n+\n+def test_psd_window_with_negative_values():\n+    \"\"\"\n+    Test that psd scaling is correct for windows with negative values.\n+\n+    The scaling for `scale_by_freq=False` should use `window.sum()**2`, but\n+    was incorrectly using `np.abs(window).sum()**2`, giving incorrect\n+    results for windows with negative lobes, such as a flattop window.\n+\n+    This test checks that the relationship between `scale_by_freq=True` and\n+    `scale_by_freq=False` holds for a flattop window.\n+    \"\"\"\n+    NFFT = 512\n+    # A proper flattop window, which has negative values, matching the\n+    # window from the issue report.\n+    n = np.arange(NFFT)\n+    a0 = 0.21557895\n+    a1 = 0.41663158\n+    a2 = 0.27726316\n+    a3 = 0.08357895\n+    a4 = 0.00694737\n+    window = (a0 - a1 * np.cos(2 * np.pi * n / (NFFT - 1)) +\n+              a2 * np.cos(4 * np.pi * n / (NFFT - 1)) -\n+              a3 * np.cos(6 * np.pi * n / (NFFT - 1)) +\n+              a4 * np.cos(8 * np.pi * n / (NFFT - 1)))\n+\n+    # A simple signal\n+    x = np.random.randn(2 * NFFT)\n+    Fs = 2.0\n+\n+    spec_s, _ = mlab.psd(x, NFFT=NFFT, Fs=Fs, window=window,\n+                           scale_by_freq=True)\n+\n+    spec_n, _ = mlab.psd(x, NFFT=NFFT, Fs=Fs, window=window,\n+                           scale_by_freq=False)\n+\n+    # This relationship should hold if the scaling is correct.\n+    # It fails with the bug because spec_n is scaled by\n+    # np.abs(window).sum()**2 instead of window.sum()**2.\n+    assert_allclose(spec_s * (window**2).sum(),\n+                    spec_n / Fs * window.sum()**2)\n"
    },
    "sphinx-doc__sphinx-8056": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_ext_napoleon_numpy_docstring.py",
        "reproduced_bug_commands": [
            "pytest tests/test_ext_napoleon_numpy_docstring.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_ext_napoleon_numpy_docstring.py b/tests/test_ext_napoleon_numpy_docstring.py\nnew file mode 100644\nindex 000000000..1f9c6e384\n--- /dev/null\n+++ b/tests/test_ext_napoleon_numpy_docstring.py\n@@ -0,0 +1,46 @@\n+import pytest\n+from unittest import TestCase\n+from textwrap import dedent\n+\n+from sphinx.ext.napoleon import Config\n+from sphinx.ext.napoleon.docstring import NumpyDocstring\n+\n+\n+class BaseDocstringTest(TestCase):\n+    pass\n+\n+\n+class NumpyDocstringTest(BaseDocstringTest):\n+    def test_multiple_parameters_on_one_line_with_optional(self):\n+        \"\"\"\n+        Tests that 'optional' is correctly parsed for multiple parameters.\n+\n+        This test reproduces the bug where ', optional' is incorrectly parsed\n+        as part of the description instead of the type. It asserts that the\n+        generated output matches the ideal, correct output.\n+\n+        This test will FAIL if the bug is present, showing a diff between\n+        the buggy output and the correct output. It will PASS once the bug\n+        is fixed.\n+        \"\"\"\n+        docstring = dedent('''\\\n+            A function with a multi-variable parameter line.\n+\n+            Parameters\n+            ----------\n+            x1, x2 : array_like, optional\n+                Input arrays, description of `x1`, `x2`.\n+            ''')\n+\n+        # This is the ideal, correct output for the single-line parameter style.\n+        expected = dedent('''\\\n+            A function with a multi-variable parameter line.\n+\n+            :Parameters: **x1, x2** (*:class:`array_like`*, *optional*) -- Input arrays, description of `x1`, `x2`.\n+            ''')\n+\n+        # The bug is apparent with napoleon_use_param=False.\n+        config = Config(napoleon_use_param=False)\n+        actual = str(NumpyDocstring(docstring, config))\n+\n+        self.assertEqual(expected.strip(), actual.strip())\n"
    },
    "sympy__sympy-19637": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/core/tests/test_kerns.py",
        "reproduced_bug_commands": [
            "./bin/test sympy/core/tests/test_kerns.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/core/tests/test_kerns.py b/sympy/core/tests/test_kerns.py\nnew file mode 100644\nindex 0000000000..f0d530ea9e\n--- /dev/null\n+++ b/sympy/core/tests/test_kerns.py\n@@ -0,0 +1,30 @@\n+from sympy import (Symbol, exp, Integer, Float, sin, cos, log, Poly, Lambda,\n+    Function, I, S, sqrt, srepr, Rational, Tuple, Matrix, Interval, Add, Mul,\n+    Pow, Or, true, false, Abs, pi, Range, Xor)\n+from sympy.abc import x, y\n+from sympy.core.sympify import (sympify, _sympify, SympifyError, kernS,\n+    CantSympify)\n+from sympy.core.decorators import _sympifyit\n+from sympy.external import import_module\n+from sympy.testing.pytest import raises, XFAIL, skip, warns_deprecated_sympy\n+from sympy.utilities.decorator import conserve_mpmath_dps\n+from sympy.geometry import Point, Line\n+from sympy.functions.combinatorial.factorials import factorial, factorial2\n+from sympy.abc import _clash, _clash1, _clash2\n+from sympy.core.compatibility import exec_, HAS_GMPY\n+from sympy.sets import FiniteSet, EmptySet\n+from sympy.tensor.array.dense_ndim_array import ImmutableDenseNDimArray\n+\n+import mpmath\n+from collections import defaultdict, OrderedDict\n+from mpmath.rational import mpq\n+\n+\n+numpy = import_module('numpy')\n+\n+\n+def test_kernS_unbound_local_error():\n+    \"\"\"Test that kernS can parse expressions containing division.\"\"\"\n+    text = \"(2*x)/(x-1)\"\n+    expr = kernS(text)\n+    assert expr == 2*x/(x - 1)\n"
    },
    "sphinx-doc__sphinx-8120": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_intl_locale_dirs_override.py",
        "reproduced_bug_commands": [
            "git clone https://github.com/jonascj/sphinx-test-locale-override.git",
            "cd sphinx-test-locale-override",
            "git checkout 8dea4cd",
            "make html",
            "python repro_test.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_intl_locale_dirs_override.py b/tests/test_intl_locale_dirs_override.py\nnew file mode 100644\nindex 000000000..0ca3d5099\n--- /dev/null\n+++ b/tests/test_intl_locale_dirs_override.py\n@@ -0,0 +1,68 @@\n+import pytest\n+from sphinx.testing.path import path\n+\n+\n+@pytest.mark.sphinx(\n+    'html',\n+    confoverrides={\n+        'language': 'da',\n+        'locale_dirs': ['locale'],\n+        'gettext_auto_build': True,\n+    }\n+)\n+def test_locale_dirs_override_for_standard_messages(app):\n+    \"\"\"\n+    Test that message catalogs in `locale_dirs` can override Sphinx's\n+    default translations.\n+\n+    This is a regression test for a bug where Sphinx would prioritize its own\n+    message catalogs over those defined in `locale_dirs`, preventing users\n+    from overriding default translations.\n+    \"\"\"\n+    # Create a custom translation file (.po) that overrides the default\n+    # Danish translation for \"Fig. %s\" (\"Figur %s\") with \"Foobar %s\",\n+    # as described in the bug report.\n+    po_dir = app.srcdir / 'locale' / 'da' / 'LC_MESSAGES'\n+    po_dir.makedirs()\n+    po_file = po_dir / 'sphinx.po'\n+    po_file.write_text(\n+        r'''\n+msgid \"\"\n+msgstr \"\"\n+\"Project-Id-Version: PACKAGE VERSION\\n\"\n+\"Report-Msgid-Bugs-To: \\n\"\n+\"POT-Creation-Date: 2023-11-20 10:00+0000\\n\"\n+\"PO-Revision-Date: 2023-11-20 10:00+0000\\n\"\n+\"Last-Translator: Full Name <email@example.com>\\n\"\n+\"Language-Team: Danish <da@li.org>\\n\"\n+\"MIME-Version: 1.0\\n\"\n+\"Content-Type: text/plain; charset=UTF-8\\n\"\n+\"Content-Transfer-Encoding: 8bit\\n\"\n+\n+msgid \"Fig. %s\"\n+msgstr \"Foobar %s\"\n+''',\n+        encoding='utf-8'\n+    )\n+\n+    # Create a document that contains a figure, which will use the \"Fig. %s\"\n+    # translation for its caption number.\n+    (app.srcdir / 'index.rst').write_text(\n+        '.. figure:: dummy.png\\n\\n'\n+        '   A caption for the figure.\\n',\n+        encoding='utf-8'\n+    )\n+    # A dummy image file is needed for the build to succeed.\n+    (app.srcdir / 'dummy.png').write_text('')\n+\n+    # Build the documentation. With gettext_auto_build=True, Sphinx will\n+    # automatically compile the .po file to a .mo file.\n+    app.build()\n+\n+    # Check the generated HTML output.\n+    result = (app.outdir / 'index.html').read_text(encoding='utf-8')\n+\n+    # This assertion checks if the custom translation \"Foobar 1\" is used.\n+    # If the bug is present, Sphinx will use its default \"Figur 1\" instead,\n+    # and this assertion will fail.\n+    assert '<span class=\"caption-number\">Foobar 1</span>' in result\n"
    },
    "django__django-13033": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "django__django-15280": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/prefetch_related/test_defer_prefetch.py",
        "reproduced_bug_commands": [
            "cd tests && python runtests.py prefetch_related.test_defer_prefetch"
        ],
        "reproduced_bug_patch": "diff --git a/tests/prefetch_related/test_defer_prefetch.py b/tests/prefetch_related/test_defer_prefetch.py\nnew file mode 100644\nindex 0000000000..3aac6f200c\n--- /dev/null\n+++ b/tests/prefetch_related/test_defer_prefetch.py\n@@ -0,0 +1,48 @@\n+from django.db import models\n+from django.db.models import Prefetch\n+from django.test import TestCase\n+\n+# Models defined for this test case based on the bug report\n+class User(models.Model):\n+    email = models.EmailField()\n+    kind = models.CharField(\n+        max_length=10, choices=[(\"ADMIN\", \"Admin\"), (\"REGULAR\", \"Regular\")]\n+    )\n+\n+    class Meta:\n+        app_label = 'prefetch_related'\n+\n+\n+class Profile(models.Model):\n+    full_name = models.CharField(max_length=255)\n+    user = models.OneToOneField(\n+        User, on_delete=models.CASCADE, related_name='profile'\n+    )\n+\n+    class Meta:\n+        app_label = 'prefetch_related'\n+\n+\n+class DeferPrefetchTests(TestCase):\n+    def test_only_related_queryset(self):\n+        \"\"\"\n+        A nested prefetch shouldn't inherit the deferred fields from its parent\n+        prefetch.\n+        \"\"\"\n+        user = User.objects.create(\n+            email=\"test@example.com\",\n+            kind=\"ADMIN\",\n+        )\n+        Profile.objects.create(user=user, full_name=\"Test Tester\")\n+        queryset = User.objects.only(\"email\").prefetch_related(\n+            Prefetch(\n+                \"profile\",\n+                queryset=Profile.objects.prefetch_related(\n+                    Prefetch(\"user\", queryset=User.objects.only(\"kind\"))\n+                ),\n+            )\n+        )\n+        with self.assertNumQueries(3):\n+            user = queryset.first()\n+        with self.assertNumQueries(0):\n+            self.assertEqual(user.profile.user.kind, \"ADMIN\")\n"
    },
    "matplotlib__matplotlib-25287": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_axes_offset_text.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_axes_offset_text.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_axes_offset_text.py b/lib/matplotlib/tests/test_axes_offset_text.py\nnew file mode 100644\nindex 0000000000..64f9f1942c\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_axes_offset_text.py\n@@ -0,0 +1,14 @@\n+import matplotlib as mpl\n+import matplotlib.pyplot as plt\n+\n+\n+def test_offset_text_labelcolor_from_rcparam():\n+    \"\"\"\n+    Test that the offset text color is determined by `ytick.labelcolor`\n+    from rcParams, not `ytick.color`.\n+    \"\"\"\n+    with mpl.rc_context({'ytick.labelcolor': 'red', 'ytick.color': 'blue'}):\n+        fig, ax = plt.subplots()\n+        ax.plot([1.01e9, 1.02e9, 1.03e9])\n+        fig.canvas.draw()\n+        assert ax.yaxis.get_offset_text().get_color() == 'red'\n"
    },
    "sympy__sympy-19783": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/physics/quantum/tests/test_dagger_identity.py",
        "reproduced_bug_commands": [
            "python -m pytest sympy/physics/quantum/tests/test_dagger_identity.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/physics/quantum/tests/test_dagger_identity.py b/sympy/physics/quantum/tests/test_dagger_identity.py\nnew file mode 100644\nindex 0000000000..0d7142dcd4\n--- /dev/null\n+++ b/sympy/physics/quantum/tests/test_dagger_identity.py\n@@ -0,0 +1,23 @@\n+from sympy import (Derivative, diff, Function, Integer, Mul, pi, sin, Symbol,\n+                   symbols)\n+from sympy.physics.quantum.qexpr import QExpr\n+from sympy.physics.quantum.dagger import Dagger\n+from sympy.physics.quantum.hilbert import HilbertSpace\n+from sympy.physics.quantum.operator import (Operator, UnitaryOperator,\n+                                            HermitianOperator, OuterProduct,\n+                                            DifferentialOperator,\n+                                            IdentityOperator)\n+from sympy.physics.quantum.state import Ket, Bra, Wavefunction\n+from sympy.physics.quantum.qapply import qapply\n+from sympy.physics.quantum.represent import represent\n+from sympy.core.trace import Tr\n+from sympy.physics.quantum.spin import JzKet, JzBra\n+from sympy.matrices import eye\n+\n+\n+def test_dagger_times_identity():\n+    \"\"\"Test that Dagger(A) * I simplifies to Dagger(A)\"\"\"\n+    A = Operator('A')\n+    identity = IdentityOperator()\n+    B = Dagger(A)\n+    assert B * identity == B\n"
    },
    "sphinx-doc__sphinx-8265": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_domain_py_arg_parsing.py",
        "reproduced_bug_commands": [
            "pytest tests/test_domain_py_arg_parsing.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_domain_py_arg_parsing.py b/tests/test_domain_py_arg_parsing.py\nnew file mode 100644\nindex 000000000..336ca7f95\n--- /dev/null\n+++ b/tests/test_domain_py_arg_parsing.py\n@@ -0,0 +1,35 @@\n+import pytest\n+from sphinx.addnodes import (\n+    desc_parameterlist,\n+    desc_parameter,\n+    desc_sig_name,\n+    desc_sig_operator,\n+)\n+from sphinx.domains.python import _pseudo_parse_arglist\n+from sphinx.testing.util import assert_node\n+\n+\n+def test_pseudo_parse_arglist_with_tuple_default():\n+    \"\"\"\n+    Tests that the Python domain's argument parser correctly handles\n+    tuple default values.\n+\n+    This reproduces a bug where a signature like `(color=(1, 1, 1))`\n+    was being incorrectly parsed, splitting the tuple into multiple arguments.\n+    \"\"\"\n+    # The node to be populated by the parser\n+    paramlist = desc_parameterlist()\n+\n+    # The signature string as it would be passed to a directive like py:method\n+    arglist = 'color=(1, 1, 1)'\n+\n+    # Run the parser on the argument string\n+    _pseudo_parse_arglist(paramlist, arglist)\n+\n+    # The bug would cause the parser to split the tuple, creating more than one\n+    # parameter node. The fix ensures the entire tuple is treated as a single\n+    # default value within one parameter node.\n+    assert len(paramlist) == 1\n+    assert_node(paramlist[0], [desc_parameter, ([desc_sig_name, 'color'],\n+                                                [desc_sig_operator, '='],\n+                                                [desc_sig_name, '(1, 1, 1)'])])\n"
    },
    "django__django-13089": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/cache/test_db_cache_cull_bug.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py cache.test_db_cache_cull_bug"
        ],
        "reproduced_bug_patch": "diff --git a/tests/cache/test_db_cache_cull_bug.py b/tests/cache/test_db_cache_cull_bug.py\nnew file mode 100644\nindex 0000000000..f3e077c30d\n--- /dev/null\n+++ b/tests/cache/test_db_cache_cull_bug.py\n@@ -0,0 +1,57 @@\n+from django.core import management\n+from django.core.cache import cache\n+from django.db import connection\n+from django.test import TransactionTestCase, override_settings\n+\n+\n+@override_settings(CACHES={\n+    'default': {\n+        'BACKEND': 'django.core.cache.backends.db.DatabaseCache',\n+        'LOCATION': 'test_cache_table_cull_bug',\n+        'OPTIONS': {\n+            'MAX_ENTRIES': 2,\n+            'CULL_FREQUENCY': 1,\n+        },\n+    },\n+})\n+class DBCacheCullBugTest(TransactionTestCase):\n+    \"\"\"\n+    Tests for a TypeError in the database cache backend's _cull method.\n+    \"\"\"\n+    available_apps = ['cache']\n+\n+    def setUp(self):\n+        super().setUp()\n+        management.call_command('createcachetable', verbosity=0)\n+\n+    def tearDown(self):\n+        super().tearDown()\n+        with connection.cursor() as cursor:\n+            table_name = connection.ops.quote_name('test_cache_table_cull_bug')\n+            cursor.execute(f'DROP TABLE {table_name}')\n+\n+    def test_cull_with_cull_frequency_of_one(self):\n+        \"\"\"\n+        _cull() fails with a TypeError when CULL_FREQUENCY is 1 and the cache\n+        is full.\n+        \"\"\"\n+        # With MAX_ENTRIES = 2, these three calls fill the cache just enough\n+        # so the next call to set() will trigger a cull.\n+        cache.set('key1', 1)\n+        cache.set('key2', 1)\n+        cache.set('key3', 1)\n+        # At this point, the table has 3 rows.\n+\n+        # This fourth call to set() triggers the bug.\n+        # 1. _base_set() sees 3 rows, which is > MAX_ENTRIES (2), so it calls _cull().\n+        # 2. _cull() counts 3 unexpired entries.\n+        # 3. The offset for the culling query is calculated as int(3 / 1) = 3.\n+        # 4. The culling query runs with OFFSET 3 on a table with 3 rows,\n+        #    returning no results.\n+        # 5. cursor.fetchone() returns None, and accessing fetchone()[0] raises\n+        #    a TypeError.\n+        cache.set('key4', 1)\n+\n+        # This assertion is the minimal check. It will only be reached if the\n+        # bug is fixed and the cache.set() call above does not crash.\n+        self.assertEqual(cache.get('key4'), 1)\n"
    },
    "django__django-15315": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/model_fields/test_field_hashing.py",
        "reproduced_bug_commands": [
            "cd tests && python runtests.py model_fields.test_field_hashing"
        ],
        "reproduced_bug_patch": "diff --git a/tests/model_fields/test_field_hashing.py b/tests/model_fields/test_field_hashing.py\nnew file mode 100644\nindex 0000000000..290c52530e\n--- /dev/null\n+++ b/tests/model_fields/test_field_hashing.py\n@@ -0,0 +1,16 @@\n+from django.db import models\n+from django.test import SimpleTestCase\n+\n+\n+class FieldHashingTests(SimpleTestCase):\n+    def test_field_hash_immutable(self):\n+        \"\"\"\n+        A field's hash shouldn't change when it's assigned to a model.\n+        \"\"\"\n+        f = models.CharField(max_length=200)\n+        d = {f: 1}\n+\n+        class Book(models.Model):\n+            title = f\n+\n+        self.assertIn(f, d)\n"
    },
    "matplotlib__matplotlib-25311": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_pickle_draggable_legend.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_pickle_draggable_legend.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_pickle_draggable_legend.py b/lib/matplotlib/tests/test_pickle_draggable_legend.py\nnew file mode 100644\nindex 0000000000..f27cbd05e7\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_pickle_draggable_legend.py\n@@ -0,0 +1,50 @@\n+import pickle\n+from io import BytesIO\n+import matplotlib.pyplot as plt\n+from matplotlib.cbook import CallbackRegistry\n+\n+def test_pickle_draggable_legend():\n+    \"\"\"\n+    A figure with a draggable legend should be picklable even on backends with\n+    unpicklable canvases.\n+\n+    This test simulates an interactive backend by using a mock canvas that is\n+    not picklable. The bug is that DraggableLegend holds a reference to the\n+    canvas, making the Figure unpicklable on interactive backends.\n+    \"\"\"\n+\n+    # This mock canvas has just enough attributes to get past the setup\n+    # and Figure's own __getstate__ method.\n+    class UnpicklableCanvas:\n+        def __init__(self, figure):\n+            self.figure = figure\n+            # Needed for leg.set_draggable() to connect events.\n+            self.callbacks = CallbackRegistry()\n+            # Needed for Figure.__getstate__() to run without error.\n+            self.manager = None\n+\n+        def mpl_connect(self, s, func):\n+            return self.callbacks.connect(s, func)\n+\n+        # This method makes the canvas unpicklable, simulating a real GUI\n+        # canvas. When pickle tries to get the state of this object, it\n+        # will raise the TypeError, reproducing the bug.\n+        def __getstate__(self):\n+            raise TypeError(f\"cannot pickle '{type(self).__name__}' object\")\n+\n+    # Use the code from the bug report.\n+    fig = plt.figure()\n+    # Replace the default, picklable 'Agg' canvas with our mock.\n+    fig.canvas = UnpicklableCanvas(fig)\n+\n+    ax = fig.add_subplot(111)\n+    ax.plot([0, 1, 2, 3, 4], [40, 43, 45, 47, 48], label=\"speed\")\n+\n+    leg = ax.legend()\n+    # This call should now succeed.\n+    leg.set_draggable(True)\n+\n+    # This is where the TypeError should be raised. The pickling process will\n+    # traverse from the Figure to the Legend, and then to the unpicklable\n+    # canvas reference held by the DraggableLegend helper object.\n+    pickle.dump(fig, BytesIO())\n"
    },
    "sympy__sympy-19954": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/combinatorics/tests/test_sylow.py",
        "reproduced_bug_commands": [
            "pytest sympy/combinatorics/tests/test_sylow.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/combinatorics/tests/test_sylow.py b/sympy/combinatorics/tests/test_sylow.py\nnew file mode 100644\nindex 0000000000..e179dacce9\n--- /dev/null\n+++ b/sympy/combinatorics/tests/test_sylow.py\n@@ -0,0 +1,13 @@\n+from sympy.combinatorics.named_groups import DihedralGroup\n+from sympy.combinatorics.perm_groups import PermutationGroup\n+from sympy.combinatorics.permutations import Permutation\n+\n+\n+def test_sylow_subgroup_dihedral_indexerror():\n+    \"\"\"\n+    Test reproducing IndexError for sylow_subgroup() with DihedralGroup.\n+    https://github.com/sympy/sympy/issues/19882\n+    \"\"\"\n+    G = DihedralGroup(18)\n+    S2 = G.sylow_subgroup(p=2)\n+    assert S2.order() == 4\n"
    },
    "sphinx-doc__sphinx-8269": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_build_linkcheck_http_error.py",
        "reproduced_bug_commands": [
            "pytest tests/test_build_linkcheck_http_error.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_build_linkcheck_http_error.py b/tests/test_build_linkcheck_http_error.py\nnew file mode 100644\nindex 000000000..dc5d6bd3e\n--- /dev/null\n+++ b/tests/test_build_linkcheck_http_error.py\n@@ -0,0 +1,36 @@\n+import pytest\n+from unittest import mock\n+import requests\n+\n+\n+@pytest.mark.sphinx('linkcheck', testroot='linkcheck', freshenv=True)\n+def test_http_error_with_anchor(app, status, warning):\n+    \"\"\"\n+    Test that linkcheck reports HTTP errors before checking for anchors.\n+\n+    A link to a non-existent page with an anchor should report the page's\n+    HTTP error, not a failed anchor lookup.\n+\n+    Regression test for https://github.com/sphinx-doc/sphinx/issues/8191.\n+    \"\"\"\n+    (app.srcdir / 'index.rst').write_text(\n+        '`foo <https://google.com/test.txt#test>`_'\n+    )\n+\n+    # Simulate a 404 Not Found error for the page.\n+    # The linkchecker uses a requests.Session object.\n+    error = requests.HTTPError(\n+        '404 Client Error: Not Found for url: https://google.com/test.txt'\n+    )\n+    with mock.patch('requests.Session.head', side_effect=error), \\\n+            mock.patch('requests.Session.get', side_effect=error):\n+        app.builder.build_all()\n+\n+    content = (app.outdir / 'output.txt').read_text()\n+\n+    # The bug causes an \"Anchor not found\" message. The fix should show the\n+    # underlying HTTP error instead.\n+    expected_error_message = (\n+        '404 Client Error: Not Found for url: https://google.com/test.txt'\n+    )\n+    assert expected_error_message in content\n"
    },
    "django__django-13109": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/custom_managers/test_foreignkey_validation.py",
        "reproduced_bug_commands": [
            "python -m django test custom_managers.test_foreignkey_validation"
        ],
        "reproduced_bug_patch": "diff --git a/tests/custom_managers/test_foreignkey_validation.py b/tests/custom_managers/test_foreignkey_validation.py\nnew file mode 100644\nindex 0000000000..1c5cf3f2d5\n--- /dev/null\n+++ b/tests/custom_managers/test_foreignkey_validation.py\n@@ -0,0 +1,52 @@\n+from django import forms\n+from django.db import models\n+from django.test import TestCase\n+\n+\n+class ArticleManager(models.Manager):\n+    def get_queryset(self):\n+        return super().get_queryset().filter(archived=False)\n+\n+\n+class Article(models.Model):\n+    title = models.CharField(max_length=100)\n+    archived = models.BooleanField(default=False)\n+\n+    objects = ArticleManager()\n+    base_manager = models.Manager()\n+\n+    class Meta:\n+        app_label = 'custom_managers'\n+\n+\n+class FavoriteArticle(models.Model):\n+    article = models.ForeignKey(Article, on_delete=models.CASCADE)\n+\n+    class Meta:\n+        app_label = 'custom_managers'\n+\n+\n+class FavoriteArticleForm(forms.ModelForm):\n+    class Meta:\n+        model = FavoriteArticle\n+        fields = '__all__'\n+\n+    def __init__(self, *args, **kwargs):\n+        super().__init__(*args, **kwargs)\n+        # Use the base manager to allow archived articles.\n+        self.fields['article'].queryset = Article.base_manager.all()\n+\n+\n+class ForeignKeyValidationTests(TestCase):\n+    def test_foreignkey_validation_uses_base_manager(self):\n+        \"\"\"\n+        ForeignKey.validate() should use the model's base manager instead of\n+        the default manager.\n+        \"\"\"\n+        archived_article = Article.objects.create(title='Archived', archived=True)\n+        data = {'article': archived_article.pk}\n+        form = FavoriteArticleForm(data)\n+        # This fails because ForeignKey.validate() uses Article.objects (the\n+        # default manager) and doesn't find the archived article. The fix is\n+        # to use the base manager for validation.\n+        self.assertTrue(form.is_valid())\n"
    },
    "django__django-15368": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/queries/test_bulk_update_f_expression.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py queries.test_bulk_update_f_expression"
        ],
        "reproduced_bug_patch": "diff --git a/tests/queries/test_bulk_update_f_expression.py b/tests/queries/test_bulk_update_f_expression.py\nnew file mode 100644\nindex 0000000000..934cfd47ff\n--- /dev/null\n+++ b/tests/queries/test_bulk_update_f_expression.py\n@@ -0,0 +1,24 @@\n+import datetime\n+\n+from django.core.exceptions import FieldDoesNotExist\n+from django.db.models import F\n+from django.db.models.functions import Lower\n+from django.test import TestCase, skipUnlessDBFeature\n+\n+from .models import (\n+    Article, CustomDbColumn, CustomPk, Detail, Individual, JSONFieldNullable,\n+    Member, Note, Number, Order, Paragraph, RelatedObject, SingleObject,\n+    SpecialCategory, Tag, Valid,\n+)\n+\n+\n+class BulkUpdateTests(TestCase):\n+    def test_update_with_plain_f_expression(self):\n+        \"\"\"\n+        Test that bulk_update() works with plain F() expressions.\n+        \"\"\"\n+        note = Note.objects.create(note='test-note', misc='test-misc')\n+        note.misc = F('note')\n+        Note.objects.bulk_update([note], ['misc'])\n+        note.refresh_from_db()\n+        self.assertEqual(note.misc, 'test-note')\n"
    },
    "matplotlib__matplotlib-25332": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_pickle_aligned_labels.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_pickle_aligned_labels.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_pickle_aligned_labels.py b/lib/matplotlib/tests/test_pickle_aligned_labels.py\nnew file mode 100644\nindex 0000000000..24a76fab94\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_pickle_aligned_labels.py\n@@ -0,0 +1,25 @@\n+import pickle\n+import matplotlib.pyplot as plt\n+\n+\n+def test_pickle_aligned_labels():\n+    \"\"\"\n+    Test that pickling a figure with aligned labels works.\n+\n+    Regression test for https://github.com/matplotlib/matplotlib/issues/25429\n+    \"\"\"\n+    fig = plt.figure()\n+    ax1 = fig.add_subplot(211)\n+    ax2 = fig.add_subplot(212)\n+    time = [0, 1, 2, 3, 4]\n+    speed = [40000, 4300, 4500, 4700, 4800]\n+    acc = [10, 11, 12, 13, 14]\n+    ax1.plot(time, speed)\n+    ax1.set_ylabel('speed')\n+    ax2.plot(time, acc)\n+    ax2.set_ylabel('acc')\n+\n+    fig.align_labels()\n+\n+    # This should not raise \"TypeError: cannot pickle 'weakref.ReferenceType'\"\n+    pickle.dumps(fig)\n"
    },
    "sympy__sympy-20154": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/utilities/tests/test_partitions_list.py",
        "reproduced_bug_commands": [
            "bin/test sympy/utilities/tests/test_partitions_list.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/utilities/tests/test_partitions_list.py b/sympy/utilities/tests/test_partitions_list.py\nnew file mode 100644\nindex 0000000000..9d2a27f1a7\n--- /dev/null\n+++ b/sympy/utilities/tests/test_partitions_list.py\n@@ -0,0 +1,10 @@\n+from sympy.utilities.iterables import partitions\n+\n+\n+def test_partitions_list():\n+    \"\"\"\n+    Tests that the partitions() iterator does not reuse the output dictionaries.\n+    This was a bug that caused list(partitions(n)) to return a list of\n+    identical dicts.\n+    \"\"\"\n+    assert list(partitions(4)) == [{4: 1}, {1: 1, 3: 1}, {2: 2}, {1: 2, 2: 1}, {1: 4}]\n"
    },
    "sphinx-doc__sphinx-8459": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_ext_autodoc_type_aliases.py",
        "reproduced_bug_commands": [
            "pytest tests/test_ext_autodoc_type_aliases.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_ext_autodoc_type_aliases.py b/tests/test_ext_autodoc_type_aliases.py\nnew file mode 100644\nindex 000000000..d3ad353fa\n--- /dev/null\n+++ b/tests/test_ext_autodoc_type_aliases.py\n@@ -0,0 +1,53 @@\n+import sys\n+import pytest\n+from sphinx.testing.util import SphinxTestApp\n+\n+@pytest.mark.skipif(sys.version_info < (3, 7), reason='python 3.7+ is required.')\n+@pytest.mark.sphinx(\n+    'text',\n+    testroot='ext-autodoc',\n+    freshenv=True,\n+    confoverrides={\n+        'autodoc_typehints': 'description',\n+        'autodoc_type_aliases': {\n+            'JSONObject': 'project_types.JSONObject',\n+        },\n+        'extensions': ['sphinx.ext.autodoc', 'sphinx.ext.napoleon'],\n+    }\n+)\n+def test_autodoc_type_aliases_with_typehints_description(app: SphinxTestApp):\n+    \"\"\"\n+    Test that autodoc_type_aliases works with autodoc_typehints = 'description'.\n+    Regression test for sphinx-doc/sphinx#8233.\n+    \"\"\"\n+    (app.srcdir / 'project_types.py').write_text(\n+        'from __future__ import annotations\\n'\n+        'from typing import Any, Dict\\n'\n+        '\\n'\n+        'JSONObject = Dict[str, Any]\\n'\n+        '\\n'\n+        'def sphinx_doc(data: JSONObject) -> JSONObject:\\n'\n+        '    \"\"\"Does it work.\\n'\n+        '\\n'\n+        '    Args:\\n'\n+        '        data: Does it args.\\n'\n+        '\\n'\n+        '    Returns:\\n'\n+        '        Does it work in return.\\n'\n+        '    \"\"\"\\n'\n+        '    return {}\\n',\n+        encoding='utf-8'\n+    )\n+    (app.srcdir / 'index.rst').write_text(\n+        '.. autofunction:: project_types.sphinx_doc\\n',\n+        encoding='utf-8'\n+    )\n+\n+    app.build()\n+\n+    content = (app.outdir / 'index.txt').read_text(encoding='utf-8')\n+\n+    # This assertion will fail with the bug, showing Dict[str, Any] instead.\n+    # When the bug is fixed, it will correctly show the aliased type.\n+    expected_param_line = '* **data** (*project_types.JSONObject*) – Does it args.'\n+    assert expected_param_line in content\n"
    },
    "django__django-13112": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/migrations/test_makemigrations_mixed_case_app.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py migrations.test_makemigrations_mixed_case_app"
        ],
        "reproduced_bug_patch": "diff --git a/tests/migrations/test_makemigrations_mixed_case_app.py b/tests/migrations/test_makemigrations_mixed_case_app.py\nnew file mode 100644\nindex 0000000000..859ad3ceee\n--- /dev/null\n+++ b/tests/migrations/test_makemigrations_mixed_case_app.py\n@@ -0,0 +1,81 @@\n+import os\n+from django.db import models\n+from django.db.migrations.autodetector import MigrationAutodetector\n+from django.db.migrations.graph import MigrationGraph\n+from django.db.migrations.loader import MigrationLoader\n+from django.db.migrations.questioner import MigrationQuestioner\n+from django.db.migrations.state import ModelState, ProjectState\n+from django.test import TestCase\n+\n+\n+class MakemigrationsMixedCaseAppTest(TestCase):\n+    \"\"\"\n+    Tests that makemigrations doesn't crash on a ForeignKey with a lazy\n+    reference to a model in an app with a mixed-case name.\n+    \"\"\"\n+\n+    def get_changes(self, from_state, to_state, questioner=None):\n+        \"\"\"\n+        A simplified version of the helper method from Django's test suite\n+        to run the autodetector.\n+        \"\"\"\n+        loader = MigrationLoader(connection=None, load=False)\n+        loader.graph = MigrationGraph()\n+        autodetector = MigrationAutodetector(\n+            from_state,\n+            to_state,\n+            questioner=questioner or MigrationQuestioner(),\n+        )\n+        return autodetector.changes(graph=loader.graph)\n+\n+    def repr_changes(self, changes):\n+        \"\"\"Simplified helper to represent changes for assertion messages.\"\"\"\n+        output = \"\"\n+        for app_label, migrations in sorted(changes.items()):\n+            output += f\"  {app_label}:\\n\"\n+            for migration in migrations:\n+                output += f\"    {migration.name}\\n\"\n+                for operation in migration.operations:\n+                    output += f\"      {operation}\\n\"\n+        return output\n+\n+    def assertNumberMigrations(self, changes, app_label, number):\n+        \"\"\"Assert a certain number of migrations are generated for an app.\"\"\"\n+        if len(changes.get(app_label, [])) != number:\n+            self.fail(\n+                f\"Incorrect number of migrations ({len(changes.get(app_label, []))}) \"\n+                f\"for {app_label} (expected {number})\\n{self.repr_changes(changes)}\"\n+            )\n+\n+    def test_foreign_key_to_mixed_case_app_label(self):\n+        \"\"\"\n+        A lazy reference to a model in an app with a mixed-case label should\n+        be resolved correctly by the autodetector.\n+        \"\"\"\n+        category_model = ModelState(\n+            app_label='DJ_RegLogin',\n+            name='Category',\n+            fields=[\n+                ('id', models.AutoField(primary_key=True)),\n+                ('title', models.CharField(max_length=100)),\n+            ],\n+        )\n+        content_model = ModelState(\n+            app_label='DJ_RegLogin',\n+            name='Content',\n+            fields=[\n+                ('id', models.AutoField(primary_key=True)),\n+                ('body', models.TextField()),\n+                ('category', models.ForeignKey('DJ_RegLogin.Category', models.CASCADE)),\n+            ],\n+        )\n+        from_state = ProjectState()\n+        to_state = ProjectState()\n+        to_state.add_model(category_model)\n+        to_state.add_model(content_model)\n+\n+        # This will raise ValueError before the fix.\n+        changes = self.get_changes(from_state, to_state)\n+\n+        # When fixed, the autodetector should create one migration for the app.\n+        self.assertNumberMigrations(changes, 'DJ_RegLogin', 1)\n"
    },
    "django__django-15375": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/aggregation_regress/test_aggregate_after_annotate.py",
        "reproduced_bug_commands": [
            "python3 tests/runtests.py aggregation_regress.test_aggregate_after_annotate"
        ],
        "reproduced_bug_patch": "diff --git a/tests/aggregation_regress/test_aggregate_after_annotate.py b/tests/aggregation_regress/test_aggregate_after_annotate.py\nnew file mode 100644\nindex 0000000000..34bea9d874\n--- /dev/null\n+++ b/tests/aggregation_regress/test_aggregate_after_annotate.py\n@@ -0,0 +1,47 @@\n+import datetime\n+from decimal import Decimal\n+\n+from django.db.models import F, Sum\n+from django.test import TestCase\n+\n+from .models import Author, Book, Publisher\n+\n+\n+class AggregateTestCase(TestCase):\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.a1 = Author.objects.create(name='Adrian Holovaty', age=34)\n+        cls.a2 = Author.objects.create(name='Jacob Kaplan-Moss', age=35)\n+        cls.a3 = Author.objects.create(name='Brad Dayley', age=45)\n+        cls.a4 = Author.objects.create(name='James Bennett', age=29)\n+        cls.a5 = Author.objects.create(name='Jeffrey Forcier', age=37)\n+        cls.a6 = Author.objects.create(name='Paul Bissex', age=29)\n+        cls.a7 = Author.objects.create(name='Wesley J. Chun', age=25)\n+        cls.a8 = Author.objects.create(name='Peter Norvig', age=57)\n+        cls.a9 = Author.objects.create(name='Stuart Russell', age=46)\n+\n+        cls.p1 = Publisher.objects.create(name='Apress', num_awards=3)\n+        cls.p2 = Publisher.objects.create(name='Sams', num_awards=1)\n+        cls.p3 = Publisher.objects.create(name='Prentice Hall', num_awards=7)\n+        cls.p4 = Publisher.objects.create(name='Morgan Kaufmann', num_awards=9)\n+\n+        cls.b1 = Book.objects.create(\n+            isbn='159059725', name='The Definitive Guide to Django: Web Development Done Right',\n+            pages=447, rating=4.5, price=Decimal('30.00'), contact=cls.a1, publisher=cls.p1,\n+            pubdate=datetime.date(2007, 12, 6)\n+        )\n+        cls.b2 = Book.objects.create(\n+            isbn='067232959', name='Sams Teach Yourself Django in 24 Hours',\n+            pages=528, rating=3.0, price=Decimal('23.09'), contact=cls.a3, publisher=cls.p2,\n+            pubdate=datetime.date(2008, 3, 3)\n+        )\n+\n+    def test_aggregate_default_after_annotate(self):\n+        \"\"\"\n+        Regression test for a crash when using aggregate() with a default\n+        value after an annotate() call.\n+        \"\"\"\n+        expected_result = Book.objects.aggregate(Sum('id'))\n+        # This query will crash with an OperationalError on SQLite.\n+        result = Book.objects.annotate(idx=F('id')).aggregate(Sum('id', default=0))\n+        self.assertEqual(result, expected_result)\n"
    },
    "matplotlib__matplotlib-25479": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_colormap.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_colormap.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_colormap.py b/lib/matplotlib/tests/test_colormap.py\nnew file mode 100644\nindex 0000000000..c2e9e440d4\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_colormap.py\n@@ -0,0 +1,58 @@\n+import pytest\n+import matplotlib as mpl\n+import matplotlib.pyplot as plt\n+from matplotlib import cm\n+from matplotlib.colors import LinearSegmentedColormap\n+import numpy as np\n+\n+\n+def test_colormap_registration_name_clash_fails():\n+    \"\"\"\n+    This test demonstrates a bug where registering a colormap with a name\n+    different from its internal `name` attribute causes `imshow` to fail.\n+\n+    The test is expected to FAIL with a `ValueError` until the bug is fixed.\n+    By failing, it correctly reproduces and highlights the bug.\n+\n+    See issue #4462.\n+    \"\"\"\n+    my_cmap_data = [[1.5e-03, 4.7e-04, 1.4e-02],\n+                    [2.3e-03, 1.3e-03, 1.8e-02],\n+                    [3.3e-03, 2.3e-03, 2.4e-02]]\n+    # Create a colormap with an internal name 'some_cmap_name'\n+    my_cmap = LinearSegmentedColormap.from_list(\n+        'some_cmap_name', my_cmap_data)\n+\n+    # Register the colormap with a *different* public name\n+    registered_name = 'my_cmap_name'\n+\n+    # Use a try/finally to ensure cleanup even if the test fails\n+    try:\n+        with pytest.warns(\n+                mpl.MatplotlibDeprecationWarning,\n+                match=r\"matplotlib\\.colormaps\\.register\\(name\\)\"\n+        ):\n+            cm.register_cmap(name=registered_name, cmap=my_cmap)\n+\n+        # Set the default colormap for plotting\n+        plt.set_cmap(registered_name)\n+\n+        # This call to imshow is expected to fail with a ValueError due to the bug.\n+        # The test does not catch the exception, so the test itself will fail.\n+        fig, ax = plt.subplots()\n+        im = ax.imshow([[1, 1], [2, 2]])\n+\n+        # This assertion will only be reached if the bug is fixed.\n+        # It checks that the image is using the correct colormap object.\n+        assert im.get_cmap() is my_cmap\n+\n+    finally:\n+        # Cleanup: unregister the colormap and close the figure\n+        with pytest.warns(\n+                mpl.MatplotlibDeprecationWarning,\n+                match=r\"matplotlib\\.colormaps\\.unregister\\(name\\)\"\n+        ):\n+            cm.unregister_cmap(registered_name)\n+        plt.close('all')\n+        # Restore rcParams to default to avoid side-effects\n+        mpl.rcdefaults()\n"
    },
    "sympy__sympy-20428": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/polys/tests/test_regressions.py",
        "reproduced_bug_commands": [
            "pytest tests/test_clear_denoms_unstripped_zero.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/polys/tests/test_regressions.py b/sympy/polys/tests/test_regressions.py\nnew file mode 100644\nindex 0000000000..e6fee60711\n--- /dev/null\n+++ b/sympy/polys/tests/test_regressions.py\n@@ -0,0 +1,22 @@\n+from sympy.polys.polytools import Poly\n+from sympy import sympify, symbols, sqrt\n+\n+\n+def test_clear_denoms_unstripped_zero():\n+    \"\"\"\n+    Test that a Poly that becomes zero after clear_denoms() is correctly\n+    identified as a zero polynomial.\n+\n+    This is a regression test for an issue where a complex constant expression\n+    simplifying to zero would result in a Poly object that reported\n+    `is_zero` as False due to an unstripped zero in its internal DMP\n+    representation, leading to errors in other methods like `terms_gcd()`.\n+    \"\"\"\n+    x = symbols(\"x\")\n+    f = Poly(sympify(\"-117968192370600*18**(1/3)/(217603955769048*(24201 + 253*sqrt(9165))**(1/3) + 2273005839412*sqrt(9165)*(24201 + 253*sqrt(9165))**(1/3)) - 15720318185*2**(2/3)*3**(1/3)*(24201 + 253*sqrt(9165))**(2/3)/(217603955769048*(24201 + 253*sqrt(9165))**(1/3) + 2273005839412*sqrt(9165)*(24201 + 253*sqrt(9165))**(1/3)) + 15720318185*12**(1/3)*(24201 + 253*sqrt(9165))**(2/3)/(217603955769048*(24201 + 253*sqrt(9165))**(1/3) + 2273005839412*sqrt(9165)*(24201 + 253*sqrt(9165))**(1/3)) + 117968192370600*2**(1/3)*3**(2/3)/(217603955769048*(24201 + 253*sqrt(9165))**(1/3) + 2273005839412*sqrt(9165)*(24201 + 253*sqrt(9165))**(1/3))\"), x)\n+    _coeff, bad_poly = f.clear_denoms()\n+\n+    # The bug causes bad_poly to have an internal representation of\n+    # DMP([EX(0)], EX, None) which should be DMP([], EX, None).\n+    # This made is_zero return False.\n+    assert bad_poly.is_zero\n"
    },
    "sphinx-doc__sphinx-8475": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_build_linkcheck_redirects.py",
        "reproduced_bug_commands": [
            "pytest tests/test_build_linkcheck_redirects.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_build_linkcheck_redirects.py b/tests/test_build_linkcheck_redirects.py\nnew file mode 100644\nindex 000000000..29cd1bae9\n--- /dev/null\n+++ b/tests/test_build_linkcheck_redirects.py\n@@ -0,0 +1,72 @@\n+import contextlib\n+import http.server\n+import threading\n+\n+import pytest\n+\n+\n+# Utility code from tests/utils.py required to run the test\n+class HttpServerThread(threading.Thread):\n+    def __init__(self, handler, *args, **kwargs):\n+        super().__init__(*args, **kwargs)\n+        self.server = http.server.HTTPServer((\"localhost\", 7777), handler)\n+\n+    def run(self):\n+        self.server.serve_forever(poll_interval=0.01)\n+\n+    def terminate(self):\n+        self.server.shutdown()\n+        self.server.server_close()\n+        self.join()\n+\n+\n+def create_server(thread_class):\n+    def server(handler):\n+        server_thread = thread_class(handler, daemon=True)\n+        server_thread.start()\n+        try:\n+            yield server_thread\n+        finally:\n+            server_thread.terminate()\n+    return contextlib.contextmanager(server)\n+\n+\n+http_server = create_server(HttpServerThread)\n+\n+\n+@pytest.mark.sphinx('linkcheck', testroot='linkcheck-localserver', freshenv=True)\n+def test_too_many_redirects_fallback(app):\n+    \"\"\"\n+    Tests that the linkchecker falls back to a GET request when a HEAD\n+    request results in a \"Too Many Redirects\" error. This simulates a server\n+    that enters an infinite redirect loop on HEAD requests.\n+    \"\"\"\n+    class TooManyRedirectsHandler(http.server.BaseHTTPRequestHandler):\n+        def do_HEAD(self):\n+            # Create an infinite redirect loop for HEAD requests\n+            self.send_response(302, 'Found')\n+            self.send_header('Location', 'http://localhost:7777/')\n+            self.end_headers()\n+\n+        def do_GET(self):\n+            # But allow GET requests to succeed after one redirect\n+            if self.path == '/?redirected=1':\n+                self.send_response(204, 'No Content')\n+                self.end_headers()\n+            else:\n+                self.send_response(302, 'Found')\n+                self.send_header('Location', 'http://localhost:7777/?redirected=1')\n+                self.end_headers()\n+\n+    with http_server(TooManyRedirectsHandler):\n+        app.builder.build_all()\n+\n+    content = (app.outdir / 'output.txt').read_text()\n+\n+    # This assertion will fail before the fix, as the status will be 'broken'\n+    # due to 'Too Many Redirects'. After the fix, the fallback to GET will\n+    # be successful, and the status will be 'redirected'.\n+    assert content == (\n+        'index.rst:1: [redirected with Found] '\n+        'http://localhost:7777/ to http://localhost:7777/?redirected=1\\n'\n+    )\n"
    },
    "django__django-13121": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "django__django-15380": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/migrations/test_autodetector_rename_model_and_field.py",
        "reproduced_bug_commands": [
            "python tests/i18n/sampleproject/manage.py test tests.migrations.test_autodetector_rename_model_and_field"
        ],
        "reproduced_bug_patch": "diff --git a/tests/migrations/test_autodetector_rename_model_and_field.py b/tests/migrations/test_autodetector_rename_model_and_field.py\nnew file mode 100644\nindex 0000000000..e3924af41a\n--- /dev/null\n+++ b/tests/migrations/test_autodetector_rename_model_and_field.py\n@@ -0,0 +1,115 @@\n+from django.db import models\n+from django.db.migrations.autodetector import MigrationAutodetector\n+from django.db.migrations.questioner import MigrationQuestioner\n+from django.db.migrations.state import ModelState, ProjectState\n+from django.test import TestCase\n+\n+\n+class AutodetectorRenameModelAndFieldTests(TestCase):\n+    \"\"\"\n+    Tests for the migration autodetector focused on a bug when renaming\n+    a model and a field in the same step.\n+    \"\"\"\n+\n+    def repr_changes(self, changes):\n+        output = \"\"\n+        for app_label, migrations_ in sorted(changes.items()):\n+            output += \"  %s:\\n\" % app_label\n+            for migration in migrations_:\n+                output += \"    %s\\n\" % migration.name\n+                for operation in migration.operations:\n+                    output += \"      %s\\n\" % operation\n+        return output\n+\n+    def assertNumberMigrations(self, changes, app_label, number):\n+        if len(changes.get(app_label, [])) != number:\n+            self.fail(\"Incorrect number of migrations (%s) for %s (expected %s)\\n%s\" % (\n+                len(changes.get(app_label, [])),\n+                app_label,\n+                number,\n+                self.repr_changes(changes),\n+            ))\n+\n+    def assertOperationTypes(self, changes, app_label, position, types):\n+        if not changes.get(app_label):\n+            self.fail(\"No migrations found for %s\\n%s\" % (app_label, self.repr_changes(changes)))\n+        if len(changes[app_label]) < position + 1:\n+            self.fail(\"No migration at index %s for %s\\n%s\" % (position, app_label, self.repr_changes(changes)))\n+        migration = changes[app_label][position]\n+        real_types = [operation.__class__.__name__ for operation in migration.operations]\n+        if types != real_types:\n+            self.fail(\"Operation type mismatch for %s.%s (expected %s):\\n%s\" % (\n+                app_label,\n+                migration.name,\n+                types,\n+                self.repr_changes(changes),\n+            ))\n+\n+    def assertOperationAttributes(self, changes, app_label, position, operation_position, **attrs):\n+        if not changes.get(app_label):\n+            self.fail(\"No migrations found for %s\\n%s\" % (app_label, self.repr_changes(changes)))\n+        if len(changes[app_label]) < position + 1:\n+            self.fail(\"No migration at index %s for %s\\n%s\" % (position, app_label, self.repr_changes(changes)))\n+        migration = changes[app_label][position]\n+        if len(migration.operations) < operation_position + 1:\n+            self.fail(\"No operation at index %s for %s.%s\\n%s\" % (\n+                operation_position,\n+                app_label,\n+                migration.name,\n+                self.repr_changes(changes),\n+            ))\n+        operation = migration.operations[operation_position]\n+        for attr, value in attrs.items():\n+            if getattr(operation, attr, None) != value:\n+                self.fail(\"Attribute mismatch for %s.%s op #%s, %s (expected %r, got %r):\\n%s\" % (\n+                    app_label,\n+                    migration.name,\n+                    operation_position,\n+                    attr,\n+                    value,\n+                    getattr(operation, attr, None),\n+                    self.repr_changes(changes),\n+                ))\n+\n+    def make_project_state(self, model_states):\n+        \"Shortcut to make ProjectStates from lists of predefined models\"\n+        project_state = ProjectState()\n+        for model_state in model_states:\n+            project_state.add_model(model_state.clone())\n+        return project_state\n+\n+    def get_changes(self, before_states, after_states, questioner=None):\n+        if not isinstance(before_states, ProjectState):\n+            before_states = self.make_project_state(before_states)\n+        if not isinstance(after_states, ProjectState):\n+            after_states = self.make_project_state(after_states)\n+        return MigrationAutodetector(\n+            before_states,\n+            after_states,\n+            questioner,\n+        )._detect_changes()\n+\n+    def test_rename_model_and_field(self):\n+        \"\"\"\n+        Tests that the autodetector doesn't crash when a model and a field on\n+        it are renamed.\n+        \"\"\"\n+        before_states = self.make_project_state([\n+            ModelState('test_one', 'MyModel', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('field', models.IntegerField()),\n+            ]),\n+        ])\n+        after_states = self.make_project_state([\n+            ModelState('test_one', 'MyModel2', [\n+                ('id', models.AutoField(primary_key=True)),\n+                ('renamed_field', models.IntegerField()),\n+            ]),\n+        ])\n+        questioner = MigrationQuestioner({'ask_rename_model': True, 'ask_rename': True})\n+        changes = self.get_changes(before_states, after_states, questioner)\n+\n+        self.assertNumberMigrations(changes, 'test_one', 1)\n+        self.assertOperationTypes(changes, 'test_one', 0, ['RenameField', 'RenameModel'])\n+        self.assertOperationAttributes(changes, 'test_one', 0, 0, model_name='mymodel', old_name='field', new_name='renamed_field')\n+        self.assertOperationAttributes(changes, 'test_one', 0, 1, old_name='MyModel', new_name='MyModel2')\n"
    },
    "matplotlib__matplotlib-25775": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_text_antialiased.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test\nt_text_antialiased.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_text_antialiased.py b/lib/matplotlib/tests/test_text_antialiased.py\nnew file mode 100644\nindex 0000000000..2456727ef3\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_text_antialiased.py\n@@ -0,0 +1,13 @@\n+import matplotlib as mpl\n+from matplotlib import rcParams\n+\n+def test_text_antialiased():\n+    \"\"\"Test that Text antialiased getter/setter work.\"\"\"\n+    # This is based on test_default_antialiased for patches.\n+    t = mpl.text.Text(0, 0, \"hello\")\n+    # Check that we can toggle it.\n+    t.set_antialiased(not rcParams['text.antialiased'])\n+    assert t.get_antialiased() == (not rcParams['text.antialiased'])\n+    # Check that None resets it.\n+    t.set_antialiased(None)\n+    assert t.get_antialiased() == rcParams['text.antialiased']\n"
    },
    "sympy__sympy-20438": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/simplify/tests/test_simplify_sets.py",
        "reproduced_bug_commands": [
            "pytest sympy/simplify/tests/test_simplify_sets.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/simplify/tests/test_simplify_sets.py b/sympy/simplify/tests/test_simplify_sets.py\nnew file mode 100644\nindex 0000000000..220f807255\n--- /dev/null\n+++ b/sympy/simplify/tests/test_simplify_sets.py\n@@ -0,0 +1,16 @@\n+from sympy.sets import FiniteSet, ProductSet\n+from sympy.core.relational import Eq\n+from sympy.simplify.simplify import simplify\n+\n+\n+def test_simplify_productset_finiteset_equality():\n+    \"\"\"\n+    Test that simplifying an equality between a ProductSet and a\n+    logically equivalent FiniteSet works, and does not raise an exception.\n+    \"\"\"\n+    a = FiniteSet(1, 2)\n+    b = ProductSet(a, a)\n+    c = FiniteSet((1, 1), (1, 2), (2, 1), (2, 2))\n+    # This should simplify to True, but it raises an AttributeError\n+    # because Complement has no `equals` method.\n+    assert simplify(Eq(b, c)) is True\n"
    },
    "sphinx-doc__sphinx-8548": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_ext_autodoc_inherited_attribute.py",
        "reproduced_bug_commands": [
            "pytest tests/test_ext_autodoc_inherited_attribute.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_ext_autodoc_inherited_attribute.py b/tests/test_ext_autodoc_inherited_attribute.py\nnew file mode 100644\nindex 000000000..a8e50e0cf\n--- /dev/null\n+++ b/tests/test_ext_autodoc_inherited_attribute.py\n@@ -0,0 +1,36 @@\n+import pytest\n+from .test_ext_autodoc import do_autodoc\n+\n+\n+@pytest.mark.sphinx('html', testroot='ext-autodoc')\n+def test_inherited_attribute(app):\n+    \"\"\"Test for inherited attributes\"\"\"\n+    (app.srcdir / 'target' / 'inheritance_attr.py').write_text(\n+        'class Base:\\n'\n+        '    #: docstring for attr\\n'\n+        '    attr = 1\\n\\n'\n+        'class Derived(Base):\\n'\n+        '    \"\"\"Docstring for Derived.\"\"\"\\n'\n+        '    pass\\n',\n+        encoding='utf-8'\n+    )\n+    options = {\n+        'members': True,\n+        'inherited-members': True,\n+    }\n+    actual = do_autodoc(app, 'class', 'target.inheritance_attr.Derived', options)\n+    assert list(actual) == [\n+        '',\n+        '.. py:class:: Derived()',\n+        '   :module: target.inheritance_attr',\n+        '',\n+        '   Docstring for Derived.',\n+        '',\n+        '',\n+        '   .. py:attribute:: Derived.attr',\n+        '      :module: target.inheritance_attr',\n+        '      :value: 1',\n+        '',\n+        '      docstring for attr',\n+        '',\n+    ]\n"
    },
    "django__django-13128": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/expressions/test_temporal.py",
        "reproduced_bug_commands": [
            "python runtests.py expressions.test_temporal"
        ],
        "reproduced_bug_patch": "diff --git a/tests/expressions/test_temporal.py b/tests/expressions/test_temporal.py\nnew file mode 100644\nindex 0000000000..71632b1801\n--- /dev/null\n+++ b/tests/expressions/test_temporal.py\n@@ -0,0 +1,22 @@\n+import datetime\n+\n+from django.db.models import DurationField, F, Value\n+from django.test import TestCase\n+\n+from .models import Experiment\n+\n+\n+class TemporalExpressionsTests(TestCase):\n+    def test_temporal_subtraction_with_timedelta_value(self):\n+        \"\"\"\n+        A FieldError should not be raised when adding a timedelta to a\n+        subtraction of two DateTimeFields.\n+        \"\"\"\n+        # The FieldError is raised during query compilation, so no data is\n+        # needed in the database.\n+        qs = Experiment.objects.annotate(\n+            delta=F('end') - F('start') + Value(datetime.timedelta(), output_field=DurationField())\n+        )\n+        # Compiling the query by calling str() will raise the FieldError.\n+        # A successful compilation indicates that the bug is fixed.\n+        str(qs.query)\n"
    },
    "django__django-15382": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/queries/test_negated_exists.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py queries.test_negated_exists"
        ],
        "reproduced_bug_patch": "diff --git a/tests/queries/test_negated_exists.py b/tests/queries/test_negated_exists.py\nnew file mode 100644\nindex 0000000000..9fcf25c8ad\n--- /dev/null\n+++ b/tests/queries/test_negated_exists.py\n@@ -0,0 +1,25 @@\n+from django.db.models import Exists\n+from django.test import TestCase\n+\n+from .models import SimpleCategory\n+\n+\n+class NegatedExistsEmptyQuerysetFilterTests(TestCase):\n+    def test_negated_exists_none_with_other_filters(self):\n+        \"\"\"\n+        Tests that a negated Exists(subquery) with an empty queryset\n+        doesn't result in an EmptyResultSet, which would incorrectly\n+        make the query return no results.\n+        \"\"\"\n+        # Create an object that should be found by the query.\n+        category = SimpleCategory.objects.create(name='test')\n+\n+        # This query is the subject of the bug.\n+        # ~Exists(empty_queryset) should always be TRUE, so this\n+        # should be equivalent to SimpleCategory.objects.filter(name='test').\n+        # The bug causes it to become an EmptyResultSet.\n+        qs = SimpleCategory.objects.filter(~Exists(SimpleCategory.objects.none()), name='test')\n+\n+        # This assertion will fail if the bug is present (qs will be empty).\n+        # It will pass when the bug is fixed.\n+        self.assertSequenceEqual(qs, [category])\n"
    },
    "matplotlib__matplotlib-25960": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_subfigure.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_subfigure.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_subfigure.py b/lib/matplotlib/tests/test_subfigure.py\nnew file mode 100644\nindex 0000000000..262e5ca175\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_subfigure.py\n@@ -0,0 +1,37 @@\n+import matplotlib.pyplot as plt\n+import numpy as np\n+\n+\n+def test_subfigure_wspace_hspace_is_ignored():\n+    \"\"\"\n+    Tests that wspace and hspace arguments to Figure.subfigures are ignored.\n+\n+    This test creates two figures with different wspace values and asserts that\n+    the resulting subfigure positions are actually different. If the bug is\n+    present, the positions will be the same, and the test will fail.\n+    \"\"\"\n+    # Create a figure with a small wspace.\n+    fig1 = plt.figure()\n+    sfigs1 = fig1.subfigures(1, 2, wspace=0.1)\n+    for sfig in sfigs1:\n+        sfig.subplots()\n+\n+    # Create another figure with a large wspace.\n+    fig2 = plt.figure()\n+    sfigs2 = fig2.subfigures(1, 2, wspace=0.8)\n+    for sfig in sfigs2:\n+        sfig.subplots()\n+\n+    # Calculate the layouts by drawing the canvases.\n+    fig1.canvas.draw()\n+    fig2.canvas.draw()\n+\n+    # Get the final bounding box of the right-hand subfigure in both figures.\n+    # A SubFigure is an Artist, so it has a .bbox attribute giving its position.\n+    bbox1 = sfigs1[1].bbox\n+    bbox2 = sfigs2[1].bbox\n+\n+    # If wspace is ignored, the x-positions of the bounding boxes will be the\n+    # same, and this assert will fail, thus demonstrating the bug.\n+    # We check the left edge (x0) of the second subfigure's bounding box.\n+    assert bbox1.x0 != bbox2.x0\n"
    },
    "sympy__sympy-20590": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/core/tests/test_symbol_2.py",
        "reproduced_bug_commands": [
            "pytest sympy/core/tests/test_symbol_2.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/core/tests/test_symbol_2.py b/sympy/core/tests/test_symbol_2.py\nnew file mode 100644\nindex 0000000000..76705bc503\n--- /dev/null\n+++ b/sympy/core/tests/test_symbol_2.py\n@@ -0,0 +1,16 @@\n+from sympy import (Symbol, Wild, GreaterThan, LessThan, StrictGreaterThan,\n+    StrictLessThan, pi, I, Rational, sympify, symbols, Dummy)\n+from sympy.core.symbol import uniquely_named_symbol, _symbol, Str\n+\n+from sympy.testing.pytest import raises\n+from sympy.core.symbol import disambiguate\n+\n+\n+def test_symbol_no_dict():\n+    \"\"\"\n+    Tests that Symbol instances do not have a __dict__ attribute.\n+\n+    This was present in older versions of SymPy for memory optimization\n+    and was accidentally removed in 1.7.\n+    \"\"\"\n+    assert not hasattr(Symbol('s'), '__dict__')\n"
    },
    "django__django-11087": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    },
    "django__django-13158": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/model_forms/test_modelmultiplechoicefield.py",
        "reproduced_bug_commands": [
            "python runtests.py model_forms.test_modelmultiplechoicefield"
        ],
        "reproduced_bug_patch": "diff --git a/tests/model_forms/test_modelmultiplechoicefield.py b/tests/model_forms/test_modelmultiplechoicefield.py\nnew file mode 100644\nindex 0000000000..35f7c0827b\n--- /dev/null\n+++ b/tests/model_forms/test_modelmultiplechoicefield.py\n@@ -0,0 +1,39 @@\n+import datetime\n+from django import forms\n+from django.test import TestCase, skipUnlessDBFeature\n+from .models import Article, Category, Writer\n+\n+\n+class ModelFormValidationTests(TestCase):\n+\n+    @skipUnlessDBFeature('supports_select_union')\n+    def test_model_multiple_choice_field_union_empty_submission(self):\n+        \"\"\"\n+        A ModelMultipleChoiceField using a union() queryset should not add all\n+        objects when the form is submitted with the field empty.\n+        \"\"\"\n+        writer = Writer.objects.create(name='Test Writer')\n+        c1 = Category.objects.create(name='cat1', slug='c1', url='u1')\n+        Category.objects.create(name='cat2', slug='c2', url='u2')\n+        c3 = Category.objects.create(name='cat3', slug='c3', url='u3')\n+\n+        class ArticleForm(forms.ModelForm):\n+            categories = forms.ModelMultipleChoiceField(\n+                Category.objects.filter(pk=c1.pk).union(Category.objects.filter(pk=c3.pk)),\n+                required=False,\n+            )\n+\n+            class Meta:\n+                model = Article\n+                fields = ['headline', 'slug', 'pub_date', 'writer', 'categories']\n+\n+        form_data = {\n+            'headline': 'Test',\n+            'slug': 'test',\n+            'pub_date': datetime.date(2023, 1, 1),\n+            'writer': writer.pk,\n+        }\n+        form = ArticleForm(form_data)\n+        self.assertTrue(form.is_valid())\n+        article_instance = form.save()\n+        self.assertEqual(article_instance.categories.count(), 0)\n"
    },
    "django__django-15467": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/modeladmin/test_radio_fields.py",
        "reproduced_bug_commands": [
            "cd tests && python runtests.py modeladmin.test_radio_fields"
        ],
        "reproduced_bug_patch": "diff --git a/tests/modeladmin/test_radio_fields.py b/tests/modeladmin/test_radio_fields.py\nnew file mode 100644\nindex 0000000000..d8bbe84c46\n--- /dev/null\n+++ b/tests/modeladmin/test_radio_fields.py\n@@ -0,0 +1,51 @@\n+from datetime import date\n+\n+from django.contrib.admin.options import ModelAdmin, VERTICAL\n+from django.contrib.admin.sites import AdminSite\n+from django.test import TestCase\n+\n+from .models import Band, Concert\n+\n+\n+class MockRequest:\n+    pass\n+\n+\n+class MockSuperUser:\n+    def has_perm(self, perm, obj=None):\n+        return True\n+\n+\n+request = MockRequest()\n+request.user = MockSuperUser()\n+\n+\n+class RadioFieldEmptyLabelTest(TestCase):\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.band = Band.objects.create(\n+            name=\"The Doors\",\n+            bio=\"\",\n+            sign_date=date(1965, 1, 1),\n+        )\n+\n+    def test_radio_fields_override_empty_label(self):\n+        \"\"\"\n+        A custom empty_label on a formfield is not overridden when the field\n+        is displayed as a radio button.\n+        \"\"\"\n+\n+        class ConcertAdmin(ModelAdmin):\n+            radio_fields = {\"opening_band\": VERTICAL}\n+\n+            def formfield_for_foreignkey(self, db_field, request, **kwargs):\n+                if db_field.name == \"opening_band\":\n+                    kwargs[\"empty_label\"] = \"I WANT TO SET MY OWN EMPTY LABEL\"\n+                return super().formfield_for_foreignkey(db_field, request, **kwargs)\n+\n+        ma = ConcertAdmin(Concert, AdminSite())\n+        form = ma.get_form(request)\n+        self.assertEqual(\n+            form.base_fields[\"opening_band\"].empty_label,\n+            \"I WANT TO SET MY OWN EMPTY LABEL\",\n+        )\n"
    },
    "matplotlib__matplotlib-26113": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_hexbin.py",
        "reproduced_bug_commands": [
            "python -m pytest lib/matplotlib/tests/test_hexbin.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_hexbin.py b/lib/matplotlib/tests/test_hexbin.py\nnew file mode 100644\nindex 0000000000..18e5f2b780\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_hexbin.py\n@@ -0,0 +1,42 @@\n+import numpy as np\n+import matplotlib.pyplot as plt\n+\n+\n+def test_hexbin_mincnt_with_C():\n+    \"\"\"\n+    Test that hexbin's mincnt parameter is consistent when C is provided.\n+\n+    When the C parameter is provided to hexbin, the filtering of bins\n+    by mincnt is inconsistent with the case where C is not provided.\n+    This test checks that the number of hexagons drawn is the same\n+    in both cases, as would be expected.\n+    \"\"\"\n+    # Setup from the bug report to reproduce the issue\n+    np.random.seed(42)\n+    x, y = np.random.multivariate_normal(\n+        [0.0, 0.0], [[1.0, 0.1], [0.1, 1.0]], size=250\n+    ).T\n+    z = np.ones_like(x)\n+    extent = [-3.0, 3.0, -3.0, 3.0]\n+    gridsize = (7, 7)\n+\n+    fig, ax = plt.subplots()\n+\n+    # Case 1: No C argument, mincnt=1. This is the correct behavior.\n+    coll_no_C = ax.hexbin(x, y, mincnt=1, extent=extent, gridsize=gridsize)\n+    ax.clear()\n+\n+    # Case 2: C argument supplied, mincnt=1. This is the buggy behavior.\n+    coll_with_C = ax.hexbin(\n+        x,\n+        y,\n+        C=z,\n+        reduce_C_function=np.sum,\n+        mincnt=1,\n+        extent=extent,\n+        gridsize=gridsize,\n+    )\n+\n+    # The number of hexagons drawn should be the same in both cases.\n+    # This fails because with C, mincnt is treated as a strict inequality.\n+    assert len(coll_no_C.get_array()) == len(coll_with_C.get_array())\n"
    },
    "sphinx-doc__sphinx-8551": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_domain_py_xref_ambiguous.py",
        "reproduced_bug_commands": [
            "pytest tests/test_domain_py_xref_ambiguous.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_domain_py_xref_ambiguous.py b/tests/test_domain_py_xref_ambiguous.py\nnew file mode 100644\nindex 000000000..af0bdb7d3\n--- /dev/null\n+++ b/tests/test_domain_py_xref_ambiguous.py\n@@ -0,0 +1,19 @@\n+import pytest\n+\n+@pytest.mark.sphinx('dummy', testroot='domain-py-xref-type-ambiguous')\n+def test_xref_in_type_fields_ambiguous(app, status, warning):\n+    \"\"\"\n+    Tests that :type: and :rtype: resolve cross-references in the correct\n+    namespace context, avoiding ambiguity warnings, as reported in issue #8498.\n+    \"\"\"\n+    app.build()\n+    warnings = warning.getvalue()\n+\n+    # The bug causes sphinx to find multiple targets for the unqualified\n+    # type 'A' in the 'mod.submod' context, where it should only find\n+    # 'mod.submod.A'. A correct implementation should not produce these\n+    # warnings.\n+    #\n+    # We check for the specific warning message to avoid failing on unrelated\n+    # warnings in the log, which was the issue with the previous test.\n+    assert \"WARNING: more than one target found for cross-reference 'A'\" not in warnings\n"
    },
    "sympy__sympy-20801": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/core/tests/test_float_false_comparison.py",
        "reproduced_bug_commands": [
            "bin/test sympy/core/tests/test_float_false_comparison.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/core/tests/test_float_false_comparison.py b/sympy/core/tests/test_float_false_comparison.py\nnew file mode 100644\nindex 0000000000..59333a5db8\n--- /dev/null\n+++ b/sympy/core/tests/test_float_false_comparison.py\n@@ -0,0 +1,14 @@\n+from sympy import S, false\n+\n+def test_float_zero_comparison_with_false():\n+    \"\"\"\n+    Tests for bug where S(0.0) == false returns True.\n+\n+    As reported in issue #20033, the comparison of a floating-point zero\n+    with `false` is not symmetric. `S(0.0) == false` incorrectly returns\n+    `True`, while the reverse comparison `false == S(0.0)` correctly\n+    returns `False`. This test ensures the incorrect case is fixed.\n+    \"\"\"\n+    # This assertion demonstrates the bug. It fails because `S(0.0) == false`\n+    # currently evaluates to `True`. It should evaluate to `False`.\n+    assert (S(0.0) == false) is False\n"
    },
    "django__django-11095": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/admin_inlines/test_get_inlines_hook.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py admin_inlines.test_get_inlines_hook"
        ],
        "reproduced_bug_patch": "diff --git a/tests/admin_inlines/test_get_inlines_hook.py b/tests/admin_inlines/test_get_inlines_hook.py\nnew file mode 100644\nindex 0000000000..b5552fcbf4\n--- /dev/null\n+++ b/tests/admin_inlines/test_get_inlines_hook.py\n@@ -0,0 +1,51 @@\n+from django.contrib import admin\n+from django.contrib.auth.models import User\n+from django.test import TestCase, override_settings\n+from django.urls import reverse\n+\n+from .admin import site as admin_site\n+from .models import Holder4, Inner4Stacked, Inner4Tabular\n+\n+\n+@override_settings(ROOT_URLCONF='admin_inlines.urls')\n+class GetInlinesHookTest(TestCase):\n+\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.superuser = User.objects.create_superuser('super', 'super@example.com', 'password')\n+\n+    def setUp(self):\n+        self.client.force_login(self.superuser)\n+\n+    def test_get_inlines_hook(self):\n+        \"\"\"\n+        ModelAdmin.get_inlines() can be used to dynamically specify inlines.\n+        \"\"\"\n+        class Inner4StackedInline(admin.StackedInline):\n+            model = Inner4Stacked\n+\n+        class Inner4TabularInline(admin.TabularInline):\n+            model = Inner4Tabular\n+\n+        class DynamicInlinesHolder4Admin(admin.ModelAdmin):\n+            inlines = [Inner4TabularInline]\n+\n+            def get_inlines(self, request, obj=None):\n+                if obj and obj.dummy > 10:\n+                    return [Inner4StackedInline]\n+                return self.inlines\n+\n+        original_admin = admin_site._registry[Holder4]\n+        admin_site.unregister(Holder4)\n+        admin_site.register(Holder4, DynamicInlinesHolder4Admin)\n+\n+        try:\n+            # When dummy > 10, the stacked inline should be used.\n+            holder = Holder4.objects.create(dummy=20)\n+            response = self.client.get(reverse('admin:admin_inlines_holder4_change', args=(holder.pk,)))\n+            self.assertContains(response, 'id=\"inner4stacked_set-group\"')\n+            self.assertNotContains(response, 'id=\"inner4tabular_set-group\"')\n+        finally:\n+            # Restore original ModelAdmin.\n+            admin_site.unregister(Holder4)\n+            admin_site.register(Holder4, original_admin)\n"
    },
    "django__django-13195": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/responses/test_delete_cookie.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py responses.test_delete_cookie"
        ],
        "reproduced_bug_patch": "diff --git a/tests/responses/test_delete_cookie.py b/tests/responses/test_delete_cookie.py\nnew file mode 100644\nindex 0000000000..08870365dc\n--- /dev/null\n+++ b/tests/responses/test_delete_cookie.py\n@@ -0,0 +1,43 @@\n+import time\n+from datetime import datetime, timedelta\n+from http import cookies\n+\n+from django.http import HttpResponse\n+from django.test import SimpleTestCase\n+from django.test.utils import freeze_time\n+from django.utils.http import http_date\n+from django.utils.timezone import utc\n+\n+\n+class DeleteCookieTests(SimpleTestCase):\n+\n+    def test_default(self):\n+        response = HttpResponse()\n+        response.delete_cookie('c')\n+        cookie = response.cookies['c']\n+        self.assertEqual(cookie['expires'], 'Thu, 01 Jan 1970 00:00:00 GMT')\n+        self.assertEqual(cookie['max-age'], 0)\n+        self.assertEqual(cookie['path'], '/')\n+        self.assertEqual(cookie['secure'], '')\n+        self.assertEqual(cookie['domain'], '')\n+\n+    def test_delete_cookie_secure_prefix(self):\n+        \"\"\"\n+        delete_cookie() sets the secure flag if the cookie name starts with\n+        __Host- or __Secure- (without that, browsers ignore cookies with those\n+        prefixes).\n+        \"\"\"\n+        response = HttpResponse()\n+        for prefix in ('Secure', 'Host'):\n+            with self.subTest(prefix=prefix):\n+                cookie_name = '__%s-c' % prefix\n+                response.delete_cookie(cookie_name)\n+                self.assertIs(response.cookies[cookie_name]['secure'], True)\n+\n+    def test_delete_cookie_samesite(self):\n+        \"\"\"\n+        delete_cookie() should accept a samesite argument.\n+        \"\"\"\n+        response = HttpResponse()\n+        response.delete_cookie('c', samesite='Lax')\n+        self.assertEqual(response.cookies['c']['samesite'], 'Lax')\n"
    },
    "django__django-15499": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/migrations/test_optimizer_create_alter_model_managers.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py migrations"
        ],
        "reproduced_bug_patch": "diff --git a/tests/migrations/test_optimizer_create_alter_model_managers.py b/tests/migrations/test_optimizer_create_alter_model_managers.py\nnew file mode 100644\nindex 0000000000..d034a506f4\n--- /dev/null\n+++ b/tests/migrations/test_optimizer_create_alter_model_managers.py\n@@ -0,0 +1,58 @@\n+from django.db import migrations, models\n+from django.db.migrations.optimizer import MigrationOptimizer\n+from django.db.migrations.serializer import serializer_factory\n+from django.test import SimpleTestCase\n+\n+from .models import EmptyManager, UnicodeModel\n+\n+\n+class OptimizerTests(SimpleTestCase):\n+    \"\"\"\n+    Tests the migration optimizer.\n+    \"\"\"\n+\n+    def optimize(self, operations, app_label):\n+        \"\"\"\n+        Handy shortcut for getting results + number of loops\n+        \"\"\"\n+        optimizer = MigrationOptimizer()\n+        return optimizer.optimize(operations, app_label), optimizer._iterations\n+\n+    def serialize(self, value):\n+        return serializer_factory(value).serialize()[0]\n+\n+    def assertOptimizesTo(\n+        self, operations, expected, exact=None, less_than=None, app_label=None\n+    ):\n+        result, iterations = self.optimize(operations, app_label or \"migrations\")\n+        result = [self.serialize(f) for f in result]\n+        expected = [self.serialize(f) for f in expected]\n+        self.assertEqual(expected, result)\n+        if exact is not None and iterations != exact:\n+            raise self.failureException(\n+                \"Optimization did not take exactly %s iterations (it took %s)\"\n+                % (exact, iterations)\n+            )\n+        if less_than is not None and iterations >= less_than:\n+            raise self.failureException(\n+                \"Optimization did not take less than %s iterations (it took %s)\"\n+                % (less_than, iterations)\n+            )\n+\n+    def test_create_alter_model_managers(self):\n+        \"\"\"\n+        CreateModel should absorb AlterModelManagers.\n+        \"\"\"\n+        managers = [\n+            (\"objects\", models.Manager()),\n+            (\"custom_manager\", EmptyManager()),\n+        ]\n+        self.assertOptimizesTo(\n+            [\n+                migrations.CreateModel(\"Foo\", fields=[]),\n+                migrations.AlterModelManagers(\"Foo\", managers),\n+            ],\n+            [\n+                migrations.CreateModel(\"Foo\", fields=[], managers=managers),\n+            ],\n+        )\n"
    },
    "matplotlib__matplotlib-26208": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_stackplot.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test\nt_stackplot.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_stackplot.py b/lib/matplotlib/tests/test_stackplot.py\nnew file mode 100644\nindex 0000000000..ce4ef7e2a8\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_stackplot.py\n@@ -0,0 +1,23 @@\n+import matplotlib.pyplot as plt\n+import numpy as np\n+import pytest\n+\n+\n+def test_twinx_stackplot_datalim():\n+    \"\"\"\n+    Test that dataLims of an Axes with a stackplot are not changed to inf\n+    when plotting on a twinned Axes.\n+    \"\"\"\n+    fig, ax1 = plt.subplots()\n+\n+    df1_index = ['16 May', '17 May']\n+    df1_values = [-22.717708333333402, 26.584999999999937]\n+    df2_values = [-0.08501399999999998, -2.9833019999999966]\n+\n+    ax1.stackplot(df1_index, df1_values)\n+\n+    ax2 = ax1.twinx()\n+    ax2.plot(df1_index, df2_values)\n+\n+    # ax1's dataLim should not be changed to inf.\n+    assert np.all(np.isfinite(ax1.dataLim.intervaly))\n"
    },
    "sphinx-doc__sphinx-8593": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_ext_autodoc_autodata_private.py",
        "reproduced_bug_commands": [
            "pytest tests/test_ext_autodoc_autodata_private.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_ext_autodoc_autodata_private.py b/tests/test_ext_autodoc_autodata_private.py\nnew file mode 100644\nindex 000000000..13fa18065\n--- /dev/null\n+++ b/tests/test_ext_autodoc_autodata_private.py\n@@ -0,0 +1,35 @@\n+import pytest\n+from .test_ext_autodoc import do_autodoc\n+\n+\n+@pytest.mark.sphinx('html', testroot='ext-autodoc')\n+def test_autodata_private_variable_with_meta_public(app):\n+    \"\"\"Tests that a private variable with ``:meta public:`` is documented.\n+\n+    This test reproduces a bug where ``:meta public:`` was not respected for\n+    module-level variables. It assumes a test module ``target.private_var``\n+    exists with the content:\n+\n+    .. code-block:: python\n+\n+        _foo = None  #: :meta public:\n+\n+    When the bug is fixed, autodoc should document ``_foo`` when documenting\n+    the module with the ``:members:`` option.\n+    \"\"\"\n+    options = {\n+        'members': '',\n+    }\n+    actual = do_autodoc(app, 'module', 'target.private_var', options)\n+    assert list(actual) == [\n+        '',\n+        '.. py:module:: target.private_var',\n+        '',\n+        '',\n+        '.. py:data:: _foo',\n+        '   :module: target.private_var',\n+        '   :value: None',\n+        '',\n+        '   :meta public:',\n+        '',\n+    ]\n"
    },
    "sympy__sympy-20916": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/printing/pretty/tests/test_pprint_bug.py",
        "reproduced_bug_commands": [
            "python -m pytest sympy/printing/pretty/tests/test_pprint_bug.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/printing/pretty/tests/test_pprint_bug.py b/sympy/printing/pretty/tests/test_pprint_bug.py\nnew file mode 100644\nindex 0000000000..c6087e6398\n--- /dev/null\n+++ b/sympy/printing/pretty/tests/test_pprint_bug.py\n@@ -0,0 +1,38 @@\n+# -*- coding: utf-8 -*-\n+from sympy import Symbol, Matrix, symbols\n+from sympy.printing.pretty import pprint\n+import io\n+import sys\n+\n+def test_pprint_w0_renders_as_w_subscript_0():\n+    \"\"\"\n+    Regression test for a bug where 'w0' is incorrectly rendered as 'ω0'.\n+\n+    This test directly calls `pprint` to capture its output, ensuring that\n+    the default settings (like line wrapping) which differ from other tests\n+    are used. The bug report indicates that in a matrix context, 'w0' can be\n+    incorrectly pretty-printed as the Greek letter omega 'ω' followed by a\n+    digit '0', instead of the correct Latin letter 'w' with a subscript '₀'.\n+\n+    This test will fail if the bug is present and pass once it is fixed.\n+    \"\"\"\n+    # Redirect stdout to capture the output of pprint\n+    original_stdout = sys.stdout\n+    captured_output = io.StringIO()\n+    sys.stdout = captured_output\n+\n+    try:\n+        # Construct the expression from the bug report\n+        t0, t1, t2, w0 = symbols('t0, t1, t2, w0')\n+        expr = Matrix([[-t0*w0, -t1*w0, -t2*w0]])\n+\n+        # Call pprint directly to ensure its default settings are used\n+        pprint(expr)\n+        output = captured_output.getvalue()\n+    finally:\n+        # Restore stdout\n+        sys.stdout = original_stdout\n+\n+    # The bug causes 'w0' to be rendered as 'ω0'. The correct output is 'w₀'.\n+    # This assertion checks for the presence of the correct string.\n+    assert 'w₀' in output\n"
    },
    "django__django-11099": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/auth_tests/test_username_validator_bug.py",
        "reproduced_bug_commands": [
            "python tests/runtests.py auth_tests.test_username_validator_bug"
        ],
        "reproduced_bug_patch": "diff --git a/tests/auth_tests/test_username_validator_bug.py b/tests/auth_tests/test_username_validator_bug.py\nnew file mode 100644\nindex 0000000000..e8edfde048\n--- /dev/null\n+++ b/tests/auth_tests/test_username_validator_bug.py\n@@ -0,0 +1,17 @@\n+import pytest\n+from django.contrib.auth import validators\n+from django.core.exceptions import ValidationError\n+from django.test import SimpleTestCase\n+\n+\n+class UsernameValidatorsTests(SimpleTestCase):\n+\n+    def test_username_validator_allows_trailing_newline(self):\n+        \"\"\"\n+        The ASCIIUsernameValidator and UnicodeUsernameValidator should not allow\n+        a trailing newline character in the username.\n+        \"\"\"\n+        for validator in (validators.ASCIIUsernameValidator(), validators.UnicodeUsernameValidator()):\n+            with self.subTest(validator=validator.__class__.__name__):\n+                with self.assertRaises(ValidationError):\n+                    validator(\"user\\n\")\n"
    },
    "django__django-13212": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/validation/test_email_validator.py",
        "reproduced_bug_commands": [
            "python -m django test validation.test_email_validator"
        ],
        "reproduced_bug_patch": "diff --git a/tests/validation/test_email_validator.py b/tests/validation/test_email_validator.py\nnew file mode 100644\nindex 0000000000..4ca41718a4\n--- /dev/null\n+++ b/tests/validation/test_email_validator.py\n@@ -0,0 +1,16 @@\n+from django.core.exceptions import ValidationError\n+from django.core.validators import EmailValidator\n+from django.test import SimpleTestCase\n+\n+\n+class ValidatorsTests(SimpleTestCase):\n+    def test_email_validator_value_in_error(self):\n+        \"\"\"\n+        ValidationError from EmailValidator includes the invalid value in\n+        its params.\n+        \"\"\"\n+        value = 'blah'\n+        message = '“%(value)s” is not a valid email.'\n+        validator = EmailValidator(message=message)\n+        with self.assertRaisesMessage(ValidationError, '“blah” is not a valid email.'):\n+            validator(value)\n"
    },
    "django__django-15503": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/model_fields/test_jsonfield_repro.py",
        "reproduced_bug_commands": [
            "python",
            "tests/runtests.py",
            "model_fields.test_jsonfield_repro"
        ],
        "reproduced_bug_patch": "diff --git a/tests/model_fields/test_jsonfield_repro.py b/tests/model_fields/test_jsonfield_repro.py\nnew file mode 100644\nindex 0000000000..c99d1a0894\n--- /dev/null\n+++ b/tests/model_fields/test_jsonfield_repro.py\n@@ -0,0 +1,589 @@\n+import operator\n+import uuid\n+from unittest import mock\n+\n+from django import forms\n+from django.core import serializers\n+from django.core.exceptions import ValidationError\n+from django.core.serializers.json import DjangoJSONEncoder\n+from django.db import (\n+    DataError,\n+    IntegrityError,\n+    NotSupportedError,\n+    OperationalError,\n+    connection,\n+    models,\n+)\n+from django.db.models import (\n+    Count,\n+    ExpressionWrapper,\n+    F,\n+    IntegerField,\n+    OuterRef,\n+    Q,\n+    Subquery,\n+    Transform,\n+    Value,\n+)\n+from django.db.models.expressions import RawSQL\n+from django.db.models.fields.json import (\n+    KeyTextTransform,\n+    KeyTransform,\n+    KeyTransformFactory,\n+    KeyTransformTextLookupMixin,\n+)\n+from django.db.models.functions import Cast\n+from django.test import SimpleTestCase, TestCase, skipIfDBFeature, skipUnlessDBFeature\n+from django.test.utils import CaptureQueriesContext\n+\n+from .models import CustomJSONDecoder, JSONModel, NullableJSONModel, RelatedJSONModel\n+\n+\n+@skipUnlessDBFeature(\"supports_json_field\")\n+class JSONFieldTests(TestCase):\n+    def test_invalid_value(self):\n+        msg = \"is not JSON serializable\"\n+        with self.assertRaisesMessage(TypeError, msg):\n+            NullableJSONModel.objects.create(\n+                value={\n+                    \"uuid\": uuid.UUID(\"d85e2076-b67c-4ee7-8c3a-2bf5a2cc2475\"),\n+                }\n+            )\n+\n+    def test_custom_encoder_decoder(self):\n+        value = {\"uuid\": uuid.UUID(\"{d85e2076-b67c-4ee7-8c3a-2bf5a2cc2475}\")}\n+        obj = NullableJSONModel(value_custom=value)\n+        obj.clean_fields()\n+        obj.save()\n+        obj.refresh_from_db()\n+        self.assertEqual(obj.value_custom, value)\n+\n+    def test_db_check_constraints(self):\n+        value = \"{@!invalid json value 123 $!@#\"\n+        with mock.patch.object(DjangoJSONEncoder, \"encode\", return_value=value):\n+            with self.assertRaises((IntegrityError, DataError, OperationalError)):\n+                NullableJSONModel.objects.create(value_custom=value)\n+\n+\n+class TestMethods(SimpleTestCase):\n+    def test_deconstruct(self):\n+        field = models.JSONField()\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(path, \"django.db.models.JSONField\")\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {})\n+\n+    def test_deconstruct_custom_encoder_decoder(self):\n+        field = models.JSONField(encoder=DjangoJSONEncoder, decoder=CustomJSONDecoder)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(kwargs[\"encoder\"], DjangoJSONEncoder)\n+        self.assertEqual(kwargs[\"decoder\"], CustomJSONDecoder)\n+\n+    def test_get_transforms(self):\n+        @models.JSONField.register_lookup\n+        class MyTransform(Transform):\n+            lookup_name = \"my_transform\"\n+\n+        field = models.JSONField()\n+        transform = field.get_transform(\"my_transform\")\n+        self.assertIs(transform, MyTransform)\n+        models.JSONField._unregister_lookup(MyTransform)\n+        models.JSONField._clear_cached_lookups()\n+        transform = field.get_transform(\"my_transform\")\n+        self.assertIsInstance(transform, KeyTransformFactory)\n+\n+    def test_key_transform_text_lookup_mixin_non_key_transform(self):\n+        transform = Transform(\"test\")\n+        msg = (\n+            \"Transform should be an instance of KeyTransform in order to use \"\n+            \"this lookup.\"\n+        )\n+        with self.assertRaisesMessage(TypeError, msg):\n+            KeyTransformTextLookupMixin(transform)\n+\n+\n+class TestValidation(SimpleTestCase):\n+    def test_invalid_encoder(self):\n+        msg = \"The encoder parameter must be a callable object.\"\n+        with self.assertRaisesMessage(ValueError, msg):\n+            models.JSONField(encoder=DjangoJSONEncoder())\n+\n+    def test_invalid_decoder(self):\n+        msg = \"The decoder parameter must be a callable object.\"\n+        with self.assertRaisesMessage(ValueError, msg):\n+            models.JSONField(decoder=CustomJSONDecoder())\n+\n+    def test_validation_error(self):\n+        field = models.JSONField()\n+        msg = \"Value must be valid JSON.\"\n+        value = uuid.UUID(\"{d85e2076-b67c-4ee7-8c3a-2bf5a2cc2475}\")\n+        with self.assertRaisesMessage(ValidationError, msg):\n+            field.clean({\"uuid\": value}, None)\n+\n+    def test_custom_encoder(self):\n+        field = models.JSONField(encoder=DjangoJSONEncoder)\n+        value = uuid.UUID(\"{d85e2076-b67c-4ee7-8c3a-2bf5a2cc2475}\")\n+        field.clean({\"uuid\": value}, None)\n+\n+\n+class TestFormField(SimpleTestCase):\n+    def test_formfield(self):\n+        model_field = models.JSONField()\n+        form_field = model_field.formfield()\n+        self.assertIsInstance(form_field, forms.JSONField)\n+\n+    def test_formfield_custom_encoder_decoder(self):\n+        model_field = models.JSONField(\n+            encoder=DjangoJSONEncoder, decoder=CustomJSONDecoder\n+        )\n+        form_field = model_field.formfield()\n+        self.assertIs(form_field.encoder, DjangoJSONEncoder)\n+        self.assertIs(form_field.decoder, CustomJSONDecoder)\n+\n+\n+class TestSerialization(SimpleTestCase):\n+    test_data = (\n+        '[{\"fields\": {\"value\": %s}, \"model\": \"model_fields.jsonmodel\", \"pk\": null}]'\n+    )\n+    test_values = (\n+        # (Python value, serialized value),\n+        ({\"a\": \"b\", \"c\": None}, '''{\"a\": \"b\", \"c\": null}'''),\n+        (\"abc\", '\"abc\"'),\n+        ('''{\"a\": \"a\"}''', '\"{\\\"a\\\": \\\"a\\\"}\"'),\n+    )\n+\n+    def test_dumping(self):\n+        for value, serialized in self.test_values:\n+            with self.subTest(value=value):\n+                instance = JSONModel(value=value)\n+                data = serializers.serialize(\"json\", [instance])\n+                self.assertJSONEqual(data, self.test_data % serialized)\n+\n+    def test_loading(self):\n+        for value, serialized in self.test_values:\n+            with self.subTest(value=value):\n+                instance = list(\n+                    serializers.deserialize(\"json\", self.test_data % serialized)\n+                )[0].object\n+                self.assertEqual(instance.value, value)\n+\n+    def test_xml_serialization(self):\n+        test_xml_data = (\n+            '''<django-objects version=\"1.0\">'''\n+            '''<object model=\"model_fields.nullablejsonmodel\">'''\n+            '''<field name=\"value\" type=\"JSONField\">%s'''\n+            '''</field></object></django-objects>'''\n+        )\n+        for value, serialized in self.test_values:\n+            with self.subTest(value=value):\n+                instance = NullableJSONModel(value=value)\n+                data = serializers.serialize(\"xml\", [instance], fields=[\"value\"])\n+                self.assertXMLEqual(data, test_xml_data % serialized)\n+                new_instance = list(serializers.deserialize(\"xml\", data))[0].object\n+                self.assertEqual(new_instance.value, instance.value)\n+\n+\n+@skipUnlessDBFeature(\"supports_json_field\")\n+class TestSaveLoad(TestCase):\n+    def test_null(self):\n+        obj = NullableJSONModel(value=None)\n+        obj.save()\n+        obj.refresh_from_db()\n+        self.assertIsNone(obj.value)\n+\n+    @skipUnlessDBFeature(\"supports_primitives_in_json_field\")\n+    def test_json_null_different_from_sql_null(self):\n+        json_null = NullableJSONModel.objects.create(value=Value(\"null\"))\n+        json_null.refresh_from_db()\n+        sql_null = NullableJSONModel.objects.create(value=None)\n+        sql_null.refresh_from_db()\n+        # '''null''' is not equal to NULL in the database.\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value=Value(\"null\")),\n+            [json_null],\n+        )\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value=None),\n+            [json_null],\n+        )\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__isnull=True),\n+            [sql_null],\n+        )\n+        # '''null''' is equal to NULL in Python (None).\n+        self.assertEqual(json_null.value, sql_null.value)\n+\n+    @skipUnlessDBFeature(\"supports_primitives_in_json_field\")\n+    def test_primitives(self):\n+        values = [\n+            True,\n+            1,\n+            1.45,\n+            \"String\",\n+            \"\",\n+        ]\n+        for value in values:\n+            with self.subTest(value=value):\n+                obj = JSONModel(value=value)\n+                obj.save()\n+                obj.refresh_from_db()\n+                self.assertEqual(obj.value, value)\n+\n+    def test_dict(self):\n+        values = [\n+            {},\n+            {\"name\": \"John\", \"age\": 20, \"height\": 180.3},\n+            {\"a\": True, \"b\": {\"b1\": False, \"b2\": None}},\n+        ]\n+        for value in values:\n+            with self.subTest(value=value):\n+                obj = JSONModel.objects.create(value=value)\n+                obj.refresh_from_db()\n+                self.assertEqual(obj.value, value)\n+\n+    def test_list(self):\n+        values = [\n+            [],\n+            [\"John\", 20, 180.3],\n+            [True, [False, None]],\n+        ]\n+        for value in values:\n+            with self.subTest(value=value):\n+                obj = JSONModel.objects.create(value=value)\n+                obj.refresh_from_db()\n+                self.assertEqual(obj.value, value)\n+\n+    def test_realistic_object(self):\n+        value = {\n+            \"name\": \"John\",\n+            \"age\": 20,\n+            \"pets\": [\n+                {\"name\": \"Kit\", \"type\": \"cat\", \"age\": 2},\n+                {\"name\": \"Max\", \"type\": \"dog\", \"age\": 1},\n+            ],\n+            \"courses\": [\n+                [\"A1\", \"A2\", \"A3\"],\n+                [\"B1\", \"B2\"],\n+                [\"C1\"],\n+            ],\n+        }\n+        obj = JSONModel.objects.create(value=value)\n+        obj.refresh_from_db()\n+        self.assertEqual(obj.value, value)\n+\n+\n+@skipUnlessDBFeature(\"supports_json_field\")\n+class TestQuerying(TestCase):\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.primitives = [True, False, \"yes\", 7, 9.6]\n+        values = [\n+            None,\n+            [],\n+            {},\n+            {\"a\": \"b\", \"c\": 14},\n+            {\n+                \"a\": \"b\",\n+                \"c\": 14,\n+                \"d\": [\"e\", {\"f\": \"g\"}],\n+                \"h\": True,\n+                \"i\": False,\n+                \"j\": None,\n+                \"k\": {\"l\": \"m\"},\n+                \"n\": [None, True, False],\n+                \"o\": '\"quoted\"',\n+                \"p\": 4.2,\n+                \"r\": {\"s\": True, \"t\": False},\n+            },\n+            [1, [2]],\n+            {\"k\": True, \"l\": False, \"foo\": \"bax\"},\n+            {\n+                \"foo\": \"bar\",\n+                \"baz\": {\"a\": \"b\", \"c\": \"d\"},\n+                \"bar\": [\"foo\", \"bar\"],\n+                \"bax\": {\"foo\": \"bar\"},\n+            },\n+        ]\n+        cls.objs = [NullableJSONModel.objects.create(value=value) for value in values]\n+        if connection.features.supports_primitives_in_json_field:\n+            cls.objs.extend(\n+                [\n+                    NullableJSONModel.objects.create(value=value)\n+                    for value in cls.primitives\n+                ]\n+            )\n+        cls.raw_sql = \"%s::jsonb\" if connection.vendor == \"postgresql\" else \"%s\"\n+\n+    def test_exact(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__exact={}),\n+            [self.objs[2]],\n+        )\n+\n+    def test_exact_complex(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__exact={\"a\": \"b\", \"c\": 14}),\n+            [self.objs[3]],\n+        )\n+\n+    def test_icontains(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__icontains=\"BaX\"),\n+            self.objs[6:8],\n+        )\n+\n+    def test_isnull(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__isnull=True),\n+            [self.objs[0]],\n+        )\n+\n+    def test_ordering_by_transform(self):\n+        mariadb = connection.vendor == \"mysql\" and connection.mysql_is_mariadb\n+        values = [\n+            {\"ord\": 93, \"name\": \"bar\"},\n+            {\"ord\": 22.1, \"name\": \"foo\"},\n+            {\"ord\": -1, \"name\": \"baz\"},\n+            {\"ord\": 21.931902, \"name\": \"spam\"},\n+            {\"ord\": -100291029, \"name\": \"eggs\"},\n+        ]\n+        for field_name in [\"value\", \"value_custom\"]:\n+            with self.subTest(field=field_name):\n+                objs = [\n+                    NullableJSONModel.objects.create(**{field_name: value})\n+                    for value in values\n+                ]\n+                query = NullableJSONModel.objects.filter(\n+                    **{\"%s__name__isnull\" % field_name: False},\n+                ).order_by(\"%s__ord\" % field_name)\n+                expected = [objs[4], objs[2], objs[3], objs[1], objs[0]]\n+                if mariadb or connection.vendor == \"oracle\":\n+                    # MariaDB and Oracle return JSON values as strings.\n+                    expected = [objs[2], objs[4], objs[3], objs[1], objs[0]]\n+                self.assertSequenceEqual(query, expected)\n+\n+    def test_ordering_grouping_by_key_transform(self):\n+        base_qs = NullableJSONModel.objects.filter(value__d__0__isnull=False)\n+        for qs in (\n+            base_qs.order_by(\"value__d__0\"),\n+            base_qs.annotate(\n+                key=KeyTransform(\"0\", KeyTransform(\"d\", \"value\"))\n+            ).order_by(\"key\"),\n+        ):\n+            self.assertSequenceEqual(qs, [self.objs[4]])\n+        qs = NullableJSONModel.objects.filter(value__isnull=False)\n+        self.assertQuerysetEqual(\n+            qs.filter(value__isnull=False)\n+            .annotate(\n+                key=KeyTextTransform(\n+                    \"f\", KeyTransform(\"1\", KeyTransform(\"d\", \"value\"))\n+                ),\n+            )\n+            .values(\"key\")\n+            .annotate(count=Count(\"key\"))\n+            .order_by(\"count\"),\n+            [(None, 0), (\"g\", 1)],\n+            operator.itemgetter(\"key\", \"count\"),\n+        )\n+\n+    def test_ordering_grouping_by_count(self):\n+        qs = (\n+            NullableJSONModel.objects.filter(\n+                value__isnull=False,\n+            )\n+            .values(\"value__d__0\")\n+            .annotate(count=Count(\"value__d__0\"))\n+            .order_by(\"count\")\n+        )\n+        self.assertQuerysetEqual(qs, [0, 1], operator.itemgetter(\"count\"))\n+\n+    def test_order_grouping_custom_decoder(self):\n+        NullableJSONModel.objects.create(value_custom={\"a\": \"b\"})\n+        qs = NullableJSONModel.objects.filter(value_custom__isnull=False)\n+        self.assertSequenceEqual(\n+            qs.values(\n+                \"value_custom__a\",\n+            )\n+            .annotate(\n+                count=Count(\"id\"),\n+            )\n+            .order_by(\"value_custom__a\"),\n+            [{\"value_custom__a\": \"b\", \"count\": 1}],\n+        )\n+\n+    def test_key_transform_raw_expression(self):\n+        expr = RawSQL(self.raw_sql, ['''{\"x\": \"bar\"}'''])\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__foo=KeyTransform(\"x\", expr)),\n+            [self.objs[7]],\n+        )\n+\n+    def test_nested_key_transform_raw_expression(self):\n+        expr = RawSQL(self.raw_sql, ['''{\"x\": {\"y\": \"bar\"}}'''])\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(\n+                value__foo=KeyTransform(\"y\", KeyTransform(\"x\", expr))\n+            ),\n+            [self.objs[7]],\n+        )\n+\n+    def test_key_transform_expression(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__d__0__isnull=False)\n+            .annotate(\n+                key=KeyTransform(\"d\", \"value\"),\n+                chain=KeyTransform(\"0\", \"key\"),\n+                expr=KeyTransform(\"0\", Cast(\"key\", models.JSONField())),\n+            )\n+            .filter(chain=F(\"expr\")),\n+            [self.objs[4]],\n+        )\n+\n+    def test_key_transform_annotation_expression(self):\n+        obj = NullableJSONModel.objects.create(value={\"d\": [\"e\", \"e\"]})\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__d__0__isnull=False)\n+            .annotate(\n+                key=F(\"value__d\"),\n+                chain=F(\"key__0\"),\n+                expr=Cast(\"key\", models.JSONField()),\n+            )\n+            .filter(chain=F(\"expr__1\")),\n+            [obj],\n+        )\n+\n+    def test_nested_key_transform_expression(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__d__0__isnull=False)\n+            .annotate(\n+                key=KeyTransform(\"d\", \"value\"),\n+                chain=KeyTransform(\"f\", KeyTransform(\"1\", \"key\")),\n+                expr=KeyTransform(\n+                    \"f\", KeyTransform(\"1\", Cast(\"key\", models.JSONField()))\n+                ),\n+            )\n+            .filter(chain=F(\"expr\")),\n+            [self.objs[4]],\n+        )\n+\n+    def test_nested_key_transform_annotation_expression(self):\n+        obj = NullableJSONModel.objects.create(\n+            value={\"d\": [\"e\", {\"f\": \"g\"}, {\"f\": \"g\"}]},\n+        )\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__d__0__isnull=False)\n+            .annotate(\n+                key=F(\"value__d\"),\n+                chain=F(\"key__1__f\"),\n+                expr=Cast(\"key\", models.JSONField()),\n+            )\n+            .filter(chain=F(\"expr__2__f\")),\n+            [obj],\n+        )\n+\n+    def test_nested_key_transform_on_subquery(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__d__0__isnull=False)\n+            .annotate(\n+                subquery_value=Subquery(\n+                    NullableJSONModel.objects.filter(pk=OuterRef(\"pk\")).values(\"value\")\n+                ),\n+                key=KeyTransform(\"d\", \"subquery_value\"),\n+                chain=KeyTransform(\"f\", KeyTransform(\"1\", \"key\")),\n+            )\n+            .filter(chain=\"g\"),\n+            [self.objs[4]],\n+        )\n+\n+    def test_expression_wrapper_key_transform(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.annotate(\n+                wrapped=ExpressionWrapper(\n+                    Value({\"wrapper\": \"content\"}), output_field=models.JSONField()\n+                ),\n+            )\n+            .filter(wrapped__wrapper=\"content\")\n+            .order_by(\"pk\"),\n+            self.objs,\n+        )\n+\n+    def test_has_key(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__has_key=\"a\"),\n+            [self.objs[3], self.objs[4]],\n+        )\n+\n+    def test_has_key_deep(self):\n+        tests = [\n+            (Q(value__baz__has_key=\"a\"), self.objs[7]),\n+            (\n+                Q(value__has_key=KeyTransform(\"a\", KeyTransform(\"baz\", \"value\"))),\n+                self.objs[7],\n+            ),\n+            (Q(value__has_key=F(\"value__baz__a\")), self.objs[7]),\n+            (\n+                Q(value__has_key=KeyTransform(\"c\", KeyTransform(\"baz\", \"value\"))),\n+                self.objs[7],\n+            ),\n+            (Q(value__has_key=F(\"value__baz__c\")), self.objs[7]),\n+            (Q(value__d__1__has_key=\"f\"), self.objs[4]),\n+            (\n+                Q(\n+                    value__has_key=KeyTransform(\n+                        \"f\", KeyTransform(\"1\", KeyTransform(\"d\", \"value\"))\n+                    )\n+                ),\n+                self.objs[4],\n+            ),\n+            (Q(value__has_key=F(\"value__d__1__f\")), self.objs[4]),\n+        ]\n+        for condition, expected in tests:\n+            with self.subTest(condition=condition):\n+                self.assertSequenceEqual(\n+                    NullableJSONModel.objects.filter(condition),\n+                    [expected],\n+                )\n+\n+    def test_has_key_list(self):\n+        obj = NullableJSONModel.objects.create(value=[{\"a\": 1}, {\"b\": \"x\"}])\n+        tests = [\n+            Q(value__1__has_key=\"b\"),\n+            Q(value__has_key=KeyTransform(\"b\", KeyTransform(1, \"value\"))),\n+            Q(value__has_key=KeyTransform(\"b\", KeyTransform(\"1\", \"value\"))),\n+            Q(value__has_key=F(\"value__1__b\")),\n+        ]\n+        for condition in tests:\n+            with self.subTest(condition=condition):\n+                self.assertSequenceEqual(\n+                    NullableJSONModel.objects.filter(condition),\n+                    [obj],\n+                )\n+\n+    def test_has_key_numeric_lookup(self):\n+        \"\"\"\n+        Test has_key, has_keys, and has_any_keys lookups with numeric keys.\n+        \"\"\"\n+        obj = NullableJSONModel.objects.create(value={\"1111\": \"bar\"})\n+        queries = [\n+            Q(value__has_key=\"1111\"),\n+            Q(value__has_keys=[\"1111\"]),\n+            Q(value__has_any_keys=[\"1111\", \"2222\"]),\n+        ]\n+        for query in queries:\n+            with self.subTest(query=query):\n+                self.assertSequenceEqual(\n+                    NullableJSONModel.objects.filter(query),\n+                    [obj],\n+                )\n+\n+    def test_has_keys(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__has_keys=[\"a\", \"c\", \"h\"]),\n+            [self.objs[4]],\n+        )\n+\n+    def test_has_any_keys(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__has_any_keys=[\"c\", \"l\"]),\n+            [self.objs[3], self.objs[4], self.objs[6]],\n+        )\n"
    },
    "matplotlib__matplotlib-26291": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/mpl_toolkits/axes_grid1/tests/test_inset_locator.py",
        "reproduced_bug_commands": [
            "pytest lib/mpl_toolkits/axes_grid1/tests/test_inset_locator.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/mpl_toolkits/axes_grid1/tests/test_inset_locator.py b/lib/mpl_toolkits/axes_grid1/tests/test_inset_locator.py\nnew file mode 100644\nindex 0000000000..71535615d7\n--- /dev/null\n+++ b/lib/mpl_toolkits/axes_grid1/tests/test_inset_locator.py\n@@ -0,0 +1,23 @@\n+import io\n+import matplotlib.pyplot as plt\n+from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n+\n+\n+def test_inset_axes_savefig_tight_bbox_error():\n+    \"\"\"\n+    Test for AttributeError with inset_axes when saving with tight bbox.\n+\n+    This test reproduces the bug where saving a figure with an inset axes\n+    and `bbox_inches='tight'` raises an `AttributeError`. The error is\n+    triggered during the tight bounding box calculation because the inset\n+    axes locator is not properly associated with a figure, leading to\n+    `self.figure` being `None`.\n+    \"\"\"\n+    fig, (ax, ax2) = plt.subplots(1, 2, figsize=[5.5, 2.8])\n+    inset_axes(ax, width=1.3, height=0.9)\n+\n+    # The bug is triggered by saving with bbox_inches='tight', which fails\n+    # with an AttributeError: 'NoneType' object has no attribute '_get_renderer'.\n+    # This test will fail before the fix and pass after. No explicit assert\n+    # is needed as the test will fail if any exception is raised.\n+    fig.savefig(io.BytesIO(), bbox_inches='tight')\n"
    },
    "sphinx-doc__sphinx-8595": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/test_ext_autodoc_empty_all.py",
        "reproduced_bug_commands": [
            "python -X dev -m pytest --durations 25 tests/test_ext_autodoc_empty_all.py"
        ],
        "reproduced_bug_patch": "diff --git a/tests/test_ext_autodoc_empty_all.py b/tests/test_ext_autodoc_empty_all.py\nnew file mode 100644\nindex 000000000..7ea8ce444\n--- /dev/null\n+++ b/tests/test_ext_autodoc_empty_all.py\n@@ -0,0 +1,52 @@\n+import sys\n+from unittest.mock import Mock\n+\n+import pytest\n+\n+from sphinx.ext.autodoc.directive import DocumenterBridge, process_documenter_options\n+from sphinx.util.docutils import LoggingReporter\n+\n+\n+def do_autodoc(app, objtype, name, options=None):\n+    if options is None:\n+        options = {}\n+    app.env.temp_data.setdefault('docname', 'index')  # set dummy docname\n+    doccls = app.registry.documenters[objtype]\n+    docoptions = process_documenter_options(doccls, app.config, options)\n+    state = Mock()\n+    state.document.settings.tab_width = 8\n+    bridge = DocumenterBridge(app.env, LoggingReporter(''), docoptions, 1, state)\n+    documenter = doccls(bridge, name)\n+    documenter.generate()\n+\n+    return bridge.result\n+\n+\n+@pytest.mark.sphinx('html', testroot='ext-autodoc')\n+def test_autodoc_empty_all_ignored(app):\n+    \"\"\"\n+    Tests that autodoc respects an empty __all__ attribute on a module.\n+\n+    This test monkey-patches the `target` module's `__all__` attribute to be an\n+    empty list. With the bug, autodoc ignores the empty `__all__` and documents\n+    members. A fixed version should respect the empty `__all__` and document\n+    no members.\n+    \"\"\"\n+    # The 'target' module is part of the testroot and is importable.\n+    import target\n+    original_all = getattr(target, '__all__', None)\n+    target.__all__ = []\n+    try:\n+        options = {'members': None}\n+        actual = do_autodoc(app, 'module', 'target', options)\n+\n+        # The bug causes members to be documented. The fix is that no members\n+        # are documented. This assertion will fail if any class members are\n+        # found in the output, and pass otherwise.\n+        assert not [line for line in actual if '.. py:class::' in line]\n+    finally:\n+        # Restore the original __all__ to avoid side-effects.\n+        if original_all is not None:\n+            target.__all__ = original_all\n+        else:\n+            del target.__all__\n"
    },
    "sympy__sympy-21379": {
        "reproduced_bug": true,
        "reproduced_bug_file": "sympy/core/tests/test_subs_issues.py",
        "reproduced_bug_commands": [
            "pytest sympy/core/tests/test_subs_issues.py"
        ],
        "reproduced_bug_patch": "diff --git a/sympy/core/tests/test_subs_issues.py b/sympy/core/tests/test_subs_issues.py\nnew file mode 100644\nindex 0000000000..7b764c12ec\n--- /dev/null\n+++ b/sympy/core/tests/test_subs_issues.py\n@@ -0,0 +1,23 @@\n+from sympy.polys.polyerrors import PolynomialError\n+from sympy import symbols, exp, sinh, Piecewise\n+from sympy.core.cache import clear_cache\n+\n+\n+def test_issue_21121_subs_on_piecewise_with_real_symbols():\n+    \"\"\"\n+    Test for unexpected PolynomialError from subs() for specific expressions.\n+\n+    This test reproduces the bug from issue #21121, where subs() fails on a\n+    particular expression involving sinh and a Piecewise function with real\n+    symbols. The correct behavior is for the substitution to complete without\n+    raising an error.\n+\n+    This test will fail with a PolynomialError if the bug is present and\n+    will pass once the bug has been fixed.\n+    \"\"\"\n+    clear_cache()\n+    x, y, z = symbols('x y z', real=True)\n+    expr = exp(sinh(Piecewise((x, y > x), (y, True)) / z))\n+    # This was raising \"PolynomialError: Piecewise generators do not make sense\"\n+    # The substitution should not raise an error.\n+    assert expr.subs({1: 1.0}) == expr\n"
    },
    "django__django-11119": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/template_tests/test_render_to_string_autoescape.py",
        "reproduced_bug_commands": [
            "./runtests.py tests.template_tests.test_render_to_string_autoescape"
        ],
        "reproduced_bug_patch": "diff --git a/tests/template_tests/test_render_to_string_autoescape.py b/tests/template_tests/test_render_to_string_autoescape.py\nnew file mode 100644\nindex 0000000000..490e205e70\n--- /dev/null\n+++ b/tests/template_tests/test_render_to_string_autoescape.py\n@@ -0,0 +1,15 @@\n+from django.template.engine import Engine\n+from django.test import SimpleTestCase\n+\n+\n+class EngineRenderToStringAutoescapeTests(SimpleTestCase):\n+\n+    def test_render_to_string_honors_autoescape_off(self):\n+        \"\"\"\n+        Engine.render_to_string() should honor autoescape=False.\n+        \"\"\"\n+        templates = {'test.html': 'Hello, {{ name }}'}\n+        loaders = [['django.template.loaders.locmem.Loader', templates]]\n+        engine = Engine(loaders=loaders, autoescape=False)\n+        rendered = engine.render_to_string('test.html', {'name': 'Bob & Jim'})\n+        self.assertEqual(rendered, 'Hello, Bob & Jim')\n"
    },
    "django__django-13279": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/sessions_tests/test_legacy_session_encoding.py",
        "reproduced_bug_commands": [
            "python manage.py test tests.sessions_tests.test_legacy_session_encoding"
        ],
        "reproduced_bug_patch": "diff --git a/tests/sessions_tests/test_legacy_session_encoding.py b/tests/sessions_tests/test_legacy_session_encoding.py\nnew file mode 100644\nindex 0000000000..a745fa2ad7\n--- /dev/null\n+++ b/tests/sessions_tests/test_legacy_session_encoding.py\n@@ -0,0 +1,43 @@\n+from django.contrib.sessions.backends.db import SessionStore as DatabaseSession\n+from django.test import TestCase, ignore_warnings, override_settings\n+from django.utils.deprecation import RemovedInDjango40Warning\n+\n+\n+class SessionTestsMixin:\n+    # This does not inherit from TestCase to avoid any tests being run with this\n+    # class, which wouldn't work, and to allow different TestCase subclasses to\n+    # be used.\n+\n+    backend = None  # subclasses must specify\n+\n+    def setUp(self):\n+        self.session = self.backend()\n+\n+    def tearDown(self):\n+        # NB: be careful to delete any sessions created; stale sessions fill up\n+        # the /tmp (with some backends) and eventually overwhelm it after lots\n+        # of runs (think buildbots)\n+        self.session.delete()\n+\n+    @ignore_warnings(category=RemovedInDjango40Warning)\n+    @override_settings(\n+        DEFAULT_HASHING_ALGORITHM='sha1',\n+        SECRET_KEY='django_tests_secret_key',\n+    )\n+    def test_legacy_encode_sha1(self):\n+        \"\"\"\n+        With DEFAULT_HASHING_ALGORITHM='sha1', encode() uses the legacy\n+        format.\n+        \"\"\"\n+        # This is the pre-Django 3.1 encoded format.\n+        legacy_encoded = (\n+            'OWUzNTNmNWQxNTBjOWExZmM4MmQ3NzNhMDRmMjU4NmYwNDUyNGI2NDp7ImEgdGVzd'\n+            'CBrZXkiOiJhIHRlc3QgdmFsdWUifQ=='\n+        )\n+        data = {'a test key': 'a test value'}\n+        encoded = self.session.encode(data)\n+        self.assertEqual(encoded, legacy_encoded)\n+\n+\n+class DatabaseSessionTests(SessionTestsMixin, TestCase):\n+    backend = DatabaseSession\n"
    },
    "django__django-15525": {
        "reproduced_bug": true,
        "reproduced_bug_file": "tests/multiple_database/test_loaddata_natural_key.py",
        "reproduced_bug_commands": [
            "python runtests.py multiple_database.test_loaddata_natural_key"
        ],
        "reproduced_bug_patch": "diff --git a/tests/multiple_database/test_loaddata_natural_key.py b/tests/multiple_database/test_loaddata_natural_key.py\nnew file mode 100644\nindex 0000000000..148ec7ece1\n--- /dev/null\n+++ b/tests/multiple_database/test_loaddata_natural_key.py\n@@ -0,0 +1,101 @@\n+import os\n+import tempfile\n+\n+from django.core import management\n+from django.db import models\n+from django.test import TestCase, override_settings\n+\n+\n+# Define models with unique names to avoid conflicts with existing test models.\n+# These models replicate the structure described in the bug report.\n+class NKAuthorManager(models.Manager):\n+    def get_by_natural_key(self, name):\n+        return self.get(name=name)\n+\n+\n+class NKAuthor(models.Model):\n+    name = models.CharField(max_length=255, unique=True)\n+    objects = NKAuthorManager()\n+\n+    class Meta:\n+        app_label = \"multiple_database\"\n+\n+    def natural_key(self):\n+        return (self.name,)\n+\n+\n+class NKBookManager(models.Manager):\n+    def get_by_natural_key(self, title, author_name):\n+        return self.get(title=title, author__name=author_name)\n+\n+\n+class NKBook(models.Model):\n+    title = models.CharField(max_length=255)\n+    author = models.ForeignKey(NKAuthor, models.DO_NOTHING)\n+    objects = NKBookManager()\n+\n+    class Meta:\n+        app_label = \"multiple_database\"\n+        unique_together = ((\"title\", \"author\"),)\n+\n+    def natural_key(self):\n+        return (self.title,) + self.author.natural_key()\n+\n+    natural_key.dependencies = [\"multiple_database.NKAuthor\"]\n+\n+\n+@override_settings(\n+    INSTALLED_APPS=[\n+        \"django.contrib.auth\",\n+        \"django.contrib.contenttypes\",\n+        \"multiple_database\",\n+    ]\n+)\n+class LoaddataNaturalKeyMultiDBTests(TestCase):\n+    databases = {\"default\", \"other\"}\n+    available_apps = [\"multiple_database\"]\n+\n+    def test_loaddata_natural_key_foreign_key_other_db(self):\n+        \"\"\"\n+        Test that loaddata works with natural keys and foreign keys on a\n+        non-default database.\n+        \"\"\"\n+        # Fixture data using natural keys, with model names updated to match\n+        # the uniquely named models defined for this test.\n+        fixture_content = \"\"\"\n+[\n+    {\n+        \"model\": \"multiple_database.nkauthor\",\n+        \"fields\": {\n+            \"name\": \"JR Tolkien\"\n+        }\n+    },\n+    {\n+        \"model\": \"multiple_database.nkbook\",\n+        \"fields\": {\n+            \"title\": \"The Ring\",\n+            \"author\": [\"JR Tolkien\"]\n+        }\n+    }\n+]\n+\"\"\"\n+        with tempfile.TemporaryDirectory() as tempdir:\n+            fixture_path = os.path.join(tempdir, \"books.json\")\n+            with open(fixture_path, \"w\") as f:\n+                f.write(fixture_content)\n+\n+            with override_settings(FIXTURE_DIRS=[tempdir]):\n+                # This command will raise NKAuthor.DoesNotExist before the fix,\n+                # because the FK lookup for the author's natural key will\n+                # incorrectly query the 'default' database instead of 'other'.\n+                management.call_command(\n+                    \"loaddata\",\n+                    \"books.json\",\n+                    database=\"other\",\n+                    verbosity=0,\n+                )\n+\n+        # This assertion will only be reached after the bug is fixed. It\n+        # confirms that the book was loaded correctly into the 'other' db.\n+        book = NKBook.objects.using(\"other\").get(title=\"The Ring\")\n+        self.assertEqual(book.author.name, \"JR Tolkien\")\n"
    },
    "matplotlib__matplotlib-26342": {
        "reproduced_bug": true,
        "reproduced_bug_file": "lib/matplotlib/tests/test_contour_set.py",
        "reproduced_bug_commands": [
            "pytest lib/matplotlib/tests/test_contour_set.py"
        ],
        "reproduced_bug_patch": "diff --git a/lib/matplotlib/tests/test_contour_set.py b/lib/matplotlib/tests/test_contour_set.py\nnew file mode 100644\nindex 0000000000..000fd94198\n--- /dev/null\n+++ b/lib/matplotlib/tests/test_contour_set.py\n@@ -0,0 +1,15 @@\n+import numpy as np\n+import pytest\n+from matplotlib import pyplot as plt\n+from matplotlib.path import Path\n+\n+\n+def test_set_paths():\n+    \"\"\"Test ContourSet.set_paths().\"\"\"\n+    fig, ax = plt.subplots()\n+    cs = ax.contour([[0, 1], [2, 3]])\n+\n+    new_paths = [Path(np.array([[0., 0.], [1., 1.]]))]\n+    cs.set_paths(new_paths)\n+\n+    assert cs.get_paths() == new_paths\n"
    },
    "sphinx-doc__sphinx-8621": {
        "reproduced_bug": false,
        "reproduced_bug_file": "None",
        "reproduced_bug_commands": null,
        "reproduced_bug_patch": null
    }
}