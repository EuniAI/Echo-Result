{"instance_id": "django__django-11885", "repo": "django/django", "version": "3.1", "environment_setup_commit": "0668164b4ac93a5be79f5b87fae83c657124d9ab", "patch_list": ["diff --git a/tests/delete/test_on_delete.py b/tests/delete/test_on_delete.py\nnew file mode 100644\nindex 0000000000..60a865e9c8\n--- /dev/null\n+++ b/tests/delete/test_on_delete.py\n@@ -0,0 +1,539 @@\n+import math\n+from math import ceil\n+\n+from django.db import IntegrityError, connection, models\n+from django.db.models.deletion import Collector\n+from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE\n+from django.test import TestCase, skipIfDBFeature, skipUnlessDBFeature\n+\n+from .models import (\n+    MR, A, Avatar, Base, Child, HiddenUser, HiddenUserProfile, M, M2MFrom,\n+    M2MTo, MRNull, Origin, Parent, R, RChild, RChildChild, Referrer, S, T,\n+    User, create_a, get_default_r, SecondReferrer,\n+)\n+\n+\n+class OnDeleteTests(TestCase):\n+    def setUp(self):\n+        self.DEFAULT = get_default_r()\n+\n+    def test_auto(self):\n+        a = create_a('auto')\n+        a.auto.delete()\n+        self.assertFalse(A.objects.filter(name='auto').exists())\n+\n+    def test_non_callable(self):\n+        msg = 'on_delete must be callable.'\n+        with self.assertRaisesMessage(TypeError, msg):\n+            models.ForeignKey('self', on_delete=None)\n+        with self.assertRaisesMessage(TypeError, msg):\n+            models.OneToOneField('self', on_delete=None)\n+\n+    def test_auto_nullable(self):\n+        a = create_a('auto_nullable')\n+        a.auto_nullable.delete()\n+        self.assertFalse(A.objects.filter(name='auto_nullable').exists())\n+\n+    def test_setvalue(self):\n+        a = create_a('setvalue')\n+        a.setvalue.delete()\n+        a = A.objects.get(pk=a.pk)\n+        self.assertEqual(self.DEFAULT, a.setvalue.pk)\n+\n+    def test_setnull(self):\n+        a = create_a('setnull')\n+        a.setnull.delete()\n+        a = A.objects.get(pk=a.pk)\n+        self.assertIsNone(a.setnull)\n+\n+    def test_setdefault(self):\n+        a = create_a('setdefault')\n+        a.setdefault.delete()\n+        a = A.objects.get(pk=a.pk)\n+        self.assertEqual(self.DEFAULT, a.setdefault.pk)\n+\n+    def test_setdefault_none(self):\n+        a = create_a('setdefault_none')\n+        a.setdefault_none.delete()\n+        a = A.objects.get(pk=a.pk)\n+        self.assertIsNone(a.setdefault_none)\n+\n+    def test_cascade(self):\n+        a = create_a('cascade')\n+        a.cascade.delete()\n+        self.assertFalse(A.objects.filter(name='cascade').exists())\n+\n+    def test_cascade_nullable(self):\n+        a = create_a('cascade_nullable')\n+        a.cascade_nullable.delete()\n+        self.assertFalse(A.objects.filter(name='cascade_nullable').exists())\n+\n+    def test_protect(self):\n+        a = create_a('protect')\n+        msg = (\n+            \"Cannot delete some instances of model 'R' because they are \"\n+            \"referenced through a protected foreign key: 'A.protect'\"\n+        )\n+        with self.assertRaisesMessage(IntegrityError, msg):\n+            a.protect.delete()\n+\n+    def test_do_nothing(self):\n+        # Testing DO_NOTHING is a bit harder: It would raise IntegrityError for a normal model,\n+        # so we connect to pre_delete and set the fk to a known value.\n+        replacement_r = R.objects.create()\n+\n+        def check_do_nothing(sender, **kwargs):\n+            obj = kwargs['instance']\n+            obj.donothing_set.update(donothing=replacement_r)\n+        models.signals.pre_delete.connect(check_do_nothing)\n+        a = create_a('do_nothing')\n+        a.donothing.delete()\n+        a = A.objects.get(pk=a.pk)\n+        self.assertEqual(replacement_r, a.donothing)\n+        models.signals.pre_delete.disconnect(check_do_nothing)\n+\n+    def test_do_nothing_qscount(self):\n+        \"\"\"\n+        A models.DO_NOTHING relation doesn't trigger a query.\n+        \"\"\"\n+        b = Base.objects.create()\n+        with self.assertNumQueries(1):\n+            # RelToBase should not be queried.\n+            b.delete()\n+        self.assertEqual(Base.objects.count(), 0)\n+\n+    def test_inheritance_cascade_up(self):\n+        child = RChild.objects.create()\n+        child.delete()\n+        self.assertFalse(R.objects.filter(pk=child.pk).exists())\n+\n+    def test_inheritance_cascade_down(self):\n+        child = RChild.objects.create()\n+        parent = child.r_ptr\n+        parent.delete()\n+        self.assertFalse(RChild.objects.filter(pk=child.pk).exists())\n+\n+    def test_cascade_from_child(self):\n+        a = create_a('child')\n+        a.child.delete()\n+        self.assertFalse(A.objects.filter(name='child').exists())\n+        self.assertFalse(R.objects.filter(pk=a.child_id).exists())\n+\n+    def test_cascade_from_parent(self):\n+        a = create_a('child')\n+        R.objects.get(pk=a.child_id).delete()\n+        self.assertFalse(A.objects.filter(name='child').exists())\n+        self.assertFalse(RChild.objects.filter(pk=a.child_id).exists())\n+\n+    def test_setnull_from_child(self):\n+        a = create_a('child_setnull')\n+        a.child_setnull.delete()\n+        self.assertFalse(R.objects.filter(pk=a.child_setnull_id).exists())\n+\n+        a = A.objects.get(pk=a.pk)\n+        self.assertIsNone(a.child_setnull)\n+\n+    def test_setnull_from_parent(self):\n+        a = create_a('child_setnull')\n+        R.objects.get(pk=a.child_setnull_id).delete()\n+        self.assertFalse(RChild.objects.filter(pk=a.child_setnull_id).exists())\n+\n+        a = A.objects.get(pk=a.pk)\n+        self.assertIsNone(a.child_setnull)\n+\n+    def test_o2o_setnull(self):\n+        a = create_a('o2o_setnull')\n+        a.o2o_setnull.delete()\n+        a = A.objects.get(pk=a.pk)\n+        self.assertIsNone(a.o2o_setnull)\n+\n+\n+class DeletionTests(TestCase):\n+\n+    def test_m2m(self):\n+        m = M.objects.create()\n+        r = R.objects.create()\n+        MR.objects.create(m=m, r=r)\n+        r.delete()\n+        self.assertFalse(MR.objects.exists())\n+\n+        r = R.objects.create()\n+        MR.objects.create(m=m, r=r)\n+        m.delete()\n+        self.assertFalse(MR.objects.exists())\n+\n+        m = M.objects.create()\n+        r = R.objects.create()\n+        m.m2m.add(r)\n+        r.delete()\n+        through = M._meta.get_field('m2m').remote_field.through\n+        self.assertFalse(through.objects.exists())\n+\n+        r = R.objects.create()\n+        m.m2m.add(r)\n+        m.delete()\n+        self.assertFalse(through.objects.exists())\n+\n+        m = M.objects.create()\n+        r = R.objects.create()\n+        MRNull.objects.create(m=m, r=r)\n+        r.delete()\n+        self.assertFalse(not MRNull.objects.exists())\n+        self.assertFalse(m.m2m_through_null.exists())\n+\n+    def test_bulk(self):\n+        s = S.objects.create(r=R.objects.create())\n+        for i in range(2 * GET_ITERATOR_CHUNK_SIZE):\n+            T.objects.create(s=s)\n+        #   1 (select related `T` instances)\n+        # + 1 (select related `U` instances)\n+        # + 2 (delete `T` instances in batches)\n+        # + 1 (delete `s`)\n+        self.assertNumQueries(5, s.delete)\n+        self.assertFalse(S.objects.exists())\n+\n+    def test_instance_update(self):\n+        deleted = []\n+        related_setnull_sets = []\n+\n+        def pre_delete(sender, **kwargs):\n+            obj = kwargs['instance']\n+            deleted.append(obj)\n+            if isinstance(obj, R):\n+                related_setnull_sets.append([a.pk for a in obj.setnull_set.all()])\n+\n+        models.signals.pre_delete.connect(pre_delete)\n+        a = create_a('update_setnull')\n+        a.setnull.delete()\n+\n+        a = create_a('update_cascade')\n+        a.cascade.delete()\n+\n+        for obj in deleted:\n+            self.assertIsNone(obj.pk)\n+\n+        for pk_list in related_setnull_sets:\n+            for a in A.objects.filter(id__in=pk_list):\n+                self.assertIsNone(a.setnull)\n+\n+        models.signals.pre_delete.disconnect(pre_delete)\n+\n+    def test_deletion_order(self):\n+        pre_delete_order = []\n+        post_delete_order = []\n+\n+        def log_post_delete(sender, **kwargs):\n+            pre_delete_order.append((sender, kwargs['instance'].pk))\n+\n+        def log_pre_delete(sender, **kwargs):\n+            post_delete_order.append((sender, kwargs['instance'].pk))\n+\n+        models.signals.post_delete.connect(log_post_delete)\n+        models.signals.pre_delete.connect(log_pre_delete)\n+\n+        r = R.objects.create(pk=1)\n+        s1 = S.objects.create(pk=1, r=r)\n+        s2 = S.objects.create(pk=2, r=r)\n+        T.objects.create(pk=1, s=s1)\n+        T.objects.create(pk=2, s=s2)\n+        RChild.objects.create(r_ptr=r)\n+        r.delete()\n+        self.assertEqual(\n+            pre_delete_order, [(T, 2), (T, 1), (RChild, 1), (S, 2), (S, 1), (R, 1)]\n+        )\n+        self.assertEqual(\n+            post_delete_order, [(T, 1), (T, 2), (RChild, 1), (S, 1), (S, 2), (R, 1)]\n+        )\n+\n+        models.signals.post_delete.disconnect(log_post_delete)\n+        models.signals.pre_delete.disconnect(log_pre_delete)\n+\n+    def test_relational_post_delete_signals_happen_before_parent_object(self):\n+        deletions = []\n+\n+        def log_post_delete(instance, **kwargs):\n+            self.assertTrue(R.objects.filter(pk=instance.r_id))\n+            self.assertIs(type(instance), S)\n+            deletions.append(instance.id)\n+\n+        r = R.objects.create(pk=1)\n+        S.objects.create(pk=1, r=r)\n+\n+        models.signals.post_delete.connect(log_post_delete, sender=S)\n+\n+        try:\n+            r.delete()\n+        finally:\n+            models.signals.post_delete.disconnect(log_post_delete)\n+\n+        self.assertEqual(len(deletions), 1)\n+        self.assertEqual(deletions[0], 1)\n+\n+    @skipUnlessDBFeature(\"can_defer_constraint_checks\")\n+    def test_can_defer_constraint_checks(self):\n+        u = User.objects.create(\n+            avatar=Avatar.objects.create()\n+        )\n+        a = Avatar.objects.get(pk=u.avatar_id)\n+        # 1 query to find the users for the avatar.\n+        # 1 query to delete the user\n+        # 1 query to delete the avatar\n+        # The important thing is that when we can defer constraint checks there\n+        # is no need to do an UPDATE on User.avatar to null it out.\n+\n+        # Attach a signal to make sure we will not do fast_deletes.\n+        calls = []\n+\n+        def noop(*args, **kwargs):\n+            calls.append('')\n+        models.signals.post_delete.connect(noop, sender=User)\n+\n+        self.assertNumQueries(3, a.delete)\n+        self.assertFalse(User.objects.exists())\n+        self.assertFalse(Avatar.objects.exists())\n+        self.assertEqual(len(calls), 1)\n+        models.signals.post_delete.disconnect(noop, sender=User)\n+\n+    @skipIfDBFeature(\"can_defer_constraint_checks\")\n+    def test_cannot_defer_constraint_checks(self):\n+        u = User.objects.create(\n+            avatar=Avatar.objects.create()\n+        )\n+        # Attach a signal to make sure we will not do fast_deletes.\n+        calls = []\n+\n+        def noop(*args, **kwargs):\n+            calls.append('')\n+        models.signals.post_delete.connect(noop, sender=User)\n+\n+        a = Avatar.objects.get(pk=u.avatar_id)\n+        # The below doesn't make sense... Why do we need to null out\n+        # user.avatar if we are going to delete the user immediately after it,\n+        # and there are no more cascades.\n+        # 1 query to find the users for the avatar.\n+        # 1 query to delete the user\n+        # 1 query to null out user.avatar, because we can't defer the constraint\n+        # 1 query to delete the avatar\n+        self.assertNumQueries(4, a.delete)\n+        self.assertFalse(User.objects.exists())\n+        self.assertFalse(Avatar.objects.exists())\n+        self.assertEqual(len(calls), 1)\n+        models.signals.post_delete.disconnect(noop, sender=User)\n+\n+    def test_hidden_related(self):\n+        r = R.objects.create()\n+        h = HiddenUser.objects.create(r=r)\n+        HiddenUserProfile.objects.create(user=h)\n+\n+        r.delete()\n+        self.assertEqual(HiddenUserProfile.objects.count(), 0)\n+\n+    def test_large_delete(self):\n+        TEST_SIZE = 2000\n+        objs = [Avatar() for i in range(0, TEST_SIZE)]\n+        Avatar.objects.bulk_create(objs)\n+        # Calculate the number of queries needed.\n+        batch_size = connection.ops.bulk_batch_size(['pk'], objs)\n+        # The related fetches are done in batches.\n+        batches = ceil(len(objs) / batch_size)\n+        # One query for Avatar.objects.all() and then one related fast delete for\n+        # each batch.\n+        fetches_to_mem = 1 + batches\n+        # The Avatar objects are going to be deleted in batches of GET_ITERATOR_CHUNK_SIZE\n+        queries = fetches_to_mem + TEST_SIZE // GET_ITERATOR_CHUNK_SIZE\n+        self.assertNumQueries(queries, Avatar.objects.all().delete)\n+        self.assertFalse(Avatar.objects.exists())\n+\n+    def test_large_delete_related(self):\n+        TEST_SIZE = 2000\n+        s = S.objects.create(r=R.objects.create())\n+        for i in range(TEST_SIZE):\n+            T.objects.create(s=s)\n+\n+        batch_size = max(connection.ops.bulk_batch_size(['pk'], range(TEST_SIZE)), 1)\n+\n+        # TEST_SIZE / batch_size (select related `T` instances)\n+        # + 1 (select related `U` instances)\n+        # + TEST_SIZE / GET_ITERATOR_CHUNK_SIZE (delete `T` instances in batches)\n+        # + 1 (delete `s`)\n+        expected_num_queries = ceil(TEST_SIZE / batch_size)\n+        expected_num_queries += ceil(TEST_SIZE / GET_ITERATOR_CHUNK_SIZE) + 2\n+\n+        self.assertNumQueries(expected_num_queries, s.delete)\n+        self.assertFalse(S.objects.exists())\n+        self.assertFalse(T.objects.exists())\n+\n+    def test_delete_with_keeping_parents(self):\n+        child = RChild.objects.create()\n+        parent_id = child.r_ptr_id\n+        child.delete(keep_parents=True)\n+        self.assertFalse(RChild.objects.filter(id=child.id).exists())\n+        self.assertTrue(R.objects.filter(id=parent_id).exists())\n+\n+    def test_delete_with_keeping_parents_relationships(self):\n+        child = RChild.objects.create()\n+        parent_id = child.r_ptr_id\n+        parent_referent_id = S.objects.create(r=child.r_ptr).pk\n+        child.delete(keep_parents=True)\n+        self.assertFalse(RChild.objects.filter(id=child.id).exists())\n+        self.assertTrue(R.objects.filter(id=parent_id).exists())\n+        self.assertTrue(S.objects.filter(pk=parent_referent_id).exists())\n+\n+        childchild = RChildChild.objects.create()\n+        parent_id = childchild.rchild_ptr.r_ptr_id\n+        child_id = childchild.rchild_ptr_id\n+        parent_referent_id = S.objects.create(r=childchild.rchild_ptr.r_ptr).pk\n+        childchild.delete(keep_parents=True)\n+        self.assertFalse(RChildChild.objects.filter(id=childchild.id).exists())\n+        self.assertTrue(RChild.objects.filter(id=child_id).exists())\n+        self.assertTrue(R.objects.filter(id=parent_id).exists())\n+        self.assertTrue(S.objects.filter(pk=parent_referent_id).exists())\n+\n+    def test_queryset_delete_returns_num_rows(self):\n+        \"\"\"\n+        QuerySet.delete() should return the number of deleted rows and a\n+        dictionary with the number of deletions for each object type.\n+        \"\"\"\n+        Avatar.objects.bulk_create([Avatar(desc='a'), Avatar(desc='b'), Avatar(desc='c')])\n+        avatars_count = Avatar.objects.count()\n+        deleted, rows_count = Avatar.objects.all().delete()\n+        self.assertEqual(deleted, avatars_count)\n+\n+        # more complex example with multiple object types\n+        r = R.objects.create()\n+        h1 = HiddenUser.objects.create(r=r)\n+        HiddenUser.objects.create(r=r)\n+        HiddenUserProfile.objects.create(user=h1)\n+        existed_objs = {\n+            R._meta.label: R.objects.count(),\n+            HiddenUser._meta.label: HiddenUser.objects.count(),\n+            A._meta.label: A.objects.count(),\n+            MR._meta.label: MR.objects.count(),\n+            HiddenUserProfile._meta.label: HiddenUserProfile.objects.count(),\n+        }\n+        deleted, deleted_objs = R.objects.all().delete()\n+        for k, v in existed_objs.items():\n+            self.assertEqual(deleted_objs[k], v)\n+\n+    def test_model_delete_returns_num_rows(self):\n+        \"\"\"\n+        Model.delete() should return the number of deleted rows and a\n+        dictionary with the number of deletions for each object type.\n+        \"\"\"\n+        r = R.objects.create()\n+        h1 = HiddenUser.objects.create(r=r)\n+        h2 = HiddenUser.objects.create(r=r)\n+        HiddenUser.objects.create(r=r)\n+        HiddenUserProfile.objects.create(user=h1)\n+        HiddenUserProfile.objects.create(user=h2)\n+        m1 = M.objects.create()\n+        m2 = M.objects.create()\n+        MR.objects.create(r=r, m=m1)\n+        r.m_set.add(m1)\n+        r.m_set.add(m2)\n+        r.save()\n+        existed_objs = {\n+            R._meta.label: R.objects.count(),\n+            HiddenUser._meta.label: HiddenUser.objects.count(),\n+            A._meta.label: A.objects.count(),\n+            MR._meta.label: MR.objects.count(),\n+            HiddenUserProfile._meta.label: HiddenUserProfile.objects.count(),\n+            M.m2m.through._meta.label: M.m2m.through.objects.count(),\n+        }\n+        deleted, deleted_objs = r.delete()\n+        self.assertEqual(deleted, sum(existed_objs.values()))\n+        for k, v in existed_objs.items():\n+            self.assertEqual(deleted_objs[k], v)\n+\n+    def test_proxied_model_duplicate_queries(self):\n+        \"\"\"\n+        #25685 - Deleting instances of a model with existing proxy\n+        classes should not issue multiple queries during cascade\n+        deletion of referring models.\n+        \"\"\"\n+        avatar = Avatar.objects.create()\n+        # One query for the Avatar table and a second for the User one.\n+        with self.assertNumQueries(2):\n+            avatar.delete()\n+\n+    def test_only_referenced_fields_selected(self):\n+        \"\"\"\n+        Only referenced fields are selected during cascade deletion SELECT\n+        unless deletion signals are connected.\n+        \"\"\"\n+        origin = Origin.objects.create()\n+        expected_sql = str(\n+            Referrer.objects.only(\n+                # Both fields are referenced by SecondReferrer.\n+                'id', 'unique_field',\n+            ).filter(origin__in=[origin]).query\n+        )\n+        with self.assertNumQueries(2) as ctx:\n+            origin.delete()\n+        self.assertEqual(ctx.captured_queries[0]['sql'], expected_sql)\n+\n+        def receiver(instance, **kwargs):\n+            pass\n+\n+        # All fields are selected if deletion signals are connected.\n+        for signal_name in ('pre_delete', 'post_delete'):\n+            with self.subTest(signal=signal_name):\n+                origin = Origin.objects.create()\n+                signal = getattr(models.signals, signal_name)\n+                signal.connect(receiver, sender=Referrer)\n+                with self.assertNumQueries(2) as ctx:\n+                    origin.delete()\n+                self.assertIn(\n+                    connection.ops.quote_name('large_field'),\n+                    ctx.captured_queries[0]['sql'],\n+                )\n+                signal.disconnect(receiver, sender=Referrer)\n+\n+\n+class FastDeleteTests(TestCase):\n+\n+    def test_fast_delete_fk(self):\n+        u = User.objects.create(\n+            avatar=Avatar.objects.create()\n+        )\n+        a = Avatar.objects.get(pk=u.avatar_id)\n+        # 1 query to fast-delete the user\n+        # 1 query to delete the avatar\n+        self.assertNumQueries(2, a.delete)\n+        self.assertFalse(User.objects.exists())\n+        self.assertFalse(Avatar.objects.exists())\n+\n+    def test_combined_fast_delete_fk(self):\n+        \"\"\"\n+        Fast deletes for multiple CASCADE relations to the same model should be\n+        combined into a single query.\n+        \"\"\"\n+        origin = Origin.objects.create()\n+        ref = Referrer.objects.create(origin=origin, unique_field=1)\n+        SecondReferrer.objects.create(referrer=ref, other_referrer=ref)\n+        # Two fast delete queries (for SecondReferrer.referrer and\n+        # SecondReferrer.other_referrer) should be combined into one.\n+        # 1. DELETE FROM SecondReferrer WHERE ... OR ...\n+        # 2. DELETE FROM Referrer WHERE ...\n+        self.assertNumQueries(2, ref.delete)\n+        self.assertFalse(Referrer.objects.filter(pk=ref.pk).exists())\n+        self.assertFalse(SecondReferrer.objects.exists())\n+\n+    def test_fast_delete_m2m(self):\n+        t = M2MTo.objects.create()\n+        f1 = M2MFrom.objects.create()\n+        f1.m2m.add(t)\n+        # 1 query to fast-delete the m2m\n+        # 1 query to delete the M2MTo\n+        self.assertNumQueries(2, t.delete)\n+        self.assertFalse(M2MFrom.objects.get(pk=f1.pk).m2m.exists())\n+\n+    def test_fast_delete_joined_qs(self):\n+        a = Avatar.objects.create(desc='a')\n+        User.objects.create(avatar=a)\n+        u2 = User.objects.create()\n+        expected_queries = 1 if connection.features.update_can_self_select else 2\n+        self.assertNumQueries(expected_queries,\n+                              User.objects.filter(avatar__desc='a').delete)\n+        self.assertEqual(User.objects.count(), 1)\n+        self.assertTrue(User.objects.filter(pk=u2.pk).exists())\n"], "arch": "x86_64", "base_commit": "04ac9b45a34440fa447feb6ae934687aacbfc5f4", "test_directives": ["delete.test_on_delete"], "coverage_files": ["django/db/models/deletion.py", "django/contrib/admin/utils.py"], "env_name": "testbed", "run_id": "full_evaluation", "patch_id": "pred_pre__Prometheus-Bug-Reproduction-Agent", "timeout": 1800, "rm_image": false, "force_rebuild": false, "exec_mode": "unit_test", "reproduction_script_name": null, "compute_coverage": true, "install": {"python": "3.6", "packages": "requirements.txt", "install": "python -m pip install -e .", "eval_commands": ["sed -i '/en_US.UTF-8/s/^# //g' /etc/locale.gen && locale-gen", "export LANG=en_US.UTF-8", "export LANGUAGE=en_US:en", "export LC_ALL=en_US.UTF-8"]}, "cache_level": "instance", "test_command": "python3 /root/trace.py --count -C coverage.cover --include-pattern '/testbed/(django/db/models/deletion\\.py|django/contrib/admin/utils\\.py)' ./tests/runtests.py --verbosity 2 --settings=test_sqlite --parallel 1 delete.test_on_delete", "req_install_commands": ["conda create -n testbed python=3.6 -y", "cat <<'EOF_59812759871' > $HOME/requirements.txt\nasgiref >= 3.2\nargon2-cffi >= 16.1.0\nbcrypt\ndocutils\ngeoip2\njinja2 >= 2.9.2\nnumpy\nPillow >= 6.2.0\npylibmc; sys.platform != 'win32'\npython-memcached >= 1.59\npytz\npywatchman; sys.platform != 'win32'\nPyYAML\nselenium\nsqlparse >= 0.2.2\ntblib >= 1.5.0\n\nEOF_59812759871", "conda activate testbed && python -m pip install -r $HOME/requirements.txt", "rm $HOME/requirements.txt"]}