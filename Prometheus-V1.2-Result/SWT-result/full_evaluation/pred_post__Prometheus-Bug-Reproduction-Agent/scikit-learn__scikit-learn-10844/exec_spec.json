{"instance_id": "scikit-learn__scikit-learn-10844", "repo": "scikit-learn/scikit-learn", "version": "0.20", "environment_setup_commit": "55bf5d93e5674f13a1134d93a11fd0cd11aabcd1", "patch_list": ["diff --git a/sklearn/metrics/cluster/supervised.py b/sklearn/metrics/cluster/supervised.py\n--- a/sklearn/metrics/cluster/supervised.py\n+++ b/sklearn/metrics/cluster/supervised.py\n@@ -852,11 +852,12 @@ def fowlkes_mallows_score(labels_true, labels_pred, sparse=False):\n     labels_true, labels_pred = check_clusterings(labels_true, labels_pred)\n     n_samples, = labels_true.shape\n \n-    c = contingency_matrix(labels_true, labels_pred, sparse=True)\n+    c = contingency_matrix(labels_true, labels_pred,\n+                           sparse=True).astype(np.int64)\n     tk = np.dot(c.data, c.data) - n_samples\n     pk = np.sum(np.asarray(c.sum(axis=0)).ravel() ** 2) - n_samples\n     qk = np.sum(np.asarray(c.sum(axis=1)).ravel() ** 2) - n_samples\n-    return tk / np.sqrt(pk * qk) if tk != 0. else 0.\n+    return np.sqrt(tk / pk) * np.sqrt(tk / qk) if tk != 0. else 0.\n \n \n def entropy(labels):\n", "diff --git a/sklearn/metrics/cluster/tests/test_fowlkes_mallows_score_overflow.py b/sklearn/metrics/cluster/tests/test_fowlkes_mallows_score_overflow.py\nnew file mode 100644\nindex 0000000000..6dd7a94ccb\n--- /dev/null\n+++ b/sklearn/metrics/cluster/tests/test_fowlkes_mallows_score_overflow.py\n@@ -0,0 +1,25 @@\n+import numpy as np\n+\n+from sklearn.metrics.cluster.supervised import fowlkes_mallows_score\n+from sklearn.utils.testing import assert_almost_equal\n+\n+\n+def test_fowlkes_mallows_score_overflow():\n+    \"\"\"Test for overflow in fowlkes_mallows_score with large clusters.\"\"\"\n+    # When the number of samples in clusters is large, the intermediate\n+    # values `pk` and `qk` in the fowlkes_mallows_score calculation can\n+    # become very large. Their product can overflow standard integer types,\n+    # leading to incorrect results (e.g., NaN).\n+    #\n+    # We create two large clusters to ensure the product `pk * qk` overflows\n+    # even 64-bit integers.\n+    n_samples_per_cluster = 80000\n+    labels = np.array([0] * n_samples_per_cluster + [1] * n_samples_per_cluster,\n+                      dtype=np.int32)\n+\n+    # For a perfect clustering, the score should be 1.0.\n+    # The buggy version calculates a large `pk` and `qk`, their product\n+    # overflows, resulting in a negative number under the square root,\n+    # and a final score of NaN.\n+    score = fowlkes_mallows_score(labels, labels)\n+    assert_almost_equal(score, 1.0)\n"], "arch": "x86_64", "base_commit": "97523985b39ecde369d83352d7c3baf403b60a22", "test_directives": ["sklearn/metrics/cluster/tests/test_fowlkes_mallows_score_overflow.py"], "coverage_files": ["sklearn/metrics/cluster/supervised.py"], "env_name": "testbed", "run_id": "full_evaluation", "patch_id": "pred_post__Prometheus-Bug-Reproduction-Agent", "timeout": 1800, "rm_image": false, "force_rebuild": false, "exec_mode": "unit_test", "reproduction_script_name": null, "compute_coverage": true, "install": {"python": "3.6", "packages": "numpy scipy cython pytest pandas matplotlib", "install": "python -m pip install -v --no-use-pep517 --no-build-isolation -e .", "pip_packages": ["cython", "numpy==1.19.2", "setuptools", "scipy==1.5.2"]}, "cache_level": "instance", "test_command": "python3 /root/trace.py --count -C coverage.cover --include-pattern '/testbed/(sklearn/metrics/cluster/supervised\\.py)' -m pytest --no-header -rA  -p no:cacheprovider sklearn/metrics/cluster/tests/test_fowlkes_mallows_score_overflow.py", "req_install_commands": ["conda create -n testbed python=3.6 numpy scipy cython pytest pandas matplotlib -y"]}