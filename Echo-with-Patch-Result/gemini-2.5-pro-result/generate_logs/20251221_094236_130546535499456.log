2025-12-21 09:42:37,120 - thread-130546535499456.app.docker.base_container - INFO - Created temporary project directory: /tmp/tmp03o2zfiw/scikit-learn
2025-12-21 09:42:37,120 - thread-130546535499456.app.docker.base_container - DEBUG - Using workdir: /testbed
2025-12-21 09:42:37,120 - thread-130546535499456.app.docker.base_container - INFO - Pulling docker image: swebench/sweb.eval.x86_64.scikit-learn_1776_scikit-learn-11310:v1
2025-12-21 09:43:02,265 - thread-130546535499456.app.docker.base_container - INFO - Tagging pulled image as: prometheus_user_defined_container_2a9f01c314
2025-12-21 09:43:02,275 - thread-130546535499456.app.docker.base_container - INFO - Starting container from image prometheus_user_defined_container_2a9f01c314
2025-12-21 09:43:09,758 - thread-130546535499456.app.docker.base_container - INFO - Starting persistent shell for interactive mode...
2025-12-21 09:43:10,662 - thread-130546535499456.app.docker.base_container - INFO - Persistent shell is ready
2025-12-21 09:43:10,663 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: . /opt/miniconda3/bin/activate
2025-12-21 09:43:10,893 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 0
2025-12-21 09:43:10,894 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:


2025-12-21 09:43:10,894 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: conda activate testbed
2025-12-21 09:43:11,123 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 0
2025-12-21 09:43:11,123 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:


2025-12-21 09:43:11,123 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: python -m pip install -v --no-use-pep517 --no-build-isolation -e .
2025-12-21 09:43:14,790 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 0
2025-12-21 09:43:14,790 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:
python -m pip install -v --no-use-pep517 --
-no-build-isolation -e .

Using pip 21.2.2 from /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/pip (python 3.6)
Obtaining file:///testbed
    Running command python setup.py egg_info
    running egg_info
    creating /tmp/pip-pip-egg-info-3mg1wbxh/scikit_learn.egg-info
    writing /tmp/pip-pip-egg-info-3mg1wbxh/scikit_learn.egg-info/PKG-INFO
    writing dependency_links to /tmp/pip-pip-egg-info-3mg1wbxh/scikit_learn.egg-info/dependency_links.txt
    writing requirements to /tmp/pip-pip-egg-info-3mg1wbxh/scikit_learn.egg-info/requires.txt
    writing top-level names to /tmp/pip-pip-egg-info-3mg1wbxh/scikit_learn.egg-info/top_level.txt
    writing manifest file '/tmp/pip-pip-egg-info-3mg1wbxh/scikit_learn.egg-info/SOURCES.txt'
    reading manifest file '/tmp/pip-pip-egg-info-3mg1wbxh/scikit_learn.egg-info/SOURCES.txt'
    reading manifest template 'MANIFEST.in'
    adding license file 'COPYING'
    adding license file 'AUTHORS.rst'
    writing manifest file '/tmp/pip-pip-egg-info-3mg1wbxh/scikit_learn.egg-info/SOURCES.txt'
    Partial import of sklearn during the build process.
Requirement already satisfied: numpy>=1.8.2 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from scikit-learn==0.20.dev0) (1.19.2)
Requirement already satisfied: scipy>=0.13.3 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from scikit-learn==0.20.dev0) (1.5.2)
Installing collected packages: scikit-learn
  Attempting uninstall: scikit-learn
    Found existing installation: scikit-learn 0.20.dev0
    Uninstalling scikit-learn-0.20.dev0:
      Removing file or directory /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scikit-learn.egg-link
      Removing pth entries from /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/easy-install.pth:
      Removing entry: /testbed
      Successfully uninstalled scikit-learn-0.20.dev0
  Running setup.py develop for scikit-learn
    Running command /opt/miniconda3/envs/testbed/bin/python -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '"'"'/testbed/setup.py'"'"'; __file__='"'"'/testbed/setup.py'"'"';f = getattr(tokenize, '"'"'open'"'"', open)(__file__) if os.path.exists(__file__) else io.StringIO('"'"'from setuptools import setup; setup()'"'"');code = f.read().replace('"'"'\r\n'"'"', '"'"'\n'"'"');f.close();exec(compile(code, __file__, '"'"'exec'"'"'))' develop --no-deps
    blas_opt_info:
    blas_mkl_info:
    customize UnixCCompiler
      libraries mkl_rt not found in ['/opt/miniconda3/envs/testbed/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
      NOT AVAILABLE

    blis_info:
      libraries blis not found in ['/opt/miniconda3/envs/testbed/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
      NOT AVAILABLE

    openblas_info:
    C compiler: gcc -pthread -B /opt/miniconda3/envs/testbed/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC

    creating /tmp/tmp9rp7vf50/tmp
    creating /tmp/tmp9rp7vf50/tmp/tmp9rp7vf50
    compile options: '-c'
    gcc: /tmp/tmp9rp7vf50/source.c
    gcc -pthread -B /opt/miniconda3/envs/testbed/compiler_compat -Wl,--sysroot=/ /tmp/tmp9rp7vf50/tmp/tmp9rp7vf50/source.o -L/opt/miniconda3/envs/testbed/lib -lopenblas -o /tmp/tmp9rp7vf50/a.out
      FOUND:
        libraries = ['openblas', 'openblas']
        library_dirs = ['/opt/miniconda3/envs/testbed/lib']
        language = c
        define_macros = [('HAVE_CBLAS', None)]

      FOUND:
        libraries = ['openblas', 'openblas']
        library_dirs = ['/opt/miniconda3/envs/testbed/lib']
        language = c
        define_macros = [('HAVE_CBLAS', None)]

    running develop
    running build_scripts
    running egg_info
    running build_src
    build_src
    building library "libsvm-skl" sources
    building extension "sklearn.__check_build._check_build" sources
    building extension "sklearn.cluster._dbscan_inner" sources
    building extension "sklearn.cluster._hierarchical" sources
    building extension "sklearn.cluster._k_means_elkan" sources
    building extension "sklearn.cluster._k_means" sources
    building extension "sklearn.datasets._svmlight_format" sources
    building extension "sklearn.decomposition._online_lda" sources
    building extension "sklearn.decomposition.cdnmf_fast" sources
    building extension "sklearn.ensemble._gradient_boosting" sources
    building extension "sklearn.feature_extraction._hashing" sources
    building extension "sklearn.manifold._utils" sources
    building extension "sklearn.manifold._barnes_hut_tsne" sources
    building extension "sklearn.metrics.cluster.expected_mutual_info_fast" sources
    building extension "sklearn.metrics.pairwise_fast" sources
    building extension "sklearn.neighbors.ball_tree" sources
    building extension "sklearn.neighbors.kd_tree" sources
    building extension "sklearn.neighbors.dist_metrics" sources
    building extension "sklearn.neighbors.typedefs" sources
    building extension "sklearn.neighbors.quad_tree" sources
    building extension "sklearn.tree._tree" sources
    building extension "sklearn.tree._splitter" sources
    building extension "sklearn.tree._criterion" sources
    building extension "sklearn.tree._utils" sources
    building extension "sklearn.svm.libsvm" sources
    building extension "sklearn.svm.liblinear" sources
    building extension "sklearn.svm.libsvm_sparse" sources
    building extension "sklearn._isotonic" sources
    building extension "sklearn.linear_model.cd_fast" sources
    building extension "sklearn.linear_model.sgd_fast" sources
    building extension "sklearn.linear_model.sag_fast" sources
    building extension "sklearn.utils.sparsefuncs_fast" sources
    building extension "sklearn.utils.arrayfuncs" sources
    building extension "sklearn.utils.murmurhash" sources
    building extension "sklearn.utils.lgamma" sources
    building extension "sklearn.utils.graph_shortest_path" sources
    building extension "sklearn.utils.fast_dict" sources
    building extension "sklearn.utils.seq_dataset" sources
    building extension "sklearn.utils.weight_vector" sources
    building extension "sklearn.utils._random" sources
    building extension "sklearn.utils._logistic_sigmoid" sources
    building data_files sources
    build_src: building npy-pkg config files
    writing scikit_learn.egg-info/PKG-INFO
    writing dependency_links to scikit_learn.egg-info/dependency_links.txt
    writing requirements to scikit_learn.egg-info/requires.txt
    writing top-level names to scikit_learn.egg-info/top_level.txt
    reading manifest file 'scikit_learn.egg-info/SOURCES.txt'
    reading manifest template 'MANIFEST.in'
    adding license file 'COPYING'
    adding license file 'AUTHORS.rst'
    writing manifest file 'scikit_learn.egg-info/SOURCES.txt'
    running build_ext
    customize UnixCCompiler
    customize UnixCCompiler using build_clib
    customize UnixCCompiler
    customize UnixCCompiler using build_ext
    resetting extension 'sklearn.svm.liblinear' language from 'c' to 'c++'.
    customize UnixCCompiler
    customize UnixCCompiler using build_ext
    Creating /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scikit-learn.egg-link (link to .)
    Adding scikit-learn 0.20.dev0 to easy-install.pth file

    Installed /testbed
    Partial import of sklearn during the build process.
Successfully installed scikit-learn-0.20.dev0
[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv[0m
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/9f/8b/a094f5da22d7abf5098205367b3296dd15b914f4232af5ca39ba6214d08c/pip-22.0-py3-none-any.whl#sha256=6cb1ea2bd7fda0668e26ae8c3e45188f301a7ef17ff22efe1f70f3643e56a822 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/4a/ca/e72b3b399d7a8cb34311aa8f52924108591c013b09f0268820afb4cd96fb/pip-22.0.tar.gz#sha256=d3fa5c3e42b33de52bddce89de40268c9a263cd6ef7c94c40774808dafb32c82 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/89/a1/2f4e58eda11e591fbfa518233378835679fc5ab766b690b3df85215014d5/pip-22.0.1-py3-none-any.whl#sha256=30739ac5fb973cfa4399b0afff0523d4fe6bed2f7a5229333f64d9c2ce0d1933 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/63/71/5686e51f06fa59da55f7e81c3101844e57434a30f4a0d7456674d1459841/pip-22.0.1.tar.gz#sha256=7fd7a92f2fb1d2ac2ae8c72fb10b1e640560a0361ed4427453509e2bcc18605b (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/83/b5/df8640236faa5a3cb80bfafd68e9fb4b22578208b8398c032ccff803f9e0/pip-22.0.2-py3-none-any.whl#sha256=682eabc4716bfce606aca8dab488e9c7b58b0737e9001004eb858cdafcd8dbdd (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/d9/c1/146b24a7648fdf3f8b4dc6521ab0b26ac151ef903bac0b63a4e1450cb4d1/pip-22.0.2.tar.gz#sha256=27b4b70c34ec35f77947f777070d8331adbb1e444842e98e7150c288dc0caea4 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/6a/df/a6ef77a6574781a668791419ffe366c8acd1c3cf4709d210cb53cd5ce1c2/pip-22.0.3-py3-none-any.whl#sha256=c146f331f0805c77017c6bb9740cec4a49a0d4582d0c3cc8244b057f83eca359 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/88/d9/761f0b1e0551a3559afe4d34bd9bf68fc8de3292363b3775dda39b62ce84/pip-22.0.3.tar.gz#sha256=f29d589df8c8ab99c060e68ad294c4a9ed896624f6368c5349d70aa581b333d0 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/4d/16/0a14ca596f30316efd412a60bdfac02a7259bf8673d4d917dc60b9a21812/pip-22.0.4-py3-none-any.whl#sha256=c6aca0f2f081363f689f041d90dab2a07a9a07fb840284db2218117a52da800b (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/33/c9/e2164122d365d8f823213a53970fa3005eb16218edcfc56ca24cb6deba2b/pip-22.0.4.tar.gz#sha256=b3a9de2c6ef801e9247d1527a4b16f92f2cc141cd1489f3fffaf6a9e96729764 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/79/3a/d341ae105c8b49eac912bee40739d496ae80f9441efa7df6c68f4997bbc8/pip-22.1b1-py3-none-any.whl#sha256=09e9e8f8e10f2515134b59600ad3630219430eabb734336079cbc6ffb2e01a0e (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/a7/c0/794f22836ef3202a7ad61f0872278ee7ac62e8c7617e4c9a08f01b5e82da/pip-22.1b1.tar.gz#sha256=f54ab61985754b56c5589178cfd7dfca5ed9f98d5c8f2de2eecb29f1341200f1 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/f3/77/23152f90de45957b59591c34dcb39b78194eb67d088d4f8799e9aa9726c4/pip-22.1-py3-none-any.whl#sha256=802e797fb741be1c2d475533d4ea951957e4940091422bd4a24848a7ac95609d (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/99/bb/696e256f4f445809f25efd4e4ce42ff99664dc089cafa1e097d5fec7fc33/pip-22.1.tar.gz#sha256=2debf847016cfe643fa1512e2d781d3ca9e5c878ba0652583842d50cc2bcc605 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/9b/e6/aa8149e048eda381f2a433599be9b1f5e5e3a189636cd6cf9614aa2ff5be/pip-22.1.1-py3-none-any.whl#sha256=e7bcf0b2cbdec2af84cc1b7b79b25fdbd7228fbdb61a4dca0b82810d0ba9d18b (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/3e/0a/6125e67aa4d3245faeed476e4e26f190b5209f84f01efd733ac6372eb247/pip-22.1.1.tar.gz#sha256=8dfb15d8a1c3d3085a4cbe11f29e19527dfaf2ba99354326fd62cec013eaee81 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/96/2f/caec18213f6a67852f6997fb0673ae08d2e93d1b81573edb93ba4ef06970/pip-22.1.2-py3-none-any.whl#sha256=a3edacb89022ef5258bf61852728bf866632a394da837ca49eb4303635835f17 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/4b/b6/0fa7aa968a9fa4ef63a51b3ff0644e59f49dcd7235b3fd6cceb23f202e08/pip-22.1.2.tar.gz#sha256=6d55b27e10f506312894a87ccc59f280136bad9061719fac9101bdad5a6bce69 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/9b/9e/9e0610f25e65e2cdf90b1ee9c47ca710865401904038558ac0129ea23cbc/pip-22.2-py3-none-any.whl#sha256=9abf423d5d64f3289ab9d5bf31da9e6234f2e9c5d8dcf1423bcb46b809a02c2c (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/cd/b6/cf07132d631444dd7ce0ed199f2327eb34e2418f1675145e5b10e1ee65cd/pip-22.2.tar.gz#sha256=8d63fcd4ee293e30b644827268a0a973d080e5c7425ef26d427f5eb2126c7681 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/84/25/5734a44897751d8bac6822efb819acda2d969bcc1b915bbd7d48102952cb/pip-22.2.1-py3-none-any.whl#sha256=0bbbc87dfbe6eed217beff0021f8b7dea04c8f4a0baa9d31dc4cff281ffc5b2b (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/46/28/addd7e66bb3af799d35a5dcbb79407b591a7ed674f4efd2bd8f930c40821/pip-22.2.1.tar.gz#sha256=50516e47a2b79e77446f0d05649f0d53772c192571486236b1905492bfc24bac (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/1f/2c/d9626f045e7b49a6225c6b09257861f24da78f4e5f23af2ddbdf852c99b8/pip-22.2.2-py3-none-any.whl#sha256=b61a374b5bc40a6e982426aede40c9b5a08ff20e640f5b56977f4f91fed1e39a (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/4b/30/e15b806597e67057e07a5acdc135216ccbf76a5f1681a324533b61066b0b/pip-22.2.2.tar.gz#sha256=3fd1929db052f056d7a998439176d3333fa1b3f6c1ad881de1885c0717608a4b (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/47/ef/8b5470b5b94b36231ed9c0bde90caa71c0d4322d4a15f009b2b7f4287fe0/pip-22.3-py3-none-any.whl#sha256=1daab4b8d3b97d1d763caeb01a4640a2250a0ea899e257b1e44b9eded91e15ab (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/f8/08/7f92782ff571c7c7cb6c5eeb8ebbb1f68cb02bdb24e55c5de4dd9ce98bc3/pip-22.3.tar.gz#sha256=8182aec21dad6c0a49a2a3d121a87cd524b950e0b6092b181625f07ebdde7530 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/09/bd/2410905c76ee14c62baf69e3f4aa780226c1bbfc9485731ad018e35b0cb5/pip-22.3.1-py3-none-any.whl#sha256=908c78e6bc29b676ede1c4d57981d490cb892eb45cd8c214ab6298125119e077 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/a3/50/c4d2727b99052780aad92c7297465af5fe6eec2dbae490aa9763273ffdc1/pip-22.3.1.tar.gz#sha256=65fd48317359f3af8e593943e6ae1506b66325085ea64b706a998c6e83eeaf38 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/ab/43/508c403c38eeaa5fc86516eb13bb470ce77601b6d2bbcdb16e26328d0a15/pip-23.0-py3-none-any.whl#sha256=b5f88adff801f5ef052bcdef3daa31b55eb67b0fccd6d0106c206fa248e0463c (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/b5/16/5e24bf63cff51dcc169f43bd43b86b005c49941e09cc3482a5b370db239e/pip-23.0.tar.gz#sha256=aee438284e82c8def684b0bcc50b1f6ed5e941af97fa940e83e2e8ef1a59da9b (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/07/51/2c0959c5adf988c44d9e1e0d940f5b074516ecc87e96b1af25f59de9ba38/pip-23.0.1-py3-none-any.whl#sha256=236bcb61156d76c4b8a05821b988c7b8c35bf0da28a4b614e8d6ab5212c25c6f (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/6b/8b/0b16094553ecc680e43ded8f920c3873b01b1da79a54274c98f08cb29fca/pip-23.0.1.tar.gz#sha256=cd015ea1bfb0fcef59d8a286c1f8bebcb983f6317719d415dc5351efb7cd7024 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/ae/db/a8821cdac455a1740580c92de3ed7b7f257cfdbad8b1ba8864e6abe58a08/pip-23.1-py3-none-any.whl#sha256=64b1d4528e491aa835ec6ece0c1ac40ce6ab6d886e60740f6519db44b2e9634d (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/da/bf/1bdbe62f5fbde085351693e3a8e387a59f8220932b911b1719fe65efa2d7/pip-23.1.tar.gz#sha256=408539897ee535dbfb83a153f7bc4d620f990d8bd44a52a986efc0b4d330d34a (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/f8/f8/17bd3f7c13515523d811ce4104410c16c03e3c6830f9276612e2f4b28382/pip-23.1.1-py3-none-any.whl#sha256=3d8d72fa0714e93c9d3c2a0ede91e898c64596e0fa7d4523f72dd95728efc418 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/43/7d/1f52f99a7f2eae870483b2c2a3064511487de87911bce146df8a154fbe81/pip-23.1.1.tar.gz#sha256=c95b53d309f903f33dfe5fd37e502a5c3a05ee3454d518e45df522a4f091b728 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/08/e3/57d4c24a050aa0bcca46b2920bff40847db79535dc78141eb83581a52eb8/pip-23.1.2-py3-none-any.whl#sha256=3ef6ac33239e4027d9a5598a381b9d30880a1477e50039db2eac6e8a8f6d1b18 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/fa/ee/74ff76da0ab649eec7581233daeb43d8aa35383d8f75317b2ab3b80c922f/pip-23.1.2.tar.gz#sha256=0e7c86f486935893c708287b30bd050a36ac827ec7fe5e43fe7cb198dd835fba (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/02/65/f15431ddee78562355ccb39097bf9160a1689f2db40dc418754be98806a1/pip-23.2-py3-none-any.whl#sha256=78e5353a9dda374b462f2054f83a7b63f3f065c98236a68361845c1b0ee7e35f (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/3d/ab/21fa8d1ecf5648559f056fda732b0f9fca0585eb2688252e67f70e74deaf/pip-23.2.tar.gz#sha256=a160a170f3331d9ca1a0247eb1cd79c758879f1f81158f9cd05bbb5df80bea5c (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/50/c2/e06851e8cc28dcad7c155f4753da8833ac06a5c704c109313b8d5a62968a/pip-23.2.1-py3-none-any.whl#sha256=7ccf472345f20d35bdc9d1841ff5f313260c2c33fe417f48c30ac46cccabf5be (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/ba/19/e63fb4e0d20e48bd2167bb7e857abc0e21679e24805ba921a224df8977c0/pip-23.2.1.tar.gz#sha256=fb0bd5435b3200c602b5bf61d2d43c2f13c02e29c1707567ae7fbc514eb9faf2 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/e0/63/b428aaca15fcd98c39b07ca7149e24bc14205ad0f1c80ba2b01835aedde1/pip-23.3-py3-none-any.whl#sha256=bc38bb52bc286514f8f7cb3a1ba5ed100b76aaef29b521d48574329331c5ae7b (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/0d/f6/07ef4561bb911285c229fa46ed3df1877bd6c5325c4c67d516560d59a6e6/pip-23.3.tar.gz#sha256=bb7d4f69f488432e4e96394612f43ab43dd478d073ef7422604a570f7157561e (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/47/6a/453160888fab7c6a432a6e25f8afe6256d0d9f2cbd25971021da6491d899/pip-23.3.1-py3-none-any.whl#sha256=55eb67bb6171d37447e82213be585b75fe2b12b359e993773aca4de9247a052b (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/1f/7f/4da15e07ccd11c84c1ccc8f6e24288d5e76c99441bf80e315b33542db951/pip-23.3.1.tar.gz#sha256=1fcaa041308d01f14575f6d0d2ea4b75a3e2871fe4f9c694976f908768e14174 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/15/aa/3f4c7bcee2057a76562a5b33ecbd199be08cdb4443a02e26bd2c3cf6fc39/pip-23.3.2-py3-none-any.whl#sha256=5052d7889c1f9d05224cd41741acb7c5d6fa735ab34e339624a614eaaa7e7d76 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/b7/06/6b1ad0ae8f97d7a0d6f6ad640db10780578999e647a9593512ceb6f06469/pip-23.3.2.tar.gz#sha256=7fd9972f96db22c8077a1ee2691b172c8089b17a5652a44494a9ecb0d78f9149 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/8a/6a/19e9fe04fca059ccf770861c7d5721ab4c2aebc539889e97c7977528a53b/pip-24.0-py3-none-any.whl#sha256=ba0d021a166865d2265246961bec0152ff124de910c5cc39f1156ce3fa7c69dc (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.7'): https://files.pythonhosted.org/packages/94/59/6638090c25e9bc4ce0c42817b5a234e183872a1129735a9330c472cc2056/pip-24.0.tar.gz#sha256=ea9bd1a847e8c5774a5777bb398c19e80bcd4e2aa16a4b301b718fe6f593aba2 (from https://pypi.org/simple/pip/) (requires-python:>=3.7)
  Link requires a different Python (3.6.13 not in: '>=3.8'): https://files.pythonhosted.org/packages/1e/65/22725f8ba583376d0c300c3b9b52b9a67cfd93d786a80be73c167e45abc8/pip-24.1b1-py3-none-any.whl#sha256=752516cffafef5cf29d3fb2f06c978f27e98709654689cf277b2fce984c7a591 (from https://pypi.org/simple/pip/) (requires-python:>=3.8)
  Link requires a different Python (3.6.13 not in: '>=3.8'): https://files.pythonhosted.org/packages/71/38/b0cb3d68b4776b6208a2f16b6d444a848a1fe465a78ce4b7dbbeb8a4fc58/pip-24.1b1.tar.gz#sha256=a9bd4c037d72325b4e903ec3f383263deea3eb73cd01db7a844edd026fc68afe (from https://pypi.org/simple/pip/) (requires-python:>=3.8)
  Link requires a different Python (3.6.13 not in: '>=3.8'): https://files.pythonhosted.org/packages/c1/64/0f1528ed3dfd75a56e084caab3c8dbed596bf87a1dfc40cbc57166bb0c25/pip-24.1b2-py3-none-any.whl#sha256=7b4ae01a2af4bfae0386860c5a12c035fcc228364ddef89192a1c31d48d263a1 (from https://pypi.org/simple/pip/) (requires-python:>=3.8)
  Link requires a different Python (3.6.13 not in: '>=3.8'): https://files.pythonhosted.org/packages/0b/b2/1d1eac32a16fd9478fb9bc6eb6b899f91e6fecceba194fa097c35d385e9a/pip-24.1b2.tar.gz#sha256=926201900a0e26929387023907bf395c9a6c0d37bbea176942ca5e1b6b27e815 (from https://pypi.org/simple/pip/) (requires-python:>=3.8)
  Link requires a different Python (3.6.13 not in: '>=3.8'): https://files.pythonhosted.org/packages/25/49/2255373efd193c6fbd97dc22399e9c830a6517a0f02ca77fbc0bd83ac5cc/pip-24.1-py3-none-any.whl#sha256=a775837439bf5da2c1a0c2fa43d5744854497c689ddbd9344cf3ea6d00598540 (from https://pypi.org/simple/pip/) (requires-python:>=3.8)
  Link requires a different Python (3.6.13 not in: '>=3.8'): https://files.pythonhosted.org/packages/df/60/7538a9cd4d76829c2f585b73d6e400c833a1769408451c813354c58de6cc/pip-24.1.tar.gz#sha256=bdae551038c0ce6a83030b4aedef27fc95f0daa683593fea22fa05e55ed8e317 (from https://pypi.org/simple/pip/) (requires-python:>=3.8)
  Link requires a different Python (3.6.13 not in: '>=3.8'): https://files.pythonhosted.org/packages/f4/ab/e3c039b5ddba9335bd8f82d599eb310de1d2a2db0411b8d804d507405c74/pip-24.1.1-py3-none-any.whl#sha256=efca15145a95e95c00608afeab66311d40bfb73bb2266a855befd705e6bb15a0 (from https://pypi.org/simple/pip/) (requires-python:>=3.8)
  Link requires a different Python (3.6.13 not in: '>=3.8'): https://files.pythonhosted.org/packages/c0/d0/9641dc7b05877874c6418f8034ddefc809495e65caa14d38c7551cd114bb/pip-24.1.1.tar.gz#sha256=5aa64f65e1952733ee0a9a9b1f52496ebdb3f3077cc46f80a16d983b58d1180a (from https://pypi.org/simple/pip/) (requires-python:>=3.8)
  Link requires a different Python (3.6.13 not in: '>=3.8'): https://files.pythonhosted.org/packages/e7/54/0c1c068542cee73d8863336e974fc881e608d0170f3af15d0c0f28644531/pip-24.1.2-py3-none-any.whl#sha256=7cd207eed4c60b0f411b444cd1464198fe186671c323b6cd6d433ed80fc9d247 (from https://pypi.org/simple/pip/) (requires-python:>=3.8)
  Link requires a different Python (3.6.13 not in: '>=3.8'): https://files.pythonhosted.org/packages/12/3d/d899257cace386bebb7bdf8a872d5fe3b935cc6381c3ddb76d3e5d99890d/pip-24.1.2.tar.gz#sha256=e5458a0b89f2755e0ee8c0c77613fe5273e05f337907874d64f13171a898a7ff (from https://pypi.org/simple/pip/) (requires-python:>=3.8)
  Link requires a different Python (3.6.13 not in: '>=3.8'): https://files.pythonhosted.org/packages/d4/55/90db48d85f7689ec6f81c0db0622d704306c5284850383c090e6c7195a5c/pip-24.2-py3-none-any.whl#sha256=2cd581cf58ab7fcfca4ce8efa6dcacd0de5bf8d0a3eb9ec927e07405f4d9e2a2 (from https://pypi.org/simple/pip/) (requires-python:>=3.8)
  Link requires a different Python (3.6.13 not in: '>=3.8'): https://files.pythonhosted.org/packages/4d/87/fb90046e096a03aeab235e139436b3fe804cdd447ed2093b0d70eba3f7f8/pip-24.2.tar.gz#sha256=5b5e490b5e9cb275c879595064adce9ebd31b854e3e803740b72f9ccf34a45b8 (from https://pypi.org/simple/pip/) (requires-python:>=3.8)
  Link requires a different Python (3.6.13 not in: '>=3.8'): https://files.pythonhosted.org/packages/ce/22/4bb91eb040e18eedaba1ba9db41ef909bc73d20023cea09024099909998a/pip-24.3-py3-none-any.whl#sha256=461877c364317128146d1eb33c62c2a80e33cb23b4cafdf4ad728bc74958e0dd (from https://pypi.org/simple/pip/) (requires-python:>=3.8)
  Link requires a different Python (3.6.13 not in: '>=3.8'): https://files.pythonhosted.org/packages/a3/63/dca2c8e2dbfbde322386caf6e674f97f46a6f11d496dc96b99594f8ecc33/pip-24.3.tar.gz#sha256=cd831345d9ce4f74ff7115203d3a0bd6730a1ba814f9327ede48910b1e30a447 (from https://pypi.org/simple/pip/) (requires-python:>=3.8)
  Link requires a different Python (3.6.13 not in: '>=3.8'): https://files.pythonhosted.org/packages/ef/7d/500c9ad20238fcfcb4cb9243eede163594d7020ce87bd9610c9e02771876/pip-24.3.1-py3-none-any.whl#sha256=3790624780082365f47549d032f3770eeb2b1e8bd1f7b2e02dace1afa361b4ed (from https://pypi.org/simple/pip/) (requires-python:>=3.8)
  Link requires a different Python (3.6.13 not in: '>=3.8'): https://files.pythonhosted.org/packages/f4/b1/b422acd212ad7eedddaf7981eee6e5de085154ff726459cf2da7c5a184c1/pip-24.3.1.tar.gz#sha256=ebcb60557f2aefabc2e0f918751cd24ea0d56d8ec5445fe1807f1d2109660b99 (from https://pypi.org/simple/pip/) (requires-python:>=3.8)
  Link requires a different Python (3.6.13 not in: '>=3.8'): https://files.pythonhosted.org/packages/85/8a/1ddf40be20103bcc605db840e9ade09c8e8c9f920a03e9cfe88eae97a058/pip-25.0-py3-none-any.whl#sha256=b6eb97a803356a52b2dd4bb73ba9e65b2ba16caa6bcb25a7497350a4e5859b65 (from https://pypi.org/simple/pip/) (requires-python:>=3.8)
  Link requires a different Python (3.6.13 not in: '>=3.8'): https://files.pythonhosted.org/packages/47/3e/68beeeeb306ea20ffd30b3ed993f531d16cd884ec4f60c9b1e238f69f2af/pip-25.0.tar.gz#sha256=8e0a97f7b4c47ae4a494560da84775e9e2f671d415d8d828e052efefb206b30b (from https://pypi.org/simple/pip/) (requires-python:>=3.8)
  Link requires a different Python (3.6.13 not in: '>=3.8'): https://files.pythonhosted.org/packages/c9/bc/b7db44f5f39f9d0494071bddae6880eb645970366d0a200022a1a93d57f5/pip-25.0.1-py3-none-any.whl#sha256=c46efd13b6aa8279f33f2864459c8ce587ea6a1a59ee20de055868d8f7688f7f (from https://pypi.org/simple/pip/) (requires-python:>=3.8)
  Link requires a different Python (3.6.13 not in: '>=3.8'): https://files.pythonhosted.org/packages/70/53/b309b4a497b09655cb7e07088966881a57d082f48ac3cb54ea729fd2c6cf/pip-25.0.1.tar.gz#sha256=88f96547ea48b940a3a385494e181e29fb8637898f88d88737c5049780f196ea (from https://pypi.org/simple/pip/) (requires-python:>=3.8)
  Link requires a different Python (3.6.13 not in: '>=3.9'): https://files.pythonhosted.org/packages/e0/f0/8a2806114cd36e282823fd4d8e88e3b94dc943c2569c350d0c826a49db38/pip-25.1-py3-none-any.whl#sha256=13b4aa0aaad055020a11bec8a1c2a70a2b2d080e12d89b962266029fff0a16ba (from https://pypi.org/simple/pip/) (requires-python:>=3.9)
  Link requires a different Python (3.6.13 not in: '>=3.9'): https://files.pythonhosted.org/packages/79/67/c06f625e2968c417052b3a4a0eef40656d5d4d44033e57b40ec474af1d28/pip-25.1.tar.gz#sha256=272bdd1289f80165e9070a4f881e8f9e1001bbb50378561d1af20e49bf5a2200 (from https://pypi.org/simple/pip/) (requires-python:>=3.9)
  Link requires a different Python (3.6.13 not in: '>=3.9'): https://files.pythonhosted.org/packages/29/a2/d40fb2460e883eca5199c62cfc2463fd261f760556ae6290f88488c362c0/pip-25.1.1-py3-none-any.whl#sha256=2913a38a2abf4ea6b64ab507bd9e967f3b53dc1ede74b01b0931e1ce548751af (from https://pypi.org/simple/pip/) (requires-python:>=3.9)
  Link requires a different Python (3.6.13 not in: '>=3.9'): https://files.pythonhosted.org/packages/59/de/241caa0ca606f2ec5fe0c1f4261b0465df78d786a38da693864a116c37f4/pip-25.1.1.tar.gz#sha256=3de45d411d308d5054c2168185d8da7f9a2cd753dbac8acbfa88a8909ecd9077 (from https://pypi.org/simple/pip/) (requires-python:>=3.9)
  Link requires a different Python (3.6.13 not in: '>=3.9'): https://files.pythonhosted.org/packages/b7/3f/945ef7ab14dc4f9d7f40288d2df998d1837ee0888ec3659c813487572faa/pip-25.2-py3-none-any.whl#sha256=6d67a2b4e7f14d8b31b8b52648866fa717f45a1eb70e83002f4331d07e953717 (from https://pypi.org/simple/pip/) (requires-python:>=3.9)
  Link requires a different Python (3.6.13 not in: '>=3.9'): https://files.pythonhosted.org/packages/20/16/650289cd3f43d5a2fadfd98c68bd1e1e7f2550a1a5326768cddfbcedb2c5/pip-25.2.tar.gz#sha256=578283f006390f85bb6282dffb876454593d637f5d1be494b5202ce4877e71f2 (from https://pypi.org/simple/pip/) (requires-python:>=3.9)
  Link requires a different Python (3.6.13 not in: '>=3.9'): https://files.pythonhosted.org/packages/44/3c/d717024885424591d5376220b5e836c2d5293ce2011523c9de23ff7bf068/pip-25.3-py3-none-any.whl#sha256=9655943313a94722b7774661c21049070f6bbb0a1516bf02f7c8d5d9201514cd (from https://pypi.org/simple/pip/) (requires-python:>=3.9)
  Link requires a different Python (3.6.13 not in: '>=3.9'): https://files.pythonhosted.org/packages/fe/6e/74a3f0179a4a73a53d66ce57fdb4de0080a8baa1de0063de206d6167acc2/pip-25.3.tar.gz#sha256=8d0538dbbd7babbd207f261ed969c65de439f6bc9e5dbd3b3b9a77f25d95f343 (from https://pypi.org/simple/pip/) (requires-python:>=3.9)

2025-12-21 09:43:14,817 - thread-130546535499456.app.lang_graph.nodes.focal_code_retrieval_node - INFO - Retrieving focal code context via external CRA
2025-12-21 09:49:06,611 - thread-130546535499456.app.lang_graph.nodes.focal_code_retrieval_node - INFO - Focal code context retrieved: 1 items
2025-12-21 09:49:06,612 - thread-130546535499456.app.lang_graph.nodes.test_case_retrieval_node - INFO - Retrieving test case context via external CRA
2025-12-21 09:53:28,185 - thread-130546535499456.app.lang_graph.nodes.test_case_retrieval_node - INFO - Test case context retrieved: 1 items
2025-12-21 09:53:28,189 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_write_message_node - DEBUG - Sending message to BugReproducingWriteNode:
content='Issue title:\nRetrieving time to refit the estimator in BaseSearchCV\n\nIssue description: \nBasically, I\'m trying to figure out how much time it takes to refit the best model on the full data after doing grid/random search. What I can so far do is retrieve the time it takes to fit and score each model:\n```\nimport sklearn.datasets\nimport sklearn.model_selection\nimport sklearn.ensemble\n\nX, y = sklearn.datasets.load_iris(return_X_y=True)\n\nrs = sklearn.model_selection.GridSearchCV(\n    estimator=sklearn.ensemble.RandomForestClassifier(),\n    param_grid={\'n_estimators\': [2, 3, 4, 5]}\n)\nrs.fit(X, y)\nprint(rs.cv_results_[\'mean_fit_time\'])\nprint(rs.cv_results_[\'mean_score_time\'])\n```\nIn case I run this on a single core, I could time the whole search procedure and subtract the time it took to fit the single folds during hyperparameter optimization. Nevertheless, this isn\'t possible any more when setting `n_jobs != 1`.\n\nThus, it would be great to have an attribute `refit_time_` which is simply the time it took to refit the best model.\n\nUsecase: for [OpenML.org](https://openml.org) we want to support uploading the results of hyperparameter optimization, including the time it takes to do the hyperparameter optimization. \n\nIssue comments:\n\n\nPatch Information:\n```diff\ndiff --git a/sklearn/model_selection/_search.py b/sklearn/model_selection/_search.py\nindex 99d6096af7..21acd9a898 100644\n--- a/sklearn/model_selection/_search.py\n+++ b/sklearn/model_selection/_search.py\n@@ -18,6 +18,7 @@ from functools import partial, reduce\n from itertools import product\n import operator\n import warnings\n+import time\n \n import numpy as np\n from scipy.stats import rankdata\n@@ -766,10 +767,12 @@ class BaseSearchCV(six.with_metaclass(ABCMeta, BaseEstimator,\n         if self.refit:\n             self.best_estimator_ = clone(base_estimator).set_params(\n                 **self.best_params_)\n+            start_time = time.time()\n             if y is not None:\n                 self.best_estimator_.fit(X, y, **fit_params)\n             else:\n                 self.best_estimator_.fit(X, **fit_params)\n+            self.refit_time_ = time.time() - start_time\n \n         # Store the only scorer not as a dict for single metric evaluation\n         self.scorer_ = scorers if self.multimetric_ else scorers[\'score\']\n@@ -1076,6 +1079,10 @@ class GridSearchCV(BaseSearchCV):\n     n_splits_ : int\n         The number of cross-validation splits (folds/iterations).\n \n+    refit_time_ : float\n+        Time for refitting the best estimator on the whole dataset in seconds.\n+        This is available only if ``refit`` is not ``False``.\n+\n     Notes\n     ------\n     The parameters selected are those that maximize the score of the left out\n@@ -1387,6 +1394,10 @@ class RandomizedSearchCV(BaseSearchCV):\n     n_splits_ : int\n         The number of cross-validation splits (folds/iterations).\n \n+    refit_time_ : float\n+        Time for refitting the best estimator on the whole dataset in seconds.\n+        This is available only if ``refit`` is not ``False``.\n+\n     Notes\n     -----\n     The parameters selected are those that maximize the score of the held-out\n\n```\n\nFocal Code Context (relevant code that may need fixing):\n{\'relative_path\': \'sklearn/model_selection/_search.py\', \'content\': \'1. """\\n2. The :mod:`sklearn.model_selection._search` includes utilities to fine-tune the\\n3. parameters of an estimator.\\n4. """\\n5. from __future__ import print_function\\n6. from __future__ import division\\n7. \\n8. # Author: Alexandre Gramfort <alexandre.gramfort@inria.fr>,\\n9. #         Gael Varoquaux <gael.varoquaux@normalesup.org>\\n10. #         Andreas Mueller <amueller@ais.uni-bonn.de>\\n11. #         Olivier Grisel <olivier.grisel@ensta.org>\\n12. #         Raghav RV <rvraghav93@gmail.com>\\n13. # License: BSD 3 clause\\n14. \\n15. from abc import ABCMeta, abstractmethod\\n16. from collections import Mapping, namedtuple, defaultdict, Sequence, Iterable\\n17. from functools import partial, reduce\\n18. from itertools import product\\n19. import operator\\n20. import warnings\\n21. \\n22. import numpy as np\\n23. from scipy.stats import rankdata\\n24. \\n25. from ..base import BaseEstimator, is_classifier, clone\\n26. from ..base import MetaEstimatorMixin\\n27. from ._split import check_cv\\n28. from ._validation import _fit_and_score\\n29. from ._validation import _aggregate_score_dicts\\n30. from ..exceptions import NotFittedError\\n31. from ..externals.joblib import Parallel, delayed\\n32. from ..externals import six\\n33. from ..utils import check_random_state\\n34. from ..utils.fixes import sp_version\\n35. from ..utils.fixes import MaskedArray\\n36. from ..utils.random import sample_without_replacement\\n37. from ..utils.validation import indexable, check_is_fitted\\n38. from ..utils.metaestimators import if_delegate_has_method\\n39. from ..utils.deprecation import DeprecationDict\\n40. from ..metrics.scorer import _check_multimetric_scoring\\n41. from ..metrics.scorer import check_scoring\\n42. \\n43. \\n44. __all__ = [\\\'GridSearchCV\\\', \\\'ParameterGrid\\\', \\\'fit_grid_point\\\',\\n45.            \\\'ParameterSampler\\\', \\\'RandomizedSearchCV\\\']\\n46. \\n47. \\n48. class ParameterGrid(object):\\n49.     """Grid of parameters with a discrete number of values for each.\\n50. \\n51.     Can be used to iterate over parameter value combinations with the\\n52.     Python built-in function iter.\\n53. \\n54.     Read more in the :ref:`User Guide <search>`.\\n55. \\n56.     Parameters\\n57.     ----------\\n58.     param_grid : dict of string to sequence, or sequence of such\\n59.         The parameter grid to explore, as a dictionary mapping estimator\\n60.         parameters to sequences of allowed values.\\n61. \\n62.         An empty dict signifies default parameters.\\n63. \\n64.         A sequence of dicts signifies a sequence of grids to search, and is\\n65.         useful to avoid exploring parameter combinations that make no sense\\n66.         or have no effect. See the examples below.\\n67. \\n68.     Examples\\n69.     --------\\n70.     >>> from sklearn.model_selection import ParameterGrid\\n71.     >>> param_grid = {\\\'a\\\': [1, 2], \\\'b\\\': [True, False]}\\n72.     >>> list(ParameterGrid(param_grid)) == (\\n73.     ...    [{\\\'a\\\': 1, \\\'b\\\': True}, {\\\'a\\\': 1, \\\'b\\\': False},\\n74.     ...     {\\\'a\\\': 2, \\\'b\\\': True}, {\\\'a\\\': 2, \\\'b\\\': False}])\\n75.     True\\n76. \\n77.     >>> grid = [{\\\'kernel\\\': [\\\'linear\\\']}, {\\\'kernel\\\': [\\\'rbf\\\'], \\\'gamma\\\': [1, 10]}]\\n78.     >>> list(ParameterGrid(grid)) == [{\\\'kernel\\\': \\\'linear\\\'},\\n79.     ...                               {\\\'kernel\\\': \\\'rbf\\\', \\\'gamma\\\': 1},\\n80.     ...                               {\\\'kernel\\\': \\\'rbf\\\', \\\'gamma\\\': 10}]\\n81.     True\\n82.     >>> ParameterGrid(grid)[1] == {\\\'kernel\\\': \\\'rbf\\\', \\\'gamma\\\': 1}\\n83.     True\\n84. \\n85.     See also\\n86.     --------\\n87.     :class:`GridSearchCV`:\\n88.         Uses :class:`ParameterGrid` to perform a full parallelized parameter\\n89.         search.\\n90.     """\\n91. \\n92.     def __init__(self, param_grid):\\n93.         if not isinstance(param_grid, (Mapping, Iterable)):\\n94.             raise TypeError(\\\'Parameter grid is not a dict or \\\'\\n95.                             \\\'a list ({!r})\\\'.format(param_grid))\\n96. \\n97.         if isinstance(param_grid, Mapping):\\n98.             # wrap dictionary in a singleton list to support either dict\\n99.             # or list of dicts\\n100.             param_grid = [param_grid]\\n101. \\n102.         # check if all entries are dictionaries of lists\\n103.         for grid in param_grid:\\n104.             if not isinstance(grid, dict):\\n105.                 raise TypeError(\\\'Parameter grid is not a \\\'\\n106.                                 \\\'dict ({!r})\\\'.format(grid))\\n107.             for key in grid:\\n108.                 if not isinstance(grid[key], Iterable):\\n109.                     raise TypeError(\\\'Parameter grid value is not iterable \\\'\\n110.                                     \\\'(key={!r}, value={!r})\\\'\\n111.                                     .format(key, grid[key]))\\n112. \\n113.         self.param_grid = param_grid\\n114. \\n115.     def __iter__(self):\\n116.         """Iterate over the points in the grid.\\n117. \\n118.         Returns\\n119.         -------\\n120.         params : iterator over dict of string to any\\n121.             Yields dictionaries mapping each estimator parameter to one of its\\n122.             allowed values.\\n123.         """\\n124.         for p in self.param_grid:\\n125.             # Always sort the keys of a dictionary, for reproducibility\\n126.             items = sorted(p.items())\\n127.             if not items:\\n128.                 yield {}\\n129.             else:\\n130.                 keys, values = zip(*items)\\n131.                 for v in product(*values):\\n132.                     params = dict(zip(keys, v))\\n133.                     yield params\\n134. \\n135.     def __len__(self):\\n136.         """Number of points on the grid."""\\n137.         # Product function that can handle iterables (np.product can\\\'t).\\n138.         product = partial(reduce, operator.mul)\\n139.         return sum(product(len(v) for v in p.values()) if p else 1\\n140.                    for p in self.param_grid)\\n141. \\n142.     def __getitem__(self, ind):\\n143.         """Get the parameters that would be ``ind``th in iteration\\n144. \\n145.         Parameters\\n146.         ----------\\n147.         ind : int\\n148.             The iteration index\\n149. \\n150.         Returns\\n151.         -------\\n152.         params : dict of string to any\\n153.             Equal to list(self)[ind]\\n154.         """\\n155.         # This is used to make discrete sampling without replacement memory\\n156.         # efficient.\\n157.         for sub_grid in self.param_grid:\\n158.             # XXX: could memoize information used here\\n159.             if not sub_grid:\\n160.                 if ind == 0:\\n161.                     return {}\\n162.                 else:\\n163.                     ind -= 1\\n164.                     continue\\n165. \\n166.             # Reverse so most frequent cycling parameter comes first\\n167.             keys, values_lists = zip(*sorted(sub_grid.items())[::-1])\\n168.             sizes = [len(v_list) for v_list in values_lists]\\n169.             total = np.product(sizes)\\n170. \\n171.             if ind >= total:\\n172.                 # Try the next grid\\n173.                 ind -= total\\n174.             else:\\n175.                 out = {}\\n176.                 for key, v_list, n in zip(keys, values_lists, sizes):\\n177.                     ind, offset = divmod(ind, n)\\n178.                     out[key] = v_list[offset]\\n179.                 return out\\n180. \\n181.         raise IndexError(\\\'ParameterGrid index out of range\\\')\\n182. \\n183. \\n184. class ParameterSampler(object):\\n185.     """Generator on parameters sampled from given distributions.\\n186. \\n187.     Non-deterministic iterable over random candidate combinations for hyper-\\n188.     parameter search. If all parameters are presented as a list,\\n189.     sampling without replacement is performed. If at least one parameter\\n190.     is given as a distribution, sampling with replacement is used.\\n191.     It is highly recommended to use continuous distributions for continuous\\n192.     parameters.\\n193. \\n194.     Note that before SciPy 0.16, the ``scipy.stats.distributions`` do not\\n195.     accept a custom RNG instance and always use the singleton RNG from\\n196.     ``numpy.random``. Hence setting ``random_state`` will not guarantee a\\n197.     deterministic iteration whenever ``scipy.stats`` distributions are used to\\n198.     define the parameter search space. Deterministic behavior is however\\n199.     guaranteed from SciPy 0.16 onwards.\\n200. \\n201.     Read more in the :ref:`User Guide <search>`.\\n202. \\n203.     Parameters\\n204.     ----------\\n205.     param_distributions : dict\\n206.         Dictionary where the keys are parameters and values\\n207.         are distributions from which a parameter is to be sampled.\\n208.         Distributions either have to provide a ``rvs`` function\\n209.         to sample from them, or can be given as a list of values,\\n210.         where a uniform distribution is assumed.\\n211. \\n212.     n_iter : integer\\n213.         Number of parameter settings that are produced.\\n214. \\n215.     random_state : int, RandomState instance or None, optional (default=None)\\n216.         Pseudo random number generator state used for random uniform sampling\\n217.         from lists of possible values instead of scipy.stats distributions.\\n218.         If int, random_state is the seed used by the random number generator;\\n219.         If RandomState instance, random_state is the random number generator;\\n220.         If None, the random number generator is the RandomState instance used\\n221.         by `np.random`.\\n222. \\n223.     Returns\\n224.     -------\\n225.     params : dict of string to any\\n226.         **Yields** dictionaries mapping each estimator parameter to\\n227.         as sampled value.\\n228. \\n229.     Examples\\n230.     --------\\n231.     >>> from sklearn.model_selection import ParameterSampler\\n232.     >>> from scipy.stats.distributions import expon\\n233.     >>> import numpy as np\\n234.     >>> np.random.seed(0)\\n235.     >>> param_grid = {\\\'a\\\':[1, 2], \\\'b\\\': expon()}\\n236.     >>> param_list = list(ParameterSampler(param_grid, n_iter=4))\\n237.     >>> rounded_list = [dict((k, round(v, 6)) for (k, v) in d.items())\\n238.     ...                 for d in param_list]\\n239.     >>> rounded_list == [{\\\'b\\\': 0.89856, \\\'a\\\': 1},\\n240.     ...                  {\\\'b\\\': 0.923223, \\\'a\\\': 1},\\n241.     ...                  {\\\'b\\\': 1.878964, \\\'a\\\': 2},\\n242.     ...                  {\\\'b\\\': 1.038159, \\\'a\\\': 2}]\\n243.     True\\n244.     """\\n245.     def __init__(self, param_distributions, n_iter, random_state=None):\\n246.         self.param_distributions = param_distributions\\n247.         self.n_iter = n_iter\\n248.         self.random_state = random_state\\n249. \\n250.     def __iter__(self):\\n251.         # check if all distributions are given as lists\\n252.         # in this case we want to sample without replacement\\n253.         all_lists = np.all([not hasattr(v, "rvs")\\n254.                             for v in self.param_distributions.values()])\\n255.         rnd = check_random_state(self.random_state)\\n256. \\n257.         if all_lists:\\n258.             # look up sampled parameter settings in parameter grid\\n259.             param_grid = ParameterGrid(self.param_distributions)\\n260.             grid_size = len(param_grid)\\n261.             n_iter = self.n_iter\\n262. \\n263.             if grid_size < n_iter:\\n264.                 warnings.warn(\\n265.                     \\\'The total space of parameters %d is smaller \\\'\\n266.                     \\\'than n_iter=%d. Running %d iterations. For exhaustive \\\'\\n267.                     \\\'searches, use GridSearchCV.\\\'\\n268.                     % (grid_size, self.n_iter, grid_size), UserWarning)\\n269.                 n_iter = grid_size\\n270.             for i in sample_without_replacement(grid_size, n_iter,\\n271.                                                 random_state=rnd):\\n272.                 yield param_grid[i]\\n273. \\n274.         else:\\n275.             # Always sort the keys of a dictionary, for reproducibility\\n276.             items = sorted(self.param_distributions.items())\\n277.             for _ in six.moves.range(self.n_iter):\\n278.                 params = dict()\\n279.                 for k, v in items:\\n280.                     if hasattr(v, "rvs"):\\n281.                         if sp_version < (0, 16):\\n282.                             params[k] = v.rvs()\\n283.                         else:\\n284.                             params[k] = v.rvs(random_state=rnd)\\n285.                     else:\\n286.                         params[k] = v[rnd.randint(len(v))]\\n287.                 yield params\\n288. \\n289.     def __len__(self):\\n290.         """Number of points that will be sampled."""\\n291.         return self.n_iter\\n292. \\n293. \\n294. def fit_grid_point(X, y, estimator, parameters, train, test, scorer,\\n295.                    verbose, error_score=\\\'raise-deprecating\\\', **fit_params):\\n296.     """Run fit on one set of parameters.\\n297. \\n298.     Parameters\\n299.     ----------\\n300.     X : array-like, sparse matrix or list\\n301.         Input data.\\n302. \\n303.     y : array-like or None\\n304.         Targets for input data.\\n305. \\n306.     estimator : estimator object\\n307.         A object of that type is instantiated for each grid point.\\n308.         This is assumed to implement the scikit-learn estimator interface.\\n309.         Either estimator needs to provide a ``score`` function,\\n310.         or ``scoring`` must be passed.\\n311. \\n312.     parameters : dict\\n313.         Parameters to be set on estimator for this grid point.\\n314. \\n315.     train : ndarray, dtype int or bool\\n316.         Boolean mask or indices for training set.\\n317. \\n318.     test : ndarray, dtype int or bool\\n319.         Boolean mask or indices for test set.\\n320. \\n321.     scorer : callable or None\\n322.         The scorer callable object / function must have its signature as\\n323.         ``scorer(estimator, X, y)``.\\n324. \\n325.         If ``None`` the estimator\\\'s default scorer is used.\\n326. \\n327.     verbose : int\\n328.         Verbosity level.\\n329. \\n330.     **fit_params : kwargs\\n331.         Additional parameter passed to the fit function of the estimator.\\n332. \\n333.     error_score : \\\'raise\\\' or numeric\\n334.         Value to assign to the score if an error occurs in estimator fitting.\\n335.         If set to \\\'raise\\\', the error is raised. If a numeric value is given,\\n336.         FitFailedWarning is raised. This parameter does not affect the refit\\n337.         step, which will always raise the error. Default is \\\'raise\\\' but from\\n338.         version 0.22 it will change to np.nan.\\n339. \\n340.     Returns\\n341.     -------\\n342.     score : float\\n343.          Score of this parameter setting on given training / test split.\\n344. \\n345.     parameters : dict\\n346.         The parameters that have been evaluated.\\n347. \\n348.     n_samples_test : int\\n349.         Number of test samples in this split.\\n350.     """\\n351.     # NOTE we are not using the return value as the scorer by itself should be\\n352.     # validated before. We use check_scoring only to reject multimetric scorer\\n353.     check_scoring(estimator, scorer)\\n354.     scores, n_samples_test = _fit_and_score(estimator, X, y,\\n355.                                             scorer, train,\\n356.                                             test, verbose, parameters,\\n357.                                             fit_params=fit_params,\\n358.                                             return_n_test_samples=True,\\n359.                                             error_score=error_score)\\n360.     return scores, parameters, n_samples_test\\n361. \\n362. \\n363. def _check_param_grid(param_grid):\\n364.     if hasattr(param_grid, \\\'items\\\'):\\n365.         param_grid = [param_grid]\\n366. \\n367.     for p in param_grid:\\n368.         for name, v in p.items():\\n369.             if isinstance(v, np.ndarray) and v.ndim > 1:\\n370.                 raise ValueError("Parameter array should be one-dimensional.")\\n371. \\n372.             if (isinstance(v, six.string_types) or\\n373.                     not isinstance(v, (np.ndarray, Sequence))):\\n374.                 raise ValueError("Parameter values for parameter ({0}) need "\\n375.                                  "to be a sequence(but not a string) or"\\n376.                                  " np.ndarray.".format(name))\\n377. \\n378.             if len(v) == 0:\\n379.                 raise ValueError("Parameter values for parameter ({0}) need "\\n380.                                  "to be a non-empty sequence.".format(name))\\n381. \\n382. \\n383. # XXX Remove in 0.20\\n384. class _CVScoreTuple (namedtuple(\\\'_CVScoreTuple\\\',\\n385.                                 (\\\'parameters\\\',\\n386.                                  \\\'mean_validation_score\\\',\\n387.                                  \\\'cv_validation_scores\\\'))):\\n388.     # A raw namedtuple is very memory efficient as it packs the attributes\\n389.     # in a struct to get rid of the __dict__ of attributes in particular it\\n390.     # does not copy the string for the keys on each instance.\\n391.     # By deriving a namedtuple class just to introduce the __repr__ method we\\n392.     # would also reintroduce the __dict__ on the instance. By telling the\\n393.     # Python interpreter that this subclass uses static __slots__ instead of\\n394.     # dynamic attributes. Furthermore we don\\\'t need any additional slot in the\\n395.     # subclass so we set __slots__ to the empty tuple.\\n396.     __slots__ = ()\\n397. \\n398.     def __repr__(self):\\n399.         """Simple custom repr to summarize the main info"""\\n400.         return "mean: {0:.5f}, std: {1:.5f}, params: {2}".format(\\n401.             self.mean_validation_score,\\n402.             np.std(self.cv_validation_scores),\\n403.             self.parameters)\\n404. \\n405. \\n406. class BaseSearchCV(six.with_metaclass(ABCMeta, BaseEstimator,\\n407.                                       MetaEstimatorMixin)):\\n408.     """Base class for hyper parameter search with cross-validation."""\\n409. \\n410.     @abstractmethod\\n411.     def __init__(self, estimator, scoring=None,\\n412.                  fit_params=None, n_jobs=1, iid=\\\'warn\\\',\\n413.                  refit=True, cv=None, verbose=0, pre_dispatch=\\\'2*n_jobs\\\',\\n414.                  error_score=\\\'raise-deprecating\\\', return_train_score=True):\\n415. \\n416.         self.scoring = scoring\\n417.         self.estimator = estimator\\n418.         self.n_jobs = n_jobs\\n419.         self.fit_params = fit_params\\n420.         self.iid = iid\\n421.         self.refit = refit\\n422.         self.cv = cv\\n423.         self.verbose = verbose\\n424.         self.pre_dispatch = pre_dispatch\\n425.         self.error_score = error_score\\n426.         self.return_train_score = return_train_score\\n427. \\n428.     @property\\n429.     def _estimator_type(self):\\n430.         return self.estimator._estimator_type\\n431. \\n432.     def score(self, X, y=None):\\n433.         """Returns the score on the given data, if the estimator has been refit.\\n434. \\n435.         This uses the score defined by ``scoring`` where provided, and the\\n436.         ``best_estimator_.score`` method otherwise.\\n437. \\n438.         Parameters\\n439.         ----------\\n440.         X : array-like, shape = [n_samples, n_features]\\n441.             Input data, where n_samples is the number of samples and\\n442.             n_features is the number of features.\\n443. \\n444.         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\\n445.             Target relative to X for classification or regression;\\n446.             None for unsupervised learning.\\n447. \\n448.         Returns\\n449.         -------\\n450.         score : float\\n451.         """\\n452.         self._check_is_fitted(\\\'score\\\')\\n453.         if self.scorer_ is None:\\n454.             raise ValueError("No score function explicitly defined, "\\n455.                              "and the estimator doesn\\\'t provide one %s"\\n456.                              % self.best_estimator_)\\n457.         score = self.scorer_[self.refit] if self.multimetric_ else self.scorer_\\n458.         return score(self.best_estimator_, X, y)\\n459. \\n460.     def _check_is_fitted(self, method_name):\\n461.         if not self.refit:\\n462.             raise NotFittedError(\\\'This %s instance was initialized \\\'\\n463.                                  \\\'with refit=False. %s is \\\'\\n464.                                  \\\'available only after refitting on the best \\\'\\n465.                                  \\\'parameters. You can refit an estimator \\\'\\n466.                                  \\\'manually using the ``best_parameters_`` \\\'\\n467.                                  \\\'attribute\\\'\\n468.                                  % (type(self).__name__, method_name))\\n469.         else:\\n470.             check_is_fitted(self, \\\'best_estimator_\\\')\\n471. \\n472.     @if_delegate_has_method(delegate=(\\\'best_estimator_\\\', \\\'estimator\\\'))\\n473.     def predict(self, X):\\n474.         """Call predict on the estimator with the best found parameters.\\n475. \\n476.         Only available if ``refit=True`` and the underlying estimator supports\\n477.         ``predict``.\\n478. \\n479.         Parameters\\n480.         -----------\\n481.         X : indexable, length n_samples\\n482.             Must fulfill the input assumptions of the\\n483.             underlying estimator.\\n484. \\n485.         """\\n486.         self._check_is_fitted(\\\'predict\\\')\\n487.         return self.best_estimator_.predict(X)\\n488. \\n489.     @if_delegate_has_method(delegate=(\\\'best_estimator_\\\', \\\'estimator\\\'))\\n490.     def predict_proba(self, X):\\n491.         """Call predict_proba on the estimator with the best found parameters.\\n492. \\n493.         Only available if ``refit=True`` and the underlying estimator supports\\n494.         ``predict_proba``.\\n495. \\n496.         Parameters\\n497.         -----------\\n498.         X : indexable, length n_samples\\n499.             Must fulfill the input assumptions of the\\n500.             underlying estimator.\\n501. \\n502.         """\\n503.         self._check_is_fitted(\\\'predict_proba\\\')\\n504.         return self.best_estimator_.predict_proba(X)\\n505. \\n506.     @if_delegate_has_method(delegate=(\\\'best_estimator_\\\', \\\'estimator\\\'))\\n507.     def predict_log_proba(self, X):\\n508.         """Call predict_log_proba on the estimator with the best found parameters.\\n509. \\n510.         Only available if ``refit=True`` and the underlying estimator supports\\n511.         ``predict_log_proba``.\\n512. \\n513.         Parameters\\n514.         -----------\\n515.         X : indexable, length n_samples\\n516.             Must fulfill the input assumptions of the\\n517.             underlying estimator.\\n518. \\n519.         """\\n520.         self._check_is_fitted(\\\'predict_log_proba\\\')\\n521.         return self.best_estimator_.predict_log_proba(X)\\n522. \\n523.     @if_delegate_has_method(delegate=(\\\'best_estimator_\\\', \\\'estimator\\\'))\\n524.     def decision_function(self, X):\\n525.         """Call decision_function on the estimator with the best found parameters.\\n526. \\n527.         Only available if ``refit=True`` and the underlying estimator supports\\n528.         ``decision_function``.\\n529. \\n530.         Parameters\\n531.         -----------\\n532.         X : indexable, length n_samples\\n533.             Must fulfill the input assumptions of the\\n534.             underlying estimator.\\n535. \\n536.         """\\n537.         self._check_is_fitted(\\\'decision_function\\\')\\n538.         return self.best_estimator_.decision_function(X)\\n539. \\n540.     @if_delegate_has_method(delegate=(\\\'best_estimator_\\\', \\\'estimator\\\'))\\n541.     def transform(self, X):\\n542.         """Call transform on the estimator with the best found parameters.\\n543. \\n544.         Only available if the underlying estimator supports ``transform`` and\\n545.         ``refit=True``.\\n546. \\n547.         Parameters\\n548.         -----------\\n549.         X : indexable, length n_samples\\n550.             Must fulfill the input assumptions of the\\n551.             underlying estimator.\\n552. \\n553.         """\\n554.         self._check_is_fitted(\\\'transform\\\')\\n555.         return self.best_estimator_.transform(X)\\n556. \\n557.     @if_delegate_has_method(delegate=(\\\'best_estimator_\\\', \\\'estimator\\\'))\\n558.     def inverse_transform(self, Xt):\\n559.         """Call inverse_transform on the estimator with the best found params.\\n560. \\n561.         Only available if the underlying estimator implements\\n562.         ``inverse_transform`` and ``refit=True``.\\n563. \\n564.         Parameters\\n565.         -----------\\n566.         Xt : indexable, length n_samples\\n567.             Must fulfill the input assumptions of the\\n568.             underlying estimator.\\n569. \\n570.         """\\n571.         self._check_is_fitted(\\\'inverse_transform\\\')\\n572.         return self.best_estimator_.inverse_transform(Xt)\\n573. \\n574.     @property\\n575.     def classes_(self):\\n576.         self._check_is_fitted("classes_")\\n577.         return self.best_estimator_.classes_\\n578. \\n579.     def fit(self, X, y=None, groups=None, **fit_params):\\n580.         """Run fit with all sets of parameters.\\n581. \\n582.         Parameters\\n583.         ----------\\n584. \\n585.         X : array-like, shape = [n_samples, n_features]\\n586.             Training vector, where n_samples is the number of samples and\\n587.             n_features is the number of features.\\n588. \\n589.         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\\n590.             Target relative to X for classification or regression;\\n591.             None for unsupervised learning.\\n592. \\n593.         groups : array-like, with shape (n_samples,), optional\\n594.             Group labels for the samples used while splitting the dataset into\\n595.             train/test set.\\n596. \\n597.         **fit_params : dict of string -> object\\n598.             Parameters passed to the ``fit`` method of the estimator\\n599.         """\\n600. \\n601.         if self.fit_params is not None:\\n602.             warnings.warn(\\\'"fit_params" as a constructor argument was \\\'\\n603.                           \\\'deprecated in version 0.19 and will be removed \\\'\\n604.                           \\\'in version 0.21. Pass fit parameters to the \\\'\\n605.                           \\\'"fit" method instead.\\\', DeprecationWarning)\\n606.             if fit_params:\\n607.                 warnings.warn(\\\'Ignoring fit_params passed as a constructor \\\'\\n608.                               \\\'argument in favor of keyword arguments to \\\'\\n609.                               \\\'the "fit" method.\\\', RuntimeWarning)\\n610.             else:\\n611.                 fit_params = self.fit_params\\n612.         estimator = self.estimator\\n613.         cv = check_cv(self.cv, y, classifier=is_classifier(estimator))\\n614. \\n615.         scorers, self.multimetric_ = _check_multimetric_scoring(\\n616.             self.estimator, scoring=self.scoring)\\n617. \\n618.         if self.multimetric_:\\n619.             if self.refit is not False and (\\n620.                     not isinstance(self.refit, six.string_types) or\\n621.                     # This will work for both dict / list (tuple)\\n622.                     self.refit not in scorers):\\n623.                 raise ValueError("For multi-metric scoring, the parameter "\\n624.                                  "refit must be set to a scorer key "\\n625.                                  "to refit an estimator with the best "\\n626.                                  "parameter setting on the whole data and "\\n627.                                  "make the best_* attributes "\\n628.                                  "available for that metric. If this is not "\\n629.                                  "needed, refit should be set to False "\\n630.                                  "explicitly. %r was passed." % self.refit)\\n631.             else:\\n632.                 refit_metric = self.refit\\n633.         else:\\n634.             refit_metric = \\\'score\\\'\\n635. \\n636.         X, y, groups = indexable(X, y, groups)\\n637.         n_splits = cv.get_n_splits(X, y, groups)\\n638.         # Regenerate parameter iterable for each fit\\n639.         candidate_params = list(self._get_param_iterator())\\n640.         n_candidates = len(candidate_params)\\n641.         if self.verbose > 0:\\n642.             print("Fitting {0} folds for each of {1} candidates, totalling"\\n643.                   " {2} fits".format(n_splits, n_candidates,\\n644.                                      n_candidates * n_splits))\\n645. \\n646.         base_estimator = clone(self.estimator)\\n647.         pre_dispatch = self.pre_dispatch\\n648. \\n649.         out = Parallel(\\n650.             n_jobs=self.n_jobs, verbose=self.verbose,\\n651.             pre_dispatch=pre_dispatch\\n652.         )(delayed(_fit_and_score)(clone(base_estimator), X, y, scorers, train,\\n653.                                   test, self.verbose, parameters,\\n654.                                   fit_params=fit_params,\\n655.                                   return_train_score=self.return_train_score,\\n656.                                   return_n_test_samples=True,\\n657.                                   return_times=True, return_parameters=False,\\n658.                                   error_score=self.error_score)\\n659.           for parameters, (train, test) in product(candidate_params,\\n660.                                                    cv.split(X, y, groups)))\\n661. \\n662.         # if one choose to see train score, "out" will contain train score info\\n663.         if self.return_train_score:\\n664.             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\\n665.              score_time) = zip(*out)\\n666.         else:\\n667.             (test_score_dicts, test_sample_counts, fit_time,\\n668.              score_time) = zip(*out)\\n669. \\n670.         # test_score_dicts and train_score dicts are lists of dictionaries and\\n671.         # we make them into dict of lists\\n672.         test_scores = _aggregate_score_dicts(test_score_dicts)\\n673.         if self.return_train_score:\\n674.             train_scores = _aggregate_score_dicts(train_score_dicts)\\n675. \\n676.         # TODO: replace by a dict in 0.21\\n677.         results = (DeprecationDict() if self.return_train_score == \\\'warn\\\'\\n678.                    else {})\\n679. \\n680.         def _store(key_name, array, weights=None, splits=False, rank=False):\\n681.             """A small helper to store the scores/times to the cv_results_"""\\n682.             # When iterated first by splits, then by parameters\\n683.             # We want `array` to have `n_candidates` rows and `n_splits` cols.\\n684.             array = np.array(array, dtype=np.float64).reshape(n_candidates,\\n685.                                                               n_splits)\\n686.             if splits:\\n687.                 for split_i in range(n_splits):\\n688.                     # Uses closure to alter the results\\n689.                     results["split%d_%s"\\n690.                             % (split_i, key_name)] = array[:, split_i]\\n691. \\n692.             array_means = np.average(array, axis=1, weights=weights)\\n693.             results[\\\'mean_%s\\\' % key_name] = array_means\\n694.             # Weighted std is not directly available in numpy\\n695.             array_stds = np.sqrt(np.average((array -\\n696.                                              array_means[:, np.newaxis]) ** 2,\\n697.                                             axis=1, weights=weights))\\n698.             results[\\\'std_%s\\\' % key_name] = array_stds\\n699. \\n700.             if rank:\\n701.                 results["rank_%s" % key_name] = np.asarray(\\n702.                     rankdata(-array_means, method=\\\'min\\\'), dtype=np.int32)\\n703. \\n704.         _store(\\\'fit_time\\\', fit_time)\\n705.         _store(\\\'score_time\\\', score_time)\\n706.         # Use one MaskedArray and mask all the places where the param is not\\n707.         # applicable for that candidate. Use defaultdict as each candidate may\\n708.         # not contain all the params\\n709.         param_results = defaultdict(partial(MaskedArray,\\n710.                                             np.empty(n_candidates,),\\n711.                                             mask=True,\\n712.                                             dtype=object))\\n713.         for cand_i, params in enumerate(candidate_params):\\n714.             for name, value in params.items():\\n715.                 # An all masked empty array gets created for the key\\n716.                 # `"param_%s" % name` at the first occurrence of `name`.\\n717.                 # Setting the value at an index also unmasks that index\\n718.                 param_results["param_%s" % name][cand_i] = value\\n719. \\n720.         results.update(param_results)\\n721.         # Store a list of param dicts at the key \\\'params\\\'\\n722.         results[\\\'params\\\'] = candidate_params\\n723. \\n724.         # NOTE test_sample counts (weights) remain the same for all candidates\\n725.         test_sample_counts = np.array(test_sample_counts[:n_splits],\\n726.                                       dtype=np.int)\\n727.         iid = self.iid\\n728.         if self.iid == \\\'warn\\\':\\n729.             if len(np.unique(test_sample_counts)) > 1:\\n730.                 warnings.warn("The default of the `iid` parameter will change "\\n731.                               "from True to False in version 0.22 and will be"\\n732.                               " removed in 0.24. This will change numeric"\\n733.                               " results when test-set sizes are unequal.",\\n734.                               DeprecationWarning)\\n735.             iid = True\\n736. \\n737.         for scorer_name in scorers.keys():\\n738.             # Computed the (weighted) mean and std for test scores alone\\n739.             _store(\\\'test_%s\\\' % scorer_name, test_scores[scorer_name],\\n740.                    splits=True, rank=True,\\n741.                    weights=test_sample_counts if iid else None)\\n742.             if self.return_train_score:\\n743.                 prev_keys = set(results.keys())\\n744.                 _store(\\\'train_%s\\\' % scorer_name, train_scores[scorer_name],\\n745.                        splits=True)\\n746. \\n747.                 if self.return_train_score == \\\'warn\\\':\\n748.                     for key in set(results.keys()) - prev_keys:\\n749.                         message = (\\n750.                             \\\'You are accessing a training score ({!r}), \\\'\\n751.                             \\\'which will not be available by default \\\'\\n752.                             \\\'any more in 0.21. If you need training scores, \\\'\\n753.                             \\\'please set return_train_score=True\\\').format(key)\\n754.                         # warn on key access\\n755.                         results.add_warning(key, message, FutureWarning)\\n756. \\n757.         # For multi-metric evaluation, store the best_index_, best_params_ and\\n758.         # best_score_ iff refit is one of the scorer names\\n759.         # In single metric evaluation, refit_metric is "score"\\n760.         if self.refit or not self.multimetric_:\\n761.             self.best_index_ = results["rank_test_%s" % refit_metric].argmin()\\n762.             self.best_params_ = candidate_params[self.best_index_]\\n763.             self.best_score_ = results["mean_test_%s" % refit_metric][\\n764.                 self.best_index_]\\n765. \\n766.         if self.refit:\\n767.             self.best_estimator_ = clone(base_estimator).set_params(\\n768.                 **self.best_params_)\\n769.             if y is not None:\\n770.                 self.best_estimator_.fit(X, y, **fit_params)\\n771.             else:\\n772.                 self.best_estimator_.fit(X, **fit_params)\\n773. \\n774.         # Store the only scorer not as a dict for single metric evaluation\\n775.         self.scorer_ = scorers if self.multimetric_ else scorers[\\\'score\\\']\\n776. \\n777.         self.cv_results_ = results\\n778.         self.n_splits_ = n_splits\\n779. \\n780.         return self\\n781. \\n782.     @property\\n783.     def grid_scores_(self):\\n784.         check_is_fitted(self, \\\'cv_results_\\\')\\n785.         if self.multimetric_:\\n786.             raise AttributeError("grid_scores_ attribute is not available for"\\n787.                                  " multi-metric evaluation.")\\n788.         warnings.warn(\\n789.             "The grid_scores_ attribute was deprecated in version 0.18"\\n790.             " in favor of the more elaborate cv_results_ attribute."\\n791.             " The grid_scores_ attribute will not be available from 0.20",\\n792.             DeprecationWarning)\\n793. \\n794.         grid_scores = list()\\n795. \\n796.         for i, (params, mean, std) in enumerate(zip(\\n797.                 self.cv_results_[\\\'params\\\'],\\n798.                 self.cv_results_[\\\'mean_test_score\\\'],\\n799.                 self.cv_results_[\\\'std_test_score\\\'])):\\n800.             scores = np.array(list(self.cv_results_[\\\'split%d_test_score\\\'\\n801.                                                     % s][i]\\n802.                                    for s in range(self.n_splits_)),\\n803.                               dtype=np.float64)\\n804.             grid_scores.append(_CVScoreTuple(params, mean, scores))\\n805. \\n806.         return grid_scores\\n807. \\n808. \\n809. class GridSearchCV(BaseSearchCV):\\n810.     """Exhaustive search over specified parameter values for an estimator.\\n811. \\n812.     Important members are fit, predict.\\n813. \\n814.     GridSearchCV implements a "fit" and a "score" method.\\n815.     It also implements "predict", "predict_proba", "decision_function",\\n816.     "transform" and "inverse_transform" if they are implemented in the\\n817.     estimator used.\\n818. \\n819.     The parameters of the estimator used to apply these methods are optimized\\n820.     by cross-validated grid-search over a parameter grid.\\n821. \\n822.     Read more in the :ref:`User Guide <grid_search>`.\\n823. \\n824.     Parameters\\n825.     ----------\\n826.     estimator : estimator object.\\n827.         This is assumed to implement the scikit-learn estimator interface.\\n828.         Either estimator needs to provide a ``score`` function,\\n829.         or ``scoring`` must be passed.\\n830. \\n831.     param_grid : dict or list of dictionaries\\n832.         Dictionary with parameters names (string) as keys and lists of\\n833.         parameter settings to try as values, or a list of such\\n834.         dictionaries, in which case the grids spanned by each dictionary\\n835.         in the list are explored. This enables searching over any sequence\\n836.         of parameter settings.\\n837. \\n838.     scoring : string, callable, list/tuple, dict or None, default: None\\n839.         A single string (see :ref:`scoring_parameter`) or a callable\\n840.         (see :ref:`scoring`) to evaluate the predictions on the test set.\\n841. \\n842.         For evaluating multiple metrics, either give a list of (unique) strings\\n843.         or a dict with names as keys and callables as values.\\n844. \\n845.         NOTE that when using custom scorers, each scorer should return a single\\n846.         value. Metric functions returning a list/array of values can be wrapped\\n847.         into multiple scorers that return one value each.\\n848. \\n849.         See :ref:`multimetric_grid_search` for an example.\\n850. \\n851.         If None, the estimator\\\'s default scorer (if available) is used.\\n852. \\n853.     fit_params : dict, optional\\n854.         Parameters to pass to the fit method.\\n855. \\n856.         .. deprecated:: 0.19\\n857.            ``fit_params`` as a constructor argument was deprecated in version\\n858.            0.19 and will be removed in version 0.21. Pass fit parameters to\\n859.            the ``fit`` method instead.\\n860. \\n861.     n_jobs : int, default=1\\n862.         Number of jobs to run in parallel.\\n863. \\n864.     pre_dispatch : int, or string, optional\\n865.         Controls the number of jobs that get dispatched during parallel\\n866.         execution. Reducing this number can be useful to avoid an\\n867.         explosion of memory consumption when more jobs get dispatched\\n868.         than CPUs can process. This parameter can be:\\n869. \\n870.             - None, in which case all the jobs are immediately\\n871.               created and spawned. Use this for lightweight and\\n872.               fast-running jobs, to avoid delays due to on-demand\\n873.               spawning of the jobs\\n874. \\n875.             - An int, giving the exact number of total jobs that are\\n876.               spawned\\n877. \\n878.             - A string, giving an expression as a function of n_jobs,\\n879.               as in \\\'2*n_jobs\\\'\\n880. \\n881.     iid : boolean, default=\\\'warn\\\'\\n882.         If True, return the average score across folds, weighted by the number\\n883.         of samples in each test set. In this case, the data is assumed to be\\n884.         identically distributed across the folds, and the loss minimized is\\n885.         the total loss per sample, and not the mean loss across the folds. If\\n886.         False, return the average score across folds. Default is True, but\\n887.         will change to False in version 0.21, to correspond to the standard\\n888.         definition of cross-validation.\\n889. \\n890.         ..versionchanged:: 0.20\\n891.             Parameter ``iid`` will change from True to False by default in\\n892.             version 0.22, and will be removed in 0.24.\\n893. \\n894.     cv : int, cross-validation generator or an iterable, optional\\n895.         Determines the cross-validation splitting strategy.\\n896.         Possible inputs for cv are:\\n897.           - None, to use the default 3-fold cross validation,\\n898.           - integer, to specify the number of folds in a `(Stratified)KFold`,\\n899.           - An object to be used as a cross-validation generator.\\n900.           - An iterable yielding train, test splits.\\n901. \\n902.         For integer/None inputs, if the estimator is a classifier and ``y`` is\\n903.         either binary or multiclass, :class:`StratifiedKFold` is used. In all\\n904.         other cases, :class:`KFold` is used.\\n905. \\n906.         Refer :ref:`User Guide <cross_validation>` for the various\\n907.         cross-validation strategies that can be used here.\\n908. \\n909.     refit : boolean, or string, default=True\\n910.         Refit an estimator using the best found parameters on the whole\\n911.         dataset.\\n912. \\n913.         For multiple metric evaluation, this needs to be a string denoting the\\n914.         scorer is used to find the best parameters for refitting the estimator\\n915.         at the end.\\n916. \\n917.         The refitted estimator is made available at the ``best_estimator_``\\n918.         attribute and permits using ``predict`` directly on this\\n919.         ``GridSearchCV`` instance.\\n920. \\n921.         Also for multiple metric evaluation, the attributes ``best_index_``,\\n922.         ``best_score_`` and ``best_parameters_`` will only be available if\\n923.         ``refit`` is set and all of them will be determined w.r.t this specific\\n924.         scorer.\\n925. \\n926.         See ``scoring`` parameter to know more about multiple metric\\n927.         evaluation.\\n928. \\n929.     verbose : integer\\n930.         Controls the verbosity: the higher, the more messages.\\n931. \\n932.     error_score : \\\'raise\\\' or numeric\\n933.         Value to assign to the score if an error occurs in estimator fitting.\\n934.         If set to \\\'raise\\\', the error is raised. If a numeric value is given,\\n935.         FitFailedWarning is raised. This parameter does not affect the refit\\n936.         step, which will always raise the error. Default is \\\'raise\\\' but from\\n937.         version 0.22 it will change to np.nan.\\n938. \\n939.     return_train_score : boolean, optional\\n940.         If ``False``, the ``cv_results_`` attribute will not include training\\n941.         scores.\\n942. \\n943.         Current default is ``\\\'warn\\\'``, which behaves as ``True`` in addition\\n944.         to raising a warning when a training score is looked up.\\n945.         That default will be changed to ``False`` in 0.21.\\n946.         Computing training scores is used to get insights on how different\\n947.         parameter settings impact the overfitting/underfitting trade-off.\\n948.         However computing the scores on the training set can be computationally\\n949.         expensive and is not strictly required to select the parameters that\\n950.         yield the best generalization performance.\\n951. \\n952. \\n953.     Examples\\n954.     --------\\n955.     >>> from sklearn import svm, datasets\\n956.     >>> from sklearn.model_selection import GridSearchCV\\n957.     >>> iris = datasets.load_iris()\\n958.     >>> parameters = {\\\'kernel\\\':(\\\'linear\\\', \\\'rbf\\\'), \\\'C\\\':[1, 10]}\\n959.     >>> svc = svm.SVC(gamma="scale")\\n960.     >>> clf = GridSearchCV(svc, parameters)\\n961.     >>> clf.fit(iris.data, iris.target)\\n962.     ...                             # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\\n963.     GridSearchCV(cv=None, error_score=...,\\n964.            estimator=SVC(C=1.0, cache_size=..., class_weight=..., coef0=...,\\n965.                          decision_function_shape=\\\'ovr\\\', degree=..., gamma=...,\\n966.                          kernel=\\\'rbf\\\', max_iter=-1, probability=False,\\n967.                          random_state=None, shrinking=True, tol=...,\\n968.                          verbose=False),\\n969.            fit_params=None, iid=..., n_jobs=1,\\n970.            param_grid=..., pre_dispatch=..., refit=..., return_train_score=...,\\n971.            scoring=..., verbose=...)\\n972.     >>> sorted(clf.cv_results_.keys())\\n973.     ...                             # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\\n974.     [\\\'mean_fit_time\\\', \\\'mean_score_time\\\', \\\'mean_test_score\\\',...\\n975.      \\\'mean_train_score\\\', \\\'param_C\\\', \\\'param_kernel\\\', \\\'params\\\',...\\n976.      \\\'rank_test_score\\\', \\\'split0_test_score\\\',...\\n977.      \\\'split0_train_score\\\', \\\'split1_test_score\\\', \\\'split1_train_score\\\',...\\n978.      \\\'split2_test_score\\\', \\\'split2_train_score\\\',...\\n979.      \\\'std_fit_time\\\', \\\'std_score_time\\\', \\\'std_test_score\\\', \\\'std_train_score\\\'...]\\n980. \\n981.     Attributes\\n982.     ----------\\n983.     cv_results_ : dict of numpy (masked) ndarrays\\n984.         A dict with keys as column headers and values as columns, that can be\\n985.         imported into a pandas ``DataFrame``.\\n986. \\n987.         For instance the below given table\\n988. \\n989.         +------------+-----------+------------+-----------------+---+---------+\\n990.         |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\\n991.         +============+===========+============+=================+===+=========+\\n992.         |  \\\'poly\\\'    |     --    |      2     |       0.80      |...|    2    |\\n993.         +------------+-----------+------------+-----------------+---+---------+\\n994.         |  \\\'poly\\\'    |     --    |      3     |       0.70      |...|    4    |\\n995.         +------------+-----------+------------+-----------------+---+---------+\\n996.         |  \\\'rbf\\\'     |     0.1   |     --     |       0.80      |...|    3    |\\n997.         +------------+-----------+------------+-----------------+---+---------+\\n998.         |  \\\'rbf\\\'     |     0.2   |     --     |       0.93      |...|    1    |\\n999.         +------------+-----------+------------+-----------------+---+---------+\\n1000. \\n1001.         will be represented by a ``cv_results_`` dict of::\\n1002. \\n1003.             {\\n1004.             \\\'param_kernel\\\': masked_array(data = [\\\'poly\\\', \\\'poly\\\', \\\'rbf\\\', \\\'rbf\\\'],\\n1005.                                          mask = [False False False False]...)\\n1006.             \\\'param_gamma\\\': masked_array(data = [-- -- 0.1 0.2],\\n1007.                                         mask = [ True  True False False]...),\\n1008.             \\\'param_degree\\\': masked_array(data = [2.0 3.0 -- --],\\n1009.                                          mask = [False False  True  True]...),\\n1010.             \\\'split0_test_score\\\'  : [0.80, 0.70, 0.80, 0.93],\\n1011.             \\\'split1_test_score\\\'  : [0.82, 0.50, 0.70, 0.78],\\n1012.             \\\'mean_test_score\\\'    : [0.81, 0.60, 0.75, 0.85],\\n1013.             \\\'std_test_score\\\'     : [0.01, 0.10, 0.05, 0.08],\\n1014.             \\\'rank_test_score\\\'    : [2, 4, 3, 1],\\n1015.             \\\'split0_train_score\\\' : [0.80, 0.92, 0.70, 0.93],\\n1016.             \\\'split1_train_score\\\' : [0.82, 0.55, 0.70, 0.87],\\n1017.             \\\'mean_train_score\\\'   : [0.81, 0.74, 0.70, 0.90],\\n1018.             \\\'std_train_score\\\'    : [0.01, 0.19, 0.00, 0.03],\\n1019.             \\\'mean_fit_time\\\'      : [0.73, 0.63, 0.43, 0.49],\\n1020.             \\\'std_fit_time\\\'       : [0.01, 0.02, 0.01, 0.01],\\n1021.             \\\'mean_score_time\\\'    : [0.01, 0.06, 0.04, 0.04],\\n1022.             \\\'std_score_time\\\'     : [0.00, 0.00, 0.00, 0.01],\\n1023.             \\\'params\\\'             : [{\\\'kernel\\\': \\\'poly\\\', \\\'degree\\\': 2}, ...],\\n1024.             }\\n1025. \\n1026.         NOTE\\n1027. \\n1028.         The key ``\\\'params\\\'`` is used to store a list of parameter\\n1029.         settings dicts for all the parameter candidates.\\n1030. \\n1031.         The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\\n1032.         ``std_score_time`` are all in seconds.\\n1033. \\n1034.         For multi-metric evaluation, the scores for all the scorers are\\n1035.         available in the ``cv_results_`` dict at the keys ending with that\\n1036.         scorer\\\'s name (``\\\'_<scorer_name>\\\'``) instead of ``\\\'_score\\\'`` shown\\n1037.         above. (\\\'split0_test_precision\\\', \\\'mean_train_precision\\\' etc.)\\n1038. \\n1039.     best_estimator_ : estimator or dict\\n1040.         Estimator that was chosen by the search, i.e. estimator\\n1041.         which gave highest score (or smallest loss if specified)\\n1042.         on the left out data. Not available if ``refit=False``.\\n1043. \\n1044.         See ``refit`` parameter for more information on allowed values.\\n1045. \\n1046.     best_score_ : float\\n1047.         Mean cross-validated score of the best_estimator\\n1048. \\n1049.         For multi-metric evaluation, this is present only if ``refit`` is\\n1050.         specified.\\n1051. \\n1052.     best_params_ : dict\\n1053.         Parameter setting that gave the best results on the hold out data.\\n1054. \\n1055.         For multi-metric evaluation, this is present only if ``refit`` is\\n1056.         specified.\\n1057. \\n1058.     best_index_ : int\\n1059.         The index (of the ``cv_results_`` arrays) which corresponds to the best\\n1060.         candidate parameter setting.\\n1061. \\n1062.         The dict at ``search.cv_results_[\\\'params\\\'][search.best_index_]`` gives\\n1063.         the parameter setting for the best model, that gives the highest\\n1064.         mean score (``search.best_score_``).\\n1065. \\n1066.         For multi-metric evaluation, this is present only if ``refit`` is\\n1067.         specified.\\n1068. \\n1069.     scorer_ : function or a dict\\n1070.         Scorer function used on the held out data to choose the best\\n1071.         parameters for the model.\\n1072. \\n1073.         For multi-metric evaluation, this attribute holds the validated\\n1074.         ``scoring`` dict which maps the scorer key to the scorer callable.\\n1075. \\n1076.     n_splits_ : int\\n1077.         The number of cross-validation splits (folds/iterations).\\n1078. \\n1079.     Notes\\n1080.     ------\\n1081.     The parameters selected are those that maximize the score of the left out\\n1082.     data, unless an explicit score is passed in which case it is used instead.\\n1083. \\n1084.     If `n_jobs` was set to a value higher than one, the data is copied for each\\n1085.     point in the grid (and not `n_jobs` times). This is done for efficiency\\n1086.     reasons if individual jobs take very little time, but may raise errors if\\n1087.     the dataset is large and not enough memory is available.  A workaround in\\n1088.     this case is to set `pre_dispatch`. Then, the memory is copied only\\n1089.     `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\\n1090.     n_jobs`.\\n1091. \\n1092.     See Also\\n1093.     ---------\\n1094.     :class:`ParameterGrid`:\\n1095.         generates all the combinations of a hyperparameter grid.\\n1096. \\n1097.     :func:`sklearn.model_selection.train_test_split`:\\n1098.         utility function to split the data into a development set usable\\n1099.         for fitting a GridSearchCV instance and an evaluation set for\\n1100.         its final evaluation.\\n1101. \\n1102.     :func:`sklearn.metrics.make_scorer`:\\n1103.         Make a scorer from a performance metric or loss function.\\n1104. \\n1105.     """\\n1106. \\n1107.     def __init__(self, estimator, param_grid, scoring=None, fit_params=None,\\n1108.                  n_jobs=1, iid=\\\'warn\\\', refit=True, cv=None, verbose=0,\\n1109.                  pre_dispatch=\\\'2*n_jobs\\\', error_score=\\\'raise-deprecating\\\',\\n1110.                  return_train_score="warn"):\\n1111.         super(GridSearchCV, self).__init__(\\n1112.             estimator=estimator, scoring=scoring, fit_params=fit_params,\\n1113.             n_jobs=n_jobs, iid=iid, refit=refit, cv=cv, verbose=verbose,\\n1114.             pre_dispatch=pre_dispatch, error_score=error_score,\\n1115.             return_train_score=return_train_score)\\n1116.         self.param_grid = param_grid\\n1117.         _check_param_grid(param_grid)\\n1118. \\n1119.     def _get_param_iterator(self):\\n1120.         """Return ParameterGrid instance for the given param_grid"""\\n1121.         return ParameterGrid(self.param_grid)\\n1122. \\n1123. \\n1124. class RandomizedSearchCV(BaseSearchCV):\\n1125.     """Randomized search on hyper parameters.\\n1126. \\n1127.     RandomizedSearchCV implements a "fit" and a "score" method.\\n1128.     It also implements "predict", "predict_proba", "decision_function",\\n1129.     "transform" and "inverse_transform" if they are implemented in the\\n1130.     estimator used.\\n1131. \\n1132.     The parameters of the estimator used to apply these methods are optimized\\n1133.     by cross-validated search over parameter settings.\\n1134. \\n1135.     In contrast to GridSearchCV, not all parameter values are tried out, but\\n1136.     rather a fixed number of parameter settings is sampled from the specified\\n1137.     distributions. The number of parameter settings that are tried is\\n1138.     given by n_iter.\\n1139. \\n1140.     If all parameters are presented as a list,\\n1141.     sampling without replacement is performed. If at least one parameter\\n1142.     is given as a distribution, sampling with replacement is used.\\n1143.     It is highly recommended to use continuous distributions for continuous\\n1144.     parameters.\\n1145. \\n1146.     Note that before SciPy 0.16, the ``scipy.stats.distributions`` do not\\n1147.     accept a custom RNG instance and always use the singleton RNG from\\n1148.     ``numpy.random``. Hence setting ``random_state`` will not guarantee a\\n1149.     deterministic iteration whenever ``scipy.stats`` distributions are used to\\n1150.     define the parameter search space.\\n1151. \\n1152.     Read more in the :ref:`User Guide <randomized_parameter_search>`.\\n1153. \\n1154.     Parameters\\n1155.     ----------\\n1156.     estimator : estimator object.\\n1157.         A object of that type is instantiated for each grid point.\\n1158.         This is assumed to implement the scikit-learn estimator interface.\\n1159.         Either estimator needs to provide a ``score`` function,\\n1160.         or ``scoring`` must be passed.\\n1161. \\n1162.     param_distributions : dict\\n1163.         Dictionary with parameters names (string) as keys and distributions\\n1164.         or lists of parameters to try. Distributions must provide a ``rvs``\\n1165.         method for sampling (such as those from scipy.stats.distributions).\\n1166.         If a list is given, it is sampled uniformly.\\n1167. \\n1168.     n_iter : int, default=10\\n1169.         Number of parameter settings that are sampled. n_iter trades\\n1170.         off runtime vs quality of the solution.\\n1171. \\n1172.     scoring : string, callable, list/tuple, dict or None, default: None\\n1173.         A single string (see :ref:`scoring_parameter`) or a callable\\n1174.         (see :ref:`scoring`) to evaluate the predictions on the test set.\\n1175. \\n1176.         For evaluating multiple metrics, either give a list of (unique) strings\\n1177.         or a dict with names as keys and callables as values.\\n1178. \\n1179.         NOTE that when using custom scorers, each scorer should return a single\\n1180.         value. Metric functions returning a list/array of values can be wrapped\\n1181.         into multiple scorers that return one value each.\\n1182. \\n1183.         See :ref:`multimetric_grid_search` for an example.\\n1184. \\n1185.         If None, the estimator\\\'s default scorer (if available) is used.\\n1186. \\n1187.     fit_params : dict, optional\\n1188.         Parameters to pass to the fit method.\\n1189. \\n1190.         .. deprecated:: 0.19\\n1191.            ``fit_params`` as a constructor argument was deprecated in version\\n1192.            0.19 and will be removed in version 0.21. Pass fit parameters to\\n1193.            the ``fit`` method instead.\\n1194. \\n1195.     n_jobs : int, default=1\\n1196.         Number of jobs to run in parallel.\\n1197. \\n1198.     pre_dispatch : int, or string, optional\\n1199.         Controls the number of jobs that get dispatched during parallel\\n1200.         execution. Reducing this number can be useful to avoid an\\n1201.         explosion of memory consumption when more jobs get dispatched\\n1202.         than CPUs can process. This parameter can be:\\n1203. \\n1204.             - None, in which case all the jobs are immediately\\n1205.               created and spawned. Use this for lightweight and\\n1206.               fast-running jobs, to avoid delays due to on-demand\\n1207.               spawning of the jobs\\n1208. \\n1209.             - An int, giving the exact number of total jobs that are\\n1210.               spawned\\n1211. \\n1212.             - A string, giving an expression as a function of n_jobs,\\n1213.               as in \\\'2*n_jobs\\\'\\n1214. \\n1215.     iid : boolean, default=\\\'warn\\\'\\n1216.         If True, return the average score across folds, weighted by the number\\n1217.         of samples in each test set. In this case, the data is assumed to be\\n1218.         identically distributed across the folds, and the loss minimized is\\n1219.         the total loss per sample, and not the mean loss across the folds. If\\n1220.         False, return the average score across folds. Default is True, but\\n1221.         will change to False in version 0.21, to correspond to the standard\\n1222.         definition of cross-validation.\\n1223. \\n1224.         ..versionchanged:: 0.20\\n1225.             Parameter ``iid`` will change from True to False by default in\\n1226.             version 0.22, and will be removed in 0.24.\\n1227. \\n1228.     cv : int, cross-validation generator or an iterable, optional\\n1229.         Determines the cross-validation splitting strategy.\\n1230.         Possible inputs for cv are:\\n1231.           - None, to use the default 3-fold cross validation,\\n1232.           - integer, to specify the number of folds in a `(Stratified)KFold`,\\n1233.           - An object to be used as a cross-validation generator.\\n1234.           - An iterable yielding train, test splits.\\n1235. \\n1236.         For integer/None inputs, if the estimator is a classifier and ``y`` is\\n1237.         either binary or multiclass, :class:`StratifiedKFold` is used. In all\\n1238.         other cases, :class:`KFold` is used.\\n1239. \\n1240.         Refer :ref:`User Guide <cross_validation>` for the various\\n1241.         cross-validation strategies that can be used here.\\n1242. \\n1243.     refit : boolean, or string default=True\\n1244.         Refit an estimator using the best found parameters on the whole\\n1245.         dataset.\\n1246. \\n1247.         For multiple metric evaluation, this needs to be a string denoting the\\n1248.         scorer that would be used to find the best parameters for refitting\\n1249.         the estimator at the end.\\n1250. \\n1251.         The refitted estimator is made available at the ``best_estimator_``\\n1252.         attribute and permits using ``predict`` directly on this\\n1253.         ``RandomizedSearchCV`` instance.\\n1254. \\n1255.         Also for multiple metric evaluation, the attributes ``best_index_``,\\n1256.         ``best_score_`` and ``best_parameters_`` will only be available if\\n1257.         ``refit`` is set and all of them will be determined w.r.t this specific\\n1258.         scorer.\\n1259. \\n1260.         See ``scoring`` parameter to know more about multiple metric\\n1261.         evaluation.\\n1262. \\n1263.     verbose : integer\\n1264.         Controls the verbosity: the higher, the more messages.\\n1265. \\n1266.     random_state : int, RandomState instance or None, optional, default=None\\n1267.         Pseudo random number generator state used for random uniform sampling\\n1268.         from lists of possible values instead of scipy.stats distributions.\\n1269.         If int, random_state is the seed used by the random number generator;\\n1270.         If RandomState instance, random_state is the random number generator;\\n1271.         If None, the random number generator is the RandomState instance used\\n1272.         by `np.random`.\\n1273. \\n1274.     error_score : \\\'raise\\\' or numeric\\n1275.         Value to assign to the score if an error occurs in estimator fitting.\\n1276.         If set to \\\'raise\\\', the error is raised. If a numeric value is given,\\n1277.         FitFailedWarning is raised. This parameter does not affect the refit\\n1278.         step, which will always raise the error. Default is \\\'raise\\\' but from\\n1279.         version 0.22 it will change to np.nan.\\n1280. \\n1281.     return_train_score : boolean, optional\\n1282.         If ``False``, the ``cv_results_`` attribute will not include training\\n1283.         scores.\\n1284. \\n1285.         Current default is ``\\\'warn\\\'``, which behaves as ``True`` in addition\\n1286.         to raising a warning when a training score is looked up.\\n1287.         That default will be changed to ``False`` in 0.21.\\n1288.         Computing training scores is used to get insights on how different\\n1289.         parameter settings impact the overfitting/underfitting trade-off.\\n1290.         However computing the scores on the training set can be computationally\\n1291.         expensive and is not strictly required to select the parameters that\\n1292.         yield the best generalization performance.\\n1293. \\n1294.     Attributes\\n1295.     ----------\\n1296.     cv_results_ : dict of numpy (masked) ndarrays\\n1297.         A dict with keys as column headers and values as columns, that can be\\n1298.         imported into a pandas ``DataFrame``.\\n1299. \\n1300.         For instance the below given table\\n1301. \\n1302.         +--------------+-------------+-------------------+---+---------------+\\n1303.         | param_kernel | param_gamma | split0_test_score |...|rank_test_score|\\n1304.         +==============+=============+===================+===+===============+\\n1305.         |    \\\'rbf\\\'     |     0.1     |       0.80        |...|       2       |\\n1306.         +--------------+-------------+-------------------+---+---------------+\\n1307.         |    \\\'rbf\\\'     |     0.2     |       0.90        |...|       1       |\\n1308.         +--------------+-------------+-------------------+---+---------------+\\n1309.         |    \\\'rbf\\\'     |     0.3     |       0.70        |...|       1       |\\n1310.         +--------------+-------------+-------------------+---+---------------+\\n1311. \\n1312.         will be represented by a ``cv_results_`` dict of::\\n1313. \\n1314.             {\\n1315.             \\\'param_kernel\\\' : masked_array(data = [\\\'rbf\\\', \\\'rbf\\\', \\\'rbf\\\'],\\n1316.                                           mask = False),\\n1317.             \\\'param_gamma\\\'  : masked_array(data = [0.1 0.2 0.3], mask = False),\\n1318.             \\\'split0_test_score\\\'  : [0.80, 0.90, 0.70],\\n1319.             \\\'split1_test_score\\\'  : [0.82, 0.50, 0.70],\\n1320.             \\\'mean_test_score\\\'    : [0.81, 0.70, 0.70],\\n1321.             \\\'std_test_score\\\'     : [0.01, 0.20, 0.00],\\n1322.             \\\'rank_test_score\\\'    : [3, 1, 1],\\n1323.             \\\'split0_train_score\\\' : [0.80, 0.92, 0.70],\\n1324.             \\\'split1_train_score\\\' : [0.82, 0.55, 0.70],\\n1325.             \\\'mean_train_score\\\'   : [0.81, 0.74, 0.70],\\n1326.             \\\'std_train_score\\\'    : [0.01, 0.19, 0.00],\\n1327.             \\\'mean_fit_time\\\'      : [0.73, 0.63, 0.43],\\n1328.             \\\'std_fit_time\\\'       : [0.01, 0.02, 0.01],\\n1329.             \\\'mean_score_time\\\'    : [0.01, 0.06, 0.04],\\n1330.             \\\'std_score_time\\\'     : [0.00, 0.00, 0.00],\\n1331.             \\\'params\\\'             : [{\\\'kernel\\\' : \\\'rbf\\\', \\\'gamma\\\' : 0.1}, ...],\\n1332.             }\\n1333. \\n1334.         NOTE\\n1335. \\n1336.         The key ``\\\'params\\\'`` is used to store a list of parameter\\n1337.         settings dicts for all the parameter candidates.\\n1338. \\n1339.         The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\\n1340.         ``std_score_time`` are all in seconds.\\n1341. \\n1342.         For multi-metric evaluation, the scores for all the scorers are\\n1343.         available in the ``cv_results_`` dict at the keys ending with that\\n1344.         scorer\\\'s name (``\\\'_<scorer_name>\\\'``) instead of ``\\\'_score\\\'`` shown\\n1345.         above. (\\\'split0_test_precision\\\', \\\'mean_train_precision\\\' etc.)\\n1346. \\n1347.     best_estimator_ : estimator or dict\\n1348.         Estimator that was chosen by the search, i.e. estimator\\n1349.         which gave highest score (or smallest loss if specified)\\n1350.         on the left out data. Not available if ``refit=False``.\\n1351. \\n1352.         For multi-metric evaluation, this attribute is present only if\\n1353.         ``refit`` is specified.\\n1354. \\n1355.         See ``refit`` parameter for more information on allowed values.\\n1356. \\n1357.     best_score_ : float\\n1358.         Mean cross-validated score of the best_estimator.\\n1359. \\n1360.         For multi-metric evaluation, this is not available if ``refit`` is\\n1361.         ``False``. See ``refit`` parameter for more information.\\n1362. \\n1363.     best_params_ : dict\\n1364.         Parameter setting that gave the best results on the hold out data.\\n1365. \\n1366.         For multi-metric evaluation, this is not available if ``refit`` is\\n1367.         ``False``. See ``refit`` parameter for more information.\\n1368. \\n1369.     best_index_ : int\\n1370.         The index (of the ``cv_results_`` arrays) which corresponds to the best\\n1371.         candidate parameter setting.\\n1372. \\n1373.         The dict at ``search.cv_results_[\\\'params\\\'][search.best_index_]`` gives\\n1374.         the parameter setting for the best model, that gives the highest\\n1375.         mean score (``search.best_score_``).\\n1376. \\n1377.         For multi-metric evaluation, this is not available if ``refit`` is\\n1378.         ``False``. See ``refit`` parameter for more information.\\n1379. \\n1380.     scorer_ : function or a dict\\n1381.         Scorer function used on the held out data to choose the best\\n1382.         parameters for the model.\\n1383. \\n1384.         For multi-metric evaluation, this attribute holds the validated\\n1385.         ``scoring`` dict which maps the scorer key to the scorer callable.\\n1386. \\n1387.     n_splits_ : int\\n1388.         The number of cross-validation splits (folds/iterations).\\n1389. \\n1390.     Notes\\n1391.     -----\\n1392.     The parameters selected are those that maximize the score of the held-out\\n1393.     data, according to the scoring parameter.\\n1394. \\n1395.     If `n_jobs` was set to a value higher than one, the data is copied for each\\n1396.     parameter setting(and not `n_jobs` times). This is done for efficiency\\n1397.     reasons if individual jobs take very little time, but may raise errors if\\n1398.     the dataset is large and not enough memory is available.  A workaround in\\n1399.     this case is to set `pre_dispatch`. Then, the memory is copied only\\n1400.     `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\\n1401.     n_jobs`.\\n1402. \\n1403.     See Also\\n1404.     --------\\n1405.     :class:`GridSearchCV`:\\n1406.         Does exhaustive search over a grid of parameters.\\n1407. \\n1408.     :class:`ParameterSampler`:\\n1409.         A generator over parameter settings, constructed from\\n1410.         param_distributions.\\n1411. \\n1412.     """\\n1413. \\n1414.     def __init__(self, estimator, param_distributions, n_iter=10, scoring=None,\\n1415.                  fit_params=None, n_jobs=1, iid=\\\'warn\\\', refit=True, cv=None,\\n1416.                  verbose=0, pre_dispatch=\\\'2*n_jobs\\\', random_state=None,\\n1417.                  error_score=\\\'raise-deprecating\\\', return_train_score="warn"):\\n1418.         self.param_distributions = param_distributions\\n1419.         self.n_iter = n_iter\\n1420.         self.random_state = random_state\\n1421.         super(RandomizedSearchCV, self).__init__(\\n1422.             estimator=estimator, scoring=scoring, fit_params=fit_params,\\n1423.             n_jobs=n_jobs, iid=iid, refit=refit, cv=cv, verbose=verbose,\\n1424.             pre_dispatch=pre_dispatch, error_score=error_score,\\n1425.             return_train_score=return_train_score)\\n1426. \\n1427.     def _get_param_iterator(self):\\n1428.         """Return ParameterSampler instance for the given distributions"""\\n1429.         return ParameterSampler(\\n1430.             self.param_distributions, self.n_iter,\\n1431.             random_state=self.random_state)\', \'start_line_number\': 1, \'end_line_number\': 1431}\n\nTest Case Context (similar existing tests for reference):\n{\'relative_path\': \'sklearn/model_selection/tests/test_search.py\', \'content\': \'1. """Test the search module"""\\n2. \\n3. from collections import Iterable, Sized\\n4. from sklearn.externals.six.moves import cStringIO as StringIO\\n5. from sklearn.externals.six.moves import xrange\\n6. from sklearn.externals.joblib._compat import PY3_OR_LATER\\n7. from itertools import chain, product\\n8. import pickle\\n9. import sys\\n10. from types import GeneratorType\\n11. import re\\n12. \\n13. import numpy as np\\n14. import scipy.sparse as sp\\n15. import pytest\\n16. \\n17. from sklearn.utils.fixes import sp_version\\n18. from sklearn.utils.testing import assert_equal\\n19. from sklearn.utils.testing import assert_not_equal\\n20. from sklearn.utils.testing import assert_raises\\n21. from sklearn.utils.testing import assert_warns\\n22. from sklearn.utils.testing import assert_warns_message\\n23. from sklearn.utils.testing import assert_no_warnings\\n24. from sklearn.utils.testing import assert_raise_message\\n25. from sklearn.utils.testing import assert_false, assert_true\\n26. from sklearn.utils.testing import assert_array_equal\\n27. from sklearn.utils.testing import assert_array_almost_equal\\n28. from sklearn.utils.testing import assert_almost_equal\\n29. from sklearn.utils.testing import ignore_warnings\\n30. from sklearn.utils.mocking import CheckingClassifier, MockDataFrame\\n31. \\n32. from scipy.stats import bernoulli, expon, uniform\\n33. \\n34. from sklearn.base import BaseEstimator\\n35. from sklearn.base import clone\\n36. from sklearn.exceptions import NotFittedError\\n37. from sklearn.exceptions import ConvergenceWarning\\n38. from sklearn.datasets import make_classification\\n39. from sklearn.datasets import make_blobs\\n40. from sklearn.datasets import make_multilabel_classification\\n41. \\n42. from sklearn.model_selection import fit_grid_point\\n43. from sklearn.model_selection import cross_val_score\\n44. from sklearn.model_selection import KFold\\n45. from sklearn.model_selection import StratifiedKFold\\n46. from sklearn.model_selection import StratifiedShuffleSplit\\n47. from sklearn.model_selection import LeaveOneGroupOut\\n48. from sklearn.model_selection import LeavePGroupsOut\\n49. from sklearn.model_selection import GroupKFold\\n50. from sklearn.model_selection import GroupShuffleSplit\\n51. from sklearn.model_selection import GridSearchCV\\n52. from sklearn.model_selection import RandomizedSearchCV\\n53. from sklearn.model_selection import ParameterGrid\\n54. from sklearn.model_selection import ParameterSampler\\n55. \\n56. from sklearn.model_selection._validation import FitFailedWarning\\n57. \\n58. from sklearn.svm import LinearSVC, SVC\\n59. from sklearn.tree import DecisionTreeRegressor\\n60. from sklearn.tree import DecisionTreeClassifier\\n61. from sklearn.cluster import KMeans\\n62. from sklearn.neighbors import KernelDensity\\n63. from sklearn.metrics import f1_score\\n64. from sklearn.metrics import recall_score\\n65. from sklearn.metrics import accuracy_score\\n66. from sklearn.metrics import make_scorer\\n67. from sklearn.metrics import roc_auc_score\\n68. from sklearn.impute import SimpleImputer\\n69. from sklearn.pipeline import Pipeline\\n70. from sklearn.linear_model import Ridge, SGDClassifier\\n71. \\n72. from sklearn.model_selection.tests.common import OneTimeSplitter\\n73. \\n74. \\n75. # Neither of the following two estimators inherit from BaseEstimator,\\n76. # to test hyperparameter search on user-defined classifiers.\\n77. class MockClassifier(object):\\n78.     """Dummy classifier to test the parameter search algorithms"""\\n79.     def __init__(self, foo_param=0):\\n80.         self.foo_param = foo_param\\n81. \\n82.     def fit(self, X, Y):\\n83.         assert_true(len(X) == len(Y))\\n84.         self.classes_ = np.unique(Y)\\n85.         return self\\n86. \\n87.     def predict(self, T):\\n88.         return T.shape[0]\\n89. \\n90.     def transform(self, X):\\n91.         return X + self.foo_param\\n92. \\n93.     def inverse_transform(self, X):\\n94.         return X - self.foo_param\\n95. \\n96.     predict_proba = predict\\n97.     predict_log_proba = predict\\n98.     decision_function = predict\\n99. \\n100.     def score(self, X=None, Y=None):\\n101.         if self.foo_param > 1:\\n102.             score = 1.\\n103.         else:\\n104.             score = 0.\\n105.         return score\\n106. \\n107.     def get_params(self, deep=False):\\n108.         return {\\\'foo_param\\\': self.foo_param}\\n109. \\n110.     def set_params(self, **params):\\n111.         self.foo_param = params[\\\'foo_param\\\']\\n112.         return self\\n113. \\n114. \\n115. class LinearSVCNoScore(LinearSVC):\\n116.     """An LinearSVC classifier that has no score method."""\\n117.     @property\\n118.     def score(self):\\n119.         raise AttributeError\\n120. \\n121. \\n122. X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\\n123. y = np.array([1, 1, 2, 2])\\n124. \\n125. \\n126. def assert_grid_iter_equals_getitem(grid):\\n127.     assert_equal(list(grid), [grid[i] for i in range(len(grid))])\\n128. \\n129. \\n130. @pytest.mark.parametrize(\\n131.     "input, error_type, error_message",\\n132.     [(0, TypeError, \\\'Parameter grid is not a dict or a list (0)\\\'),\\n133.      ([{\\\'foo\\\': [0]}, 0], TypeError, \\\'Parameter grid is not a dict (0)\\\'),\\n134.      ({\\\'foo\\\': 0}, TypeError, "Parameter grid value is not iterable "\\n135.       "(key=\\\'foo\\\', value=0)")]\\n136. )\\n137. def test_validate_parameter_grid_input(input, error_type, error_message):\\n138.     with pytest.raises(error_type, message=error_message):\\n139.         ParameterGrid(input)\\n140. \\n141. def test_parameter_grid():\\n142. \\n143.     # Test basic properties of ParameterGrid.\\n144.     params1 = {"foo": [1, 2, 3]}\\n145.     grid1 = ParameterGrid(params1)\\n146.     assert_true(isinstance(grid1, Iterable))\\n147.     assert_true(isinstance(grid1, Sized))\\n148.     assert_equal(len(grid1), 3)\\n149.     assert_grid_iter_equals_getitem(grid1)\\n150. \\n151.     params2 = {"foo": [4, 2],\\n152.                "bar": ["ham", "spam", "eggs"]}\\n153.     grid2 = ParameterGrid(params2)\\n154.     assert_equal(len(grid2), 6)\\n155. \\n156.     # loop to assert we can iterate over the grid multiple times\\n157.     for i in xrange(2):\\n158.         # tuple + chain transforms {"a": 1, "b": 2} to ("a", 1, "b", 2)\\n159.         points = set(tuple(chain(*(sorted(p.items())))) for p in grid2)\\n160.         assert_equal(points,\\n161.                      set(("bar", x, "foo", y)\\n162.                          for x, y in product(params2["bar"], params2["foo"])))\\n163.     assert_grid_iter_equals_getitem(grid2)\\n164. \\n165.     # Special case: empty grid (useful to get default estimator settings)\\n166.     empty = ParameterGrid({})\\n167.     assert_equal(len(empty), 1)\\n168.     assert_equal(list(empty), [{}])\\n169.     assert_grid_iter_equals_getitem(empty)\\n170.     assert_raises(IndexError, lambda: empty[1])\\n171. \\n172.     has_empty = ParameterGrid([{\\\'C\\\': [1, 10]}, {}, {\\\'C\\\': [.5]}])\\n173.     assert_equal(len(has_empty), 4)\\n174.     assert_equal(list(has_empty), [{\\\'C\\\': 1}, {\\\'C\\\': 10}, {}, {\\\'C\\\': .5}])\\n175.     assert_grid_iter_equals_getitem(has_empty)\\n176. \\n177. \\n178. def test_grid_search():\\n179.     # Test that the best estimator contains the right value for foo_param\\n180.     clf = MockClassifier()\\n181.     grid_search = GridSearchCV(clf, {\\\'foo_param\\\': [1, 2, 3]}, verbose=3)\\n182.     # make sure it selects the smallest parameter in case of ties\\n183.     old_stdout = sys.stdout\\n184.     sys.stdout = StringIO()\\n185.     grid_search.fit(X, y)\\n186.     sys.stdout = old_stdout\\n187.     assert_equal(grid_search.best_estimator_.foo_param, 2)\\n188. \\n189.     assert_array_equal(grid_search.cv_results_["param_foo_param"].data,\\n190.                        [1, 2, 3])\\n191. \\n192.     # Smoke test the score etc:\\n193.     grid_search.score(X, y)\\n194.     grid_search.predict_proba(X)\\n195.     grid_search.decision_function(X)\\n196.     grid_search.transform(X)\\n197. \\n198.     # Test exception handling on scoring\\n199.     grid_search.scoring = \\\'sklearn\\\'\\n200.     assert_raises(ValueError, grid_search.fit, X, y)\\n201. \\n202. \\n203. def check_hyperparameter_searcher_with_fit_params(klass, **klass_kwargs):\\n204.     X = np.arange(100).reshape(10, 10)\\n205.     y = np.array([0] * 5 + [1] * 5)\\n206.     clf = CheckingClassifier(expected_fit_params=[\\\'spam\\\', \\\'eggs\\\'])\\n207.     searcher = klass(clf, {\\\'foo_param\\\': [1, 2, 3]}, cv=2, **klass_kwargs)\\n208. \\n209.     # The CheckingClassifier generates an assertion error if\\n210.     # a parameter is missing or has length != len(X).\\n211.     assert_raise_message(AssertionError,\\n212.                          "Expected fit parameter(s) [\\\'eggs\\\'] not seen.",\\n213.                          searcher.fit, X, y, spam=np.ones(10))\\n214.     assert_raise_message(AssertionError,\\n215.                          "Fit parameter spam has length 1; expected 4.",\\n216.                          searcher.fit, X, y, spam=np.ones(1),\\n217.                          eggs=np.zeros(10))\\n218.     searcher.fit(X, y, spam=np.ones(10), eggs=np.zeros(10))\\n219. \\n220. \\n221. def test_grid_search_with_fit_params():\\n222.     check_hyperparameter_searcher_with_fit_params(GridSearchCV)\\n223. \\n224. \\n225. def test_random_search_with_fit_params():\\n226.     check_hyperparameter_searcher_with_fit_params(RandomizedSearchCV, n_iter=1)\\n227. \\n228. \\n229. def test_grid_search_fit_params_deprecation():\\n230.     # NOTE: Remove this test in v0.21\\n231. \\n232.     # Use of `fit_params` in the class constructor is deprecated,\\n233.     # but will still work until v0.21.\\n234.     X = np.arange(100).reshape(10, 10)\\n235.     y = np.array([0] * 5 + [1] * 5)\\n236.     clf = CheckingClassifier(expected_fit_params=[\\\'spam\\\'])\\n237.     grid_search = GridSearchCV(clf, {\\\'foo_param\\\': [1, 2, 3]},\\n238.                                fit_params={\\\'spam\\\': np.ones(10)})\\n239.     assert_warns(DeprecationWarning, grid_search.fit, X, y)\\n240. \\n241. \\n242. def test_grid_search_fit_params_two_places():\\n243.     # NOTE: Remove this test in v0.21\\n244. \\n245.     # If users try to input fit parameters in both\\n246.     # the constructor (deprecated use) and the `fit`\\n247.     # method, we\\\'ll ignore the values passed to the constructor.\\n248.     X = np.arange(100).reshape(10, 10)\\n249.     y = np.array([0] * 5 + [1] * 5)\\n250.     clf = CheckingClassifier(expected_fit_params=[\\\'spam\\\'])\\n251. \\n252.     # The "spam" array is too short and will raise an\\n253.     # error in the CheckingClassifier if used.\\n254.     grid_search = GridSearchCV(clf, {\\\'foo_param\\\': [1, 2, 3]},\\n255.                                fit_params={\\\'spam\\\': np.ones(1)})\\n256. \\n257.     expected_warning = (\\\'Ignoring fit_params passed as a constructor \\\'\\n258.                         \\\'argument in favor of keyword arguments to \\\'\\n259.                         \\\'the "fit" method.\\\')\\n260.     assert_warns_message(RuntimeWarning, expected_warning,\\n261.                          grid_search.fit, X, y, spam=np.ones(10))\\n262. \\n263.     # Verify that `fit` prefers its own kwargs by giving valid\\n264.     # kwargs in the constructor and invalid in the method call\\n265.     grid_search = GridSearchCV(clf, {\\\'foo_param\\\': [1, 2, 3]},\\n266.                                fit_params={\\\'spam\\\': np.ones(10)})\\n267.     assert_raise_message(AssertionError, "Fit parameter spam has length 1",\\n268.                          grid_search.fit, X, y, spam=np.ones(1))\\n269. \\n270. \\n271. @ignore_warnings\\n272. def test_grid_search_no_score():\\n273.     # Test grid-search on classifier that has no score function.\\n274.     clf = LinearSVC(random_state=0)\\n275.     X, y = make_blobs(random_state=0, centers=2)\\n276.     Cs = [.1, 1, 10]\\n277.     clf_no_score = LinearSVCNoScore(random_state=0)\\n278.     grid_search = GridSearchCV(clf, {\\\'C\\\': Cs}, scoring=\\\'accuracy\\\')\\n279.     grid_search.fit(X, y)\\n280. \\n281.     grid_search_no_score = GridSearchCV(clf_no_score, {\\\'C\\\': Cs},\\n282.                                         scoring=\\\'accuracy\\\')\\n283.     # smoketest grid search\\n284.     grid_search_no_score.fit(X, y)\\n285. \\n286.     # check that best params are equal\\n287.     assert_equal(grid_search_no_score.best_params_, grid_search.best_params_)\\n288.     # check that we can call score and that it gives the correct result\\n289.     assert_equal(grid_search.score(X, y), grid_search_no_score.score(X, y))\\n290. \\n291.     # giving no scoring function raises an error\\n292.     grid_search_no_score = GridSearchCV(clf_no_score, {\\\'C\\\': Cs})\\n293.     assert_raise_message(TypeError, "no scoring", grid_search_no_score.fit,\\n294.                          [[1]])\\n295. \\n296. \\n297. def test_grid_search_score_method():\\n298.     X, y = make_classification(n_samples=100, n_classes=2, flip_y=.2,\\n299.                                random_state=0)\\n300.     clf = LinearSVC(random_state=0)\\n301.     grid = {\\\'C\\\': [.1]}\\n302. \\n303.     search_no_scoring = GridSearchCV(clf, grid, scoring=None).fit(X, y)\\n304.     search_accuracy = GridSearchCV(clf, grid, scoring=\\\'accuracy\\\').fit(X, y)\\n305.     search_no_score_method_auc = GridSearchCV(LinearSVCNoScore(), grid,\\n306.                                               scoring=\\\'roc_auc\\\').fit(X, y)\\n307.     search_auc = GridSearchCV(clf, grid, scoring=\\\'roc_auc\\\').fit(X, y)\\n308. \\n309.     # Check warning only occurs in situation where behavior changed:\\n310.     # estimator requires score method to compete with scoring parameter\\n311.     score_no_scoring = search_no_scoring.score(X, y)\\n312.     score_accuracy = search_accuracy.score(X, y)\\n313.     score_no_score_auc = search_no_score_method_auc.score(X, y)\\n314.     score_auc = search_auc.score(X, y)\\n315. \\n316.     # ensure the test is sane\\n317.     assert_true(score_auc < 1.0)\\n318.     assert_true(score_accuracy < 1.0)\\n319.     assert_not_equal(score_auc, score_accuracy)\\n320. \\n321.     assert_almost_equal(score_accuracy, score_no_scoring)\\n322.     assert_almost_equal(score_auc, score_no_score_auc)\\n323. \\n324. \\n325. def test_grid_search_groups():\\n326.     # Check if ValueError (when groups is None) propagates to GridSearchCV\\n327.     # And also check if groups is correctly passed to the cv object\\n328.     rng = np.random.RandomState(0)\\n329. \\n330.     X, y = make_classification(n_samples=15, n_classes=2, random_state=0)\\n331.     groups = rng.randint(0, 3, 15)\\n332. \\n333.     clf = LinearSVC(random_state=0)\\n334.     grid = {\\\'C\\\': [1]}\\n335. \\n336.     group_cvs = [LeaveOneGroupOut(), LeavePGroupsOut(2), GroupKFold(),\\n337.                  GroupShuffleSplit()]\\n338.     for cv in group_cvs:\\n339.         gs = GridSearchCV(clf, grid, cv=cv)\\n340.         assert_raise_message(ValueError,\\n341.                              "The \\\'groups\\\' parameter should not be None.",\\n342.                              gs.fit, X, y)\\n343.         gs.fit(X, y, groups=groups)\\n344. \\n345.     non_group_cvs = [StratifiedKFold(), StratifiedShuffleSplit()]\\n346.     for cv in non_group_cvs:\\n347.         gs = GridSearchCV(clf, grid, cv=cv)\\n348.         # Should not raise an error\\n349.         gs.fit(X, y)\\n350. \\n351. \\n352. def test_return_train_score_warn():\\n353.     # Test that warnings are raised. Will be removed in 0.21\\n354. \\n355.     X = np.arange(100).reshape(10, 10)\\n356.     y = np.array([0] * 5 + [1] * 5)\\n357.     grid = {\\\'C\\\': [1, 2]}\\n358. \\n359.     estimators = [GridSearchCV(LinearSVC(random_state=0), grid, iid=False),\\n360.                   RandomizedSearchCV(LinearSVC(random_state=0), grid,\\n361.                                      n_iter=2, iid=False)]\\n362. \\n363.     result = {}\\n364.     for estimator in estimators:\\n365.         for val in [True, False, \\\'warn\\\']:\\n366.             estimator.set_params(return_train_score=val)\\n367.             fit_func = ignore_warnings(estimator.fit,\\n368.                                        category=ConvergenceWarning)\\n369.             result[val] = assert_no_warnings(fit_func, X, y).cv_results_\\n370. \\n371.     train_keys = [\\\'split0_train_score\\\', \\\'split1_train_score\\\',\\n372.                   \\\'split2_train_score\\\', \\\'mean_train_score\\\', \\\'std_train_score\\\']\\n373.     for key in train_keys:\\n374.         msg = (\\n375.             \\\'You are accessing a training score ({!r}), \\\'\\n376.             \\\'which will not be available by default \\\'\\n377.             \\\'any more in 0.21. If you need training scores, \\\'\\n378.             \\\'please set return_train_score=True\\\').format(key)\\n379.         train_score = assert_warns_message(FutureWarning, msg,\\n380.                                            result[\\\'warn\\\'].get, key)\\n381.         assert np.allclose(train_score, result[True][key])\\n382.         assert key not in result[False]\\n383. \\n384.     for key in result[\\\'warn\\\']:\\n385.         if key not in train_keys:\\n386.             assert_no_warnings(result[\\\'warn\\\'].get, key)\\n387. \\n388. \\n389. def test_classes__property():\\n390.     # Test that classes_ property matches best_estimator_.classes_\\n391.     X = np.arange(100).reshape(10, 10)\\n392.     y = np.array([0] * 5 + [1] * 5)\\n393.     Cs = [.1, 1, 10]\\n394. \\n395.     grid_search = GridSearchCV(LinearSVC(random_state=0), {\\\'C\\\': Cs})\\n396.     grid_search.fit(X, y)\\n397.     assert_array_equal(grid_search.best_estimator_.classes_,\\n398.                        grid_search.classes_)\\n399. \\n400.     # Test that regressors do not have a classes_ attribute\\n401.     grid_search = GridSearchCV(Ridge(), {\\\'alpha\\\': [1.0, 2.0]})\\n402.     grid_search.fit(X, y)\\n403.     assert_false(hasattr(grid_search, \\\'classes_\\\'))\\n404. \\n405.     # Test that the grid searcher has no classes_ attribute before it\\\'s fit\\n406.     grid_search = GridSearchCV(LinearSVC(random_state=0), {\\\'C\\\': Cs})\\n407.     assert_false(hasattr(grid_search, \\\'classes_\\\'))\\n408. \\n409.     # Test that the grid searcher has no classes_ attribute without a refit\\n410.     grid_search = GridSearchCV(LinearSVC(random_state=0),\\n411.                                {\\\'C\\\': Cs}, refit=False)\\n412.     grid_search.fit(X, y)\\n413.     assert_false(hasattr(grid_search, \\\'classes_\\\'))\\n414. \\n415. \\n416. def test_trivial_cv_results_attr():\\n417.     # Test search over a "grid" with only one point.\\n418.     # Non-regression test: grid_scores_ wouldn\\\'t be set by GridSearchCV.\\n419.     clf = MockClassifier()\\n420.     grid_search = GridSearchCV(clf, {\\\'foo_param\\\': [1]})\\n421.     grid_search.fit(X, y)\\n422.     assert_true(hasattr(grid_search, "cv_results_"))\\n423. \\n424.     random_search = RandomizedSearchCV(clf, {\\\'foo_param\\\': [0]}, n_iter=1)\\n425.     random_search.fit(X, y)\\n426.     assert_true(hasattr(grid_search, "cv_results_"))\\n427. \\n428. \\n429. def test_no_refit():\\n430.     # Test that GSCV can be used for model selection alone without refitting\\n431.     clf = MockClassifier()\\n432.     for scoring in [None, [\\\'accuracy\\\', \\\'precision\\\']]:\\n433.         grid_search = GridSearchCV(clf, {\\\'foo_param\\\': [1, 2, 3]}, refit=False)\\n434.         grid_search.fit(X, y)\\n435.         assert_true(not hasattr(grid_search, "best_estimator_") and\\n436.                     hasattr(grid_search, "best_index_") and\\n437.                     hasattr(grid_search, "best_params_"))\\n438. \\n439.         # Make sure the functions predict/transform etc raise meaningful\\n440.         # error messages\\n441.         for fn_name in (\\\'predict\\\', \\\'predict_proba\\\', \\\'predict_log_proba\\\',\\n442.                         \\\'transform\\\', \\\'inverse_transform\\\'):\\n443.             assert_raise_message(NotFittedError,\\n444.                                  (\\\'refit=False. %s is available only after \\\'\\n445.                                   \\\'refitting on the best parameters\\\'\\n446.                                   % fn_name), getattr(grid_search, fn_name), X)\\n447. \\n448.     # Test that an invalid refit param raises appropriate error messages\\n449.     for refit in ["", 5, True, \\\'recall\\\', \\\'accuracy\\\']:\\n450.         assert_raise_message(ValueError, "For multi-metric scoring, the "\\n451.                              "parameter refit must be set to a scorer key",\\n452.                              GridSearchCV(clf, {}, refit=refit,\\n453.                                           scoring={\\\'acc\\\': \\\'accuracy\\\',\\n454.                                                    \\\'prec\\\': \\\'precision\\\'}).fit,\\n455.                              X, y)\\n456. \\n457. \\n458. def test_grid_search_error():\\n459.     # Test that grid search will capture errors on data with different length\\n460.     X_, y_ = make_classification(n_samples=200, n_features=100, random_state=0)\\n461. \\n462.     clf = LinearSVC()\\n463.     cv = GridSearchCV(clf, {\\\'C\\\': [0.1, 1.0]})\\n464.     assert_raises(ValueError, cv.fit, X_[:180], y_)\\n465. \\n466. \\n467. def test_grid_search_one_grid_point():\\n468.     X_, y_ = make_classification(n_samples=200, n_features=100, random_state=0)\\n469.     param_dict = {"C": [1.0], "kernel": ["rbf"], "gamma": [0.1]}\\n470. \\n471.     clf = SVC()\\n472.     cv = GridSearchCV(clf, param_dict)\\n473.     cv.fit(X_, y_)\\n474. \\n475.     clf = SVC(C=1.0, kernel="rbf", gamma=0.1)\\n476.     clf.fit(X_, y_)\\n477. \\n478.     assert_array_equal(clf.dual_coef_, cv.best_estimator_.dual_coef_)\\n479. \\n480. \\n481. def test_grid_search_when_param_grid_includes_range():\\n482.     # Test that the best estimator contains the right value for foo_param\\n483.     clf = MockClassifier()\\n484.     grid_search = None\\n485.     if PY3_OR_LATER:\\n486.         grid_search = GridSearchCV(clf, {\\\'foo_param\\\': range(1, 4)})\\n487.     else:\\n488.         grid_search = GridSearchCV(clf, {\\\'foo_param\\\': xrange(1, 4)})\\n489.     grid_search.fit(X, y)\\n490.     assert_equal(grid_search.best_estimator_.foo_param, 2)\\n491. \\n492. \\n493. def test_grid_search_bad_param_grid():\\n494.     param_dict = {"C": 1.0}\\n495.     clf = SVC()\\n496.     assert_raise_message(\\n497.         ValueError,\\n498.         "Parameter values for parameter (C) need to be a sequence"\\n499.         "(but not a string) or np.ndarray.",\\n500.         GridSearchCV, clf, param_dict)\\n501. \\n502.     param_dict = {"C": []}\\n503.     clf = SVC(gamma="scale")\\n504.     assert_raise_message(\\n505.         ValueError,\\n506.         "Parameter values for parameter (C) need to be a non-empty sequence.",\\n507.         GridSearchCV, clf, param_dict)\\n508. \\n509.     param_dict = {"C": "1,2,3"}\\n510.     clf = SVC()\\n511.     assert_raise_message(\\n512.         ValueError,\\n513.         "Parameter values for parameter (C) need to be a sequence"\\n514.         "(but not a string) or np.ndarray.",\\n515.         GridSearchCV, clf, param_dict)\\n516. \\n517.     param_dict = {"C": np.ones(6).reshape(3, 2)}\\n518.     clf = SVC(gamma="scale")\\n519.     assert_raises(ValueError, GridSearchCV, clf, param_dict)\\n520. \\n521. \\n522. def test_grid_search_sparse():\\n523.     # Test that grid search works with both dense and sparse matrices\\n524.     X_, y_ = make_classification(n_samples=200, n_features=100, random_state=0)\\n525. \\n526.     clf = LinearSVC()\\n527.     cv = GridSearchCV(clf, {\\\'C\\\': [0.1, 1.0]})\\n528.     cv.fit(X_[:180], y_[:180])\\n529.     y_pred = cv.predict(X_[180:])\\n530.     C = cv.best_estimator_.C\\n531. \\n532.     X_ = sp.csr_matrix(X_)\\n533.     clf = LinearSVC()\\n534.     cv = GridSearchCV(clf, {\\\'C\\\': [0.1, 1.0]})\\n535.     cv.fit(X_[:180].tocoo(), y_[:180])\\n536.     y_pred2 = cv.predict(X_[180:])\\n537.     C2 = cv.best_estimator_.C\\n538. \\n539.     assert_true(np.mean(y_pred == y_pred2) >= .9)\\n540.     assert_equal(C, C2)\\n541. \\n542. \\n543. def test_grid_search_sparse_scoring():\\n544.     X_, y_ = make_classification(n_samples=200, n_features=100, random_state=0)\\n545. \\n546.     clf = LinearSVC()\\n547.     cv = GridSearchCV(clf, {\\\'C\\\': [0.1, 1.0]}, scoring="f1")\\n548.     cv.fit(X_[:180], y_[:180])\\n549.     y_pred = cv.predict(X_[180:])\\n550.     C = cv.best_estimator_.C\\n551. \\n552.     X_ = sp.csr_matrix(X_)\\n553.     clf = LinearSVC()\\n554.     cv = GridSearchCV(clf, {\\\'C\\\': [0.1, 1.0]}, scoring="f1")\\n555.     cv.fit(X_[:180], y_[:180])\\n556.     y_pred2 = cv.predict(X_[180:])\\n557.     C2 = cv.best_estimator_.C\\n558. \\n559.     assert_array_equal(y_pred, y_pred2)\\n560.     assert_equal(C, C2)\\n561.     # Smoke test the score\\n562.     # np.testing.assert_allclose(f1_score(cv.predict(X_[:180]), y[:180]),\\n563.     #                            cv.score(X_[:180], y[:180]))\\n564. \\n565.     # test loss where greater is worse\\n566.     def f1_loss(y_true_, y_pred_):\\n567.         return -f1_score(y_true_, y_pred_)\\n568.     F1Loss = make_scorer(f1_loss, greater_is_better=False)\\n569.     cv = GridSearchCV(clf, {\\\'C\\\': [0.1, 1.0]}, scoring=F1Loss)\\n570.     cv.fit(X_[:180], y_[:180])\\n571.     y_pred3 = cv.predict(X_[180:])\\n572.     C3 = cv.best_estimator_.C\\n573. \\n574.     assert_equal(C, C3)\\n575.     assert_array_equal(y_pred, y_pred3)\\n576. \\n577. \\n578. def test_grid_search_precomputed_kernel():\\n579.     # Test that grid search works when the input features are given in the\\n580.     # form of a precomputed kernel matrix\\n581.     X_, y_ = make_classification(n_samples=200, n_features=100, random_state=0)\\n582. \\n583.     # compute the training kernel matrix corresponding to the linear kernel\\n584.     K_train = np.dot(X_[:180], X_[:180].T)\\n585.     y_train = y_[:180]\\n586. \\n587.     clf = SVC(kernel=\\\'precomputed\\\')\\n588.     cv = GridSearchCV(clf, {\\\'C\\\': [0.1, 1.0]})\\n589.     cv.fit(K_train, y_train)\\n590. \\n591.     assert_true(cv.best_score_ >= 0)\\n592. \\n593.     # compute the test kernel matrix\\n594.     K_test = np.dot(X_[180:], X_[:180].T)\\n595.     y_test = y_[180:]\\n596. \\n597.     y_pred = cv.predict(K_test)\\n598. \\n599.     assert_true(np.mean(y_pred == y_test) >= 0)\\n600. \\n601.     # test error is raised when the precomputed kernel is not array-like\\n602.     # or sparse\\n603.     assert_raises(ValueError, cv.fit, K_train.tolist(), y_train)\\n604. \\n605. \\n606. def test_grid_search_precomputed_kernel_error_nonsquare():\\n607.     # Test that grid search returns an error with a non-square precomputed\\n608.     # training kernel matrix\\n609.     K_train = np.zeros((10, 20))\\n610.     y_train = np.ones((10, ))\\n611.     clf = SVC(kernel=\\\'precomputed\\\')\\n612.     cv = GridSearchCV(clf, {\\\'C\\\': [0.1, 1.0]})\\n613.     assert_raises(ValueError, cv.fit, K_train, y_train)\\n614. \\n615. \\n616. class BrokenClassifier(BaseEstimator):\\n617.     """Broken classifier that cannot be fit twice"""\\n618. \\n619.     def __init__(self, parameter=None):\\n620.         self.parameter = parameter\\n621. \\n622.     def fit(self, X, y):\\n623.         assert_true(not hasattr(self, \\\'has_been_fit_\\\'))\\n624.         self.has_been_fit_ = True\\n625. \\n626.     def predict(self, X):\\n627.         return np.zeros(X.shape[0])\\n628. \\n629. \\n630. @ignore_warnings\\n631. def test_refit():\\n632.     # Regression test for bug in refitting\\n633.     # Simulates re-fitting a broken estimator; this used to break with\\n634.     # sparse SVMs.\\n635.     X = np.arange(100).reshape(10, 10)\\n636.     y = np.array([0] * 5 + [1] * 5)\\n637. \\n638.     clf = GridSearchCV(BrokenClassifier(), [{\\\'parameter\\\': [0, 1]}],\\n639.                        scoring="precision", refit=True)\\n640.     clf.fit(X, y)\\n641. \\n642. \\n643. def test_gridsearch_nd():\\n644.     # Pass X as list in GridSearchCV\\n645.     X_4d = np.arange(10 * 5 * 3 * 2).reshape(10, 5, 3, 2)\\n646.     y_3d = np.arange(10 * 7 * 11).reshape(10, 7, 11)\\n647.     check_X = lambda x: x.shape[1:] == (5, 3, 2)\\n648.     check_y = lambda x: x.shape[1:] == (7, 11)\\n649.     clf = CheckingClassifier(check_X=check_X, check_y=check_y)\\n650.     grid_search = GridSearchCV(clf, {\\\'foo_param\\\': [1, 2, 3]})\\n651.     grid_search.fit(X_4d, y_3d).score(X, y)\\n652.     assert_true(hasattr(grid_search, "cv_results_"))\\n653. \\n654. \\n655. def test_X_as_list():\\n656.     # Pass X as list in GridSearchCV\\n657.     X = np.arange(100).reshape(10, 10)\\n658.     y = np.array([0] * 5 + [1] * 5)\\n659. \\n660.     clf = CheckingClassifier(check_X=lambda x: isinstance(x, list))\\n661.     cv = KFold(n_splits=3)\\n662.     grid_search = GridSearchCV(clf, {\\\'foo_param\\\': [1, 2, 3]}, cv=cv)\\n663.     grid_search.fit(X.tolist(), y).score(X, y)\\n664.     assert_true(hasattr(grid_search, "cv_results_"))\\n665. \\n666. \\n667. def test_y_as_list():\\n668.     # Pass y as list in GridSearchCV\\n669.     X = np.arange(100).reshape(10, 10)\\n670.     y = np.array([0] * 5 + [1] * 5)\\n671. \\n672.     clf = CheckingClassifier(check_y=lambda x: isinstance(x, list))\\n673.     cv = KFold(n_splits=3)\\n674.     grid_search = GridSearchCV(clf, {\\\'foo_param\\\': [1, 2, 3]}, cv=cv)\\n675.     grid_search.fit(X, y.tolist()).score(X, y)\\n676.     assert_true(hasattr(grid_search, "cv_results_"))\\n677. \\n678. \\n679. @ignore_warnings\\n680. def test_pandas_input():\\n681.     # check cross_val_score doesn\\\'t destroy pandas dataframe\\n682.     types = [(MockDataFrame, MockDataFrame)]\\n683.     try:\\n684.         from pandas import Series, DataFrame\\n685.         types.append((DataFrame, Series))\\n686.     except ImportError:\\n687.         pass\\n688. \\n689.     X = np.arange(100).reshape(10, 10)\\n690.     y = np.array([0] * 5 + [1] * 5)\\n691. \\n692.     for InputFeatureType, TargetType in types:\\n693.         # X dataframe, y series\\n694.         X_df, y_ser = InputFeatureType(X), TargetType(y)\\n695. \\n696.         def check_df(x):\\n697.             return isinstance(x, InputFeatureType)\\n698. \\n699.         def check_series(x):\\n700.             return isinstance(x, TargetType)\\n701. \\n702.         clf = CheckingClassifier(check_X=check_df, check_y=check_series)\\n703. \\n704.         grid_search = GridSearchCV(clf, {\\\'foo_param\\\': [1, 2, 3]})\\n705.         grid_search.fit(X_df, y_ser).score(X_df, y_ser)\\n706.         grid_search.predict(X_df)\\n707.         assert_true(hasattr(grid_search, "cv_results_"))\\n708. \\n709. \\n710. def test_unsupervised_grid_search():\\n711.     # test grid-search with unsupervised estimator\\n712.     X, y = make_blobs(random_state=0)\\n713.     km = KMeans(random_state=0)\\n714. \\n715.     # Multi-metric evaluation unsupervised\\n716.     scoring = [\\\'adjusted_rand_score\\\', \\\'fowlkes_mallows_score\\\']\\n717.     for refit in [\\\'adjusted_rand_score\\\', \\\'fowlkes_mallows_score\\\']:\\n718.         grid_search = GridSearchCV(km, param_grid=dict(n_clusters=[2, 3, 4]),\\n719.                                    scoring=scoring, refit=refit)\\n720.         grid_search.fit(X, y)\\n721.         # Both ARI and FMS can find the right number :)\\n722.         assert_equal(grid_search.best_params_["n_clusters"], 3)\\n723. \\n724.     # Single metric evaluation unsupervised\\n725.     grid_search = GridSearchCV(km, param_grid=dict(n_clusters=[2, 3, 4]),\\n726.                                scoring=\\\'fowlkes_mallows_score\\\')\\n727.     grid_search.fit(X, y)\\n728.     assert_equal(grid_search.best_params_["n_clusters"], 3)\\n729. \\n730.     # Now without a score, and without y\\n731.     grid_search = GridSearchCV(km, param_grid=dict(n_clusters=[2, 3, 4]))\\n732.     grid_search.fit(X)\\n733.     assert_equal(grid_search.best_params_["n_clusters"], 4)\\n734. \\n735. \\n736. def test_gridsearch_no_predict():\\n737.     # test grid-search with an estimator without predict.\\n738.     # slight duplication of a test from KDE\\n739.     def custom_scoring(estimator, X):\\n740.         return 42 if estimator.bandwidth == .1 else 0\\n741.     X, _ = make_blobs(cluster_std=.1, random_state=1,\\n742.                       centers=[[0, 1], [1, 0], [0, 0]])\\n743.     search = GridSearchCV(KernelDensity(),\\n744.                           param_grid=dict(bandwidth=[.01, .1, 1]),\\n745.                           scoring=custom_scoring)\\n746.     search.fit(X)\\n747.     assert_equal(search.best_params_[\\\'bandwidth\\\'], .1)\\n748.     assert_equal(search.best_score_, 42)\\n749. \\n750. \\n751. def test_param_sampler():\\n752.     # test basic properties of param sampler\\n753.     param_distributions = {"kernel": ["rbf", "linear"],\\n754.                            "C": uniform(0, 1)}\\n755.     sampler = ParameterSampler(param_distributions=param_distributions,\\n756.                                n_iter=10, random_state=0)\\n757.     samples = [x for x in sampler]\\n758.     assert_equal(len(samples), 10)\\n759.     for sample in samples:\\n760.         assert_true(sample["kernel"] in ["rbf", "linear"])\\n761.         assert_true(0 <= sample["C"] <= 1)\\n762. \\n763.     # test that repeated calls yield identical parameters\\n764.     param_distributions = {"C": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\\n765.     sampler = ParameterSampler(param_distributions=param_distributions,\\n766.                                n_iter=3, random_state=0)\\n767.     assert_equal([x for x in sampler], [x for x in sampler])\\n768. \\n769.     if sp_version >= (0, 16):\\n770.         param_distributions = {"C": uniform(0, 1)}\\n771.         sampler = ParameterSampler(param_distributions=param_distributions,\\n772.                                    n_iter=10, random_state=0)\\n773.         assert_equal([x for x in sampler], [x for x in sampler])\\n774. \\n775. \\n776. def check_cv_results_array_types(search, param_keys, score_keys):\\n777.     # Check if the search `cv_results`\\\'s array are of correct types\\n778.     cv_results = search.cv_results_\\n779.     assert_true(all(isinstance(cv_results[param], np.ma.MaskedArray)\\n780.                     for param in param_keys))\\n781.     assert_true(all(cv_results[key].dtype == object for key in param_keys))\\n782.     assert_false(any(isinstance(cv_results[key], np.ma.MaskedArray)\\n783.                      for key in score_keys))\\n784.     assert_true(all(cv_results[key].dtype == np.float64\\n785.                     for key in score_keys if not key.startswith(\\\'rank\\\')))\\n786. \\n787.     scorer_keys = search.scorer_.keys() if search.multimetric_ else [\\\'score\\\']\\n788. \\n789.     for key in scorer_keys:\\n790.         assert_true(cv_results[\\\'rank_test_%s\\\' % key].dtype == np.int32)\\n791. \\n792. \\n793. def check_cv_results_keys(cv_results, param_keys, score_keys, n_cand):\\n794.     # Test the search.cv_results_ contains all the required results\\n795.     assert_array_equal(sorted(cv_results.keys()),\\n796.                        sorted(param_keys + score_keys + (\\\'params\\\',)))\\n797.     assert_true(all(cv_results[key].shape == (n_cand,)\\n798.                     for key in param_keys + score_keys))\\n799. \\n800. \\n801. def check_cv_results_grid_scores_consistency(search):\\n802.     # TODO Remove test in 0.20\\n803.     if search.multimetric_:\\n804.         assert_raise_message(AttributeError, "not available for multi-metric",\\n805.                              getattr, search, \\\'grid_scores_\\\')\\n806.     else:\\n807.         cv_results = search.cv_results_\\n808.         res_scores = np.vstack(list([cv_results["split%d_test_score" % i]\\n809.                                      for i in range(search.n_splits_)])).T\\n810.         res_means = cv_results["mean_test_score"]\\n811.         res_params = cv_results["params"]\\n812.         n_cand = len(res_params)\\n813.         grid_scores = assert_warns(DeprecationWarning, getattr,\\n814.                                    search, \\\'grid_scores_\\\')\\n815.         assert_equal(len(grid_scores), n_cand)\\n816.         # Check consistency of the structure of grid_scores\\n817.         for i in range(n_cand):\\n818.             assert_equal(grid_scores[i].parameters, res_params[i])\\n819.             assert_array_equal(grid_scores[i].cv_validation_scores,\\n820.                                res_scores[i, :])\\n821.             assert_array_equal(grid_scores[i].mean_validation_score,\\n822.                                res_means[i])\\n823. \\n824. \\n825. def test_grid_search_cv_results():\\n826.     X, y = make_classification(n_samples=50, n_features=4,\\n827.                                random_state=42)\\n828. \\n829.     n_splits = 3\\n830.     n_grid_points = 6\\n831.     params = [dict(kernel=[\\\'rbf\\\', ], C=[1, 10], gamma=[0.1, 1]),\\n832.               dict(kernel=[\\\'poly\\\', ], degree=[1, 2])]\\n833. \\n834.     param_keys = (\\\'param_C\\\', \\\'param_degree\\\', \\\'param_gamma\\\', \\\'param_kernel\\\')\\n835.     score_keys = (\\\'mean_test_score\\\', \\\'mean_train_score\\\',\\n836.                   \\\'rank_test_score\\\',\\n837.                   \\\'split0_test_score\\\', \\\'split1_test_score\\\',\\n838.                   \\\'split2_test_score\\\',\\n839.                   \\\'split0_train_score\\\', \\\'split1_train_score\\\',\\n840.                   \\\'split2_train_score\\\',\\n841.                   \\\'std_test_score\\\', \\\'std_train_score\\\',\\n842.                   \\\'mean_fit_time\\\', \\\'std_fit_time\\\',\\n843.                   \\\'mean_score_time\\\', \\\'std_score_time\\\')\\n844.     n_candidates = n_grid_points\\n845. \\n846.     for iid in (False, True):\\n847.         search = GridSearchCV(SVC(gamma=\\\'scale\\\'), cv=n_splits, iid=iid,\\n848.                               param_grid=params)\\n849.         search.fit(X, y)\\n850.         assert_equal(iid, search.iid)\\n851.         cv_results = search.cv_results_\\n852.         # Check if score and timing are reasonable\\n853.         assert_true(all(cv_results[\\\'rank_test_score\\\'] >= 1))\\n854.         assert_true(all(cv_results[k] >= 0) for k in score_keys\\n855.                     if k is not \\\'rank_test_score\\\')\\n856.         assert_true(all(cv_results[k] <= 1) for k in score_keys\\n857.                     if \\\'time\\\' not in k and\\n858.                     k is not \\\'rank_test_score\\\')\\n859.         # Check cv_results structure\\n860.         check_cv_results_array_types(search, param_keys, score_keys)\\n861.         check_cv_results_keys(cv_results, param_keys, score_keys, n_candidates)\\n862.         # Check masking\\n863.         cv_results = search.cv_results_\\n864.         n_candidates = len(search.cv_results_[\\\'params\\\'])\\n865.         assert_true(all((cv_results[\\\'param_C\\\'].mask[i] and\\n866.                          cv_results[\\\'param_gamma\\\'].mask[i] and\\n867.                          not cv_results[\\\'param_degree\\\'].mask[i])\\n868.                         for i in range(n_candidates)\\n869.                         if cv_results[\\\'param_kernel\\\'][i] == \\\'linear\\\'))\\n870.         assert_true(all((not cv_results[\\\'param_C\\\'].mask[i] and\\n871.                          not cv_results[\\\'param_gamma\\\'].mask[i] and\\n872.                          cv_results[\\\'param_degree\\\'].mask[i])\\n873.                         for i in range(n_candidates)\\n874.                         if cv_results[\\\'param_kernel\\\'][i] == \\\'rbf\\\'))\\n875.         check_cv_results_grid_scores_consistency(search)\\n876. \\n877. \\n878. def test_random_search_cv_results():\\n879.     X, y = make_classification(n_samples=50, n_features=4, random_state=42)\\n880. \\n881.     n_splits = 3\\n882.     n_search_iter = 30\\n883. \\n884.     params = dict(C=expon(scale=10), gamma=expon(scale=0.1))\\n885.     param_keys = (\\\'param_C\\\', \\\'param_gamma\\\')\\n886.     score_keys = (\\\'mean_test_score\\\', \\\'mean_train_score\\\',\\n887.                   \\\'rank_test_score\\\',\\n888.                   \\\'split0_test_score\\\', \\\'split1_test_score\\\',\\n889.                   \\\'split2_test_score\\\',\\n890.                   \\\'split0_train_score\\\', \\\'split1_train_score\\\',\\n891.                   \\\'split2_train_score\\\',\\n892.                   \\\'std_test_score\\\', \\\'std_train_score\\\',\\n893.                   \\\'mean_fit_time\\\', \\\'std_fit_time\\\',\\n894.                   \\\'mean_score_time\\\', \\\'std_score_time\\\')\\n895.     n_cand = n_search_iter\\n896. \\n897.     for iid in (False, True):\\n898.         search = RandomizedSearchCV(SVC(gamma=\\\'scale\\\'), n_iter=n_search_iter,\\n899.                                     cv=n_splits, iid=iid,\\n900.                                     param_distributions=params)\\n901.         search.fit(X, y)\\n902.         assert_equal(iid, search.iid)\\n903.         cv_results = search.cv_results_\\n904.         # Check results structure\\n905.         check_cv_results_array_types(search, param_keys, score_keys)\\n906.         check_cv_results_keys(cv_results, param_keys, score_keys, n_cand)\\n907.         # For random_search, all the param array vals should be unmasked\\n908.         assert_false(any(cv_results[\\\'param_C\\\'].mask) or\\n909.                      any(cv_results[\\\'param_gamma\\\'].mask))\\n910.         check_cv_results_grid_scores_consistency(search)\\n911. \\n912. \\n913. @ignore_warnings(category=DeprecationWarning)\\n914. def test_search_iid_param():\\n915.     # Test the IID parameter\\n916.     # noise-free simple 2d-data\\n917.     X, y = make_blobs(centers=[[0, 0], [1, 0], [0, 1], [1, 1]], random_state=0,\\n918.                       cluster_std=0.1, shuffle=False, n_samples=80)\\n919.     # split dataset into two folds that are not iid\\n920.     # first one contains data of all 4 blobs, second only from two.\\n921.     mask = np.ones(X.shape[0], dtype=np.bool)\\n922.     mask[np.where(y == 1)[0][::2]] = 0\\n923.     mask[np.where(y == 2)[0][::2]] = 0\\n924.     # this leads to perfect classification on one fold and a score of 1/3 on\\n925.     # the other\\n926.     # create "cv" for splits\\n927.     cv = [[mask, ~mask], [~mask, mask]]\\n928.     # once with iid=True (default)\\n929.     grid_search = GridSearchCV(SVC(), param_grid={\\\'C\\\': [1, 10]},\\n930.                                cv=cv)\\n931.     random_search = RandomizedSearchCV(SVC(), n_iter=2,\\n932.                                        param_distributions={\\\'C\\\': [1, 10]},\\n933.                                        cv=cv)\\n934.     for search in (grid_search, random_search):\\n935.         search.fit(X, y)\\n936.         assert_true(search.iid or search.iid is None)\\n937. \\n938.         test_cv_scores = np.array(list(search.cv_results_[\\\'split%d_test_score\\\'\\n939.                                                           % s_i][0]\\n940.                                        for s_i in range(search.n_splits_)))\\n941.         test_mean = search.cv_results_[\\\'mean_test_score\\\'][0]\\n942.         test_std = search.cv_results_[\\\'std_test_score\\\'][0]\\n943. \\n944.         train_cv_scores = np.array(list(search.cv_results_[\\\'split%d_train_\\\'\\n945.                                                            \\\'score\\\' % s_i][0]\\n946.                                         for s_i in range(search.n_splits_)))\\n947.         train_mean = search.cv_results_[\\\'mean_train_score\\\'][0]\\n948.         train_std = search.cv_results_[\\\'std_train_score\\\'][0]\\n949. \\n950.         # Test the first candidate\\n951.         assert_equal(search.cv_results_[\\\'param_C\\\'][0], 1)\\n952.         assert_array_almost_equal(test_cv_scores, [1, 1. / 3.])\\n953.         assert_array_almost_equal(train_cv_scores, [1, 1])\\n954. \\n955.         # for first split, 1/4 of dataset is in test, for second 3/4.\\n956.         # take weighted average and weighted std\\n957.         expected_test_mean = 1 * 1. / 4. + 1. / 3. * 3. / 4.\\n958.         expected_test_std = np.sqrt(1. / 4 * (expected_test_mean - 1) ** 2 +\\n959.                                     3. / 4 * (expected_test_mean - 1. / 3.) **\\n960.                                     2)\\n961.         assert_almost_equal(test_mean, expected_test_mean)\\n962.         assert_almost_equal(test_std, expected_test_std)\\n963.         assert_array_almost_equal(test_cv_scores,\\n964.                                   cross_val_score(SVC(C=1), X,\\n965.                                                   y, cv=cv))\\n966. \\n967.         # For the train scores, we do not take a weighted mean irrespective of\\n968.         # i.i.d. or not\\n969.         assert_almost_equal(train_mean, 1)\\n970.         assert_almost_equal(train_std, 0)\\n971. \\n972.     # once with iid=False\\n973.     grid_search = GridSearchCV(SVC(),\\n974.                                param_grid={\\\'C\\\': [1, 10]},\\n975.                                cv=cv, iid=False)\\n976.     random_search = RandomizedSearchCV(SVC(), n_iter=2,\\n977.                                        param_distributions={\\\'C\\\': [1, 10]},\\n978.                                        cv=cv, iid=False)\\n979. \\n980.     for search in (grid_search, random_search):\\n981.         search.fit(X, y)\\n982.         assert_false(search.iid)\\n983. \\n984.         test_cv_scores = np.array(list(search.cv_results_[\\\'split%d_test_score\\\'\\n985.                                                           % s][0]\\n986.                                        for s in range(search.n_splits_)))\\n987.         test_mean = search.cv_results_[\\\'mean_test_score\\\'][0]\\n988.         test_std = search.cv_results_[\\\'std_test_score\\\'][0]\\n989. \\n990.         train_cv_scores = np.array(list(search.cv_results_[\\\'split%d_train_\\\'\\n991.                                                            \\\'score\\\' % s][0]\\n992.                                         for s in range(search.n_splits_)))\\n993.         train_mean = search.cv_results_[\\\'mean_train_score\\\'][0]\\n994.         train_std = search.cv_results_[\\\'std_train_score\\\'][0]\\n995. \\n996.         assert_equal(search.cv_results_[\\\'param_C\\\'][0], 1)\\n997.         # scores are the same as above\\n998.         assert_array_almost_equal(test_cv_scores, [1, 1. / 3.])\\n999.         # Unweighted mean/std is used\\n1000.         assert_almost_equal(test_mean, np.mean(test_cv_scores))\\n1001.         assert_almost_equal(test_std, np.std(test_cv_scores))\\n1002. \\n1003.         # For the train scores, we do not take a weighted mean irrespective of\\n1004.         # i.i.d. or not\\n1005.         assert_almost_equal(train_mean, 1)\\n1006.         assert_almost_equal(train_std, 0)\\n1007. \\n1008. \\n1009. def test_grid_search_cv_results_multimetric():\\n1010.     X, y = make_classification(n_samples=50, n_features=4, random_state=42)\\n1011. \\n1012.     n_splits = 3\\n1013.     params = [dict(kernel=[\\\'rbf\\\', ], C=[1, 10], gamma=[0.1, 1]),\\n1014.               dict(kernel=[\\\'poly\\\', ], degree=[1, 2])]\\n1015. \\n1016.     for iid in (False, True):\\n1017.         grid_searches = []\\n1018.         for scoring in ({\\\'accuracy\\\': make_scorer(accuracy_score),\\n1019.                          \\\'recall\\\': make_scorer(recall_score)},\\n1020.                         \\\'accuracy\\\', \\\'recall\\\'):\\n1021.             grid_search = GridSearchCV(SVC(gamma=\\\'scale\\\'), cv=n_splits,\\n1022.                                        iid=iid, param_grid=params,\\n1023.                                        scoring=scoring, refit=False)\\n1024.             grid_search.fit(X, y)\\n1025.             assert_equal(grid_search.iid, iid)\\n1026.             grid_searches.append(grid_search)\\n1027. \\n1028.         compare_cv_results_multimetric_with_single(*grid_searches, iid=iid)\\n1029. \\n1030. \\n1031. def test_random_search_cv_results_multimetric():\\n1032.     X, y = make_classification(n_samples=50, n_features=4, random_state=42)\\n1033. \\n1034.     n_splits = 3\\n1035.     n_search_iter = 30\\n1036.     scoring = (\\\'accuracy\\\', \\\'recall\\\')\\n1037. \\n1038.     # Scipy 0.12\\\'s stats dists do not accept seed, hence we use param grid\\n1039.     params = dict(C=np.logspace(-10, 1), gamma=np.logspace(-5, 0, base=0.1))\\n1040.     for iid in (True, False):\\n1041.         for refit in (True, False):\\n1042.             random_searches = []\\n1043.             for scoring in ((\\\'accuracy\\\', \\\'recall\\\'), \\\'accuracy\\\', \\\'recall\\\'):\\n1044.                 # If True, for multi-metric pass refit=\\\'accuracy\\\'\\n1045.                 if refit:\\n1046.                     refit = \\\'accuracy\\\' if isinstance(scoring, tuple) else refit\\n1047.                 clf = SVC(probability=True, random_state=42)\\n1048.                 random_search = RandomizedSearchCV(clf, n_iter=n_search_iter,\\n1049.                                                    cv=n_splits, iid=iid,\\n1050.                                                    param_distributions=params,\\n1051.                                                    scoring=scoring,\\n1052.                                                    refit=refit, random_state=0)\\n1053.                 random_search.fit(X, y)\\n1054.                 random_searches.append(random_search)\\n1055. \\n1056.             compare_cv_results_multimetric_with_single(*random_searches,\\n1057.                                                        iid=iid)\\n1058.             if refit:\\n1059.                 compare_refit_methods_when_refit_with_acc(\\n1060.                     random_searches[0], random_searches[1], refit)\\n1061. \\n1062. \\n1063. def compare_cv_results_multimetric_with_single(\\n1064.         search_multi, search_acc, search_rec, iid):\\n1065.     """Compare multi-metric cv_results with the ensemble of multiple\\n1066.     single metric cv_results from single metric grid/random search"""\\n1067. \\n1068.     assert_equal(search_multi.iid, iid)\\n1069.     assert_true(search_multi.multimetric_)\\n1070.     assert_array_equal(sorted(search_multi.scorer_),\\n1071.                        (\\\'accuracy\\\', \\\'recall\\\'))\\n1072. \\n1073.     cv_results_multi = search_multi.cv_results_\\n1074.     cv_results_acc_rec = {re.sub(\\\'_score$\\\', \\\'_accuracy\\\', k): v\\n1075.                           for k, v in search_acc.cv_results_.items()}\\n1076.     cv_results_acc_rec.update({re.sub(\\\'_score$\\\', \\\'_recall\\\', k): v\\n1077.                                for k, v in search_rec.cv_results_.items()})\\n1078. \\n1079.     # Check if score and timing are reasonable, also checks if the keys\\n1080.     # are present\\n1081.     assert_true(all((np.all(cv_results_multi[k] <= 1) for k in (\\n1082.                     \\\'mean_score_time\\\', \\\'std_score_time\\\', \\\'mean_fit_time\\\',\\n1083.                     \\\'std_fit_time\\\'))))\\n1084. \\n1085.     # Compare the keys, other than time keys, among multi-metric and\\n1086.     # single metric grid search results. np.testing.assert_equal performs a\\n1087.     # deep nested comparison of the two cv_results dicts\\n1088.     np.testing.assert_equal({k: v for k, v in cv_results_multi.items()\\n1089.                              if not k.endswith(\\\'_time\\\')},\\n1090.                             {k: v for k, v in cv_results_acc_rec.items()\\n1091.                              if not k.endswith(\\\'_time\\\')})\\n1092. \\n1093. \\n1094. def compare_refit_methods_when_refit_with_acc(search_multi, search_acc, refit):\\n1095.     """Compare refit multi-metric search methods with single metric methods"""\\n1096.     if refit:\\n1097.         assert_equal(search_multi.refit, \\\'accuracy\\\')\\n1098.     else:\\n1099.         assert_false(search_multi.refit)\\n1100.     assert_equal(search_acc.refit, refit)\\n1101. \\n1102.     X, y = make_blobs(n_samples=100, n_features=4, random_state=42)\\n1103.     for method in (\\\'predict\\\', \\\'predict_proba\\\', \\\'predict_log_proba\\\'):\\n1104.         assert_almost_equal(getattr(search_multi, method)(X),\\n1105.                             getattr(search_acc, method)(X))\\n1106.     assert_almost_equal(search_multi.score(X, y), search_acc.score(X, y))\\n1107.     for key in (\\\'best_index_\\\', \\\'best_score_\\\', \\\'best_params_\\\'):\\n1108.         assert_equal(getattr(search_multi, key), getattr(search_acc, key))\\n1109. \\n1110. \\n1111. def test_search_cv_results_rank_tie_breaking():\\n1112.     X, y = make_blobs(n_samples=50, random_state=42)\\n1113. \\n1114.     # The two C values are close enough to give similar models\\n1115.     # which would result in a tie of their mean cv-scores\\n1116.     param_grid = {\\\'C\\\': [1, 1.001, 0.001]}\\n1117. \\n1118.     grid_search = GridSearchCV(SVC(gamma="scale"), param_grid=param_grid)\\n1119.     random_search = RandomizedSearchCV(SVC(gamma="scale"), n_iter=3,\\n1120.                                        param_distributions=param_grid)\\n1121. \\n1122.     for search in (grid_search, random_search):\\n1123.         search.fit(X, y)\\n1124.         cv_results = search.cv_results_\\n1125.         # Check tie breaking strategy -\\n1126.         # Check that there is a tie in the mean scores between\\n1127.         # candidates 1 and 2 alone\\n1128.         assert_almost_equal(cv_results[\\\'mean_test_score\\\'][0],\\n1129.                             cv_results[\\\'mean_test_score\\\'][1])\\n1130.         assert_almost_equal(cv_results[\\\'mean_train_score\\\'][0],\\n1131.                             cv_results[\\\'mean_train_score\\\'][1])\\n1132.         assert_false(np.allclose(cv_results[\\\'mean_test_score\\\'][1],\\n1133.                                  cv_results[\\\'mean_test_score\\\'][2]))\\n1134.         assert_false(np.allclose(cv_results[\\\'mean_train_score\\\'][1],\\n1135.                                  cv_results[\\\'mean_train_score\\\'][2]))\\n1136.         # \\\'min\\\' rank should be assigned to the tied candidates\\n1137.         assert_almost_equal(search.cv_results_[\\\'rank_test_score\\\'], [1, 1, 3])\\n1138. \\n1139. \\n1140. def test_search_cv_results_none_param():\\n1141.     X, y = [[1], [2], [3], [4], [5]], [0, 0, 0, 0, 1]\\n1142.     estimators = (DecisionTreeRegressor(), DecisionTreeClassifier())\\n1143.     est_parameters = {"random_state": [0, None]}\\n1144.     cv = KFold(random_state=0)\\n1145. \\n1146.     for est in estimators:\\n1147.         grid_search = GridSearchCV(est, est_parameters, cv=cv).fit(X, y)\\n1148.         assert_array_equal(grid_search.cv_results_[\\\'param_random_state\\\'],\\n1149.                            [0, None])\\n1150. \\n1151. \\n1152. @ignore_warnings()\\n1153. def test_search_cv_timing():\\n1154.     svc = LinearSVC(random_state=0)\\n1155. \\n1156.     X = [[1, ], [2, ], [3, ], [4, ]]\\n1157.     y = [0, 1, 1, 0]\\n1158. \\n1159.     gs = GridSearchCV(svc, {\\\'C\\\': [0, 1]}, cv=2, error_score=0)\\n1160.     rs = RandomizedSearchCV(svc, {\\\'C\\\': [0, 1]}, cv=2, error_score=0, n_iter=2)\\n1161. \\n1162.     for search in (gs, rs):\\n1163.         search.fit(X, y)\\n1164.         for key in [\\\'mean_fit_time\\\', \\\'std_fit_time\\\']:\\n1165.             # NOTE The precision of time.time in windows is not high\\n1166.             # enough for the fit/score times to be non-zero for trivial X and y\\n1167.             assert_true(np.all(search.cv_results_[key] >= 0))\\n1168.             assert_true(np.all(search.cv_results_[key] < 1))\\n1169. \\n1170.         for key in [\\\'mean_score_time\\\', \\\'std_score_time\\\']:\\n1171.             assert_true(search.cv_results_[key][1] >= 0)\\n1172.             assert_true(search.cv_results_[key][0] == 0.0)\\n1173.             assert_true(np.all(search.cv_results_[key] < 1))\\n1174. \\n1175. \\n1176. def test_grid_search_correct_score_results():\\n1177.     # test that correct scores are used\\n1178.     n_splits = 3\\n1179.     clf = LinearSVC(random_state=0)\\n1180.     X, y = make_blobs(random_state=0, centers=2)\\n1181.     Cs = [.1, 1, 10]\\n1182.     for score in [\\\'f1\\\', \\\'roc_auc\\\']:\\n1183.         grid_search = GridSearchCV(clf, {\\\'C\\\': Cs}, scoring=score, cv=n_splits)\\n1184.         cv_results = grid_search.fit(X, y).cv_results_\\n1185. \\n1186.         # Test scorer names\\n1187.         result_keys = list(cv_results.keys())\\n1188.         expected_keys = (("mean_test_score", "rank_test_score") +\\n1189.                          tuple("split%d_test_score" % cv_i\\n1190.                                for cv_i in range(n_splits)))\\n1191.         assert_true(all(np.in1d(expected_keys, result_keys)))\\n1192. \\n1193.         cv = StratifiedKFold(n_splits=n_splits)\\n1194.         n_splits = grid_search.n_splits_\\n1195.         for candidate_i, C in enumerate(Cs):\\n1196.             clf.set_params(C=C)\\n1197.             cv_scores = np.array(\\n1198.                 list(grid_search.cv_results_[\\\'split%d_test_score\\\'\\n1199.                                              % s][candidate_i]\\n1200.                      for s in range(n_splits)))\\n1201.             for i, (train, test) in enumerate(cv.split(X, y)):\\n1202.                 clf.fit(X[train], y[train])\\n1203.                 if score == "f1":\\n1204.                     correct_score = f1_score(y[test], clf.predict(X[test]))\\n1205.                 elif score == "roc_auc":\\n1206.                     dec = clf.decision_function(X[test])\\n1207.                     correct_score = roc_auc_score(y[test], dec)\\n1208.                 assert_almost_equal(correct_score, cv_scores[i])\\n1209. \\n1210. \\n1211. def test_fit_grid_point():\\n1212.     X, y = make_classification(random_state=0)\\n1213.     cv = StratifiedKFold(random_state=0)\\n1214.     svc = LinearSVC(random_state=0)\\n1215.     scorer = make_scorer(accuracy_score)\\n1216. \\n1217.     for params in ({\\\'C\\\': 0.1}, {\\\'C\\\': 0.01}, {\\\'C\\\': 0.001}):\\n1218.         for train, test in cv.split(X, y):\\n1219.             this_scores, this_params, n_test_samples = fit_grid_point(\\n1220.                 X, y, clone(svc), params, train, test,\\n1221.                 scorer, verbose=False)\\n1222. \\n1223.             est = clone(svc).set_params(**params)\\n1224.             est.fit(X[train], y[train])\\n1225.             expected_score = scorer(est, X[test], y[test])\\n1226. \\n1227.             # Test the return values of fit_grid_point\\n1228.             assert_almost_equal(this_scores, expected_score)\\n1229.             assert_equal(params, this_params)\\n1230.             assert_equal(n_test_samples, test.size)\\n1231. \\n1232.     # Should raise an error upon multimetric scorer\\n1233.     assert_raise_message(ValueError, "For evaluating multiple scores, use "\\n1234.                          "sklearn.model_selection.cross_validate instead.",\\n1235.                          fit_grid_point, X, y, svc, params, train, test,\\n1236.                          {\\\'score\\\': scorer}, verbose=True)\\n1237. \\n1238. \\n1239. def test_pickle():\\n1240.     # Test that a fit search can be pickled\\n1241.     clf = MockClassifier()\\n1242.     grid_search = GridSearchCV(clf, {\\\'foo_param\\\': [1, 2, 3]}, refit=True)\\n1243.     grid_search.fit(X, y)\\n1244.     grid_search_pickled = pickle.loads(pickle.dumps(grid_search))\\n1245.     assert_array_almost_equal(grid_search.predict(X),\\n1246.                               grid_search_pickled.predict(X))\\n1247. \\n1248.     random_search = RandomizedSearchCV(clf, {\\\'foo_param\\\': [1, 2, 3]},\\n1249.                                        refit=True, n_iter=3)\\n1250.     random_search.fit(X, y)\\n1251.     random_search_pickled = pickle.loads(pickle.dumps(random_search))\\n1252.     assert_array_almost_equal(random_search.predict(X),\\n1253.                               random_search_pickled.predict(X))\\n1254. \\n1255. \\n1256. def test_grid_search_with_multioutput_data():\\n1257.     # Test search with multi-output estimator\\n1258. \\n1259.     X, y = make_multilabel_classification(return_indicator=True,\\n1260.                                           random_state=0)\\n1261. \\n1262.     est_parameters = {"max_depth": [1, 2, 3, 4]}\\n1263.     cv = KFold(random_state=0)\\n1264. \\n1265.     estimators = [DecisionTreeRegressor(random_state=0),\\n1266.                   DecisionTreeClassifier(random_state=0)]\\n1267. \\n1268.     # Test with grid search cv\\n1269.     for est in estimators:\\n1270.         grid_search = GridSearchCV(est, est_parameters, cv=cv)\\n1271.         grid_search.fit(X, y)\\n1272.         res_params = grid_search.cv_results_[\\\'params\\\']\\n1273.         for cand_i in range(len(res_params)):\\n1274.             est.set_params(**res_params[cand_i])\\n1275. \\n1276.             for i, (train, test) in enumerate(cv.split(X, y)):\\n1277.                 est.fit(X[train], y[train])\\n1278.                 correct_score = est.score(X[test], y[test])\\n1279.                 assert_almost_equal(\\n1280.                     correct_score,\\n1281.                     grid_search.cv_results_[\\\'split%d_test_score\\\' % i][cand_i])\\n1282. \\n1283.     # Test with a randomized search\\n1284.     for est in estimators:\\n1285.         random_search = RandomizedSearchCV(est, est_parameters,\\n1286.                                            cv=cv, n_iter=3)\\n1287.         random_search.fit(X, y)\\n1288.         res_params = random_search.cv_results_[\\\'params\\\']\\n1289.         for cand_i in range(len(res_params)):\\n1290.             est.set_params(**res_params[cand_i])\\n1291. \\n1292.             for i, (train, test) in enumerate(cv.split(X, y)):\\n1293.                 est.fit(X[train], y[train])\\n1294.                 correct_score = est.score(X[test], y[test])\\n1295.                 assert_almost_equal(\\n1296.                     correct_score,\\n1297.                     random_search.cv_results_[\\\'split%d_test_score\\\'\\n1298.                                               % i][cand_i])\\n1299. \\n1300. \\n1301. def test_predict_proba_disabled():\\n1302.     # Test predict_proba when disabled on estimator.\\n1303.     X = np.arange(20).reshape(5, -1)\\n1304.     y = [0, 0, 1, 1, 1]\\n1305.     clf = SVC(gamma=\\\'scale\\\', probability=False)\\n1306.     gs = GridSearchCV(clf, {}, cv=2).fit(X, y)\\n1307.     assert_false(hasattr(gs, "predict_proba"))\\n1308. \\n1309. \\n1310. def test_grid_search_allows_nans():\\n1311.     # Test GridSearchCV with SimpleImputer\\n1312.     X = np.arange(20, dtype=np.float64).reshape(5, -1)\\n1313.     X[2, :] = np.nan\\n1314.     y = [0, 0, 1, 1, 1]\\n1315.     p = Pipeline([\\n1316.         (\\\'imputer\\\', SimpleImputer(strategy=\\\'mean\\\', missing_values=\\\'NaN\\\')),\\n1317.         (\\\'classifier\\\', MockClassifier()),\\n1318.     ])\\n1319.     GridSearchCV(p, {\\\'classifier__foo_param\\\': [1, 2, 3]}, cv=2).fit(X, y)\\n1320. \\n1321. \\n1322. class FailingClassifier(BaseEstimator):\\n1323.     """Classifier that raises a ValueError on fit()"""\\n1324. \\n1325.     FAILING_PARAMETER = 2\\n1326. \\n1327.     def __init__(self, parameter=None):\\n1328.         self.parameter = parameter\\n1329. \\n1330.     def fit(self, X, y=None):\\n1331.         if self.parameter == FailingClassifier.FAILING_PARAMETER:\\n1332.             raise ValueError("Failing classifier failed as required")\\n1333. \\n1334.     def predict(self, X):\\n1335.         return np.zeros(X.shape[0])\\n1336. \\n1337. \\n1338. def test_grid_search_failing_classifier():\\n1339.     # GridSearchCV with on_error != \\\'raise\\\'\\n1340.     # Ensures that a warning is raised and score reset where appropriate.\\n1341. \\n1342.     X, y = make_classification(n_samples=20, n_features=10, random_state=0)\\n1343. \\n1344.     clf = FailingClassifier()\\n1345. \\n1346.     # refit=False because we only want to check that errors caused by fits\\n1347.     # to individual folds will be caught and warnings raised instead. If\\n1348.     # refit was done, then an exception would be raised on refit and not\\n1349.     # caught by grid_search (expected behavior), and this would cause an\\n1350.     # error in this test.\\n1351.     gs = GridSearchCV(clf, [{\\\'parameter\\\': [0, 1, 2]}], scoring=\\\'accuracy\\\',\\n1352.                       refit=False, error_score=0.0)\\n1353.     assert_warns(FitFailedWarning, gs.fit, X, y)\\n1354.     n_candidates = len(gs.cv_results_[\\\'params\\\'])\\n1355. \\n1356.     # Ensure that grid scores were set to zero as required for those fits\\n1357.     # that are expected to fail.\\n1358.     def get_cand_scores(i):\\n1359.         return np.array(list(gs.cv_results_[\\\'split%d_test_score\\\' % s][i]\\n1360.                              for s in range(gs.n_splits_)))\\n1361. \\n1362.     assert all((np.all(get_cand_scores(cand_i) == 0.0)\\n1363.                 for cand_i in range(n_candidates)\\n1364.                 if gs.cv_results_[\\\'param_parameter\\\'][cand_i] ==\\n1365.                 FailingClassifier.FAILING_PARAMETER))\\n1366. \\n1367.     gs = GridSearchCV(clf, [{\\\'parameter\\\': [0, 1, 2]}], scoring=\\\'accuracy\\\',\\n1368.                       refit=False, error_score=float(\\\'nan\\\'))\\n1369.     assert_warns(FitFailedWarning, gs.fit, X, y)\\n1370.     n_candidates = len(gs.cv_results_[\\\'params\\\'])\\n1371.     assert all(np.all(np.isnan(get_cand_scores(cand_i)))\\n1372.                for cand_i in range(n_candidates)\\n1373.                if gs.cv_results_[\\\'param_parameter\\\'][cand_i] ==\\n1374.                FailingClassifier.FAILING_PARAMETER)\\n1375. \\n1376.     ranks = gs.cv_results_[\\\'rank_test_score\\\']\\n1377. \\n1378.     # Check that succeeded estimators have lower ranks\\n1379.     assert ranks[0] <= 2 and ranks[1] <= 2\\n1380.     # Check that failed estimator has the highest rank\\n1381.     assert ranks[clf.FAILING_PARAMETER] == 3\\n1382.     assert gs.best_index_ != clf.FAILING_PARAMETER\\n1383. \\n1384. \\n1385. def test_grid_search_failing_classifier_raise():\\n1386.     # GridSearchCV with on_error == \\\'raise\\\' raises the error\\n1387. \\n1388.     X, y = make_classification(n_samples=20, n_features=10, random_state=0)\\n1389. \\n1390.     clf = FailingClassifier()\\n1391. \\n1392.     # refit=False because we want to test the behaviour of the grid search part\\n1393.     gs = GridSearchCV(clf, [{\\\'parameter\\\': [0, 1, 2]}], scoring=\\\'accuracy\\\',\\n1394.                       refit=False, error_score=\\\'raise\\\')\\n1395. \\n1396.     # FailingClassifier issues a ValueError so this is what we look for.\\n1397.     assert_raises(ValueError, gs.fit, X, y)\\n1398. \\n1399. \\n1400. def test_parameters_sampler_replacement():\\n1401.     # raise warning if n_iter is bigger than total parameter space\\n1402.     params = {\\\'first\\\': [0, 1], \\\'second\\\': [\\\'a\\\', \\\'b\\\', \\\'c\\\']}\\n1403.     sampler = ParameterSampler(params, n_iter=7)\\n1404.     n_iter = 7\\n1405.     grid_size = 6\\n1406.     expected_warning = (\\\'The total space of parameters %d is smaller \\\'\\n1407.                         \\\'than n_iter=%d. Running %d iterations. For \\\'\\n1408.                         \\\'exhaustive searches, use GridSearchCV.\\\'\\n1409.                         % (grid_size, n_iter, grid_size))\\n1410.     assert_warns_message(UserWarning, expected_warning,\\n1411.                          list, sampler)\\n1412. \\n1413.     # degenerates to GridSearchCV if n_iter the same as grid_size\\n1414.     sampler = ParameterSampler(params, n_iter=6)\\n1415.     samples = list(sampler)\\n1416.     assert_equal(len(samples), 6)\\n1417.     for values in ParameterGrid(params):\\n1418.         assert_true(values in samples)\\n1419. \\n1420.     # test sampling without replacement in a large grid\\n1421.     params = {\\\'a\\\': range(10), \\\'b\\\': range(10), \\\'c\\\': range(10)}\\n1422.     sampler = ParameterSampler(params, n_iter=99, random_state=42)\\n1423.     samples = list(sampler)\\n1424.     assert_equal(len(samples), 99)\\n1425.     hashable_samples = ["a%db%dc%d" % (p[\\\'a\\\'], p[\\\'b\\\'], p[\\\'c\\\'])\\n1426.                         for p in samples]\\n1427.     assert_equal(len(set(hashable_samples)), 99)\\n1428. \\n1429.     # doesn\\\'t go into infinite loops\\n1430.     params_distribution = {\\\'first\\\': bernoulli(.5), \\\'second\\\': [\\\'a\\\', \\\'b\\\', \\\'c\\\']}\\n1431.     sampler = ParameterSampler(params_distribution, n_iter=7)\\n1432.     samples = list(sampler)\\n1433.     assert_equal(len(samples), 7)\\n1434. \\n1435. \\n1436. def test_stochastic_gradient_loss_param():\\n1437.     # Make sure the predict_proba works when loss is specified\\n1438.     # as one of the parameters in the param_grid.\\n1439.     param_grid = {\\n1440.         \\\'loss\\\': [\\\'log\\\'],\\n1441.     }\\n1442.     X = np.arange(24).reshape(6, -1)\\n1443.     y = [0, 0, 0, 1, 1, 1]\\n1444.     clf = GridSearchCV(estimator=SGDClassifier(tol=1e-3, loss=\\\'hinge\\\'),\\n1445.                        param_grid=param_grid)\\n1446. \\n1447.     # When the estimator is not fitted, `predict_proba` is not available as the\\n1448.     # loss is \\\'hinge\\\'.\\n1449.     assert_false(hasattr(clf, "predict_proba"))\\n1450.     clf.fit(X, y)\\n1451.     clf.predict_proba(X)\\n1452.     clf.predict_log_proba(X)\\n1453. \\n1454.     # Make sure `predict_proba` is not available when setting loss=[\\\'hinge\\\']\\n1455.     # in param_grid\\n1456.     param_grid = {\\n1457.         \\\'loss\\\': [\\\'hinge\\\'],\\n1458.     }\\n1459.     clf = GridSearchCV(estimator=SGDClassifier(tol=1e-3, loss=\\\'hinge\\\'),\\n1460.                        param_grid=param_grid)\\n1461.     assert_false(hasattr(clf, "predict_proba"))\\n1462.     clf.fit(X, y)\\n1463.     assert_false(hasattr(clf, "predict_proba"))\\n1464. \\n1465. \\n1466. def test_search_train_scores_set_to_false():\\n1467.     X = np.arange(6).reshape(6, -1)\\n1468.     y = [0, 0, 0, 1, 1, 1]\\n1469.     clf = LinearSVC(random_state=0)\\n1470. \\n1471.     gs = GridSearchCV(clf, param_grid={\\\'C\\\': [0.1, 0.2]},\\n1472.                       return_train_score=False)\\n1473.     gs.fit(X, y)\\n1474. \\n1475. \\n1476. def test_grid_search_cv_splits_consistency():\\n1477.     # Check if a one time iterable is accepted as a cv parameter.\\n1478.     n_samples = 100\\n1479.     n_splits = 5\\n1480.     X, y = make_classification(n_samples=n_samples, random_state=0)\\n1481. \\n1482.     gs = GridSearchCV(LinearSVC(random_state=0),\\n1483.                       param_grid={\\\'C\\\': [0.1, 0.2, 0.3]},\\n1484.                       cv=OneTimeSplitter(n_splits=n_splits,\\n1485.                                          n_samples=n_samples))\\n1486.     gs.fit(X, y)\\n1487. \\n1488.     gs2 = GridSearchCV(LinearSVC(random_state=0),\\n1489.                        param_grid={\\\'C\\\': [0.1, 0.2, 0.3]},\\n1490.                        cv=KFold(n_splits=n_splits))\\n1491.     gs2.fit(X, y)\\n1492. \\n1493.     # Give generator as a cv parameter\\n1494.     assert_true(isinstance(KFold(n_splits=n_splits,\\n1495.                                  shuffle=True, random_state=0).split(X, y),\\n1496.                            GeneratorType))\\n1497.     gs3 = GridSearchCV(LinearSVC(random_state=0),\\n1498.                        param_grid={\\\'C\\\': [0.1, 0.2, 0.3]},\\n1499.                        cv=KFold(n_splits=n_splits, shuffle=True,\\n1500.                                 random_state=0).split(X, y))\\n1501.     gs3.fit(X, y)\\n1502. \\n1503.     gs4 = GridSearchCV(LinearSVC(random_state=0),\\n1504.                        param_grid={\\\'C\\\': [0.1, 0.2, 0.3]},\\n1505.                        cv=KFold(n_splits=n_splits, shuffle=True,\\n1506.                                 random_state=0))\\n1507.     gs4.fit(X, y)\\n1508. \\n1509.     def _pop_time_keys(cv_results):\\n1510.         for key in (\\\'mean_fit_time\\\', \\\'std_fit_time\\\',\\n1511.                     \\\'mean_score_time\\\', \\\'std_score_time\\\'):\\n1512.             cv_results.pop(key)\\n1513.         return cv_results\\n1514. \\n1515.     # Check if generators are supported as cv and\\n1516.     # that the splits are consistent\\n1517.     np.testing.assert_equal(_pop_time_keys(gs3.cv_results_),\\n1518.                             _pop_time_keys(gs4.cv_results_))\\n1519. \\n1520.     # OneTimeSplitter is a non-re-entrant cv where split can be called only\\n1521.     # once if ``cv.split`` is called once per param setting in GridSearchCV.fit\\n1522.     # the 2nd and 3rd parameter will not be evaluated as no train/test indices\\n1523.     # will be generated for the 2nd and subsequent cv.split calls.\\n1524.     # This is a check to make sure cv.split is not called once per param\\n1525.     # setting.\\n1526.     np.testing.assert_equal({k: v for k, v in gs.cv_results_.items()\\n1527.                              if not k.endswith(\\\'_time\\\')},\\n1528.                             {k: v for k, v in gs2.cv_results_.items()\\n1529.                              if not k.endswith(\\\'_time\\\')})\\n1530. \\n1531.     # Check consistency of folds across the parameters\\n1532.     gs = GridSearchCV(LinearSVC(random_state=0),\\n1533.                       param_grid={\\\'C\\\': [0.1, 0.1, 0.2, 0.2]},\\n1534.                       cv=KFold(n_splits=n_splits, shuffle=True))\\n1535.     gs.fit(X, y)\\n1536. \\n1537.     # As the first two param settings (C=0.1) and the next two param\\n1538.     # settings (C=0.2) are same, the test and train scores must also be\\n1539.     # same as long as the same train/test indices are generated for all\\n1540.     # the cv splits, for both param setting\\n1541.     for score_type in (\\\'train\\\', \\\'test\\\'):\\n1542.         per_param_scores = {}\\n1543.         for param_i in range(4):\\n1544.             per_param_scores[param_i] = list(\\n1545.                 gs.cv_results_[\\\'split%d_%s_score\\\' % (s, score_type)][param_i]\\n1546.                 for s in range(5))\\n1547. \\n1548.         assert_array_almost_equal(per_param_scores[0],\\n1549.                                   per_param_scores[1])\\n1550.         assert_array_almost_equal(per_param_scores[2],\\n1551.                                   per_param_scores[3])\\n1552. \\n1553. \\n1554. def test_transform_inverse_transform_round_trip():\\n1555.     clf = MockClassifier()\\n1556.     grid_search = GridSearchCV(clf, {\\\'foo_param\\\': [1, 2, 3]}, verbose=3)\\n1557. \\n1558.     grid_search.fit(X, y)\\n1559.     X_round_trip = grid_search.inverse_transform(grid_search.transform(X))\\n1560.     assert_array_equal(X, X_round_trip)\\n1561. \\n1562. \\n1563. def test_deprecated_grid_search_iid():\\n1564.     depr_message = ("The default of the `iid` parameter will change from True "\\n1565.                     "to False in version 0.22")\\n1566.     X, y = make_blobs(n_samples=54, random_state=0, centers=2)\\n1567.     grid = GridSearchCV(SVC(gamma=\\\'scale\\\'), param_grid={\\\'C\\\': [1]}, cv=3)\\n1568.     # no warning with equally sized test sets\\n1569.     assert_no_warnings(grid.fit, X, y)\\n1570. \\n1571.     grid = GridSearchCV(SVC(gamma=\\\'scale\\\'), param_grid={\\\'C\\\': [1]}, cv=5)\\n1572.     # warning because 54 % 5 != 0\\n1573.     assert_warns_message(DeprecationWarning, depr_message, grid.fit, X, y)\\n1574. \\n1575.     grid = GridSearchCV(SVC(gamma=\\\'scale\\\'), param_grid={\\\'C\\\': [1]}, cv=2)\\n1576.     # warning because stratification into two classes and 27 % 2 != 0\\n1577.     assert_warns_message(DeprecationWarning, depr_message, grid.fit, X, y)\\n1578. \\n1579.     grid = GridSearchCV(SVC(gamma=\\\'scale\\\'), param_grid={\\\'C\\\': [1]}, cv=KFold(2))\\n1580.     # no warning because no stratification and 54 % 2 == 0\\n1581.     assert_no_warnings(grid.fit, X, y)\', \'start_line_number\': 1, \'end_line_number\': 1581}\n\nNow generate the complete self-contained test case that reproduces the bug with the same error/exception.\n' additional_kwargs={} response_metadata={}
2025-12-21 09:54:36,542 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_write_node - DEBUG - content='' additional_kwargs={} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 52357, 'total_token_count': 52357, 'prompt_tokens_details': [{'modality': 1, 'token_count': 52357}], 'candidates_token_count': 0, 'thoughts_token_count': 0, 'cached_content_token_count': 0, 'cache_tokens_details': [], 'candidates_tokens_details': []}, 'finish_reason': 'MALFORMED_FUNCTION_CALL', 'finish_message': 'Malformed function call: import pytest\nimport numpy as np\n\nfrom sklearn.datasets import load_iris\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\n\ndef test_refit_time():\n    """Test that refit_time_ is recorded for search CV estimators."""\n    X, y = load_iris(return_X_y=True)\n    params = {\'n_estimators\': [1, 2]}\n\n    searches = [\n        GridSearchCV(\n            estimator=RandomForestClassifier(random_state=0),\n            param_grid=params, cv=2, iid=False, refit=True),\n        RandomizedSearchCV(\n            estimator=RandomForestClassifier(random_state=0),\n            param_distributions=params, n_iter=1, cv=2, iid=False,\n            random_state=0, refit=True)\n    ]\n\n    for search in searches:\n        search.fit(X, y)\n        assert hasattr(search, \'refit_time_\')\n        assert isinstance(search.refit_time_, float)\n        assert search.refit_time_ >= 0', 'model_name': 'gemini-2.5-pro'} id='run--48473656-ee1e-405c-b669-359b365b034b-0' usage_metadata={'input_tokens': 52357, 'output_tokens': 0, 'total_tokens': 52357, 'input_token_details': {'cache_read': 0}}
2025-12-21 09:54:50,839 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_file_node - DEBUG - content='' additional_kwargs={'function_call': {'name': 'create_file', 'arguments': '{"content": "import pytest\\nfrom httpx import AsyncClient\\nfrom main import app\\n\\n@pytest.mark.asyncio\\nasync def test_read_root():\\n    async with AsyncClient(app=app, base_url=\\"http://test\\") as ac:\\n        response = await ac.get(\\"/\\")\\n    assert response.status_code == 200\\n    assert response.json() == {\\"message\\": \\"Hello World\\"}", "relative_path": "tests/test_bug.py"}'}, '__gemini_function_call_thought_signatures__': {'0b656f09-c39d-472e-9d69-30f1c746ccd4': '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'}} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 317, 'candidates_token_count': 104, 'total_token_count': 1720, 'prompt_tokens_details': [{'modality': 1, 'token_count': 317}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 104}], 'thoughts_token_count': 1299, 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -1.965471707857572, 'model_name': 'gemini-2.5-pro'} id='run--88ad0054-bcfb-40d0-989f-bdc4a40c4293-0' tool_calls=[{'name': 'create_file', 'args': {'content': 'import pytest\nfrom httpx import AsyncClient\nfrom main import app\n\n@pytest.mark.asyncio\nasync def test_read_root():\n    async with AsyncClient(app=app, base_url="http://test") as ac:\n        response = await ac.get("/")\n    assert response.status_code == 200\n    assert response.json() == {"message": "Hello World"}', 'relative_path': 'tests/test_bug.py'}, 'id': '0b656f09-c39d-472e-9d69-30f1c746ccd4', 'type': 'tool_call'}] usage_metadata={'input_tokens': 317, 'output_tokens': 104, 'total_tokens': 1720, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1299}}
2025-12-21 09:54:51,586 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_file_node - DEBUG - content='tests/test_bug.py' additional_kwargs={} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 438, 'candidates_token_count': 7, 'total_token_count': 445, 'prompt_tokens_details': [{'modality': 1, 'token_count': 1737}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 7}], 'thoughts_token_count': 0, 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.00027056194708815644, 'model_name': 'gemini-2.5-pro'} id='run--6277193a-cba6-426a-9218-4bcc90d1dffa-0' usage_metadata={'input_tokens': 438, 'output_tokens': 7, 'total_tokens': 445, 'input_token_details': {'cache_read': 0}}
2025-12-21 09:54:51,724 - thread-130546535499456.app.lang_graph.nodes.git_diff_node - INFO - Generated patch:
diff --git a/tests/test_bug.py b/tests/test_bug.py
new file mode 100644
index 0000000000..74cfae14c2
--- /dev/null
+++ b/tests/test_bug.py
@@ -0,0 +1,10 @@
+import pytest
+from httpx import AsyncClient
+from main import app
+
+@pytest.mark.asyncio
+async def test_read_root():
+    async with AsyncClient(app=app, base_url="http://test") as ac:
+        response = await ac.get("/")
+    assert response.status_code == 200
+    assert response.json() == {"message": "Hello World"}
\ No newline at end of file

2025-12-21 09:54:51,726 - thread-130546535499456.app.lang_graph.nodes.update_container_node - INFO - Copy over all updated files to the container
2025-12-21 09:54:51,766 - thread-130546535499456.app.docker.base_container - INFO - Resetting git repository in the container
2025-12-21 09:54:51,766 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: git reset --hard
2025-12-21 09:54:52,251 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 0
2025-12-21 09:54:52,251 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:

HEAD is now at 553b5fb8f BLD fix sphx gallery errors (#11307)

2025-12-21 09:54:52,251 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: git clean -fd
2025-12-21 09:54:52,353 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 0
2025-12-21 09:54:52,353 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:


2025-12-21 09:54:52,353 - thread-130546535499456.app.docker.base_container - INFO - Updating files in the container after edits.
2025-12-21 09:54:52,353 - thread-130546535499456.app.docker.base_container - INFO - Creating directory tests in the container
2025-12-21 09:54:52,353 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: mkdir -p tests
2025-12-21 09:54:52,455 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 0
2025-12-21 09:54:52,455 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:


2025-12-21 09:54:52,460 - thread-130546535499456.app.docker.base_container - INFO - Updating tests/test_bug.py in the container
2025-12-21 09:54:52,470 - thread-130546535499456.app.docker.base_container - INFO - Files updated successfully
2025-12-21 09:54:53,882 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_execute_node - DEBUG - content='' additional_kwargs={'function_call': {'name': 'run_command', 'arguments': '{"command": "ls -F"}'}, '__gemini_function_call_thought_signatures__': {'4e521b6d-2399-4bf0-81aa-37f9e1cc505d': 'CrACAY89a19esh63ZYJJ6cHsn5l/KbgJi2+ePDn5neUqhxLqQdUa7jBKOPzCb4nLbKNdwM2xSGrCfOj97D31BLNNPJA+g/7YRn+UCg3mLSlSyYTM+009Z3PJkytZWMnRN6iBL35sNrp7Ccw4xtLeoP6dK6wOviZVuFAngD850bXCqEm+RhVtyUOdRMvrLbQZGxZMuhMZju/vq2MJl/+I4ocFKcyMZ3uht1mj2tMSo/q2zjIRKUtPyUPRH6tEqjDsGgxDWf1a3rHFAJ6zRTJ1RIwmUIW4nQ9ZuwJyByPWelDHUVgTCpctfsKbvdPEpVL6Yoy2gWSUxpKeWQiQXGKNqwmDWLNugn4M3ZHi2XpZl+96WDa8JeogLayEjZcPb25YqpdJd60B/M/krZPyVmxrrH8ltg=='}} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 543, 'candidates_token_count': 7, 'total_token_count': 610, 'prompt_tokens_details': [{'modality': 1, 'token_count': 543}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 7}], 'thoughts_token_count': 60, 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.9384725434439523, 'model_name': 'gemini-2.5-pro'} id='run--4418a2bd-8afc-41f2-8b41-3ab710c26f8d-0' tool_calls=[{'name': 'run_command', 'args': {'command': 'ls -F'}, 'id': '4e521b6d-2399-4bf0-81aa-37f9e1cc505d', 'type': 'tool_call'}] usage_metadata={'input_tokens': 543, 'output_tokens': 7, 'total_tokens': 610, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 60}}
2025-12-21 09:54:53,885 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: ls -F
2025-12-21 09:54:53,987 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 0
2025-12-21 09:54:53,987 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:

AUTHORS.rst	   PULL_REQUEST_TEMPLATE.md  conftest.py	     site.cfg
CONTRIBUTING.md    README.rst		     doc/		     sklearn/
COPYING		   appveyor.yml		     examples/		     tests/
ISSUE_TEMPLATE.md  benchmarks/		     scikit_learn.egg-info/
MANIFEST.in	   build/		     setup.cfg
Makefile	   build_tools/		     setup.py*

2025-12-21 09:54:55,388 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_execute_node - DEBUG - content='' additional_kwargs={'function_call': {'name': 'run_command', 'arguments': '{"command": "pytest tests/test_bug.py"}'}, '__gemini_function_call_thought_signatures__': {'17bda1dd-bc15-4f2e-9a63-3376d0e5fb67': 'CpICAY89a1+QnS9vTm5q4O5AUKRgL1+Gncvm32OvKxnjzXfQnsoaxMM0iQwUmSnplLCNn1zDd0IjG5/25gSJuVUEectFmDX2U4YFdSUEiNwg4b3N3JfSy2gt0xX/G9qdgYYxrPPQ86onWCE+tvKk2F8TDaTDl/TpeEDdi64SFNpHoeO677DtupOsHNd7rPP7S6Hjc/ktbSX6bSkRK/+BBv6C5MHabab13rDDEk5NbgyI1TXA00KkfGLC8b1PQzdGD51+h9S/tWY3Zd9oA7fa9vhroO7uS6RqfAWyjZFdILuQRSCspbSZKm0md9SRQsRbaMX8XYvwScv5gJWu4A2XUAYGfTb0P7Lm/mq8d8p9iCu4kxbx6g=='}} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 664, 'candidates_token_count': 12, 'total_token_count': 743, 'prompt_tokens_details': [{'modality': 1, 'token_count': 724}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 12}], 'thoughts_token_count': 67, 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.384941299756368, 'model_name': 'gemini-2.5-pro'} id='run--e0719871-2ee8-4525-9d69-13ac4552632d-0' tool_calls=[{'name': 'run_command', 'args': {'command': 'pytest tests/test_bug.py'}, 'id': '17bda1dd-bc15-4f2e-9a63-3376d0e5fb67', 'type': 'tool_call'}] usage_metadata={'input_tokens': 664, 'output_tokens': 12, 'total_tokens': 743, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 67}}
2025-12-21 09:54:55,391 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: pytest tests/test_bug.py
2025-12-21 09:54:56,376 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 2
2025-12-21 09:54:56,376 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:

[1m============================= test session starts ==============================[0m
platform linux -- Python 3.6.13, pytest-6.2.4, py-1.11.0, pluggy-0.13.1
rootdir: /testbed, configfile: setup.cfg
[1mcollecting ... [0m[1m
collected 0 items / 2 errors                                                   [0m

==================================== ERRORS ====================================
[31m[1m______________________ ERROR collecting tests/test_bug.py ______________________[0m
[1m[31mtests/test_bug.py[0m:2: in <module>
    from httpx import AsyncClient
[1m[31mE   ModuleNotFoundError: No module named 'httpx'[0m
[31m[1m______________________ ERROR collecting tests/test_bug.py ______________________[0m
[31mImportError while importing test module '/testbed/tests/test_bug.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/opt/miniconda3/envs/testbed/lib/python3.6/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_bug.py:2: in <module>
    from httpx import AsyncClient
E   ModuleNotFoundError: No module named 'httpx'[0m
!!!!!!!!!!!!!!!!!!! Interrupted: 2 errors during collection !!!!!!!!!!!!!!!!!!!!
[31m============================== [31m[1m2 errors[0m[31m in 0.40s[0m[31m ===============================[0m

2025-12-21 09:54:57,405 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_execute_node - DEBUG - content='' additional_kwargs={'function_call': {'name': 'run_command', 'arguments': '{"command": "pip install httpx"}'}, '__gemini_function_call_thought_signatures__': {'5a10bdf5-68ea-43e2-99a3-15e427083a57': 'CpUBAY89a1+/L2YWsZT7mw5ewlmDVBS0o6sc/ACRZeUfBh+mjLn8bzmFHyOSg447ShndJMRXfFAmVNIB06ccFJf5wlEeZSFf8dYPdw+lcsUx4qDVaGubTgPHojZdMsrKPE1zV/Uqr1k3j8B+0peueIVyTr7R3r0KOH0yjK0K8b07NT8xb/R28BQa4vjde4n8eGBt2krtApE='}} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 1085, 'candidates_token_count': 8, 'total_token_count': 1122, 'prompt_tokens_details': [{'modality': 1, 'token_count': 1212}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 8}], 'thoughts_token_count': 29, 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.21379505097866058, 'model_name': 'gemini-2.5-pro'} id='run--ce572e27-f297-4bfe-b5e0-555119c17c91-0' tool_calls=[{'name': 'run_command', 'args': {'command': 'pip install httpx'}, 'id': '5a10bdf5-68ea-43e2-99a3-15e427083a57', 'type': 'tool_call'}] usage_metadata={'input_tokens': 1085, 'output_tokens': 8, 'total_tokens': 1122, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 29}}
2025-12-21 09:54:57,408 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: pip install httpx
2025-12-21 09:55:04,191 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 0
2025-12-21 09:55:04,191 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:

Collecting httpx
  Downloading httpx-0.22.0-py3-none-any.whl (84 kB)
[?25l
[K     |###                             | 10 kB 11.0 MB/s eta 0:00:01
[K     |#######                         | 20 kB 6.0 MB/s eta 0:00:01
[K     |###########                     | 30 kB 2.0 MB/s eta 0:00:01
[K     |###############                 | 40 kB 2.4 MB/s eta 0:00:01
[K     |###################             | 51 kB 2.5 MB/s eta 0:00:01
[K     |#######################         | 61 kB 1.9 MB/s eta 0:00:01
[K     |###########################     | 71 kB 2.1 MB/s eta 0:00:01
[K     |############################### | 81 kB 2.4 MB/s eta 0:00:01
[K     |################################| 84 kB 1.1 MB/s 
[?25hCollecting sniffio
  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)
Collecting charset-normalizer
  Downloading charset_normalizer-3.0.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)
[?25l
[K     |##                              | 10 kB 4.7 MB/s eta 0:00:01
[K     |####                            | 20 kB 3.5 MB/s eta 0:00:01
[K     |######                          | 30 kB 4.9 MB/s eta 0:00:01
[K     |########                        | 40 kB 4.9 MB/s eta 0:00:01
[K     |##########                      | 51 kB 4.6 MB/s eta 0:00:01
[K     |############                    | 61 kB 5.3 MB/s eta 0:00:01
[K     |##############                  | 71 kB 5.2 MB/s eta 0:00:01
[K     |################                | 81 kB 4.1 MB/s eta 0:00:01
[K     |##################              | 92 kB 4.5 MB/s eta 0:00:01
[K     |####################            | 102 kB 4.6 MB/s eta 0:00:01
[K     |######################          | 112 kB 4.6 MB/s eta 0:00:01
[K     |########################        | 122 kB 4.6 MB/s eta 0:00:01
[K     |##########################      | 133 kB 4.6 MB/s eta 0:00:01
[K     |############################    | 143 kB 4.6 MB/s eta 0:00:01
[K     |##############################  | 153 kB 4.6 MB/s eta 0:00:01
[K     |################################| 162 kB 4.6 MB/s 
[?25hCollecting async-generator
  Downloading async_generator-1.10-py3-none-any.whl (18 kB)
Collecting rfc3986[idna2008]<2,>=1.3
  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)
Collecting httpcore<0.15.0,>=0.14.5
  Downloading httpcore-0.14.7-py3-none-any.whl (68 kB)
[?25l
[K     |####                            | 10 kB 18.2 MB/s eta 0:00:01
[K     |#########                       | 20 kB 9.6 MB/s eta 0:00:01
[K     |##############                  | 30 kB 13.2 MB/s eta 0:00:01
[K     |###################             | 40 kB 7.6 MB/s eta 0:00:01
[K     |#######################         | 51 kB 7.9 MB/s eta 0:00:01
[K     |############################    | 61 kB 9.2 MB/s eta 0:00:01
[K     |################################| 68 kB 2.8 MB/s 
[?25hRequirement already satisfied: certifi in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from httpx) (2021.5.30)
Collecting h11<0.13,>=0.11
  Downloading h11-0.12.0-py3-none-any.whl (54 kB)
[?25l
[K     |#####                           | 10 kB 5.8 MB/s eta 0:00:01
[K     |###########                     | 20 kB 5.9 MB/s eta 0:00:01
[K     |#################               | 30 kB 8.3 MB/s eta 0:00:01
[K     |#######################         | 40 kB 5.9 MB/s eta 0:00:01
[K     |#############################   | 51 kB 7.0 MB/s eta 0:00:01
[K     |################################| 54 kB 2.2 MB/s 
[?25hCollecting anyio==3.*
  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)
[?25l
[K     |####                            | 10 kB 28.0 MB/s eta 0:00:01
[K     |########                        | 20 kB 5.9 MB/s eta 0:00:01
[K     |############                    | 30 kB 8.3 MB/s eta 0:00:01
[K     |################                | 40 kB 7.3 MB/s eta 0:00:01
[K     |####################            | 51 kB 5.7 MB/s eta 0:00:01
[K     |########################        | 61 kB 6.6 MB/s eta 0:00:01
[K     |############################    | 71 kB 6.9 MB/s eta 0:00:01
[K     |################################| 80 kB 5.6 MB/s 
[?25hCollecting dataclasses
  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)
Collecting idna>=2.8
  Downloading idna-3.10-py3-none-any.whl (70 kB)
[?25l
[K     |####                            | 10 kB 6.7 MB/s eta 0:00:01
[K     |#########                       | 20 kB 5.0 MB/s eta 0:00:01
[K     |#############                   | 30 kB 7.0 MB/s eta 0:00:01
[K     |##################              | 40 kB 5.6 MB/s eta 0:00:01
[K     |#######################         | 51 kB 5.3 MB/s eta 0:00:01
[K     |###########################     | 61 kB 6.2 MB/s eta 0:00:01
[K     |################################| 70 kB 3.1 MB/s 
[?25hCollecting contextvars
  Downloading contextvars-2.4.tar.gz (9.6 kB)
Requirement already satisfied: typing-extensions in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from anyio==3.*->httpcore<0.15.0,>=0.14.5->httpx) (4.1.1)
Collecting immutables>=0.9
  Downloading immutables-0.19-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (116 kB)
[?25l
[K     |##                              | 10 kB 21.8 MB/s eta 0:00:01
[K     |#####                           | 20 kB 7.9 MB/s eta 0:00:01
[K     |########                        | 30 kB 11.0 MB/s eta 0:00:01
[K     |###########                     | 40 kB 10.2 MB/s eta 0:00:01
[K     |##############                  | 51 kB 6.1 MB/s eta 0:00:01
[K     |################                | 61 kB 7.1 MB/s eta 0:00:01
[K     |###################             | 71 kB 2.5 MB/s eta 0:00:01
[K     |######################          | 81 kB 2.7 MB/s eta 0:00:01
[K     |#########################       | 92 kB 2.8 MB/s eta 0:00:01
[K     |############################    | 102 kB 3.1 MB/s eta 0:00:01
[K     |############################### | 112 kB 3.1 MB/s eta 0:00:01
[K     |################################| 116 kB 3.1 MB/s 
[?25hBuilding wheels for collected packages: contextvars
  Building wheel for contextvars (setup.py) ... [?25l- \ done
[?25h  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7681 sha256=cfa819b5274ecce912603e9656aae37f39c31c1e73b1419dfd7d1315c7cea856
  Stored in directory: /root/.cache/pip/wheels/41/11/53/911724983aa48deb94792432e14e518447212dd6c5477d49d3
Successfully built contextvars
Installing collected packages: immutables, contextvars, sniffio, idna, dataclasses, rfc3986, h11, anyio, httpcore, charset-normalizer, async-generator, httpx
Successfully installed anyio-3.6.2 async-generator-1.10 charset-normalizer-3.0.1 contextvars-2.4 dataclasses-0.8 h11-0.12.0 httpcore-0.14.7 httpx-0.22.0 idna-3.10 immutables-0.19 rfc3986-1.5.0 sniffio-1.2.0
[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv[0m

2025-12-21 09:55:05,322 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_execute_node - DEBUG - content='' additional_kwargs={'function_call': {'name': 'run_command', 'arguments': '{"command": "pytest tests/test_bug.py"}'}, '__gemini_function_call_thought_signatures__': {'f1b19b6e-a489-4ccc-866b-89d870cc68d3': 'CmEBjz1rX+2pCbDo8Dtzz1QfX8a3MCTFOoVbX1di5Lg3OcI0PEQ2Jk+mLEGYYKaLHUAAZQ+feWucMWrIzC1lFsCFXbGCz08hqJPyEozk3+d74rM/e1ZdwYAM82cZ9/ngqDyt'}} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 4022, 'candidates_token_count': 12, 'total_token_count': 4052, 'prompt_tokens_details': [{'modality': 1, 'token_count': 4178}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 12}], 'thoughts_token_count': 18, 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.008085044721762339, 'model_name': 'gemini-2.5-pro'} id='run--d9bb5950-4823-4fbf-a342-74a901474dbc-0' tool_calls=[{'name': 'run_command', 'args': {'command': 'pytest tests/test_bug.py'}, 'id': 'f1b19b6e-a489-4ccc-866b-89d870cc68d3', 'type': 'tool_call'}] usage_metadata={'input_tokens': 4022, 'output_tokens': 12, 'total_tokens': 4052, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 18}}
2025-12-21 09:55:05,325 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: pytest tests/test_bug.py
2025-12-21 09:55:06,663 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 2
2025-12-21 09:55:06,663 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:

[1m============================= test session starts ==============================[0m
platform linux -- Python 3.6.13, pytest-6.2.4, py-1.11.0, pluggy-0.13.1
rootdir: /testbed, configfile: setup.cfg
plugins: anyio-3.6.2
[1mcollecting ... [0m[1m
collected 0 items / 2 errors                                                   [0m

==================================== ERRORS ====================================
[31m[1m______________________ ERROR collecting tests/test_bug.py ______________________[0m
[1m[31mtests/test_bug.py[0m:3: in <module>
    from main import app
[1m[31mE   ModuleNotFoundError: No module named 'main'[0m
[31m[1m______________________ ERROR collecting tests/test_bug.py ______________________[0m
[31mImportError while importing test module '/testbed/tests/test_bug.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/opt/miniconda3/envs/testbed/lib/python3.6/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_bug.py:3: in <module>
    from main import app
E   ModuleNotFoundError: No module named 'main'[0m
!!!!!!!!!!!!!!!!!!! Interrupted: 2 errors during collection !!!!!!!!!!!!!!!!!!!!
[31m============================== [31m[1m2 errors[0m[31m in 0.56s[0m[31m ===============================[0m

2025-12-21 09:55:08,913 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_execute_node - DEBUG - content='' additional_kwargs={'function_call': {'name': 'run_command', 'arguments': '{"command": "cat tests/test_bug.py"}'}, '__gemini_function_call_thought_signatures__': {'c382a5ce-5478-4881-a650-0be59b848ac5': 'CvkDAY89a190wVQtSwg1Lw14sB7hUHERu4xXPHvkFHcGLyIjxuC5A2ZHDnK99v6EU5vCvisbvRuND7CsB/lPenI7tBsDrlSM8EkPHn63xTAhh1/DEflwGLM8xZvLPOnUTfB8bwlbtsz2eYvX4M2y3WPqByef6K6AGFavzAWT+ur4ndTJGc6U7e3+p3Wyo6KEBr9zQvyauNEyFwg21tshowOU4jZ7PLViQqmcs9YRHaKARGzGhjy/LeeW6jWGD+Sp4d13rvOYPg7mUJyluAMF8JSzpENT+CftNaGchlKwBYqHIylguimYNY9Hc5Bt+7vmmiNA+4Aa/J9yGTZLheNJihn565TaxKKR1wqPM1hXu40+zNcG8m/2aRsIUwGhOgkUDB5JxXEIyvs5yye7toLZ6t4zXsW14W8OdMLgUWp59C6/x8uPZOH40RgomaGYMoBSQ6rkG5VKUsRrYXaN2LHvfvloF2kbXakGM0bu7soOA2kgaCgvSUJiblMyVKFnsYvcg4HAR+2+CZKocENxzvyiY5bK9ErKogvmgaKZBKjTdm+srF+quSoc2ZvDNqPHD/cxTg1IXpmNaLTBXjrkqdqiQN56yx+HNP1peBABzWAYtuaoU60tpQlnQr9gxomCKiyxitqjr3WdZr7FWhnm9cu3d5evW0ZxoOFwMa1CmA=='}} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 4448, 'candidates_token_count': 12, 'total_token_count': 4587, 'cached_content_token_count': 3196, 'prompt_tokens_details': [{'modality': 1, 'token_count': 4622}], 'cache_tokens_details': [{'modality': 1, 'token_count': 3196}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 12}], 'thoughts_token_count': 127}, 'finish_reason': 'STOP', 'avg_logprobs': -0.9044221242268881, 'model_name': 'gemini-2.5-pro'} id='run--9a7c0bd5-3810-4cf3-b632-ad48f3f72ed6-0' tool_calls=[{'name': 'run_command', 'args': {'command': 'cat tests/test_bug.py'}, 'id': 'c382a5ce-5478-4881-a650-0be59b848ac5', 'type': 'tool_call'}] usage_metadata={'input_tokens': 4448, 'output_tokens': 12, 'total_tokens': 4587, 'input_token_details': {'cache_read': 3196}, 'output_token_details': {'reasoning': 127}}
2025-12-21 09:55:08,916 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: cat tests/test_bug.py
2025-12-21 09:55:09,017 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 0
2025-12-21 09:55:09,017 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:

import pytest
from httpx import AsyncClient
from main import app

@pytest.mark.asyncio
async def test_read_root():
    async with AsyncClient(app=app, base_url="http://test") as ac:
        response = await ac.get("/")
    assert response.status_code == 200

2025-12-21 09:55:10,515 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_execute_node - DEBUG - content='' additional_kwargs={'function_call': {'name': 'run_command', 'arguments': '{"command": "cat main.py"}'}, '__gemini_function_call_thought_signatures__': {'132ac4a0-7414-4723-87b9-605465b3f246': 'CpUCAY89a18m1z3FgxG3KLic2Hoq8H8o6B1cWxoLTCeHwmCOI6hRsudPvLi0OtUlHzu952gIcTj4wFU1RdW+aCwHyV25XI3+3HhxeYcHirgvJ6r3NdbjoRXo0CFeAeFvZtzlcy7g4x9Ex0HfJiMH7sH8E8+SIsKJ5DmlycQyGHgIq7nvIrEF0XkZhv5XFEhF5DNsf5mHTzyKoyHASpeYPRRUjQZs30IX37mxOT0pK1817j920k6kv5kkD570lV9Bdf6p67nciT/oCVv0W0SmJ4a63cfczBfvroppRoQoQ6khO+vpZYvJk51iW3zg0bE7Jy/Mp3qndKuSMD5lpExPXj7LsqS9FpMsnadrckd//OAEM8fX7V3E4w=='}} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 4541, 'candidates_token_count': 8, 'total_token_count': 4618, 'cached_content_token_count': 3204, 'prompt_tokens_details': [{'modality': 1, 'token_count': 4842}], 'cache_tokens_details': [{'modality': 1, 'token_count': 3204}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 8}], 'thoughts_token_count': 69}, 'finish_reason': 'STOP', 'avg_logprobs': -1.3407001495361328, 'model_name': 'gemini-2.5-pro'} id='run--d3cb0b48-d397-4ff8-9886-580a361b7428-0' tool_calls=[{'name': 'run_command', 'args': {'command': 'cat main.py'}, 'id': '132ac4a0-7414-4723-87b9-605465b3f246', 'type': 'tool_call'}] usage_metadata={'input_tokens': 4541, 'output_tokens': 8, 'total_tokens': 4618, 'input_token_details': {'cache_read': 3204}, 'output_token_details': {'reasoning': 69}}
2025-12-21 09:55:10,517 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: cat main.py
2025-12-21 09:55:10,619 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 1
2025-12-21 09:55:10,619 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:

cat: main.py: No such file or directory

2025-12-21 09:55:14,042 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_execute_node - DEBUG - content='' additional_kwargs={'function_call': {'name': 'run_command', 'arguments': '{"command": "cat Makefile"}'}, '__gemini_function_call_thought_signatures__': {'47c0c57d-8cf8-4896-ac6f-e4e471b9c911': 'Cu4IAY89a19XP7tueJ08JprK/K7vD3OQ4GI6DtmZo43IS0q2G+gsHrr9S8qmJm+PrhpFIDS0wZGD1SsMFGmAt/n4xYCLDOOWDbJWTX43PqghNXRCQMUPYJurK9qrimcn5ffPm5ah3+GOS+v6OTus3v+Jhk833mJZwJRqc5xHRYFHjS5yO17rLwNOakyleyu4WEAxFT+VtZa78M6OIuXJJcGvBe9ZLyRFZBtx7ZkAFAFZkK2wEXGUuRFthpyQ6a+6X7krU6Oq0wz99ZfQg72hIWgThEe+oSfol0S9rzizQfbkgHYPrf7616/xUpuy/Pq9BZLT+BbLcEefLvNFVUkWBCQxV9qhCt8jOWh+6Nyg1fzV5Up0bQhfbcsMXT1pVUf+AKId5memkX4rlLmF2l3G7aMVXG+P/runrKm7NXJRM0fQwRYECFqK7R5hqSh1IJnFERaCNuMr0kyg7xl2+VSGGlTgYksXZ1412astDpdp2qczpdTt20wfrfZg8CHTom/Dvml3ZUP1+oLaCXvt8xsQjNbQ0/x7U6VWV8hXTuU4VO4qmmKuMxMBudJ/nWg75lHLNcaWLCGwsLgZWWS9U8OD2KWeh/qkuxdgEAmZFUmD60U4HCr9ywz9YtBhg7yxV6A4m0FdQl3cYiwXDzW87z41AOYx86pU3B2Tjeg34DmAOZlTsHwsZlILJm8fE76b87BGA4SYZW5SEh43su3iXH1pBtBUvrGAK62X8jIA0FnmM65oBjb+9Wrt45Ze2EVYueJYdD+rpdRTWLiATEkXntq+Q9TAO9Vck3aFLqyMtzEChbX2RaJ1NurGYHzHrGKFjGdKD1gF72CDds92kLdj5DCAjmTXlrZXDnMttdmoa1+Aky37r9Zvmf8RN58WRcEI5tP1LU0hE60yPm6Hr/EjNtZipMiSPyDGjgShsCdypXMBcyGaRxcWop2Ha1BzkRwzksIcUtcnGOW+tsL5fp+pzPD9TIranfBa2+E+te716EMoF4kHHdVmDveazznOs6LS+fJr71QAxPYjKiV9F/XY2uGRC2csScVeMAYs2FzUXdCT6Xl8MB1fGQUKNUJJuTIKG/gG0qGEOeSNFMk4A90t2/UYzcWKQGNrijSfx/PLZvSvCU+/xSeivrqRTWnKkOrnRdzWy5eImhSkvZ/rafnOQoC8SlHUMCJLvcHjJld8n0Comu/HEafMMokctNO9Az9J7AazTFmegh4NRMU6r53pktWigZsoTFBcQALOJWjYxeQBtq99kHAmSido7qyexwitWcLPg+ZmMV8hCoHmd1AL5rO94/xQf6zlc+jKz6fqqx1Pf1EqDANCYCAHFg8TPq/DJxxAc4ionP864K9qiDOG59MiMT8kP/E4UkYmdyER/aGxVGHPt9uKyqN0wRab+K+9Gxc67alqPJNJqcKm021ZCffoRjoOo/8fFj2xoEn+hJ1IoCe+B+KWOEZikvqq6+BFRSnPyt1wA1BeCFcp0kb8IVKxeBkm/AdRdOibv8JoFHd96Ung'}} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 4566, 'candidates_token_count': 6, 'total_token_count': 4870, 'cached_content_token_count': 4797, 'prompt_tokens_details': [{'modality': 1, 'token_count': 4936}], 'cache_tokens_details': [{'modality': 1, 'token_count': 4797}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 6}], 'thoughts_token_count': 298}, 'finish_reason': 'STOP', 'avg_logprobs': -5.139288584391276, 'model_name': 'gemini-2.5-pro'} id='run--ea634784-2cdc-44f6-b2d9-2ce3b37518f7-0' tool_calls=[{'name': 'run_command', 'args': {'command': 'cat Makefile'}, 'id': '47c0c57d-8cf8-4896-ac6f-e4e471b9c911', 'type': 'tool_call'}] usage_metadata={'input_tokens': 4566, 'output_tokens': 6, 'total_tokens': 4870, 'input_token_details': {'cache_read': 4797}, 'output_token_details': {'reasoning': 298}}
2025-12-21 09:55:14,046 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: cat Makefile
2025-12-21 09:55:14,148 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 0
2025-12-21 09:55:14,148 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:

# simple makefile to simplify repetitive build env management tasks under posix

# caution: testing won't work on windows, see README

PYTHON ?= python
CYTHON ?= cython
PYTEST ?= pytest
CTAGS ?= ctags

# skip doctests on 32bit python
BITS := $(shell python -c 'import struct; print(8 * struct.calcsize("P"))')

all: clean inplace test

clean-ctags:
	rm -f tags

clean: clean-ctags
	$(PYTHON) setup.py clean
	rm -rf dist

in: inplace # just a shortcut
inplace:
	$(PYTHON) setup.py build_ext -i

test-code: in
	$(PYTEST) --showlocals -v sklearn
test-sphinxext:
	$(PYTEST) --showlocals -v doc/sphinxext/
test-doc:
ifeq ($(BITS),64)
	$(PYTEST) $(shell find doc -name '*.rst' | sort)
endif

test-coverage:
	rm -rf coverage .coverage
	$(PYTEST) sklearn --showlocals -v --cov=sklearn --cov-report=html:coverage

test: test-code test-sphinxext test-doc

trailing-spaces:
	find sklearn -name "*.py" -exec perl -pi -e 's/[ \t]*$$//' {} \;

cython:
	python setup.py build_src

ctags:
	# make tags for symbol based navigation in emacs and vim
	# Install with: sudo apt-get install exuberant-ctags
	$(CTAGS) --python-kinds=-i -R sklearn

doc: inplace
	$(MAKE) -C doc html

doc-noplot: inplace
	$(MAKE) -C doc html-noplot

code-analysis:
	flake8 sklearn | grep -v __init__ | grep -v external
	pylint -E -i y sklearn/ -d E1103,E0611,E1101

flake8-diff:
	./build_tools/travis/flake8_diff.sh

2025-12-21 09:55:15,968 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_execute_node - DEBUG - content='' additional_kwargs={'function_call': {'name': 'run_command', 'arguments': '{"command": "ls -F sklearn"}'}, '__gemini_function_call_thought_signatures__': {'21de2980-b3a6-4218-b2df-47e1e7e7a353': 'CokDAY89a18vArWCnHRPB/b3KKdHW/N8Tt0PRHIUl/e3Qjyn6dj7uhiCKqBCgy1h50VxKPVsYD5GG24K7NxY1nz358ckJDpj+6D+lCz6kBtv7XBxyKTw+YhOtLw6CYAMhm2JOdoGmpuPkA67n7II+isMOLwe45TGaWEcigyBCpjnWeToR8zPy13Z0E0cIULS/IFoQljAg+7WtDufiLOWtC0VQUMLfhmqUu0J+goBrwP05etjrPtJuvrpGgMO+gx7/l3L6FquIadw+OD4f+s21KrLGkOjjyTjpZnmOjYXYSIx5ZaeYEPi37UVlAXZQiBlCrisPbuT4opdia4bkCDgKpPihjENntjrD8MLN28d65mqMsXPqMUGn49PWpfEUxuMge8RFvvrPZs4bH29fM3oBkAicPqxd28gaoh/3UxtehYUMWUnA2bz1N6DPP4klkLUPTNK4357/TgeY6xVab6CSC8GphFAVThaY9msP4d5gvdiwP51EmaW1gBLJiqEDw+3BJeSwb0p8pklxDeO'}} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 5057, 'candidates_token_count': 8, 'total_token_count': 5156, 'cached_content_token_count': 4861, 'prompt_tokens_details': [{'modality': 1, 'token_count': 5725}], 'cache_tokens_details': [{'modality': 1, 'token_count': 4861}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 8}], 'thoughts_token_count': 91}, 'finish_reason': 'STOP', 'avg_logprobs': -1.9354826211929321, 'model_name': 'gemini-2.5-pro'} id='run--b6682e47-7040-4b51-99bd-2265b03d22ee-0' tool_calls=[{'name': 'run_command', 'args': {'command': 'ls -F sklearn'}, 'id': '21de2980-b3a6-4218-b2df-47e1e7e7a353', 'type': 'tool_call'}] usage_metadata={'input_tokens': 5057, 'output_tokens': 8, 'total_tokens': 5156, 'input_token_details': {'cache_read': 4861}, 'output_token_details': {'reasoning': 91}}
2025-12-21 09:55:15,971 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: ls -F sklearn
2025-12-21 09:55:16,073 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 0
2025-12-21 09:55:16,073 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:

__check_build/				    impute.py
__init__.py				    isotonic.py
__pycache__/				    kernel_approximation.py
_build_utils/				    kernel_ridge.py
_config.py				    learning_curve.py
_isotonic.c				    linear_model/
_isotonic.cpython-36m-x86_64-linux-gnu.so*  manifold/
_isotonic.pyx				    metrics/
base.py					    mixture/
calibration.py				    model_selection/
cluster/				    multiclass.py
compose/				    multioutput.py
covariance/				    naive_bayes.py
cross_decomposition/			    neighbors/
cross_validation.py			    neural_network/
datasets/				    pipeline.py
decomposition/				    preprocessing/
discriminant_analysis.py		    random_projection.py
dummy.py				    semi_supervised/
ensemble/				    setup.py
exceptions.py				    src/
externals/				    svm/
feature_extraction/			    tests/
feature_selection/			    tree/
gaussian_process/			    utils/
grid_search.py

2025-12-21 09:55:20,649 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_execute_node - DEBUG - content='' additional_kwargs={'function_call': {'name': 'run_command', 'arguments': '{"command": "ls -F sklearn/model_selection/tests/"}'}, '__gemini_function_call_thought_signatures__': {'22a33482-7134-4b83-8f57-5fb0c8ad251f': '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'}} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 5343, 'candidates_token_count': 15, 'total_token_count': 5772, 'cached_content_token_count': 4802, 'prompt_tokens_details': [{'modality': 1, 'token_count': 6102}], 'cache_tokens_details': [{'modality': 1, 'token_count': 4802}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 15}], 'thoughts_token_count': 414}, 'finish_reason': 'STOP', 'avg_logprobs': -4.949443562825521, 'model_name': 'gemini-2.5-pro'} id='run--33ca1b7f-4ea9-41f8-b32c-69d0d9f0ff85-0' tool_calls=[{'name': 'run_command', 'args': {'command': 'ls -F sklearn/model_selection/tests/'}, 'id': '22a33482-7134-4b83-8f57-5fb0c8ad251f', 'type': 'tool_call'}] usage_metadata={'input_tokens': 5343, 'output_tokens': 15, 'total_tokens': 5772, 'input_token_details': {'cache_read': 4802}, 'output_token_details': {'reasoning': 414}}
2025-12-21 09:55:20,652 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: ls -F sklearn/model_selection/tests/
2025-12-21 09:55:20,754 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 0
2025-12-21 09:55:20,754 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:

__init__.py  common.py	test_search.py	test_split.py  test_validation.py

2025-12-21 09:55:22,777 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_execute_node - DEBUG - content='' additional_kwargs={'function_call': {'name': 'run_command', 'arguments': '{"command": "grep -i refit_time sklearn/model_selection/tests/test_search.py"}'}, '__gemini_function_call_thought_signatures__': {'3316470e-15ec-44e1-99f1-d7577f21ccbd': 'CsoCAY89a1/xcdKjYUOsLnhI2uLCfl6AKdTQm0BGx0DHjR90Rrg6lsr+oHBbbeu73YUPNFg6KpIGxX50RD3EAtvC+/EJ5Fkton/GtxNj6/QDgatMgg3Y2IPJDk5xr/OYFt+IFHug+WSlHBBkUbYeb06sTH4igwklrK16TucX89ZsaGloFyzfQXnSGvHtlw+NJJpQ/OhnCp+/VSonhA06eHIVgA5qmp+6x2Zdu2boxX2+zMTP8/ahuDbuE852h806OZW7RfFEladqzI6rskTisnEo0Zw2SYSXydpYVucz6DkKzHwJaKDKx/VvktBeQLerFQbA0vjxwGTHz2gPFzChr5yb6nGMOwYEYmDe34x93SnveSfOPTJijakXKADv4847JLMDNTFkhkwXw4PczFDIgdkG7p2j/glLCozS+r2FOQpa8C5oceOsOVqCA4s9'}} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 5390, 'candidates_token_count': 24, 'total_token_count': 5503, 'cached_content_token_count': 4854, 'prompt_tokens_details': [{'modality': 1, 'token_count': 6563}], 'cache_tokens_details': [{'modality': 1, 'token_count': 4854}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 24}], 'thoughts_token_count': 89}, 'finish_reason': 'STOP', 'avg_logprobs': -0.4869629144668579, 'model_name': 'gemini-2.5-pro'} id='run--f27a6d4d-b341-4c21-aa61-b080e379e406-0' tool_calls=[{'name': 'run_command', 'args': {'command': 'grep -i refit_time sklearn/model_selection/tests/test_search.py'}, 'id': '3316470e-15ec-44e1-99f1-d7577f21ccbd', 'type': 'tool_call'}] usage_metadata={'input_tokens': 5390, 'output_tokens': 24, 'total_tokens': 5503, 'input_token_details': {'cache_read': 4854}, 'output_token_details': {'reasoning': 89}}
2025-12-21 09:55:22,780 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: grep -i refit_time sklearn/model_selection/tests/test_search.py
2025-12-21 09:55:22,882 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 1
2025-12-21 09:55:22,882 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:
grep -i refit_time sklearn/model_selection/
/tests/test_search.py


2025-12-21 09:55:27,459 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_execute_node - DEBUG - content='' additional_kwargs={'function_call': {'name': 'run_command', 'arguments': '{"command": "cat tests/test_bug.py"}'}, '__gemini_function_call_thought_signatures__': {'b795e3d5-7f8e-4b02-b415-9fb0320dd216': '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'}} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 5441, 'candidates_token_count': 12, 'total_token_count': 5905, 'cached_content_token_count': 6470, 'prompt_tokens_details': [{'modality': 1, 'token_count': 6703}], 'cache_tokens_details': [{'modality': 1, 'token_count': 6470}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 12}], 'thoughts_token_count': 452}, 'finish_reason': 'STOP', 'avg_logprobs': -3.352258046468099, 'model_name': 'gemini-2.5-pro'} id='run--04b32cd6-fd08-4287-b2d1-5d32ee8f47a5-0' tool_calls=[{'name': 'run_command', 'args': {'command': 'cat tests/test_bug.py'}, 'id': 'b795e3d5-7f8e-4b02-b415-9fb0320dd216', 'type': 'tool_call'}] usage_metadata={'input_tokens': 5441, 'output_tokens': 12, 'total_tokens': 5905, 'input_token_details': {'cache_read': 6470}, 'output_token_details': {'reasoning': 452}}
2025-12-21 09:55:27,462 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: cat tests/test_bug.py
2025-12-21 09:55:27,563 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 0
2025-12-21 09:55:27,564 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:

import pytest
from httpx import AsyncClient
from main import app

@pytest.mark.asyncio
async def test_read_root():
    async with AsyncClient(app=app, base_url="http://test") as ac:
        response = await ac.get("/")
    assert response.status_code == 200

2025-12-21 09:55:29,393 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_execute_node - DEBUG - content='' additional_kwargs={'function_call': {'name': 'run_command', 'arguments': '{"command": "find . -name main.py"}'}, '__gemini_function_call_thought_signatures__': {'26f708bc-8b1f-4916-91e4-558e1a469070': 'Cr0CAY89a19hzm60UG1ALOOWsbPlH+GvjyyWJTnaSyzb1AYaEax8pNH5JaAQ86HktOnCm7FEGcIybCOi4b3A46jXSYMKuBM0kJtpZsCoNkFjrYTJnPziOEluENFvtQQWM+jFPJrazGmIj/PeW9Ly5s9EJl3ARU4tI+AE2YzwXhSR/G/rnxjC9Mk5AJtdaPqfIcJDAce8FwZNJYfiICPEjoLGnUR1ppuIVf1QvwkSvvb8UEj44lp8vJQtwE9K+xFSKyE40NOslum5NSzYi/dXtTG5mXcBriMZmiXgB/WwDmdYNzL4TbSoe/koY2vehjqykXDwzSfTo5omv+igkEGc6IgdgD/PlZ75wOcJwqfRpSb37WeU9Dzhq8nuKazUq5ZdVPNYOWLwaNnsNnqZlQ2D25odjkT6rElt2nfsUKNG6Ks='}} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 5534, 'candidates_token_count': 11, 'total_token_count': 5618, 'cached_content_token_count': 6539, 'prompt_tokens_details': [{'modality': 1, 'token_count': 7248}], 'cache_tokens_details': [{'modality': 1, 'token_count': 6539}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 11}], 'thoughts_token_count': 73}, 'finish_reason': 'STOP', 'avg_logprobs': -0.7961957237937234, 'model_name': 'gemini-2.5-pro'} id='run--46be1ec0-3df0-49ab-ab5b-bb1331aa66e0-0' tool_calls=[{'name': 'run_command', 'args': {'command': 'find . -name main.py'}, 'id': '26f708bc-8b1f-4916-91e4-558e1a469070', 'type': 'tool_call'}] usage_metadata={'input_tokens': 5534, 'output_tokens': 11, 'total_tokens': 5618, 'input_token_details': {'cache_read': 6539}, 'output_token_details': {'reasoning': 73}}
2025-12-21 09:55:29,396 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: find . -name main.py
2025-12-21 09:55:29,497 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 0
2025-12-21 09:55:29,497 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:


2025-12-21 09:55:33,487 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_execute_node - DEBUG - content='' additional_kwargs={'function_call': {'name': 'run_command', 'arguments': '{"command": "pytest sklearn/model_selection/tests/test_search.py"}'}, '__gemini_function_call_thought_signatures__': {'732c0a80-9da2-4d78-bb7b-edbf82e50ed8': 'Cv4JAY89a1/HKO+mg2pxzc1P4HaKbkOyaKSy25v06xanoHL0N8ODkubi4Le2bVe/IxPvCYLWIi3zQQP+Khpg1qUJSbJiKJdUxIAIRTnkKgcb2e5STIdUiWMAZ1/UMVI0SXqD4QAIEalsI3eh7TIjgdrj7lFxGdIItDroc8K1a1p3UoFsDviCRJ2fpTHWmh0Hu7ApzCirgN/LCM50riSB1tGBQbnqBpSqAuWGuQUHLCtvop0hBOD+7P62DQO5JY4axHc/gTextbCKNA3fioSF2LibeP/8KQNFEtjklr4o2MhjmSbXXnKYG48VlNtFaa4Qfv/rJ/KbBIU2lK1KZiCAMOgFDrVLe72cwrZLDr85xqQ5MeWTyjmMLfOtYcva8ihos4kA7fQdpFbyuGmEetUhOQl2we+oRSOwzig7UAbkXBMjU+znAm9wpJu09cGMgdkpI4Iusu0iDjGPsxYc92aobt+TdFXP4Ia8bFZp3VRLH8zggDQ+DRVgOyNEPHfNAdAcbEGViUSR4/LruSX08ZgTxkfmuy/VYDJHmYOpRHpKPc/Vj2WqGas1pCP59znxbLftFdoY7wfSXwt/ELvGoZ6UcEgXV/uz1Smbs3qlpF5zo9PGHaPGGofxR8tibHHShnDjFb9hiXWTGHt/XihhHd1/ghwppHy/HcrztFJ01CWImiv/ofXC0YVpLk+cgvGDBah6E5TySapGosCKwy2lcdxuzZ4PbVEbaylAmP4xpeG8L2NCZIMGuuZCKAW/C4fBId80FaBFxG89xvp88vn5fqMFm5FIB3IEBjilsLureU6+EC9J+0MJN/kIvYJL4HTfqEDGIEzQ66gmA6zftQCaIWaxKqffzA3f1OCSgKTBsXaqUHrCiTR/FsMBzu/ayY15vo3473hKAagwnN1wvOxUwG2d++014tlGXY/IkZtQSXacDfEOTEIfUaHmrg5X3fd9kPQouokQ6wi21ziyGsgwzS5QgVsu6zzTyRQ4DR1VKFObF7PRgIiqbZ9vDRUtsYvNtIpO9Ynz3uumXtgWQ7mxc+NbSTaw5VABDdORO9BNTbV5FTWH4MpAvERzp2Z5sO2I24+cELjLnyJn0m8OnEUWUThcYyU+t2S6gSWmRjgZsUMb7Qzcsxc/YPpoPc/OQGm/Op6UUYSUieU4fQrzLJk9ZuDca6gyEG4SR06OdXbjoyuh7mZa7G/a2wf9CO4Asd4Y8CPmnrnA9u8q08omjfe/7hfzPvkHQodJgZlzrX6WF9REfsCZ4E/Lzsaa728eKVaypQNcFYxdPa4kLfGWOGfObgoj/wt9hpMfJ20OaAWw0XmWEl4pa1XRgK7BA4LcKN8vi/Bi4uocMQyaRNEw2bVvZVR0ZqJT6D4OrO9JQIQnkeiDrVxFDcv1uzSF1dox4xdHBez+ERcKTi8s7tnAmTcYdMPBrYpFdfosE4QVCBfpCTsiCPmPRPPErcM59oecAOAuPG2AMNrhta9iv9DvYvtqXGkWGfF7h93EIeYBPnermlLxro7IfDBEwKmy99z8QH3uwJ1luE7SBh0LIv9yaYWuuX4DKGsXF6xiAgPv0TgCaDqgJYmSA07HUAZdxNZnpEJXMFTuK2oHyuuCNMjCQlvMxZQl7uZpRS0MsPdFdeEhpk4Dp6sVKigkI2+43ixKGpou47nc+91OtSl5hlw4q+BvvFfzUTM3AU2KTmPCb5jyVGLLPTlK'}} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 5550, 'candidates_token_count': 18, 'total_token_count': 5904, 'cached_content_token_count': 6530, 'prompt_tokens_details': [{'modality': 1, 'token_count': 7337}], 'cache_tokens_details': [{'modality': 1, 'token_count': 6530}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 18}], 'thoughts_token_count': 336}, 'finish_reason': 'STOP', 'avg_logprobs': -2.1518622504340277, 'model_name': 'gemini-2.5-pro'} id='run--ef97994b-46f5-46a8-b626-d366e936ee46-0' tool_calls=[{'name': 'run_command', 'args': {'command': 'pytest sklearn/model_selection/tests/test_search.py'}, 'id': '732c0a80-9da2-4d78-bb7b-edbf82e50ed8', 'type': 'tool_call'}] usage_metadata={'input_tokens': 5550, 'output_tokens': 18, 'total_tokens': 5904, 'input_token_details': {'cache_read': 6530}, 'output_token_details': {'reasoning': 336}}
2025-12-21 09:55:33,490 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: pytest sklearn/model_selection/tests/test_search.py
2025-12-21 09:55:43,576 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 1
2025-12-21 09:55:43,577 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:
pytest sklearn/model_selection/tests/test_s
search.py

[1m============================= test session starts ==============================[0m
platform linux -- Python 3.6.13, pytest-6.2.4, py-1.11.0, pluggy-0.13.1
rootdir: /testbed, configfile: setup.cfg
plugins: anyio-3.6.2
[1mcollecting ... [0m[1m
collecting 0 items                                                             [0m[1m
collected 54 items                                                             [0m

sklearn/model_selection/tests/test_search.py [31mF[0m[31mF[0m[31mF[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[31m [ 50%]
[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[31m                                              [100%][0m

=================================== FAILURES ===================================
[31m[1m_ test_validate_parameter_grid_input[0-TypeError-Parameter grid is not a dict or a list (0)] _[0m

input = 0, error_type = <class 'TypeError'>
error_message = 'Parameter grid is not a dict or a list (0)'

    @pytest.mark.parametrize(
        "input, error_type, error_message",
        [(0, TypeError, 'Parameter grid is not a dict or a list (0)'),
         ([{'foo': [0]}, 0], TypeError, 'Parameter grid is not a dict (0)'),
         ({'foo': 0}, TypeError, "Parameter grid value is not iterable "
          "(key='foo', value=0)")]
    )
    def test_validate_parameter_grid_input(input, error_type, error_message):
>       with pytest.raises(error_type, message=error_message):
[1m[31mE       TypeError: Unexpected keyword arguments passed to pytest.raises: message[0m
[1m[31mE       Use context-manager form instead?[0m

[1m[31msklearn/model_selection/tests/test_search.py[0m:138: TypeError
[31m[1m_ test_validate_parameter_grid_input[input1-TypeError-Parameter grid is not a dict (0)] _[0m

input = [{'foo': [0]}, 0], error_type = <class 'TypeError'>
error_message = 'Parameter grid is not a dict (0)'

    @pytest.mark.parametrize(
        "input, error_type, error_message",
        [(0, TypeError, 'Parameter grid is not a dict or a list (0)'),
         ([{'foo': [0]}, 0], TypeError, 'Parameter grid is not a dict (0)'),
         ({'foo': 0}, TypeError, "Parameter grid value is not iterable "
          "(key='foo', value=0)")]
    )
    def test_validate_parameter_grid_input(input, error_type, error_message):
>       with pytest.raises(error_type, message=error_message):
[1m[31mE       TypeError: Unexpected keyword arguments passed to pytest.raises: message[0m
[1m[31mE       Use context-manager form instead?[0m

[1m[31msklearn/model_selection/tests/test_search.py[0m:138: TypeError
[31m[1m_ test_validate_parameter_grid_input[input2-TypeError-Parameter grid value is not iterable (key='foo', value=0)] _[0m

input = {'foo': 0}, error_type = <class 'TypeError'>
error_message = "Parameter grid value is not iterable (key='foo', value=0)"

    @pytest.mark.parametrize(
        "input, error_type, error_message",
        [(0, TypeError, 'Parameter grid is not a dict or a list (0)'),
         ([{'foo': [0]}, 0], TypeError, 'Parameter grid is not a dict (0)'),
         ({'foo': 0}, TypeError, "Parameter grid value is not iterable "
          "(key='foo', value=0)")]
    )
    def test_validate_parameter_grid_input(input, error_type, error_message):
>       with pytest.raises(error_type, message=error_message):
[1m[31mE       TypeError: Unexpected keyword arguments passed to pytest.raises: message[0m
[1m[31mE       Use context-manager form instead?[0m

[1m[31msklearn/model_selection/tests/test_search.py[0m:138: TypeError
[31m================== [31m[1m3 failed[0m, [32m51 passed[0m, [33m158 warnings[0m[31m in 9.28s[0m[31m ==================[0m

2025-12-21 09:55:47,091 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_execute_node - DEBUG - content='' additional_kwargs={'function_call': {'name': 'run_command', 'arguments': '{"command": "pip install pytest==4.6.11"}'}, '__gemini_function_call_thought_signatures__': {'27183d30-2bea-481c-a6e5-dc064ee99e39': 'CqEIAY89a1865jocXJJEqTv0uWteAvQBeOI9+G0bEhXy36GcZEruiLJZ1YPR1Hrp4Mm8lGcSFRpfb5682z0GzA5b66El95ZbH4M7dFAHUWXNWDogG3GRR/l92ginOLawuthhVCVs+pdEM5REgq5y94WPStGzBFMXjyEzetRPINIKc5K/Vc9TrJXX0Eu8ixpuEMqdP7+BIFZPKWRocRA+jbkeRamEQy6/HYgV6uSFLw9hc5Ed9YtiMIYbfashbByb3wSKv5FUmnps2KfW+ME78+NG/e4pBAki+YACTVOjmotax6H70TU8h2wv89OLJwKeq8/eD0xS4wQrMhpbNpd5yVQhaVH+MUiAsNqRTi/v+JPOrzPck1Ih8HkLFr+mkVeAHzLwhLD9ewEL2JZ1qJu+mio2K48ep1RFT6gSn3cR6iRs6RaXfAnnDD9dAGJppkk2z1ZRMnNGRilmHMkt+fZthB8OkqWROqbPMZNWT2KQo5CH2VujemIqoFa778t5KGe7RaIkRIrJB9YQRXrLg64FNb//n0X89T8dghWo52oQ+dwPY5yls+/zoFTYVUHWWdHLCdoK9+1QO2elQntiVFrPBVRYz3M5RSkN7NcVyQabpyx3X+uCL8GPGf3ecj6N4x/bHzXUMg3hoVyGA0NF2K8NF59+PiPH+YHKPI3vCZ++G5V8ki/TLvU2HEpoLW0VXFLKYEQx+EJ9rZg/dyW+Dpu1v0PffB7HrABuBdzyc0FX+aZrm/6hgMxfPD4RP1sJ+r+4JitOwCOEW9ugpiPVf/JZHCnTxvOezOIax5hqg1kh9z0AJa1LpDFlX5s66p03tgeilC+jOqmgwKO3VNnoCzaWmWj/Kn9450VK7ZM4WqUicuZUM+jfdcd0k05yZqfQQQWL1x0dBogq3PHXqLxZ0B6NelUC+dkpN9nTfnUsTkZGGnodHvP/ZGfUA+oRgVY+giBU6547g50+QdCEuDZZVqCU4L87wFo12iPQbrAz6+ZF9bMD9aA+/iisraK7RUHjjNEGIgDJIY+rbXuf+5SbufXV9xB7SU6exGWNKLUD8APLoc4Ji8K0rc9vIJBUvtILxJOhBlMnsclAKlylghDhmRlEN/6j2RY+qAARfj2X8kO4jmlWN2J7+WZNIlCqYxxA525dUf29wNs9yXP5Wk/wztFQkEATSQVeJKWDGi7QeJNyl6gWAegoVnPP+FlH8K8/P4lamb2m4zVXOl0y+l3/CZQJvRViDQZwqoQ62Mj/Q0nRM/lpDK76eQs7bjz6ez3/C4cKYIm1Tm23H9xIMcWVChljZkAJ8NuRKLSL6LCCy+WO5SBOYMwpg+YJ8LFFi7LMGiEJ103uTObXzXy11BT/vifmV5haEF9XYRLRHRqzi6JnsFdLLpGznL1pIxYbmXc3P6/Lm9lIKg=='}} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 7138, 'candidates_token_count': 14, 'total_token_count': 7417, 'cached_content_token_count': 6388, 'prompt_tokens_details': [{'modality': 1, 'token_count': 9261}], 'cache_tokens_details': [{'modality': 1, 'token_count': 6388}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 14}], 'thoughts_token_count': 265}, 'finish_reason': 'STOP', 'avg_logprobs': -1.9790815625871931, 'model_name': 'gemini-2.5-pro'} id='run--d6b153c5-6cce-4748-b842-523f6993a955-0' tool_calls=[{'name': 'run_command', 'args': {'command': 'pip install pytest==4.6.11'}, 'id': '27183d30-2bea-481c-a6e5-dc064ee99e39', 'type': 'tool_call'}] usage_metadata={'input_tokens': 7138, 'output_tokens': 14, 'total_tokens': 7417, 'input_token_details': {'cache_read': 6388}, 'output_token_details': {'reasoning': 265}}
2025-12-21 09:55:47,094 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: pip install pytest==4.6.11
2025-12-21 09:55:50,383 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 0
2025-12-21 09:55:50,383 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:

Collecting pytest==4.6.11
  Downloading pytest-4.6.11-py2.py3-none-any.whl (231 kB)
[?25l
[K     |#                               | 10 kB 3.8 MB/s eta 0:00:01
[K     |##                              | 20 kB 1.4 MB/s eta 0:00:01
[K     |####                            | 30 kB 2.0 MB/s eta 0:00:01
[K     |#####                           | 40 kB 1.9 MB/s eta 0:00:01
[K     |#######                         | 51 kB 1.6 MB/s eta 0:00:01
[K     |########                        | 61 kB 1.9 MB/s eta 0:00:01
[K     |#########                       | 71 kB 2.0 MB/s eta 0:00:01
[K     |###########                     | 81 kB 2.3 MB/s eta 0:00:01
[K     |############                    | 92 kB 2.4 MB/s eta 0:00:01
[K     |##############                  | 102 kB 2.5 MB/s eta 0:00:01
[K     |###############                 | 112 kB 2.5 MB/s eta 0:00:01
[K     |################                | 122 kB 2.5 MB/s eta 0:00:01
[K     |##################              | 133 kB 2.5 MB/s eta 0:00:01
[K     |###################             | 143 kB 2.5 MB/s eta 0:00:01
[K     |#####################           | 153 kB 2.5 MB/s eta 0:00:01
[K     |######################          | 163 kB 2.5 MB/s eta 0:00:01
[K     |########################        | 174 kB 2.5 MB/s eta 0:00:01
[K     |#########################       | 184 kB 2.5 MB/s eta 0:00:01
[K     |##########################      | 194 kB 2.5 MB/s eta 0:00:01
[K     |############################    | 204 kB 2.5 MB/s eta 0:00:01
[K     |#############################   | 215 kB 2.5 MB/s eta 0:00:01
[K     |############################### | 225 kB 2.5 MB/s eta 0:00:01
[K     |################################| 231 kB 2.5 MB/s 
[?25hCollecting atomicwrites>=1.0
  Downloading atomicwrites-1.4.1.tar.gz (14 kB)
Requirement already satisfied: py>=1.5.0 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from pytest==4.6.11) (1.11.0)
Requirement already satisfied: six>=1.10.0 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from pytest==4.6.11) (1.16.0)
Requirement already satisfied: more-itertools>=4.0.0 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from pytest==4.6.11) (8.12.0)
Requirement already satisfied: attrs>=17.4.0 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from pytest==4.6.11) (21.4.0)
Collecting wcwidth
  Downloading wcwidth-0.2.14-py2.py3-none-any.whl (37 kB)
Requirement already satisfied: importlib-metadata>=0.12 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from pytest==4.6.11) (4.8.1)
Requirement already satisfied: pluggy<1.0,>=0.12 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from pytest==4.6.11) (0.13.1)
Requirement already satisfied: packaging in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from pytest==4.6.11) (21.3)
Requirement already satisfied: zipp>=0.5 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from importlib-metadata>=0.12->pytest==4.6.11) (3.6.0)
Requirement already satisfied: typing-extensions>=3.6.4 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from importlib-metadata>=0.12->pytest==4.6.11) (4.1.1)
Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from packaging->pytest==4.6.11) (3.0.4)
Building wheels for collected packages: atomicwrites
  Building wheel for atomicwrites (setup.py) ... [?25l- \ done
[?25h  Created wheel for atomicwrites: filename=atomicwrites-1.4.1-py2.py3-none-any.whl size=6957 sha256=0d45d3351e2898c3de0989c085bed3088e128984adf5acfe79c7aa517c49975f
  Stored in directory: /root/.cache/pip/wheels/a1/e7/28/46d397595a418eb7ce1a8e6bbdfcea9e73753249bc824cc9cb
Successfully built atomicwrites
Installing collected packages: wcwidth, atomicwrites, pytest
  Attempting uninstall: pytest
    Found existing installation: pytest 6.2.4
    Uninstalling pytest-6.2.4:
      Successfully uninstalled pytest-6.2.4
Successfully installed atomicwrites-1.4.1 pytest-4.6.11 wcwidth-0.2.14
[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv[0m

2025-12-21 09:55:51,413 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_execute_node - DEBUG - content='' additional_kwargs={'function_call': {'name': 'run_command', 'arguments': '{"command": "pytest sklearn/model_selection/tests/test_search.py"}'}, '__gemini_function_call_thought_signatures__': {'5179ec71-c5c8-4e5b-8cea-9611e3e6efb8': 'CmcBjz1rX67JakEBPzGq3pBi0cQEdGX53XzAXk1lV0AKx5kEXWL3pIy57LdvMQOHE9/COAMeeW9dAuMu7/ervilDj5d517jPTqbBHddVrhL3VgJVF0cHIwsyhwvphPXt0xfHWOhFgU5H'}} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 8849, 'candidates_token_count': 18, 'total_token_count': 8884, 'prompt_tokens_details': [{'modality': 1, 'token_count': 11237}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 18}], 'thoughts_token_count': 17, 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.09687406486935085, 'model_name': 'gemini-2.5-pro'} id='run--09363a95-0348-4600-9dc9-7069a1d47f0c-0' tool_calls=[{'name': 'run_command', 'args': {'command': 'pytest sklearn/model_selection/tests/test_search.py'}, 'id': '5179ec71-c5c8-4e5b-8cea-9611e3e6efb8', 'type': 'tool_call'}] usage_metadata={'input_tokens': 8849, 'output_tokens': 18, 'total_tokens': 8884, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 17}}
2025-12-21 09:55:51,416 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: pytest sklearn/model_selection/tests/test_search.py
2025-12-21 09:56:00,998 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 0
2025-12-21 09:56:00,999 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:
pytest sklearn/model_selection/tests/test_s
search.py

[1m============================= test session starts ==============================[0m
platform linux -- Python 3.6.13, pytest-4.6.11, py-1.11.0, pluggy-0.13.1
rootdir: /testbed, inifile: setup.cfg
plugins: anyio-3.6.2
[1mcollecting ... [0m[1m
collecting 0 items                                                             [0m[1m
collected 54 items                                                             [0m

sklearn/model_selection/tests/test_search.py [32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[36m [ 50%]
[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[36m                                              [100%][0m

[33m[1m=================== 54 passed, 161 warnings in 8.64 seconds ====================[0m

2025-12-21 09:56:11,079 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_execute_node - DEBUG - content='' additional_kwargs={'function_call': {'name': 'run_command', 'arguments': '{"command": "echo \\"import pytest\\nimport sklearn.datasets\\nimport sklearn.model_selection\\nimport sklearn.ensemble\\n\\ndef test_refit_time_attribute():\\n    X, y = sklearn.datasets.load_iris(return_X_y=True)\\n\\n    rs = sklearn.model_selection.GridSearchCV(\\n        estimator=sklearn.ensemble.RandomForestClassifier(),\\n        param_grid={\'n_estimators\': [2, 3, 4, 5]}\\n    )\\n    rs.fit(X, y)\\n\\n    assert hasattr(rs, \'refit_time_\')\\n\\" > tests/test_bug.py"}'}, '__gemini_function_call_thought_signatures__': {'d093d40a-457a-4007-b240-c7bfcd5994f1': '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'}} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 9515, 'candidates_token_count': 142, 'total_token_count': 10592, 'prompt_tokens_details': [{'modality': 1, 'token_count': 11920}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 142}], 'thoughts_token_count': 935, 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.6787872314453125, 'model_name': 'gemini-2.5-pro'} id='run--3a32ab83-1aea-42fd-91af-b93ca5510969-0' tool_calls=[{'name': 'run_command', 'args': {'command': 'echo "import pytest\nimport sklearn.datasets\nimport sklearn.model_selection\nimport sklearn.ensemble\n\ndef test_refit_time_attribute():\n    X, y = sklearn.datasets.load_iris(return_X_y=True)\n\n    rs = sklearn.model_selection.GridSearchCV(\n        estimator=sklearn.ensemble.RandomForestClassifier(),\n        param_grid={\'n_estimators\': [2, 3, 4, 5]}\n    )\n    rs.fit(X, y)\n\n    assert hasattr(rs, \'refit_time_\')\n" > tests/test_bug.py'}, 'id': 'd093d40a-457a-4007-b240-c7bfcd5994f1', 'type': 'tool_call'}] usage_metadata={'input_tokens': 9515, 'output_tokens': 142, 'total_tokens': 10592, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 935}}
2025-12-21 09:56:11,082 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: echo "import pytest
import sklearn.datasets
import sklearn.model_selection
import sklearn.ensemble

def test_refit_time_attribute():
    X, y = sklearn.datasets.load_iris(return_X_y=True)

    rs = sklearn.model_selection.GridSearchCV(
        estimator=sklearn.ensemble.RandomForestClassifier(),
        param_grid={'n_estimators': [2, 3, 4, 5]}
    )
    rs.fit(X, y)

    assert hasattr(rs, 'refit_time_')
" > tests/test_bug.py
2025-12-21 09:56:11,184 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 0
2025-12-21 09:56:11,184 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:
echo "import pytest

> import sklearn.datasets

> import sklearn.model_selection

> import sklearn.ensemble

> 

> def test_refit_time_attribute():

>     X, y = sklearn.datasets.load_iris(return_X_y=True)

> 

>     rs = sklearn.model_selection.GridSearchCV(

>         estimator=sklearn.ensemble.RandomForestClassifier(),

>         param_grid={'n_estimators': [2, 3, 4, 5]}

>     )

>     rs.fit(X, y)

> 

>     assert hasattr(rs, 'refit_time_')

> " > tests/test_bug.py


2025-12-21 09:56:12,283 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_execute_node - DEBUG - content='' additional_kwargs={'function_call': {'name': 'run_command', 'arguments': '{"command": "pytest tests/test_bug.py"}'}, '__gemini_function_call_thought_signatures__': {'b47de862-66a2-409b-ad3d-1fbd7f6a690e': 'CmQBjz1rX6sk+PmatMACHSdfE4WF0ADLvSj3MYqPeNry69puUnTydUwVg294sy0cDXkj/r9q23YVN0G94Hiwvzk4uxTRUw5KdelQZigmu6Xe+eUdgQQyheVWevuwlYm5nD8VKSQH'}} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 9821, 'candidates_token_count': 12, 'total_token_count': 9850, 'cached_content_token_count': 11398, 'prompt_tokens_details': [{'modality': 1, 'token_count': 13161}], 'cache_tokens_details': [{'modality': 1, 'token_count': 11398}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 12}], 'thoughts_token_count': 17}, 'finish_reason': 'STOP', 'avg_logprobs': -0.14474978049596152, 'model_name': 'gemini-2.5-pro'} id='run--0cf29be0-dbea-4b82-8248-0169457f461d-0' tool_calls=[{'name': 'run_command', 'args': {'command': 'pytest tests/test_bug.py'}, 'id': 'b47de862-66a2-409b-ad3d-1fbd7f6a690e', 'type': 'tool_call'}] usage_metadata={'input_tokens': 9821, 'output_tokens': 12, 'total_tokens': 9850, 'input_token_details': {'cache_read': 11398}, 'output_token_details': {'reasoning': 17}}
2025-12-21 09:56:12,285 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: pytest tests/test_bug.py
2025-12-21 09:56:13,812 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 1
2025-12-21 09:56:13,812 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:

[1m============================= test session starts ==============================[0m
platform linux -- Python 3.6.13, pytest-4.6.11, py-1.11.0, pluggy-0.13.1
rootdir: /testbed, inifile: setup.cfg
plugins: anyio-3.6.2
[1mcollecting ... [0m[1m
collecting 0 items                                                             [0m[1m
collected 1 item                                                               [0m

tests/test_bug.py [31mF[0m[36m                                                      [100%][0m

=================================== FAILURES ===================================
[31m[1m__________________________ test_refit_time_attribute ___________________________[0m

[1m    def test_refit_time_attribute():[0m
[1m        X, y = sklearn.datasets.load_iris(return_X_y=True)[0m
[1m    [0m
[1m        rs = sklearn.model_selection.GridSearchCV([0m
[1m            estimator=sklearn.ensemble.RandomForestClassifier(),[0m
[1m            param_grid={'n_estimators': [2, 3, 4, 5]}[0m
[1m        )[0m
[1m        rs.fit(X, y)[0m
[1m    [0m
[1m>       assert hasattr(rs, 'refit_time_')[0m
[1m[31mE       AssertionError: assert False[0m
[1m[31mE        +  where False = hasattr(GridSearchCV(cv=None, error_score='raise-deprecating',\n       estimator=RandomForestClassifier(bootstrap=True, class_w...mators': [2, 3, 4, 5]}, pre_dispatch='2*n_jobs',\n       refit=True, return_train_score='warn', scoring=None, verbose=0), 'refit_time_')[0m

[1m[31mtests/test_bug.py[0m:15: AssertionError
[31m[1m===================== 1 failed, 1 warnings in 0.87 seconds =====================[0m

2025-12-21 09:56:19,123 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_execute_node - DEBUG - content="I have executed the bug reproduction test file `tests/test_bug.py`. Here is the output:\n\n```\n============================= test session starts ==============================\nplatform linux -- Python 3.6.13, pytest-4.6.11, py-1.11.0, pluggy-0.13.1\nrootdir: /testbed, inifile: setup.cfg\nplugins: anyio-3.6.2\ncollecting ... \ncollected 1 item\n\ntests/test_bug.py F                                                      [100%]\n\n=================================== FAILURES ===================================\n__________________________ test_refit_time_attribute ___________________________\n\n    def test_refit_time_attribute():\n        X, y = sklearn.datasets.load_iris(return_X_y=True)\n    \n        rs = sklearn.model_selection.GridSearchCV(\n            estimator=sklearn.ensemble.RandomForestClassifier(),\n            param_grid={'n_estimators': [2, 3, 4, 5]}\n        )\n        rs.fit(X, y)\n    \n>       assert hasattr(rs, 'refit_time_')\nE       AssertionError: assert False\nE        +  where False = hasattr(GridSearchCV(cv=None, error_score='raise-deprecating',\n       estimator=RandomForestClassifier(bootstrap=True, class_w...mators': [2, 3, 4, 5]}, pre_dispatch='2*n_jobs',\n       refit=True, return_train_score='warn', scoring=None, verbose=0), 'refit_time_')\n\ntests/test_bug.py:15: AssertionError\n===================== 1 failed, 1 warnings in 0.87 seconds =====================\n```" additional_kwargs={} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 10372, 'candidates_token_count': 403, 'total_token_count': 10952, 'cached_content_token_count': 12939, 'prompt_tokens_details': [{'modality': 1, 'token_count': 13729}], 'cache_tokens_details': [{'modality': 1, 'token_count': 12939}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 403}], 'thoughts_token_count': 177}, 'finish_reason': 'STOP', 'avg_logprobs': -0.061205075928945994, 'model_name': 'gemini-2.5-pro'} id='run--c816afd1-4582-4f1f-9826-725235fbdf25-0' usage_metadata={'input_tokens': 10372, 'output_tokens': 403, 'total_tokens': 10952, 'input_token_details': {'cache_read': 12939}, 'output_token_details': {'reasoning': 177}}
2025-12-21 09:56:29,706 - thread-130546535499456.app.lang_graph.nodes.bug_reproducing_structured_node - DEBUG - reproduced_bug=True reproduced_bug_failure_log="\n============================= test session starts ==============================\nplatform linux -- Python 3.6.13, pytest-4.6.11, py-1.11.0, pluggy-0.13.1\nrootdir: /testbed, inifile: setup.cfg\nplugins: anyio-3.6.2\ncollecting ... \ncollecting 0 items                                                             \ncollected 1 item                                                               \n\ntests/test_bug.py F                                                      [100%]\n\n=================================== FAILURES ===================================\n__________________________ test_refit_time_attribute ___________________________\n\n    def test_refit_time_attribute():\n        X, y = sklearn.datasets.load_iris(return_X_y=True)\n    \n        rs = sklearn.model_selection.GridSearchCV(\n            estimator=sklearn.ensemble.RandomForestClassifier(),\n            param_grid={'n_estimators': [2, 3, 4, 5]}\n        )\n        rs.fit(X, y)\n    \n>       assert hasattr(rs, 'refit_time_')\nE       AssertionError: assert False\nE        +  where False = hasattr(GridSearchCV(cv=None, error_score='raise-deprecating',\n       estimator=RandomForestClassifier(bootstrap=True, class_w...mators': [2, 3, 4, 5]}, pre_dispatch='2*n_jobs',\n       refit=True, return_train_score='warn', scoring=None, verbose=0), 'refit_time_')\n\ntests/test_bug.py:15: AssertionError\n===================== 1 failed, 1 warnings in 0.87 seconds =====================" reproduced_bug_commands=['pytest tests/test_bug.py']
2025-12-21 09:56:29,707 - thread-130546535499456.app.lang_graph.nodes.dual_version_validation_node - INFO - Starting dual-version validation
2025-12-21 09:56:29,707 - thread-130546535499456.app.lang_graph.nodes.dual_version_validation_node - INFO - Running test on old codebase (should fail)
2025-12-21 09:56:29,707 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: pytest tests/test_bug.py
2025-12-21 09:56:31,154 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 1
2025-12-21 09:56:31,154 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:

[1m============================= test session starts ==============================[0m
platform linux -- Python 3.6.13, pytest-4.6.11, py-1.11.0, pluggy-0.13.1
rootdir: /testbed, inifile: setup.cfg
plugins: anyio-3.6.2
[1mcollecting ... [0m[1m
collecting 0 items                                                             [0m[1m
collected 1 item                                                               [0m

tests/test_bug.py [31mF[0m[36m                                                      [100%][0m

=================================== FAILURES ===================================
[31m[1m__________________________ test_refit_time_attribute ___________________________[0m

[1m    def test_refit_time_attribute():[0m
[1m        X, y = sklearn.datasets.load_iris(return_X_y=True)[0m
[1m    [0m
[1m        rs = sklearn.model_selection.GridSearchCV([0m
[1m            estimator=sklearn.ensemble.RandomForestClassifier(),[0m
[1m            param_grid={'n_estimators': [2, 3, 4, 5]}[0m
[1m        )[0m
[1m        rs.fit(X, y)[0m
[1m    [0m
[1m>       assert hasattr(rs, 'refit_time_')[0m
[1m[31mE       AssertionError: assert False[0m
[1m[31mE        +  where False = hasattr(GridSearchCV(cv=None, error_score='raise-deprecating',\n       estimator=RandomForestClassifier(bootstrap=True, class_w...mators': [2, 3, 4, 5]}, pre_dispatch='2*n_jobs',\n       refit=True, return_train_score='warn', scoring=None, verbose=0), 'refit_time_')[0m

[1m[31mtests/test_bug.py[0m:15: AssertionError
[31m[1m===================== 1 failed, 1 warnings in 0.80 seconds =====================[0m

2025-12-21 09:56:31,154 - thread-130546535499456.app.lang_graph.nodes.dual_version_validation_node - INFO - Test failed on old codebase (as expected)
2025-12-21 09:56:31,154 - thread-130546535499456.app.lang_graph.nodes.dual_version_validation_node - INFO - Applying patch to repository
2025-12-21 09:56:31,159 - thread-130546535499456.app.lang_graph.nodes.dual_version_validation_node - INFO - Updating container with patched code
2025-12-21 09:56:31,160 - thread-130546535499456.app.docker.base_container - INFO - Updating files in the container after edits.
2025-12-21 09:56:31,160 - thread-130546535499456.app.docker.base_container - INFO - Creating directory sklearn/model_selection in the container
2025-12-21 09:56:31,160 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: mkdir -p sklearn/model_selection
2025-12-21 09:56:31,261 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 0
2025-12-21 09:56:31,262 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:


2025-12-21 09:56:31,262 - thread-130546535499456.app.docker.base_container - INFO - Updating sklearn/model_selection/_search.py in the container
2025-12-21 09:56:31,269 - thread-130546535499456.app.docker.base_container - INFO - Files updated successfully
2025-12-21 09:56:31,269 - thread-130546535499456.app.lang_graph.nodes.dual_version_validation_node - INFO - Running test on patched codebase (should pass)
2025-12-21 09:56:31,269 - thread-130546535499456.app.docker.base_container - DEBUG - Executing command: pytest tests/test_bug.py
2025-12-21 09:56:32,729 - thread-130546535499456.app.docker.base_container - DEBUG - Command exit code: 0
2025-12-21 09:56:32,729 - thread-130546535499456.app.docker.base_container - DEBUG - Command output:

[1m============================= test session starts ==============================[0m
platform linux -- Python 3.6.13, pytest-4.6.11, py-1.11.0, pluggy-0.13.1
rootdir: /testbed, inifile: setup.cfg
plugins: anyio-3.6.2
[1mcollecting ... [0m[1m
collecting 0 items                                                             [0m[1m
collected 1 item                                                               [0m

tests/test_bug.py [32m.[0m[36m                                                      [100%][0m

[33m[1m===================== 1 passed, 1 warnings in 0.76 seconds =====================[0m

2025-12-21 09:56:32,729 - thread-130546535499456.app.lang_graph.nodes.dual_version_validation_node - INFO - Resetting repository to clean state
2025-12-21 09:56:32,750 - thread-130546535499456.app.lang_graph.nodes.dual_version_validation_node - INFO - Validation PASSED: Test fails on old, passes on new
2025-12-21 09:56:32,752 - thread-130546535499456.app.docker.base_container - INFO - Cleaning up container and temporary files
2025-12-21 09:56:32,752 - thread-130546535499456.app.docker.base_container - INFO - Closing persistent shell...
2025-12-21 09:56:32,852 - thread-130546535499456.app.docker.base_container - INFO - Cleaning up container and temporary files
