{"instance_id": "django__django-11087", "repo": "django/django", "version": "3.0", "environment_setup_commit": "419a78300f7cd27611196e1e464d50fd0385ff27", "patch_list": ["diff --git a/delete_regress/tests.py b/delete_regress/tests.py\nnew file mode 100644\nindex 0000000000..8d657e3738\n--- /dev/null\n+++ b/delete_regress/tests.py\n@@ -0,0 +1,417 @@\n+import datetime\n+\n+from django.db import connection, models, transaction\n+from django.test import TestCase, TransactionTestCase, skipUnlessDBFeature\n+\n+from .models import (\n+    Award, AwardNote, Book, Child, Contact, Eaten, Email, File, Food, FooFile,\n+    FooFileProxy, FooImage, FooPhoto, House, Image, Item, Location, Login,\n+    OrderedPerson, OrgUnit, Person, Photo, PlayedWith, PlayedWithNote, Policy,\n+    Researcher, Toy, Version,\n+)\n+\n+\n+# Can't run this test under SQLite, because you can't\n+# get two connections to an in-memory database.\n+@skipUnlessDBFeature('test_db_allows_multiple_connections')\n+class DeleteLockingTest(TransactionTestCase):\n+\n+    available_apps = ['delete_regress']\n+\n+    def setUp(self):\n+        # Create a second connection to the default database\n+        self.conn2 = connection.copy()\n+        self.conn2.set_autocommit(False)\n+\n+    def tearDown(self):\n+        # Close down the second connection.\n+        self.conn2.rollback()\n+        self.conn2.close()\n+\n+    def test_concurrent_delete(self):\n+        \"\"\"Concurrent deletes don't collide and lock the database (#9479).\"\"\"\n+        with transaction.atomic():\n+            Book.objects.create(id=1, pagecount=100)\n+            Book.objects.create(id=2, pagecount=200)\n+            Book.objects.create(id=3, pagecount=300)\n+\n+        with transaction.atomic():\n+            # Start a transaction on the main connection.\n+            self.assertEqual(3, Book.objects.count())\n+\n+            # Delete something using another database connection.\n+            with self.conn2.cursor() as cursor2:\n+                cursor2.execute(\"DELETE from delete_regress_book WHERE id = 1\")\n+            self.conn2.commit()\n+\n+            # In the same transaction on the main connection, perform a\n+            # queryset delete that covers the object deleted with the other\n+            # connection. This causes an infinite loop under MySQL InnoDB\n+            # unless we keep track of already deleted objects.\n+            Book.objects.filter(pagecount__lt=250).delete()\n+\n+        self.assertEqual(1, Book.objects.count())\n+\n+\n+class DeleteCascadeTests(TestCase):\n+    def test_generic_relation_cascade(self):\n+        \"\"\"\n+        Django cascades deletes through generic-related objects to their\n+        reverse relations.\n+        \"\"\"\n+        person = Person.objects.create(name='Nelson Mandela')\n+        award = Award.objects.create(name='Nobel', content_object=person)\n+        AwardNote.objects.create(note='a peace prize', award=award)\n+        self.assertEqual(AwardNote.objects.count(), 1)\n+        person.delete()\n+        self.assertEqual(Award.objects.count(), 0)\n+        # first two asserts are just sanity checks, this is the kicker:\n+        self.assertEqual(AwardNote.objects.count(), 0)\n+\n+    def test_fk_to_m2m_through(self):\n+        \"\"\"\n+        If an M2M relationship has an explicitly-specified through model, and\n+        some other model has an FK to that through model, deletion is cascaded\n+        from one of the participants in the M2M, to the through model, to its\n+        related model.\n+        \"\"\"\n+        juan = Child.objects.create(name='Juan')\n+        paints = Toy.objects.create(name='Paints')\n+        played = PlayedWith.objects.create(child=juan, toy=paints, date=datetime.date.today())\n+        PlayedWithNote.objects.create(played=played, note='the next Jackson Pollock')\n+        self.assertEqual(PlayedWithNote.objects.count(), 1)\n+        paints.delete()\n+        self.assertEqual(PlayedWith.objects.count(), 0)\n+        # first two asserts just sanity checks, this is the kicker:\n+        self.assertEqual(PlayedWithNote.objects.count(), 0)\n+\n+    def test_15776(self):\n+        policy = Policy.objects.create(pk=1, policy_number=\"1234\")\n+        version = Version.objects.create(policy=policy)\n+        location = Location.objects.create(version=version)\n+        Item.objects.create(version=version, location=location)\n+        policy.delete()\n+\n+\n+class DeleteCascadeTransactionTests(TransactionTestCase):\n+\n+    available_apps = ['delete_regress']\n+\n+    def test_inheritance(self):\n+        \"\"\"\n+        Auto-created many-to-many through tables referencing a parent model are\n+        correctly found by the delete cascade when a child of that parent is\n+        deleted.\n+\n+        Refs #14896.\n+        \"\"\"\n+        r = Researcher.objects.create()\n+        email = Email.objects.create(\n+            label=\"office-email\", email_address=\"carl@science.edu\"\n+        )\n+        r.contacts.add(email)\n+\n+        email.delete()\n+\n+    def test_to_field(self):\n+        \"\"\"\n+        Cascade deletion works with ForeignKey.to_field set to non-PK.\n+        \"\"\"\n+        apple = Food.objects.create(name=\"apple\")\n+        Eaten.objects.create(food=apple, meal=\"lunch\")\n+\n+        apple.delete()\n+        self.assertFalse(Food.objects.exists())\n+        self.assertFalse(Eaten.objects.exists())\n+\n+\n+class LargeDeleteTests(TestCase):\n+    def test_large_deletes(self):\n+        \"Regression for #13309 -- if the number of objects > chunk size, deletion still occurs\"\n+        for x in range(300):\n+            Book.objects.create(pagecount=x + 100)\n+        # attach a signal to make sure we will not fast-delete\n+\n+        def noop(*args, **kwargs):\n+            pass\n+        models.signals.post_delete.connect(noop, sender=Book)\n+        Book.objects.all().delete()\n+        models.signals.post_delete.disconnect(noop, sender=Book)\n+        self.assertEqual(Book.objects.count(), 0)\n+\n+\n+class ProxyDeleteTest(TestCase):\n+    \"\"\"\n+    Tests on_delete behavior for proxy models.\n+\n+    See #16128.\n+    \"\"\"\n+    def create_image(self):\n+        \"\"\"Return an Image referenced by both a FooImage and a FooFile.\"\"\"\n+        # Create an Image\n+        test_image = Image()\n+        test_image.save()\n+        foo_image = FooImage(my_image=test_image)\n+        foo_image.save()\n+\n+        # Get the Image instance as a File\n+        test_file = File.objects.get(pk=test_image.pk)\n+        foo_file = FooFile(my_file=test_file)\n+        foo_file.save()\n+\n+        return test_image\n+\n+    def test_delete_proxy(self):\n+        \"\"\"\n+        Deleting the *proxy* instance bubbles through to its non-proxy and\n+        *all* referring objects are deleted.\n+        \"\"\"\n+        self.create_image()\n+\n+        Image.objects.all().delete()\n+\n+        # An Image deletion == File deletion\n+        self.assertEqual(len(Image.objects.all()), 0)\n+        self.assertEqual(len(File.objects.all()), 0)\n+\n+        # The Image deletion cascaded and *all* references to it are deleted.\n+        self.assertEqual(len(FooImage.objects.all()), 0)\n+        self.assertEqual(len(FooFile.objects.all()), 0)\n+\n+    def test_delete_proxy_of_proxy(self):\n+        \"\"\"\n+        Deleting a proxy-of-proxy instance should bubble through to its proxy\n+        and non-proxy parents, deleting *all* referring objects.\n+        \"\"\"\n+        test_image = self.create_image()\n+\n+        # Get the Image as a Photo\n+        test_photo = Photo.objects.get(pk=test_image.pk)\n+        foo_photo = FooPhoto(my_photo=test_photo)\n+        foo_photo.save()\n+\n+        Photo.objects.all().delete()\n+\n+        # A Photo deletion == Image deletion == File deletion\n+        self.assertEqual(len(Photo.objects.all()), 0)\n+        self.assertEqual(len(Image.objects.all()), 0)\n+        self.assertEqual(len(File.objects.all()), 0)\n+\n+        # The Photo deletion should have cascaded and deleted *all*\n+        # references to it.\n+        self.assertEqual(len(FooPhoto.objects.all()), 0)\n+        self.assertEqual(len(FooFile.objects.all()), 0)\n+        self.assertEqual(len(FooImage.objects.all()), 0)\n+\n+    def test_delete_concrete_parent(self):\n+        \"\"\"\n+        Deleting an instance of a concrete model should also delete objects\n+        referencing its proxy subclass.\n+        \"\"\"\n+        self.create_image()\n+\n+        File.objects.all().delete()\n+\n+        # A File deletion == Image deletion\n+        self.assertEqual(len(File.objects.all()), 0)\n+        self.assertEqual(len(Image.objects.all()), 0)\n+\n+        # The File deletion should have cascaded and deleted *all* references\n+        # to it.\n+        self.assertEqual(len(FooFile.objects.all()), 0)\n+        self.assertEqual(len(FooImage.objects.all()), 0)\n+\n+    def test_delete_proxy_pair(self):\n+        \"\"\"\n+        If a pair of proxy models are linked by an FK from one concrete parent\n+        to the other, deleting one proxy model cascade-deletes the other, and\n+        the deletion happens in the right order (not triggering an\n+        IntegrityError on databases unable to defer integrity checks).\n+\n+        Refs #17918.\n+        \"\"\"\n+        # Create an Image (proxy of File) and FooFileProxy (proxy of FooFile,\n+        # which has an FK to File)\n+        image = Image.objects.create()\n+        as_file = File.objects.get(pk=image.pk)\n+        FooFileProxy.objects.create(my_file=as_file)\n+\n+        Image.objects.all().delete()\n+\n+        self.assertEqual(len(FooFileProxy.objects.all()), 0)\n+\n+    def test_19187_values(self):\n+        msg = 'Cannot call delete() after .values() or .values_list()'\n+        with self.assertRaisesMessage(TypeError, msg):\n+            Image.objects.values().delete()\n+        with self.assertRaisesMessage(TypeError, msg):\n+            Image.objects.values_list().delete()\n+\n+\n+class Ticket19102Tests(TestCase):\n+    \"\"\"\n+    Test different queries which alter the SELECT clause of the query. We\n+    also must be using a subquery for the deletion (that is, the original\n+    query has a join in it). The deletion should be done as \"fast-path\"\n+    deletion (that is, just one query for the .delete() call).\n+\n+    Note that .values() is not tested here on purpose. .values().delete()\n+    doesn't work for non fast-path deletes at all.\n+    \"\"\"\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.o1 = OrgUnit.objects.create(name='o1')\n+        cls.o2 = OrgUnit.objects.create(name='o2')\n+        cls.l1 = Login.objects.create(description='l1', orgunit=cls.o1)\n+        cls.l2 = Login.objects.create(description='l2', orgunit=cls.o2)\n+\n+    @skipUnlessDBFeature(\"update_can_self_select\")\n+    def test_ticket_19102_annotate(self):\n+        with self.assertNumQueries(1):\n+            Login.objects.order_by('description').filter(\n+                orgunit__name__isnull=False\n+            ).annotate(\n+                n=models.Count('description')\n+            ).filter(\n+                n=1, pk=self.l1.pk\n+            ).delete()\n+        self.assertFalse(Login.objects.filter(pk=self.l1.pk).exists())\n+        self.assertTrue(Login.objects.filter(pk=self.l2.pk).exists())\n+\n+    @skipUnlessDBFeature(\"update_can_self_select\")\n+    def test_ticket_19102_extra(self):\n+        with self.assertNumQueries(1):\n+            Login.objects.order_by('description').filter(\n+                orgunit__name__isnull=False\n+            ).extra(\n+                select={'extraf': '1'}\n+            ).filter(\n+                pk=self.l1.pk\n+            ).delete()\n+        self.assertFalse(Login.objects.filter(pk=self.l1.pk).exists())\n+        self.assertTrue(Login.objects.filter(pk=self.l2.pk).exists())\n+\n+    @skipUnlessDBFeature(\"update_can_self_select\")\n+    @skipUnlessDBFeature('can_distinct_on_fields')\n+    def test_ticket_19102_distinct_on(self):\n+        # Both Login objs should have same description so that only the one\n+        # having smaller PK will be deleted.\n+        Login.objects.update(description='description')\n+        with self.assertNumQueries(1):\n+            Login.objects.distinct('description').order_by('pk').filter(\n+                orgunit__name__isnull=False\n+            ).delete()\n+        # Assumed that l1 which is created first has smaller PK.\n+        self.assertFalse(Login.objects.filter(pk=self.l1.pk).exists())\n+        self.assertTrue(Login.objects.filter(pk=self.l2.pk).exists())\n+\n+    @skipUnlessDBFeature(\"update_can_self_select\")\n+    def test_ticket_19102_select_related(self):\n+        with self.assertNumQueries(1):\n+            Login.objects.filter(\n+                pk=self.l1.pk\n+            ).filter(\n+                orgunit__name__isnull=False\n+            ).order_by(\n+                'description'\n+            ).select_related('orgunit').delete()\n+        self.assertFalse(Login.objects.filter(pk=self.l1.pk).exists())\n+        self.assertTrue(Login.objects.filter(pk=self.l2.pk).exists())\n+\n+    @skipUnlessDBFeature(\"update_can_self_select\")\n+    def test_ticket_19102_defer(self):\n+        with self.assertNumQueries(1):\n+            Login.objects.filter(\n+                pk=self.l1.pk\n+            ).filter(\n+                orgunit__name__isnull=False\n+            ).order_by(\n+                'description'\n+            ).only('id').delete()\n+        self.assertFalse(Login.objects.filter(pk=self.l1.pk).exists())\n+        self.assertTrue(Login.objects.filter(pk=self.l2.pk).exists())\n+\n+\n+class DeleteTests(TestCase):\n+    def test_meta_ordered_delete(self):\n+        # When a subquery is performed by deletion code, the subquery must be\n+        # cleared of all ordering. There was a but that caused _meta ordering\n+        # to be used. Refs #19720.\n+        h = House.objects.create(address='Foo')\n+        OrderedPerson.objects.create(name='Jack', lives_in=h)\n+        OrderedPerson.objects.create(name='Bob', lives_in=h)\n+        OrderedPerson.objects.filter(lives_in__address='Foo').delete()\n+        self.assertEqual(OrderedPerson.objects.count(), 0)\n+\n+    def test_foreign_key_delete_nullifies_correct_columns(self):\n+        \"\"\"\n+        With a model (Researcher) that has two foreign keys pointing to the\n+        same model (Contact), deleting an instance of the target model\n+        (contact1) nullifies the correct fields of Researcher.\n+        \"\"\"\n+        contact1 = Contact.objects.create(label='Contact 1')\n+        contact2 = Contact.objects.create(label='Contact 2')\n+        researcher1 = Researcher.objects.create(\n+            primary_contact=contact1,\n+            secondary_contact=contact2,\n+        )\n+        researcher2 = Researcher.objects.create(\n+            primary_contact=contact2,\n+            secondary_contact=contact1,\n+        )\n+        contact1.delete()\n+        researcher1.refresh_from_db()\n+        researcher2.refresh_from_db()\n+        self.assertIsNone(researcher1.primary_contact)\n+        self.assertEqual(researcher1.secondary_contact, contact2)\n+        self.assertEqual(researcher2.primary_contact, contact2)\n+        self.assertIsNone(researcher2.secondary_contact)\n+\n+    def test_delete_only_fetches_required_fields(self):\n+        \"\"\"\n+        A regression test for #29744.\n+\n+        This test checks that during a cascade delete, Django's ORM only\n+        fetches the primary key of related objects, not all of their fields.\n+        This is the correct, optimized behavior.\n+\n+        The test is designed to FAIL on the buggy codebase because the buggy\n+        code fetches extra fields. The test will PASS once the bug is fixed.\n+        \"\"\"\n+        child = Child.objects.create(name='test child')\n+        toy = Toy.objects.create(name='test toy')\n+        played = PlayedWith.objects.create(child=child, toy=toy, date=datetime.date.today())\n+        PlayedWithNote.objects.create(played=played, note='good note')\n+\n+        # Connect a signal handler to prevent the fast-delete path and ensure\n+        # the Collector is used, which is where the bug resides.\n+        def post_delete_handler(sender, **kwargs):\n+            pass\n+        models.signals.post_delete.connect(post_delete_handler, sender=PlayedWithNote)\n+\n+        try:\n+            with self.settings(DEBUG=True):\n+                connection.queries_log.clear()\n+                child.delete()\n+\n+                playedwithnote_select_sql = None\n+                playedwithnote_table = connection.ops.quote_name(PlayedWithNote._meta.db_table)\n+                for query in connection.queries:\n+                    # Find the query that collects related PlayedWithNote objects.\n+                    if query['sql'].startswith('SELECT') and playedwithnote_table in query['sql']:\n+                        playedwithnote_select_sql = query['sql']\n+                        break\n+\n+                self.assertIsNotNone(playedwithnote_select_sql, \"Collector's SELECT query for PlayedWithNote not found.\")\n+\n+                # This assertion defines the correct behavior. It will fail if\n+                # the bug is present because the unoptimized query will select\n+                # all columns, including the 'note' field.\n+                select_clause = playedwithnote_select_sql.split(' FROM ')[0]\n+                self.assertNotIn(\n+                    connection.ops.quote_name('note'),\n+                    select_clause,\n+                    \"The 'note' column was unnecessarily fetched during cascade delete.\"\n+                )\n+        finally:\n+            models.signals.post_delete.disconnect(post_delete_handler, sender=PlayedWithNote)\n"], "arch": "x86_64", "base_commit": "8180ffba21bf10f4be905cb0d4890dc2bcff2788", "test_directives": ["delete_regress.tests"], "coverage_files": ["django/db/models/deletion.py"], "env_name": "testbed", "run_id": "patch_evaluation", "patch_id": "pred_pre__Prometheus-Bug-Reproduction-Agent", "timeout": 1800, "rm_image": false, "force_rebuild": true, "exec_mode": "unit_test", "reproduction_script_name": null, "compute_coverage": true, "install": {"python": "3.6", "packages": "requirements.txt", "install": "python -m pip install -e .", "eval_commands": ["sed -i '/en_US.UTF-8/s/^# //g' /etc/locale.gen && locale-gen", "export LANG=en_US.UTF-8", "export LANGUAGE=en_US:en", "export LC_ALL=en_US.UTF-8"]}, "cache_level": "instance", "test_command": "python3 /root/trace.py --count -C coverage.cover --include-pattern '/testbed/(django/db/models/deletion\\.py)' ./tests/runtests.py --verbosity 2 --settings=test_sqlite --parallel 1 delete_regress.tests", "req_install_commands": ["conda create -n testbed python=3.6 -y", "cat <<'EOF_59812759871' > $HOME/requirements.txt\nasgiref ~= 3.2\nargon2-cffi >= 16.1.0\nbcrypt\ndocutils\ngeoip2\njinja2 >= 2.9.2\nnumpy\nPillow != 5.4.0\npylibmc; sys.platform != 'win32'\npython-memcached >= 1.59\npytz\npywatchman; sys.platform != 'win32'\nPyYAML\nselenium\nsqlparse >= 0.2.2\ntblib >= 1.5.0\n\nEOF_59812759871", "conda activate testbed && python -m pip install -r $HOME/requirements.txt", "rm $HOME/requirements.txt"]}